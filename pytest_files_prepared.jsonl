{"prompt":"class IncidentType\n\nclass IncidentTypeCount\n\nclass Incident\n\nclass Get\n\nclass GetList\n\nclass Resolve\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# -*- coding: utf-8 -*-\n\nimport unittest.mock\n\nimport pytest\n\nimport pycamunda.incident\nfrom tests.mock import raise_requests_exception_mock, not_ok_response_mock\n\n\ndef test_get_params(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n\n    assert get_incident.url == engine_url + '\/incident\/anId'\n    assert get_incident.query_parameters() == {}\n    assert get_incident.body_parameters() == {}\n\n\n@unittest.mock.patch('pycamunda.incident.Incident.load', unittest.mock.MagicMock())\n@unittest.mock.patch('requests.Session.request')\ndef test_get_calls_requests(mock, engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    get_incident()\n\n    assert mock.called\n    assert mock.call_args[1]['method'].upper() == 'GET'\n\n\n@unittest.mock.patch('requests.Session.request', raise_requests_exception_mock)\ndef test_get_raises_pycamunda_exception(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    with pytest.raises(pycamunda.PyCamundaException):\n        get_incident()\n\n\n@unittest.mock.patch('requests.Session.request', not_ok_response_mock)\n@unittest.mock.patch('pycamunda.incident.Incident', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.base._raise_for_status')\ndef test_get_raises_for_status(mock, engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    get_incident()\n\n    assert mock.called\n\n\n@unittest.mock.patch('requests.Session.request', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.base.from_isoformat', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.incident.IncidentType', unittest.mock.MagicMock())\ndef test_get_returns_incident(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    incident = get_incident()\n\n    assert isinstance(incident, pycamunda.incident.Incident)\n"}
{"prompt":"fn OrbitalPeriod(primary_mass, secondary_mass, semimajor_axis, gravitational_constant)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom engine.constants import G\nfrom pytest import param as p\n\nfrom .orbit_derived_parameters import OrbitalPeriod\n\n\n@pytest.mark.parametrize(\n    (\"primary_mass\", \"secondary_mass\", \"semimajor_axis\", \"expected\"),\n    [p(10e10, 100, 10, 76.9102, id=\"arbitrary period\")],\n)\ndef test_orbital_period(primary_mass, secondary_mass, semimajor_axis, expected):\n    assert OrbitalPeriod(\n        primary_mass, secondary_mass, semimajor_axis, G\n    ).evalf() == pytest.approx(expected, 1e-3)\n"}
{"prompt":"class User\n\nclass UserFactory\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom djcookie_demo_proj.users.models import User\nfrom djcookie_demo_proj.users.tests.factories import UserFactory\n\n\n@pytest.fixture(autouse=True)\ndef media_storage(settings, tmpdir):\n    settings.MEDIA_ROOT = tmpdir.strpath\n\n\n@pytest.fixture\ndef user() -> User:\n    return UserFactory()\n"}
{"prompt":"class MeshRouter\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom receptor.router import MeshRouter\n\ntest_networks = [\n    (\n        [\n            (\"a\", \"b\", 1),\n            (\"a\", \"d\", 1),\n            (\"a\", \"f\", 1),\n            (\"b\", \"d\", 1),\n            (\"b\", \"c\", 1),\n            (\"c\", \"e\", 1),\n            (\"c\", \"h\", 1),\n            (\"c\", \"j\", 1),\n            (\"e\", \"f\", 1),\n            (\"e\", \"g\", 1),\n            (\"e\", \"h\", 1),\n            (\"f\", \"g\", 1),\n            (\"g\", \"h\", 1),\n            (\"h\", \"j\", 1),\n            (\"h\", \"k\", 1),\n            (\"j\", \"k\", 1),\n            (\"j\", \"m\", 1),\n            (\"l\", \"m\", 1),\n        ],\n        [(\"a\", \"f\", \"f\"), (\"a\", \"m\", \"b\"), (\"h\", \"d\", \"c\")],\n        [(\"a\", {\"b\", \"d\", \"f\"}), (\"f\", {\"a\", \"e\", \"g\"}), (\"j\", {\"c\", \"h\", \"k\", \"m\"})],\n    ),\n    (\n        [(\"a\", \"b\", 1), (\"b\", \"c\", 1), (\"c\", \"d\", 1), (\"d\", \"e\", 1), (\"e\", \"f\", 1)],\n        [(\"a\", \"f\", \"b\"), (\"c\", \"a\", \"b\"), (\"f\", \"c\", \"e\")],\n        [(\"a\", {\"b\"}), (\"f\", {\"e\"}), (\"c\", {\"b\", \"d\"})],\n    ),\n]\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_next_hop(edges, expected_next_hops, expected_neighbors):\n    for node_id, remote, enh in expected_next_hops:\n        r = MeshRouter(node_id=node_id)\n        r.add_or_update_edges(edges)\n        assert r.next_hop(remote) == enh\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_neighbors(edges, expected_next_hops, expected_neighbors):\n    r = MeshRouter(node_id=edges[0][0])\n    r.add_or_update_edges(edges)\n    for node_id, neighbors in expected_neighbors:\n        assert r.get_neighbors(node_id) == neighbors\n"}
{"prompt":"class EnvironmentParseError\n\n\"\"\"Splits space-separated variable assignments into a list of individual assignments.\n\n>>> split_env_items('VAR=abc')\n['VAR=abc']\n>>> split_env_items('VAR=\"a string\" THING=3')\n['VAR=\"a string\"', 'THING=3']\n>>> split_env_items('VAR=\"a string\" THING=\\'single \"quotes\"\\'')\n['VAR=\"a string\"', 'THING=\\'single \"quotes\"\\'']\n>>> split_env_items('VAR=\"dont \\\\\"forget\\\\\" about backslashes\"')\n['VAR=\"dont \\\\\"forget\\\\\" about backslashes\"']\n>>> split_env_items('PATH=\"$PATH;\/opt\/cibw_test_path\"')\n['PATH=\"$PATH;\/opt\/cibw_test_path\"']\n>>> split_env_items('PATH2=\"something with spaces\"')\n['PATH2=\"something with spaces\"']\"\"\"\nfn split_env_items(env_string: str) -> List[str]\n\nclass EnvironmentAssignment\n\nclass ParsedEnvironment\n\nfn parse_environment(env_string: str) -> ParsedEnvironment\n\nclass DockerContainer\n\nfn shell_quote(path: PurePath) -> str\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import platform\nimport random\nimport shutil\nimport subprocess\nimport textwrap\nfrom pathlib import Path, PurePath\n\nimport pytest\n\nfrom cibuildwheel.docker_container import DockerContainer\nfrom cibuildwheel.environment import EnvironmentAssignment\n\n# for these tests we use manylinux2014 images, because they're available on\n# multi architectures and include python3.8\npm = platform.machine()\nif pm == \"x86_64\":\n    DEFAULT_IMAGE = \"quay.io\/pypa\/manylinux2014_x86_64:2020-05-17-2f8ac3b\"\nelif pm == \"aarch64\":\n    DEFAULT_IMAGE = \"quay.io\/pypa\/manylinux2014_aarch64:2020-05-17-2f8ac3b\"\nelif pm == \"ppc64le\":\n    DEFAULT_IMAGE = \"quay.io\/pypa\/manylinux2014_ppc64le:2020-05-17-2f8ac3b\"\nelif pm == \"s390x\":\n    DEFAULT_IMAGE = \"quay.io\/pypa\/manylinux2014_s390x:2020-05-17-2f8ac3b\"\n\n\n@pytest.mark.docker\ndef test_simple():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert container.call([\"echo\", \"hello\"], capture_output=True) == \"hello\\n\"\n\n\n@pytest.mark.docker\ndef test_no_lf():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert container.call([\"printf\", \"hello\"], capture_output=True) == \"hello\"\n\n\n@pytest.mark.docker\ndef test_environment():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert (\n            container.call(\n                [\"sh\", \"-c\", \"echo $TEST_VAR\"], env={\"TEST_VAR\": \"1\"}, capture_output=True\n            )\n            == \"1\\n\"\n        )\n\n\n@pytest.mark.docker\ndef test_cwd():\n    with DockerContainer(DEFAULT_IMAGE, cwd=\"\/cibuildwheel\/working_directory\") as container:\n        assert container.call([\"pwd\"], capture_output=True) == \"\/cibuildwheel\/working_directory\\n\"\n        assert container.call([\"pwd\"], capture_output=True, cwd=\"\/opt\") == \"\/opt\\n\"\n\n\n@pytest.mark.docker\ndef test_container_removed():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        docker_containers_listing = subprocess.run(\n            \"docker container ls\",\n            shell=True,\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        ).stdout\n        assert container.name in docker_containers_listing\n        old_container_name = container.name\n\n    docker_containers_listing = subprocess.run(\n        \"docker container ls\",\n        shell=True,\n        check=True,\n        stdout=subprocess.PIPE,\n        universal_newlines=True,\n    ).stdout\n    assert old_container_name not in docker_containers_listing\n\n\n@pytest.mark.docker\ndef test_large_environment():\n    # max environment variable size is 128kB\n    long_env_var_length = 127 * 1024\n    large_environment = {\n        \"a\": \"0\" * long_env_var_length,\n        \"b\": \"0\" * long_env_var_length,\n        \"c\": \"0\" * long_env_var_length,\n        \"d\": \"0\" * long_env_var_length,\n    }\n\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # check the length of d\n        assert (\n            container.call([\"sh\", \"-c\", \"echo ${#d}\"], env=large_environment, capture_output=True)\n            == f\"{long_env_var_length}\\n\"\n        )\n\n\n@pytest.mark.docker\ndef test_binary_output():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # note: the below embedded snippets are in python2\n\n        # check that we can pass though arbitrary binary data without erroring\n        container.call(\n            [\n                \"\/usr\/bin\/python2\",\n                \"-c\",\n                textwrap.dedent(\n                    \"\"\"\n                    import sys\n                    sys.stdout.write(''.join(chr(n) for n in range(0, 256)))\n                    \"\"\"\n                ),\n            ]\n        )\n\n        # check that we can capture arbitrary binary data\n        output = container.call(\n            [\n                \"\/usr\/bin\/python2\",\n                \"-c\",\n                textwrap.dedent(\n                    \"\"\"\n                    import sys\n                    sys.stdout.write(''.join(chr(n % 256) for n in range(0, 512)))\n                    \"\"\"\n                ),\n            ],\n            capture_output=True,\n        )\n\n        data = bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n        for i in range(512):\n            assert data[i] == i % 256\n\n        # check that environment variables can carry binary data, except null characters\n        # (https:\/\/www.gnu.org\/software\/libc\/manual\/html_node\/Environment-Variables.html)\n        binary_data = bytes(n for n in range(1, 256))\n        binary_data_string = str(binary_data, encoding=\"utf8\", errors=\"surrogateescape\")\n        output = container.call(\n            [\"python2\", \"-c\", 'import os, sys; sys.stdout.write(os.environ[\"TEST_VAR\"])'],\n            env={\"TEST_VAR\": binary_data_string},\n            capture_output=True,\n        )\n        assert output == binary_data_string\n\n\n@pytest.mark.docker\ndef test_file_operations(tmp_path: Path):\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # test copying a file in\n        test_binary_data = bytes(random.randrange(256) for _ in range(1000))\n        original_test_file = tmp_path \/ \"test.dat\"\n        original_test_file.write_bytes(test_binary_data)\n\n        dst_file = PurePath(\"\/tmp\/test.dat\")\n\n        container.copy_into(original_test_file, dst_file)\n\n        output = container.call([\"cat\", dst_file], capture_output=True)\n        assert test_binary_data == bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n\n@pytest.mark.docker\ndef test_dir_operations(tmp_path: Path):\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        test_binary_data = bytes(random.randrange(256) for _ in range(1000))\n        original_test_file = tmp_path \/ \"test.dat\"\n        original_test_file.write_bytes(test_binary_data)\n\n        # test copying a dir in\n        test_dir = tmp_path \/ \"test_dir\"\n        test_dir.mkdir()\n        test_file = test_dir \/ \"test.dat\"\n        shutil.copyfile(original_test_file, test_file)\n\n        dst_dir = PurePath(\"\/tmp\/test_dir\")\n        dst_file = dst_dir \/ \"test.dat\"\n        container.copy_into(test_dir, dst_dir)\n\n        output = container.call([\"cat\", dst_file], capture_output=True)\n        assert test_binary_data == bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n        # test glob\n        assert container.glob(dst_dir, \"*.dat\") == [dst_file]\n\n        # test copy dir out\n        new_test_dir = tmp_path \/ \"test_dir_new\"\n        container.copy_out(dst_dir, new_test_dir)\n\n        assert test_binary_data == (new_test_dir \/ \"test.dat\").read_bytes()\n\n\n@pytest.mark.docker\ndef test_environment_executor():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assignment = EnvironmentAssignment(\"TEST=$(echo 42)\")\n        assert assignment.evaluated_value({}, container.environment_executor) == \"42\"\n"}
{"prompt":"fn _vcr_integration_test(decorated)\n\nclass EngineOverrideConfigSource\n\nclass FallbackConfigSource\n\nclass IntegrationTestsV1\n\nclass IntegrationTestsV2\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"Integration tests for Glesys\"\"\"\nfrom unittest import TestCase\n\nimport pytest\nfrom lexicon.tests.providers.integration_tests import IntegrationTestsV1\n\n\n# Hook into testing framework by inheriting unittest.TestCase and reuse\n# the tests which *each and every* implementation of the interface must\n# pass, by inheritance from define_tests.TheTests\n# TODO: migrate to IntegrationTestsV2 and its extended test suite\nclass GlesysProviderTests(TestCase, IntegrationTestsV1):\n    \"\"\"TestCase for Glesys\"\"\"\n    provider_name = 'glesys'\n    domain = \"capsulecd.com\"\n\n    def _filter_headers(self):\n        return ['Authorization']\n\n    # TODO: enable the skipped tests\n    @pytest.mark.skip(reason=\"new test, missing recording\")\n    def test_provider_when_calling_update_record_should_modify_record_name_specified(self):\n        return\n"}
{"prompt":"fn create_future()\n\nfn unpartial(fn)\n\nfn _done_callback(fut, task)\n\nfn _cache_invalidate(wrapped, typed)\n\nfn _cache_clear(wrapped)\n\nfn _open(wrapped)\n\nfn _close(wrapped)\n\nfn _wait_closed(wrapped)\n\nfn _close_waited(wrapped, _)\n\nfn _cache_info(wrapped, maxsize)\n\nfn __cache_touch(wrapped, key)\n\nfn _cache_hit(wrapped, key)\n\nfn _cache_miss(wrapped, key)\n\nfn _get_loop(cls, kwargs, fn, fn_args, fn_kwargs)\n\nfn alru_cache(fn, maxsize, typed, expiration_time)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import asyncio\nimport time\n\nimport pytest\n\nfrom async_lru import alru_cache\n\npytestmark = pytest.mark.asyncio\n\n\nasync def test_expiration(check_lru, loop):\n    @alru_cache(maxsize=4, expiration_time=2, loop=loop)\n    async def coro(val):\n        return val\n\n    inputs = [1, 2, 3]\n    coros = [coro(v) for v in inputs]\n    ret = await asyncio.gather(*coros, loop=loop)\n    assert ret == inputs\n    check_lru(coro, hits=0, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(1)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(3)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=4, cache=3, tasks=0, maxsize=4)\n"}
{"prompt":"\"\"\"Perform string comparison with multiple levels of tolerance\n\nArgs:\n    word1: a string\n    word2: another string\n\nReturns:\n    a tuple with booleans specifying respectively whether the raw strings, their lower-case counterparts, their\n        unidecode counterparts and their lower-case unidecode counterparts match\"\"\"\nfn string_match(word1: str, word2: str) -> Tuple[(bool, bool, bool, bool)]\n\nclass TextMatch\n\n\"\"\"Compute the IoU between two sets of bounding boxes\n\nArgs:\n    boxes_1: bounding boxes of shape (N, 4) in format (xmin, ymin, xmax, ymax)\n    boxes_2: bounding boxes of shape (M, 4) in format (xmin, ymin, xmax, ymax)\nReturns:\n    the IoU matrix of shape (N, M)\"\"\"\nfn box_iou(boxes_1: np.ndarray, boxes_2: np.ndarray) -> np.ndarray\n\n\"\"\"Compute the IoA (intersection over area) between two sets of bounding boxes:\nioa(i, j) = inter(i, j) \/ area(i)\n\nArgs:\n    boxes_1: bounding boxes of shape (N, 4) in format (xmin, ymin, xmax, ymax)\n    boxes_2: bounding boxes of shape (M, 4) in format (xmin, ymin, xmax, ymax)\nReturns:\n    the IoA matrix of shape (N, M)\"\"\"\nfn box_ioa(boxes_1: np.ndarray, boxes_2: np.ndarray) -> np.ndarray\n\n\"\"\"Compute the IoU between two sets of boolean masks\n\nArgs:\n    masks_1: boolean masks of shape (N, H, W)\n    masks_2: boolean masks of shape (M, H, W)\n\nReturns:\n    the IoU matrix of shape (N, M)\"\"\"\nfn mask_iou(masks_1: np.ndarray, masks_2: np.ndarray) -> np.ndarray\n\n\"\"\"Convert boxes to masks\n\nArgs:\n    boxes: rotated bounding boxes of shape (N, 5) in format (x, y, w, h, alpha)\n    shape: spatial shapes of the output masks\n\nReturns:\n    the boolean masks of shape (N, H, W)\"\"\"\nfn rbox_to_mask(boxes: np.ndarray, shape: Tuple[(int, int)]) -> np.ndarray\n\n\"\"\"Perform non-max suppression, borrowed from <https:\/\/github.com\/rbgirshick\/fast-rcnn>`_.\n\nArgs:\n    boxes: np array of straight boxes: (*, 5), (xmin, ymin, xmax, ymax, score)\n    thresh: iou threshold to perform box suppression.\n\nReturns:\n    A list of box indexes to keep\"\"\"\nfn nms(boxes: np.ndarray, thresh: float) -> List[int]\n\nclass LocalizationConfusion\n\nclass OCRMetric\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright (C) 2021, Mindee.\n\n# This program is licensed under the Apache License version 2.\n# See LICENSE or go to <https:\/\/www.apache.org\/licenses\/LICENSE-2.0.txt> for full license details.\n\nimport pytest\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\nfrom doctr.utils.metrics import box_iou\n\n\n@pytest.mark.asyncio\nasync def test_text_detection(test_app_asyncio, mock_detection_image):\n\n    response = await test_app_asyncio.post(\"\/detection\", files={'file': mock_detection_image})\n    assert response.status_code == 200\n    json_response = response.json()\n\n    gt_boxes = np.array([[1240, 430, 1355, 470], [1360, 430, 1495, 470]], dtype=np.float32)\n    gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] \/ 1654\n    gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] \/ 2339\n\n    # Check that IoU with GT if reasonable\n    assert isinstance(json_response, list) and len(json_response) == gt_boxes.shape[0]\n    pred_boxes = np.array([elt['box'] for elt in json_response])\n    iou_mat = box_iou(gt_boxes, pred_boxes)\n    gt_idxs, pred_idxs = linear_sum_assignment(-iou_mat)\n    is_kept = iou_mat[gt_idxs, pred_idxs] >= 0.8\n    assert gt_idxs[is_kept].shape[0] == gt_boxes.shape[0]\n"}
{"prompt":"fn Error()\n\nclass TestError\n\nfn Boolean()\n\nclass TestBoolean\n\nfn Missing()\n\nclass TestMissing\n\nfn Number()\n\nclass TestNumber\n\nfn Text()\n\nclass TestText\n\nfn Index()\n\nclass TestIndex\n\nfn DateTimeField()\n\nclass TestDateTimeField\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright (c) 2010-2019 openpyxl\nimport pytest\n\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nfrom openpyxl.packaging.manifest import Manifest\nfrom openpyxl.xml.functions import fromstring, tostring\nfrom openpyxl.tests.helper import compare_xml\n\nfrom .test_fields import (\n    Index,\n    Number,\n    Text,\n)\n\n@pytest.fixture\ndef Record():\n    from ..record import Record\n    return Record\n\n\nclass TestRecord:\n\n    def test_ctor(self, Record, Number, Text, Index):\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = n + s + x\n        field = Record(_fields=fields)\n        xml = tostring(field.to_tree())\n        expected = \"\"\"\n        <r>\n          <n v=\"1\"\/>\n          <n v=\"25\"\/>\n          <s v=\"2014-03-24\"\/>\n          <x v=\"0\"\/>\n          <x v=\"0\"\/>\n          <x v=\"0\"\/>\n        <\/r>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Record, Number, Text, Index):\n        src = \"\"\"\n        <r>\n          <n v=\"1\"\/>\n          <x v=\"0\"\/>\n          <s v=\"2014-03-24\"\/>\n          <x v=\"0\"\/>\n          <n v=\"25\"\/>\n          <x v=\"0\"\/>\n        <\/r>\n        \"\"\"\n        node = fromstring(src)\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = [\n            Number(v=1),\n            Index(),\n            Text(v=\"2014-03-24\"),\n            Index(),\n            Number(v=25),\n            Index(),\n        ]\n        field = Record.from_tree(node)\n        assert field == Record(_fields=fields)\n\n\n@pytest.fixture\ndef RecordList():\n    from ..record import RecordList\n    return RecordList\n\n\nclass TestRecordList:\n\n    def test_ctor(self, RecordList):\n        cache = RecordList()\n        xml = tostring(cache.to_tree())\n        expected = \"\"\"\n        <pivotCacheRecords xmlns=\"http:\/\/schemas.openxmlformats.org\/spreadsheetml\/2006\/main\"\n           count=\"0\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, RecordList):\n        src = \"\"\"\n        <pivotCacheRecords count=\"0\" \/>\n        \"\"\"\n        node = fromstring(src)\n        cache = RecordList.from_tree(node)\n        assert cache == RecordList()\n\n\n    def test_write(self, RecordList):\n        out = BytesIO()\n        archive = ZipFile(out, mode=\"w\")\n        manifest = Manifest()\n\n        records = RecordList()\n        xml = tostring(records.to_tree())\n        records._write(archive, manifest)\n        manifest.append(records)\n\n        assert archive.namelist() == [records.path[1:]]\n        assert manifest.find(records.mime_type)\n"}
{"prompt":"fn _generate_path_reserved_chars()\n\nfn _contains_quoted_reserved_chars(x)\n\n\"\"\"Normalize the href to be a path only relative to hostname and\nschema.\"\"\"\nfn _normalize_href(base, href)\n\nclass InvalidXMLResponse\n\nfn _clean_body(content, bad_chars)\n\nfn _parse_xml(content)\n\nfn _merge_xml(items)\n\nfn _fuzzy_matches_mimetype(strict, weak)\n\nclass Discover\n\nclass CalDiscover\n\nclass CardDiscover\n\nclass DAVSession\n\nclass DAVStorage\n\nclass CalDAVStorage\n\nclass CardDAVStorage\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom vdirsyncer.storage.dav import _BAD_XML_CHARS\nfrom vdirsyncer.storage.dav import _merge_xml\nfrom vdirsyncer.storage.dav import _parse_xml\n\n\ndef test_xml_utilities():\n    x = _parse_xml(\n        b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n        <multistatus xmlns=\"DAV:\">\n            <response>\n                <propstat>\n                    <status>HTTP\/1.1 404 Not Found<\/status>\n                    <prop>\n                        <getcontenttype\/>\n                    <\/prop>\n                <\/propstat>\n                <propstat>\n                    <prop>\n                        <resourcetype>\n                            <collection\/>\n                        <\/resourcetype>\n                    <\/prop>\n                <\/propstat>\n            <\/response>\n        <\/multistatus>\n    \"\"\"\n    )\n\n    response = x.find(\"{DAV:}response\")\n    props = _merge_xml(response.findall(\"{DAV:}propstat\/{DAV:}prop\"))\n    assert props.find(\"{DAV:}resourcetype\/{DAV:}collection\") is not None\n    assert props.find(\"{DAV:}getcontenttype\") is not None\n\n\n@pytest.mark.parametrize(\"char\", range(32))\ndef test_xml_specialchars(char):\n    x = _parse_xml(\n        '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'\n        \"<foo>ye{}s\\r\\n\"\n        \"hello<\/foo>\".format(chr(char)).encode(\"ascii\")\n    )\n\n    if char in _BAD_XML_CHARS:\n        assert x.text == \"yes\\nhello\"\n"}
{"prompt":"class ArbitraryAccessObj\n\nclass Mock\n\nclass ObjectIdHashComparator\n\nclass SubtypesInstanceManager\n\n\"\"\"Recursively get all subclasses of the given class.\"\"\"\nfn get_all_subclasses(clazz: Type) -> Set[Type]\n\nfn fully_qualified_class_name(klass: Type) -> str\n\n\"\"\"Return 'value' if it is not None, or 'alternative' otherwise.\"\"\"\nfn not_none_or(value: Optional[Any], alternative: Any) -> Any\n\n\"\"\"Recursively apply `func` to `obj` (might be a list, dict, or other object).\"\"\"\nfn recurse_object(obj: ComplexType, func: Callable, path: str) -> ComplexType\n\n\"\"\"Recursively changes all dict keys to first character lowercase. Skip children\nof any elements whose names are contained in skip_children_of (e.g., ['Tags'])\"\"\"\nfn keys_to_lower(obj: ComplexType, skip_children_of: List[str]) -> ComplexType\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom localstack.utils.objects import SubtypesInstanceManager\n\n\ndef test_subtypes_instance_manager():\n    class BaseClass(SubtypesInstanceManager):\n        def foo(self):\n            pass\n\n    class C1(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c1\"\n\n        def foo(self):\n            return \"bar\"\n\n    instance1 = BaseClass.get(\"c1\")\n    assert instance1\n    assert BaseClass.get(\"c1\") == instance1\n    assert instance1.foo() == \"bar\"\n    with pytest.raises(Exception):\n        assert BaseClass.get(\"c2\")\n\n    class C2(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c2\"\n\n        def foo(self):\n            return \"baz\"\n\n    instance2 = BaseClass.get(\"c2\")\n    assert BaseClass.get(\"c2\") == instance2\n    assert instance2.foo() == \"baz\"\n"}
{"prompt":"fn T(x)\n\nclass FakeCalendar\n\nclass TestCalendarRegistration\n\n\"\"\"Test dispatcher and calendar default values.\"\"\"\nfn test_default_calendars()\n\nfn test_days_at_time(day, day_offset, time_offset, tz, expected)\n\n\"\"\"Get csv file as DataFrame for given calendar `name`.\"\"\"\nfn get_csv(name: str) -> pd.DataFrame\n\nclass Answers\n\n\"\"\"Wrap a method under test so that it skips input parsing.\"\"\"\nfn no_parsing(f: typing.Callable)\n\nclass ExchangeCalendarTestBase\n\nclass EuronextCalendarTestBase\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom exchange_calendars.exchange_calendar_xshg import XSHGExchangeCalendar\nfrom .test_exchange_calendar import ExchangeCalendarTestBase\nfrom .test_utils import T\n\n\nclass TestXSHGCalendar(ExchangeCalendarTestBase):\n    @pytest.fixture(scope=\"class\")\n    def calendar_cls(self):\n        yield XSHGExchangeCalendar\n\n    @pytest.fixture\n    def max_session_hours(self):\n        # Shanghai stock exchange is open from 9:30 am to 3pm\n        yield 5.5\n\n    @pytest.fixture\n    def start_bound(self):\n        yield T(\"1999-01-01\")\n\n    @pytest.fixture\n    def end_bound(self):\n        yield T(\"2025-12-31\")\n\n    @pytest.fixture\n    def regular_holidays_sample(self):\n        yield [\n            # 2017\n            \"2017-01-02\",\n            \"2017-01-27\",\n            \"2017-01-30\",\n            \"2017-01-31\",\n            \"2017-02-01\",\n            \"2017-02-02\",\n            \"2017-04-03\",\n            \"2017-04-04\",\n            \"2017-05-01\",\n            \"2017-05-29\",\n            \"2017-05-30\",\n            \"2017-10-02\",\n            \"2017-10-03\",\n            \"2017-10-04\",\n            \"2017-10-05\",\n            \"2017-10-06\",\n\n            # 2020\n            \"2020-01-31\"\n        ]\n"}
{"prompt":"class MeasureIterator\n\nclass Measure\n\nclass PartIterator\n\nclass Part\n\nclass BeatIterator\n\nclass Beat\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\r\n\r\nfrom MidiCompose.logic.rhythm.beat import Beat\r\nfrom MidiCompose.logic.rhythm.measure import Measure\r\nfrom MidiCompose.logic.rhythm.part import Part\r\n\r\n@pytest.fixture\r\ndef part_1():\r\n\r\n    m1 = Measure([Beat([1,2,1,2]),\r\n                  Beat([1,0,0,1])])\r\n    m2 = Measure([Beat([2,2,1,1]),\r\n                  Beat([2,2,2,2])])\r\n\r\n    part = Part([m1,m2])\r\n\r\n    return part\r\n\r\ndef test_empty_constructor():\r\n    p = Part()\r\n    assert p.n_measures == 1\r\n    assert p.n_beats == 1\r\n    assert p.n_note_on == 0\r\n\r\ndef test_n_note_on(part_1):\r\n\r\n    assert part_1.n_note_on == 6\r\n\r\n\r\ndef test_iterator(part_1):\r\n    for m in part_1:\r\n        assert type(m) == Measure\r\n\r\n\r\n\r\n"}
{"prompt":"class User\n\nclass UserChangeForm\n\nclass UserCreationForm\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom my_blog.users.forms import UserCreationForm\nfrom my_blog.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"}
{"prompt":"\"\"\"Take a list of structures and write them to a json file.\n:param filename:\n:param structures:\"\"\"\nfn md_trajectory_to_file(filename: str, structures: List[Structure])\n\n\"\"\"Read a list of structures from a json file, formatted as in md_trajectory_to_file.\n:param filename:\"\"\"\nfn md_trajectory_from_file(filename: str)\n\nclass Structure\n\nclass StructureSource\n\nclass ForceSource\n\nclass Trajectory\n\n\"\"\"Returns a list of the unique species passed in, and a list of\nintegers indexing them.\n\n:param species: Species to index uniquely\n:return: List of the unique species, and integer indexes\"\"\"\nfn get_unique_species(species: List[Any]) -> (List, List[int])\n\n\"\"\"Helper utility to take a vasprun file name or Vasprun object\nand return a vasprun object.\n:param vasprun: Vasprun filename or object\"\"\"\nfn check_vasprun(vasprun: None, vasprun_kwargs: dict)\n\n\"\"\"Returns the positions, species, and cell of a POSCAR file.\nOutputs are specced for OTF module.\n\n:param input: POSCAR file input\n:return:\"\"\"\nfn parse_dft_input(input: str)\n\n\"\"\"Run a VASP calculation.\n:param calc_dir: Name of directory to perform calculation in\n:param dft_loc: Name of VASP command (i.e. executable location)\n:param structure: flare structure object\n:param en: whether to return the final energy along with the forces\n:param vasp_cmd: Command to run VASP (leave a formatter \"{}\" to insert dft_loc);\n    this can be used to specify mpirun, srun, etc.\nReturns:\n    forces on each atom (and energy if en=True)\"\"\"\nfn run_dft(calc_dir: str, dft_loc: str, structure: Structure, en: bool, vasp_cmd: None)\n\nfn run_dft_par(dft_input: str, structure: Structure, dft_command: str, n_cpus, dft_out, parallel_prefix, mpi, npool, screen_out)\n\n\"\"\"Parse the DFT input in a directory.\n:param vasp_input: directory of vasp input\"\"\"\nfn dft_input_to_structure(poscar: str)\n\n\"\"\"Writes a VASP POSCAR file from structure with the name poscar .\nWARNING: Destructively replaces the file with the name specified by poscar\n:param poscar: Name of file\n:param structure: structure to write to file\"\"\"\nfn edit_dft_input_positions(output_name: str, structure: Structure)\n\n\"\"\"Parses the DFT forces from the last ionic step of a VASP vasprun.xml file\n:param vasprun: pymatgen Vasprun object or vasprun filename\"\"\"\nfn parse_dft_forces(vasprun: None)\n\n\"\"\"Parses the DFT forces and energy from a VASP vasprun.xml file\n:param vasprun: pymatgen Vasprun object or vasprun filename\"\"\"\nfn parse_dft_forces_and_energy(vasprun: None)\n\n\"\"\"Returns a list of flare Structure objects decorated with forces, stress,\nand total energy from a MD trajectory performed in VASP.\n:param vasprun: pymatgen Vasprun object or vasprun filename\n:param ionic_step_skips: if True, only samples the configuration every\n    ionic_skip_steps steps.\"\"\"\nfn md_trajectory_from_vasprun(vasprun: None, ionic_step_skips: None, vasprun_kwargs: dict)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\npmgout = pytest.importorskip(\"pymatgen.io.vasp.outputs\")\nVasprun = pmgout.Vasprun\nimport os\nimport numpy as np\nfrom flare.struc import Structure, get_unique_species\nfrom flare.dft_interface.vasp_util import md_trajectory_from_vasprun\nfrom flare.utils.flare_io import md_trajectory_to_file, md_trajectory_from_file\n\npytestmark = pytest.mark.filterwarnings(\n    \"ignore::UserWarning\", \"ignore::pymatgen.io.vasp.outputs.UnconvergedVASPWarning\"\n)\n\n\ndef test_read_write_trajectory():\n    structures = md_trajectory_from_vasprun(\"test_files\/test_vasprun.xml\")\n    fname = \"tst_traj.json\"\n    md_trajectory_to_file(fname, structures)\n    fstructures = md_trajectory_from_file(fname)\n    for s, f in zip(structures, fstructures):\n        assert np.isclose(s.forces, f.forces).all()\n        assert np.isclose(s.positions, f.positions).all()\n    os.system(\"rm tst_traj.json\")\n"}
{"prompt":"fn getClient(name: str) -> GirderClient\n\nfn getTestFolder(client: GirderClient)\n\nfn admin_client() -> GirderClient\n\n\"\"\"Wait for all worker jobs to complete\"\"\"\nfn wait_for_jobs(client: GirderClient, max_wait_timeout, expected_status)\n\nfn match_user_server_data(user: Dict[(str, Any)], dataset) -> List[dict]\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import json\n\nfrom girder.constants import AccessType\nfrom girder_client import HttpError\nimport pytest\n\nfrom .conftest import getClient, getTestFolder, localDataRoot, users, wait_for_jobs\n\n\n@pytest.mark.integration\n@pytest.mark.parametrize(\"user\", users.values())\n@pytest.mark.run(order=3)\ndef test_reset_integration_env(user: dict):\n    client = getClient(user['login'])\n    privateFolder = getTestFolder(client)\n    client.delete(f\"folder\/{privateFolder['_id']}\")\n\n\n@pytest.mark.integration\n@pytest.mark.parametrize(\"user\", users.values())\n@pytest.mark.run(order=4)\ndef test_upload_user_data(user: dict):\n    client = getClient(user['login'])\n    createdDatasets = []\n    for dataset in user['data']:\n        dsPath = localDataRoot \/ str(dataset['path'])\n        privateFolder = getTestFolder(client)\n        newDatasetFolder = client.createFolder(\n            privateFolder['_id'],\n            dataset['name'],\n            metadata={\n                'fps': dataset['fps'],\n                'type': dataset['type'],\n            },\n        )\n        createdDatasets.append(newDatasetFolder)\n        # Validate the fileset\n        filenames = [file.name for file in dsPath.iterdir()]\n        valid = client.post('dive_dataset\/validate_files', json=filenames)\n        assert valid['ok'], 'File validation failed'\n        for file in dsPath.iterdir():\n            if file.is_file():\n                client.uploadFileToFolder(newDatasetFolder['_id'], str(file))\n        client.post(f'dive_rpc\/postprocess\/{newDatasetFolder[\"_id\"]}')\n        if dataset.get('sharedWith', False):\n            me = client.get('user\/me')\n            otherClient = getClient(dataset['sharedWith'])\n            otherUser = otherClient.get('user\/me')\n            with pytest.raises(HttpError):\n                otherClient.get(f'dive_dataset\/{newDatasetFolder[\"_id\"]}')\n            client.put(\n                f'folder\/{newDatasetFolder[\"_id\"]}\/access',\n                data={\n                    'public': False,\n                    'recurse': False,\n                    'progress': False,\n                    'access': json.dumps(\n                        {\n                            'users': [\n                                {'id': me['_id'], 'level': AccessType.ADMIN, 'flags': []},\n                                {'id': otherUser['_id'], 'level': AccessType.READ, 'flags': []},\n                            ],\n                            'groups': [],\n                        }\n                    ),\n                },\n            )\n            assert (\n                otherClient.get(\n                    f'dive_dataset\/{newDatasetFolder[\"_id\"]}', jsonResp=False\n                ).status_code\n                == 200\n            )\n\n    wait_for_jobs(client)\n    # Confirm that the new dataset looks like it should.\n    for created, expected in zip(createdDatasets, user['data']):\n        created = client.get(f'dive_dataset\/{created[\"_id\"]}')\n        if expected['type'] == 'video':\n            assert created['fps'] == expected['originalFps'] or created['fps'] == expected['fps']\n            assert created['annotate']\n            assert created['originalFps'] == expected['originalFps']\n"}
{"prompt":"\"\"\"Get list of file names from latest n ICESat-2 cycles\n\nParameters\n----------\nfiles : list\n    A list of file names.\ncycles: list\n    A list of available ICESat-2 cycles\nn: int, default 1\n    Number of latest ICESat-2 cycles to pick\n\nReturns\n-------\nviz_file_list : list\n    A list of file names from latest n ICESat-2 cycles\"\"\"\nfn files_in_latest_n_cycles(files: list, cycles: list, n: int, default 1) -> list\n\n\"\"\"Returns a list of granule information for file name string.\n\nParameters\n----------\nfilename: String\n    ICESat-2 file name\n\nReturns\n-------\ngran_paras_list : list\n    A list of parameters including RGT, cycle, and datetime of ICESat-2 data granule\"\"\"\nfn gran_paras(filename: String) -> list\n\n\"\"\"Check if user wants to proceed visualization when the API request number exceeds 200\n\nParameters\n----------\nmessage : string\n    Message to indicate users the options\"\"\"\nfn user_check(message: string)\n\nclass Visualize\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom icepyx.core.visualization import Visualize\nimport icepyx.core.visualization as vis\n\n\n@pytest.mark.parametrize(\n    \"n, exp\",\n    [\n        (\n            1,\n            [\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n        (\n            2,\n            [\n                \"ATL06_20200612151119_11920712_004_01.h5\",\n                \"ATL06_20200616021517_12450710_004_01.h5\",\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n        (\n            3,\n            [\n                \"ATL06_20200612151119_11920712_004_01.h5\",\n                \"ATL06_20200616021517_12450710_004_01.h5\",\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n    ],\n)\ndef test_files_in_latest_cycles(n, exp):\n    files = [\n        \"ATL06_20190710071617_01860412_004_01.h5\",\n        \"ATL06_20190713182016_02390410_004_01.h5\",\n        \"ATL06_20200612151119_11920712_004_01.h5\",\n        \"ATL06_20200616021517_12450710_004_01.h5\",\n        \"ATL06_20200702014158_01020810_004_01.h5\",\n        \"ATL06_20200703011618_01170810_004_01.h5\",\n    ]\n    cycles = [8, 7, 4]\n    obs = vis.files_in_latest_n_cycles(files, cycles=cycles, n=n)\n    assert obs == exp\n\n\n@pytest.mark.parametrize(\n    \"filename, expect\",\n    [\n        ('ATL06_20190525202604_08790310_004_01.h5', [879, 3, '2019-05-25']),\n        ('ATL06_20190614194425_11840310_004_01.h5', [1184, 3, '2019-06-14']),\n        ('ATL07-02_20190624063616_13290301_004_01.h5', [1329, 3, '2019-06-24']),\n        ('ATL07-02_20190602190916_10010301_004_01.h5', [1001, 3, '2019-06-02']),\n        ('ATL10-02_20190611072656_11310301_004_01.h5', [1131, 3, '2019-06-11']),\n        ('ATL10-02_20190731045538_05060401_004_01.h5', [506, 4, '2019-07-31']),\n        ('ATL12_20190615023544_11890301_004_01.h5', [1189, 3, '2019-06-15']),\n        ('ATL12_20190721170332_03610401_004_01.h5', [361, 4, '2019-07-21']),\n    ],\n)\ndef test_gran_paras(filename, expect):\n\n    para_list = vis.gran_paras(filename)\n\n    assert para_list == expect\n\n\n@pytest.mark.parametrize(\n    \"product, date_range, bbox, expect\",\n    [\n        (\"ATL06\", [\"2019-6-15\", \"2019-7-1\"], [-64.5, -66, -63.5, -65], 3240),\n        (\"ATL07\", [\"2019-7-1\", \"2019-8-1\"], [-65, -66, -64.5, -65], 7160),\n        (\"ATL08\", [\"2019-6-15\", \"2019-7-1\"], [-18, 63, -17, 64], 852),\n        (\"ATL10\", [\"2019-8-1\", \"2019-9-1\"], [-64, -67, -60, -60], 7375),\n        (\"ATL12\", [\"2019-7-1\", \"2019-10-1\"], [-65.5, -65.5, -64.5, -65], 95),\n        (\"ATL13\", [\"2019-6-1\", \"2019-12-1\"], [-75, -51, -74, -50], 20),\n    ],\n)\ndef test_visualization_date_range(product, date_range, bbox, expect):\n\n    region_viz = Visualize(product=product, spatial_extent=bbox, date_range=date_range)\n    data_size = region_viz.parallel_request_OA().size\n\n    assert data_size == expect\n\n\n@pytest.mark.parametrize(\n    \"product, bbox, cycles, tracks, expect\",\n    [\n        (\"ATL06\", [-64.5, -66, -63.5, -65], [\"03\"], [\"1306\"], 3240),\n        (\"ATL07\", [-65, -66, -64.5, -65], [\"04\"], [\"0186\"], 7130),\n        (\"ATL08\", [-18, 63, -17, 64], [\"03\"], [\"1320\"], 852),\n        (\"ATL10\", [-64, -67, -60, -60], [\"04\"], [\"0681\"], 6015),\n        (\"ATL12\", [-65.5, -65.5, -64.5, -65], [\"05\"], [\"0041\"], 95),\n        (\"ATL13\", [-75, -51, -74, -50], [\"05\"], [\"0293\"], 20),\n    ],\n)\ndef test_visualization_orbits(product, bbox, cycles, tracks, expect):\n\n    region_viz = Visualize(\n        product=product, spatial_extent=bbox, cycles=cycles, tracks=tracks\n    )\n    data_size = region_viz.parallel_request_OA().size\n\n    assert data_size == expect\n"}
{"prompt":"class PostgreSQLConnection\n\nclass PostgreSQLTransaction\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom migri.backends.postgresql import PostgreSQLConnection\nfrom test import QUERIES\n\n\n@pytest.mark.parametrize(\n    \"query_element,expected_query,expected_values\",\n    [\n        (QUERIES[0], \"INSERT INTO mytable (a) VALUES ($1), ($2)\", [150, 300]),\n        (QUERIES[1], \"UPDATE tbl SET info=$2 WHERE id=$1\", [39, \"ok\"]),\n        (QUERIES[2], \"SELECT * FROM school\", []),\n        (\n            QUERIES[3],\n            \"SELECT * FROM val WHERE (value < $1 AND status = $3) \"\n            \"OR (value > $2 AND status = $3)\",\n            [20, 100, \"ok\"],\n        ),\n    ],\n)\ndef test_compile(query_element, expected_query, expected_values):\n    backend = PostgreSQLConnection(\"postgres\")\n    assert backend._compile(query_element) == {\n        \"query\": expected_query,\n        \"values\": expected_values,\n    }\n"}
{"prompt":"fn add_custom_commands()\n\nfn add_method(cls)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"Pytest plugin entry point. Used for any fixtures needed.\"\"\"\nimport pytest\nfrom .pytest_selenium_enhancer import add_custom_commands\n\n\n@pytest.fixture(scope='session')\ndef selenium_patcher():\n    \"\"\"Add custom .\"\"\"\n    add_custom_commands()\n"}
{"prompt":"class State\n\nclass EigerStatus\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom tickit.devices.eiger.eiger_status import EigerStatus\n\n# # # # # EigerStatus Tests # # # # #\n\n\n@pytest.fixture\ndef eiger_status() -> EigerStatus:\n    return EigerStatus()\n\n\ndef test_eiger_status_constructor():\n    EigerStatus()\n\n\ndef test_eiger_status_getitem(eiger_status):\n    assert 24.5 == eiger_status[\"th0_temp\"]\n"}
{"prompt":"class LinearReward\n\nclass ExpReward\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nimport sinergym.utils.rewards as R\n\n\n@pytest.mark.parametrize(\n    'power,temperatures,month,day,reward,reward_energy,reward_comfort',\n    [\n        # Input 1\n        (\n            186.5929171535975,\n            [22.16742570092868],\n            3,\n            31,\n            -0.009329645857679876,\n            -0.018659291715359752,\n            -0.0\n        ),\n        # Input 2\n        (\n            688.0477550424935,\n            [26.7881162590194],\n            3,\n            30,\n            -1.6784605172618248,\n            -0.06880477550424935,\n            -3.2881162590194\n        ),\n        # Input 3\n        (\n            23168.30752221127,\n            [20.37505026953311],\n            2,\n            25,\n            -1.1584153761105636,\n            -2.316830752221127,\n            -0.0\n        ),\n    ]\n)\ndef test_calculate(\n        simple_reward,\n        power,\n        temperatures,\n        month,\n        day,\n        reward,\n        reward_energy,\n        reward_comfort):\n    result = simple_reward.calculate(power, temperatures, month, day)\n    assert result[0] == reward\n    assert result[1]['reward_energy'] == reward_energy\n    assert result[1]['reward_comfort'] == reward_comfort\n"}
{"prompt":"\"\"\"    \"\"\"\nfn verify_all(module, ALL)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nimport pytest ; pytest\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Standard library imports\n\n# External imports\n\n# Bokeh imports\nfrom bokeh._testing.util.api import verify_all\n\n# Module under test\n#import bokeh.sampledata.glucose as bsg\n\n#-----------------------------------------------------------------------------\n# Setup\n#-----------------------------------------------------------------------------\n\nALL = (\n    'data',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\nTest___all__ = pytest.mark.sampledata(verify_all(\"bokeh.sampledata.glucose\", ALL))\n\n@pytest.mark.sampledata\ndef test_data(pd):\n    import bokeh.sampledata.glucose as bsg\n    assert isinstance(bsg.data, pd.DataFrame)\n\n    # don't check detail for external data\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n"}
{"prompt":"class LabelCalibrator\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"#  Copyright 2021 ZBW  – Leibniz Information Centre for Economics\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n\nimport numpy as np\nimport pytest\nfrom sklearn.exceptions import NotFittedError\nfrom stwfsapy.text_features import mk_text_features\n\nfrom qualle.label_calibration.simple import LabelCalibrator\nfrom tests.common import DummyRegressor\n\n\n@pytest.fixture\ndef calibrator():\n    return LabelCalibrator(DummyRegressor())\n\n\ndef test_lc_predict(calibrator, X):\n    calibrator.fit(X, [3, 5])\n    assert np.array_equal(calibrator.predict(X), [0, 1])\n\n\ndef test_lc_predict_without_fit_raises_exc(calibrator, X):\n    with pytest.raises(NotFittedError):\n        calibrator.predict(X)\n\n\ndef test_lc_fit_fits_regressor_with_txt_features(calibrator, X, mocker):\n    y = [3, 5]\n    txt_features = mk_text_features().fit(X)\n    X_transformed = txt_features.transform(X)\n\n    spy = mocker.spy(calibrator.regressor, 'fit')\n    calibrator.fit(X, y)\n    spy.assert_called_once()\n    assert (spy.call_args[0][0].toarray() == X_transformed.toarray()).all()\n    assert spy.call_args[0][1] == y\n"}
{"prompt":"class Backend\n\nclass NumpyBackend\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nimport numpy as np\nimport random\n\nfrom cem.backend import backend, NumpyBackend\n\ntry:\n    from cem.backend import CuPyBackend\n    import cupy as cp\n    skip_cupy_test = False\nexcept ImportError:\n    skip_cupy_test = True\n\n\ndef test_numpy_backend():\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, NumpyBackend)\n    assert isinstance(zeros, np.ndarray)\n    assert isinstance(ones, np.ndarray)\n    assert backend.int == np.int64\n    assert backend.float == np.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).any() == np.sin(ones).any()\n    assert backend.cos(ones).any() == np.cos(ones).any()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_cupy_backend():\n    backend.set_backend('cupy')\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, CuPyBackend)\n    assert isinstance(zeros, cp.ndarray)\n    assert isinstance(ones, cp.ndarray)\n    assert backend.int == cp.int64\n    assert backend.float == cp.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).all() == cp.sin(ones).all()\n    assert backend.cos(ones).all() == cp.cos(ones).all()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_set_backend():\n    backend.set_backend('numpy')\n    assert isinstance(backend, NumpyBackend)\n    backend.set_backend('cupy')\n    assert isinstance(backend, CuPyBackend)\n"}
{"prompt":"class Bigchain\n\nclass BigchainDBError\n\nclass CriticalDoubleSpend\n\nclass CriticalDoubleInclusion\n\nclass CriticalDuplicateVote\n\nclass Voting\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom unittest.mock import patch\nfrom collections import Counter\n\nfrom bigchaindb.core import Bigchain\nfrom bigchaindb.exceptions import CriticalDuplicateVote\nfrom bigchaindb.voting import Voting, INVALID, VALID, UNDECIDED\n\n\n################################################################################\n# Tests for checking vote eligibility\n\n\ndef test_partition_eligible_votes():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            if vote['node_pubkey'] == 'invalid sig':\n                return False\n            if vote['node_pubkey'] == 'value error':\n                raise ValueError()\n            return True\n\n    voters = ['valid', 'invalid sig', 'value error', 'not in set']\n    votes = [{'node_pubkey': k} for k in voters]\n\n    el, inel = TestVoting.partition_eligible_votes(votes, voters[:-1])\n    assert el == [votes[0]]\n    assert inel == votes[1:]\n\n\n################################################################################\n# Test vote counting\n\n\ndef test_count_votes():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return vote['node_pubkey'] != 'malformed'\n\n    voters = (['says invalid', 'malformed'] +\n              ['kosher' + str(i) for i in range(10)])\n\n    votes = [Bigchain(v).vote('block', 'a', True) for v in voters]\n    votes[0]['vote']['is_block_valid'] = False\n    # Incorrect previous block subtracts from n_valid and adds to n_invalid\n    votes[-1]['vote']['previous_block'] = 'z'\n\n    by_voter = dict(enumerate(votes))\n\n    assert TestVoting.count_votes(by_voter) == {\n        'counts': {\n            'n_valid': 9,    # 9 kosher votes\n            'n_invalid': 3,  # 1 invalid, 1 malformed, 1 rogue prev block\n        },\n        'malformed': [votes[1]],\n        'previous_block': 'a',\n        'other_previous_block': {'z': 1},\n    }\n\n\ndef test_must_agree_prev_block():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return True\n\n    voters = 'abcd'\n    votes = [Bigchain(v).vote('block', 'a', True) for v in voters]\n    votes[0]['vote']['previous_block'] = 'b'\n    votes[1]['vote']['previous_block'] = 'c'\n    by_voter = dict(enumerate(votes))\n    assert TestVoting.count_votes(by_voter) == {\n        'counts': {\n            'n_valid': 2,\n            'n_invalid': 2,\n        },\n        'previous_block': 'a',\n        'other_previous_block': {'b': 1, 'c': 1},\n        'malformed': [],\n    }\n\n\n################################################################################\n# Tests for vote decision making\n\n\nDECISION_TESTS = [\n    {'n_voters': 1, 'n_valid': 1, 'n_invalid': 1},\n    {'n_voters': 2, 'n_valid': 2, 'n_invalid': 1},\n    {'n_voters': 3, 'n_valid': 2, 'n_invalid': 2},\n    {'n_voters': 4, 'n_valid': 3, 'n_invalid': 2},\n    {'n_voters': 5, 'n_valid': 3, 'n_invalid': 3},\n    {'n_voters': 6, 'n_valid': 4, 'n_invalid': 3},\n    {'n_voters': 7, 'n_valid': 4, 'n_invalid': 4},\n    {'n_voters': 8, 'n_valid': 5, 'n_invalid': 4}\n]\n\n\n@pytest.mark.parametrize('kwargs', DECISION_TESTS)\ndef test_decide_votes_valid(kwargs):\n    kwargs = kwargs.copy()\n    kwargs['n_invalid'] = 0\n    assert Voting.decide_votes(**kwargs) == VALID\n    kwargs['n_valid'] -= 1\n    assert Voting.decide_votes(**kwargs) == UNDECIDED\n\n\n@pytest.mark.parametrize('kwargs', DECISION_TESTS)\ndef test_decide_votes_invalid(kwargs):\n    kwargs = kwargs.copy()\n    kwargs['n_valid'] = 0\n    assert Voting.decide_votes(**kwargs) == INVALID\n    kwargs['n_invalid'] -= 1\n    assert Voting.decide_votes(**kwargs) == UNDECIDED\n\n\n################################################################################\n# Actions - test state transitions\n\n\n@pytest.mark.parametrize('n_voters', range(8))\ndef test_vote_actions(n_voters):\n    \"\"\"* Legal transitions are UNDECIDED -> [VALID|INVALID] only\n    * Block is never left UNDECIDED after voting\n    * Accomodates rogues on previous block \/ invalid schema\n    \"\"\"\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return type(vote['vote']['is_block_valid']) == bool\n\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            return True\n\n    keyring = 'abcdefghijklmnopqrstuvwxyz'[:n_voters]\n    block = {'id': 'block', 'block': {'voters': keyring}}\n    state = UNDECIDED\n    todo = [(state, [], [])]\n\n    def branch(p, r):\n        todo.append((state, votes, votes + [{\n            'node_pubkey': keyring[len(votes)],\n            'vote': {'previous_block': p, 'is_block_valid': r}\n        }]))\n\n    while todo:\n        prev_state, prev_votes, votes = todo.pop(0)\n        results = Counter(v['vote']['is_block_valid'] for v in votes)\n        prev_blocks = Counter(v['vote']['previous_block'] for v in votes)\n        majority = n_voters \/\/ 2 + 1\n        honest = (len(votes) == majority and len(prev_blocks) == 1 and\n                  not results['lol'] and len(results) == 1)\n        closed = len(votes) == n_voters\n\n        # Test legal transition\n        if votes:\n            state = TestVoting.block_election(block, votes, keyring)['status']\n            assert prev_state in [state, UNDECIDED]\n\n        # Test that decision has been reached\n        if honest or closed:\n            assert state != UNDECIDED or n_voters == 0\n\n        if closed:\n            continue\n\n        # Can accomodate more votes, add them to the todo list.\n        # This vote is the good case\n        branch('A', True)\n        # This vote disagrees on previous block\n        branch('B', True)\n        # This vote says the block is invalid\n        branch('A', False)\n        # This vote is invalid\n        branch('A', 'lol')\n\n\n################################################################################\n# Tests for vote signature\n\n\ndef test_verify_vote_signature_passes(b):\n    vote = b.vote('block', 'a', True)\n    assert Voting.verify_vote_signature(vote)\n    vote['signature'] = ''\n    assert not Voting.verify_vote_signature(vote)\n\n\n################################################################################\n# Tests for vote schema\n\n\ndef test_verify_vote_schema(b):\n    vote = b.vote('b' * 64, 'a' * 64, True)\n    assert Voting.verify_vote_schema(vote)\n    vote = b.vote('b' * 64, 'a', True)\n    assert not Voting.verify_vote_schema(vote)\n    vote = b.vote('b', 'a' * 64, True)\n    assert not Voting.verify_vote_schema(vote)\n\n\n################################################################################\n# block_election tests\n\n\ndef test_block_election(b):\n\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            return True\n\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return True\n\n    keyring = 'abc'\n    block = {'id': 'xyz', 'block': {'voters': 'ab'}}\n    votes = [{\n        'node_pubkey': c,\n        'vote': {'is_block_valid': True, 'previous_block': 'a'}\n    } for c in 'abc']\n\n    assert TestVoting.block_election(block, votes, keyring) == {\n        'status': VALID,\n        'block_id': 'xyz',\n        'counts': {'n_valid': 2, 'n_invalid': 0},\n        'ineligible': [votes[-1]],\n        'malformed': [],\n        'previous_block': 'a',\n        'other_previous_block': {},\n    }\n\n\n@patch('bigchaindb.voting.Voting.verify_vote_signature', return_value=True)\ndef test_duplicate_vote_throws_critical_error(b):\n    keyring = 'abc'\n    block = {'id': 'xyz', 'block': {'voters': 'ab'}}\n    votes = [{\n        'node_pubkey': c,\n        'vote': {'is_block_valid': True, 'previous_block': 'a'}\n    } for c in 'aabc']\n    with pytest.raises(CriticalDuplicateVote):\n        Voting.block_election(block, votes, keyring)\n"}
{"prompt":"class MoleculeGraphData\n\nclass BatchMoleculeGraphData\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import unittest\nimport pytest\nimport numpy as np\nfrom deepchem.utils.molecule_graph import MoleculeGraphData, BatchMoleculeGraphData\n\n\nclass TestMoleculeGraph(unittest.TestCase):\n\n  def test_molecule_graph_data(self):\n    num_nodes, num_node_features = 4, 32\n    num_edges, num_edge_features = 6, 32\n    node_features = np.random.random_sample((num_nodes, num_node_features))\n    edge_features = np.random.random_sample((num_edges, num_edge_features))\n    targets = np.random.random_sample(5)\n    edge_index = np.array([\n        [0, 1, 2, 2, 3, 4],\n        [1, 2, 0, 3, 4, 0],\n    ])\n    graph_features = None\n\n    mol_graph = MoleculeGraphData(\n        node_features=node_features,\n        edge_index=edge_index,\n        targets=targets,\n        edge_features=edge_features,\n        graph_features=graph_features)\n\n    assert mol_graph.num_nodes == num_nodes\n    assert mol_graph.num_node_features == num_node_features\n    assert mol_graph.num_edges == num_edges\n    assert mol_graph.num_edge_features == num_edge_features\n    assert mol_graph.targets.shape == (5,)\n\n  def test_invalid_molecule_graph_data(self):\n    with pytest.raises(ValueError):\n      invalid_node_features_type = list(np.random.random_sample((5, 5)))\n      edge_index = np.array([\n          [0, 1, 2, 2, 3, 4],\n          [1, 2, 0, 3, 4, 0],\n      ])\n      targets = np.random.random_sample(5)\n      mol_graph = MoleculeGraphData(\n          node_features=invalid_node_features_type,\n          edge_index=edge_index,\n          targets=targets,\n      )\n\n    with pytest.raises(ValueError):\n      node_features = np.random.random_sample((5, 5))\n      invalid_edge_index_shape = np.array([\n          [0, 1, 2, 2, 3, 4],\n          [1, 2, 0, 3, 4, 0],\n          [2, 2, 1, 4, 0, 3],\n      ])\n      targets = np.random.random_sample(5)\n      mol_graph = MoleculeGraphData(\n          node_features=node_features,\n          edge_index=invalid_edge_index_shape,\n          targets=targets,\n      )\n\n    with pytest.raises(TypeError):\n      node_features = np.random.random_sample((5, 5))\n      mol_graph = MoleculeGraphData(node_features=node_features)\n\n  def test_batch_molecule_graph_data(self):\n    num_nodes_list, num_edge_list = [3, 4, 5], [2, 4, 5]\n    num_node_features, num_edge_features = 32, 32\n    edge_index_list = [\n        np.array([[0, 1], [1, 2]]),\n        np.array([[0, 1, 2, 3], [1, 2, 0, 2]]),\n        np.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]])\n    ]\n    targets = np.random.random_sample(5)\n\n    molecule_graphs = [\n        MoleculeGraphData(\n            node_features=np.random.random_sample((num_nodes_list[i],\n                                                   num_node_features)),\n            edge_index=edge_index_list[i],\n            targets=targets,\n            edge_features=np.random.random_sample((num_edge_list[i],\n                                                   num_edge_features)),\n            graph_features=None) for i in range(len(num_edge_list))\n    ]\n    batch = BatchMoleculeGraphData(molecule_graphs)\n\n    assert batch.num_nodes == sum(num_nodes_list)\n    assert batch.num_node_features == num_node_features\n    assert batch.num_edges == sum(num_edge_list)\n    assert batch.num_edge_features == num_edge_features\n    assert batch.targets.shape == (3, 5)\n    assert batch.graph_index.shape == (sum(num_nodes_list),)\n"}
{"prompt":"class MockMemcacheClient\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import six\nimport pytest\n\nfrom pymemcache.test.utils import MockMemcacheClient\n\n\n@pytest.mark.unit()\ndef test_get_set():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(b\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_unicide_key():\n    client = MockMemcacheClient()\n    assert client.get(u\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(u\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_non_ascii_value():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    # This is the value of msgpack.packb('non_ascii')\n    non_ascii_str = b'\\xa9non_ascii'\n    client.set(b\"hello\", non_ascii_str)\n    assert client.get(b\"hello\") == non_ascii_str\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many():\n    client = MockMemcacheClient()\n    client.set(b\"h\", 1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": 1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(dict(h=1, e=2, z=3)))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many_non_ascii_values():\n    client = MockMemcacheClient()\n\n    # These are the values of calling msgpack.packb() on '1', '2', and '3'\n    non_ascii_1 = b'\\xa11'\n    non_ascii_2 = b'\\xa12'\n    non_ascii_3 = b'\\xa13'\n    client.set(b\"h\", non_ascii_1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": non_ascii_1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(\n                dict(h=non_ascii_1, e=non_ascii_2, z=non_ascii_3)\n             ))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_add():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.add(b\"k\", 25)\n    assert client.get(b\"k\") == 2\n\n\n@pytest.mark.unit()\ndef test_delete():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.delete(b\"k\")\n    assert client.get(b\"k\") is None\n\n\n@pytest.mark.unit()\ndef test_incr_decr():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n\n    client.incr(b\"k\", 4)\n    assert client.get(b\"k\") == 6\n\n    client.decr(b\"k\", 2)\n    assert client.get(b\"k\") == 4\n\n\n@pytest.mark.unit()\ndef test_prepand_append():\n    client = MockMemcacheClient()\n\n    client.set(b\"k\", '1')\n    client.append(b\"k\", 'a')\n    client.prepend(b\"k\", 'p')\n    assert client.get(b\"k\") == b'p1a'\n"}
{"prompt":"class InvalidArgumentCombination\n\nclass ConditionType\n\nclass DerivedCondition\n\nclass Or\n\nclass And\n\nclass Xor\n\nclass Not\n\nclass argcomb\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"Tests for ArgComb. \"\"\"\n\n# pylint: disable=unused-argument, unused-variable\n\nfrom typing import Any, Callable\n\nimport pytest\n\nfrom argcomb import And, Else, InvalidArgumentCombination, Not, Or, Xor, argcomb\n\n\ndef test_default() -> None:\n    \"\"\"Test the ``default`` parameter of :function:``argcomb.__init__``.\n\n    This test also serves to check the basic functionality of\n    ``argcomb`` for different types of signature: normal arguments,\n    keyword only arguments, positional only arguments, or any\n    combination of the above.\n    \"\"\"\n\n    def test_func(\n        func: Callable[..., None], kw_only_count: int, pos_only_count: int\n    ) -> None:\n        \"\"\"Test a given function ``f``. \"\"\"\n\n        with pytest.raises(InvalidArgumentCombination):\n            func()\n        if pos_only_count == 0:\n            func(a=1)\n            func(a=1, b=1)\n            func(a=1, b=None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(a=None, b=1)\n        if kw_only_count < 2:\n            func(1)\n\n        if kw_only_count < 2 and pos_only_count < 2:\n            func(1, b=1)\n            func(1, b=None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(None, b=1)\n\n        if kw_only_count == 0:\n            func(1, 1)\n            func(1, None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(None, 1)\n\n        if pos_only_count < 2:\n            with pytest.raises(InvalidArgumentCombination):\n                func(b=1)\n\n    @argcomb(\"a\")\n    def f(a: Any = None, b: Any = None) -> None:\n        ...\n\n    test_func(f, kw_only_count=0, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def g(a: Any = None, *, b: Any = None) -> None:\n        ...\n\n    test_func(g, kw_only_count=1, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def h(*, a: Any = None, b: Any = None) -> None:\n        ...\n\n    test_func(h, kw_only_count=2, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def i(a: Any = None, \/, b: Any = None) -> None:\n        ...\n\n    test_func(i, kw_only_count=0, pos_only_count=1)\n\n    @argcomb(\"a\")\n    def j(a: Any = None, b: Any = None, \/) -> None:\n        ...\n\n    test_func(j, kw_only_count=0, pos_only_count=2)\n\n    @argcomb(\"a\")\n    def k(a: Any = None, \/, *, b: Any = None) -> None:\n        ...\n\n    test_func(k, kw_only_count=1, pos_only_count=1)\n\n\ndef test_argument_specs() -> None:\n    \"\"\"Test providing specifications for arguments. \"\"\"\n\n    @argcomb(a=\"b\", c=\"d\")\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # 9 valid combinations\n    f()\n    f(d=1)\n    f(c=1, d=1)\n    f(b=1)\n    f(b=1, d=1)\n    f(b=1, c=1, d=1)\n    f(a=1, b=1)\n    f(a=1, b=1, d=1)\n    f(a=1, b=1, c=1, d=1)\n\n    # 7 invalid combinations\n    with pytest.raises(InvalidArgumentCombination):\n        f(c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, d=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1, d=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1, c=1)\n\n\ndef test_value_dependent_specs() -> None:\n    \"\"\"Test specifications which depend on argument value. \"\"\"\n\n    @argcomb(a={1: \"b\", 2: \"c\", 3: \"d\"})\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # valid\n    f()\n    f(a=1, b=4)\n    f(a=2, c=5)\n    f(a=3, d=6)\n    f(a=1, b=4, c=5)\n    f(a=1, b=4, c=5, d=6)\n    f(a=1, b=4, d=6)\n    f(a=2, c=5, d=6)\n    f(a=4)\n    f(b=4, c=5)\n    f(d=6)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=5)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=5, d=6)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, b=3)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, d=4)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=3, b=3, c=4)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=3)\n\n\ndef test_and() -> None:\n    \"\"\"Test ``And`` condition. \"\"\"\n\n    @argcomb(And(\"a\", \"b\"))\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    #  valid\n    f(a=1, b=2)\n    f(a=1, b=2, c=3)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=None)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=None, b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_or() -> None:\n    \"\"\"Test ``Or`` condition. \"\"\"\n\n    @argcomb(Or(\"a\", \"b\"))\n    def f(a: Any = None, b: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1)\n    f(b=2)\n    f(a=1, b=2)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_not() -> None:\n    \"\"\"Test ``Not`` condition. \"\"\"\n\n    @argcomb(Not(\"a\"))\n    def f(a: Any = None) -> None:\n        ...\n\n    # valid\n    f()\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n\n\ndef test_xor() -> None:\n    \"\"\"Test ``Xor`` condition. \"\"\"\n\n    @argcomb(Xor(\"a\", \"b\", \"c\"))\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1)\n    f(b=1)\n    f(c=1)\n\n    #  invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_else() -> None:\n    \"\"\"Test ``Else`` in value dependent specifications. \"\"\"\n\n    @argcomb(a={1: \"b\", Else: \"c\"})\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=2, c=1)\n\n    #  invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, b=1)\n\n\ndef test_nested_condition() -> None:\n    \"\"\"Test a nested condition. \"\"\"\n\n    @argcomb(Or(And(\"a\", \"b\"), And(\"c\", \"d\")))\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1, b=1)\n    f(c=1, d=1)\n    f(a=1, b=1, c=1, d=1)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_argument_named_default() -> None:\n    \"\"\"Test when an argument is named ``default``.\n\n    This collides with a positional only argument named ``default`` in\n    the ``argcomb`` signature, but as this is positional only this\n    should not matter.\n    \"\"\"\n\n    @argcomb(default=\"a\")\n    def f(default: Any = None, a: Any = None) -> None:\n        ...\n\n    f(a=1)\n    f(default=1, a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(default=1)\n\n\ndef test_arguments_same_name() -> None:\n    \"\"\"Test that a warning is emitted when a function with two\n    identically named arguments. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(a: Any = None, \/, b: Any = None, **kwargs: Any) -> None:\n        ...\n\n    with pytest.warns(UserWarning):\n        f(1, 2, a=3)  # pylint: disable=E1124\n\n\ndef test_default_arguments() -> None:\n    \"\"\"Test that default arguments are correctly recognised when they\n    are not ``None``. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(a: int = 1, b: int = 2) -> None:\n        ...\n\n    # valid since ``a`` is the default value\n    f(a=1)\n\n    with pytest.raises(InvalidArgumentCombination):\n        # invalid since ``b`` is the default value\n        f(a=2, b=2)\n\n\ndef test_kwargs() -> None:\n    \"\"\"Test functionality when signature uses ``**kwargs``. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(**kwargs: Any) -> None:\n        ...\n\n    f(a=1, b=1)\n    f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n"}
{"prompt":"fn setroot(engine, root)\n\nclass OctaveWithMatlabInterface\n\nfn octave_engine(root)\n\nfn matlab_engine(root)\n\nfn matrix(engine, obj)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright 2019 Alastair Pharo\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nimport numpy\nimport os\nimport scipy\nfrom numpy.testing import assert_allclose\nfrom infsocsol.helpers import matrix\n\n@pytest.fixture(scope=\"module\", params=[\n    # engine    states time_step start         steps  steady steady_accuracy optim_accuracy\n    ( 'matlab', 10,    1,        (100.0, 0.5), 100,   True,  0.01,           0.009 ),\n    ( 'matlab', 20,    0.5,      (600.0, 0.6), 200,   True,  0.01,           0.015 ),\n    ( 'matlab', 40,    0.25,     (60.0, 0.1),  300,   True,  0.01,           0.018 ),\n    ( 'matlab', 10,    1,        (600.0, 1.0), 200,   False, 0.001,          None  ),\n    ( 'octave', 10,    1,        (100.0, 0.5), 100,   True,  0.001,          0.009 ),\n    ( 'octave', 20,    0.5,      (600.0, 0.6), 200,   True,  0.001,          0.015 )\n])\ndef fisheries_scenario(request):\n    return request.param\n\ndef test_fisheries_det_basic(engines, fisheries_scenario):\n    _engine, states, time_step, _start, steps, steady, steady_accuracy, optim_accuracy = fisheries_scenario\n    engine = engines[_engine]\n    start = matrix(engine, _start)\n    engine.cd(os.path.join(os.path.dirname(__file__), \"fisheries_det_basic\"))\n\n    engine.solve(float(states), float(time_step), nargout=0)\n    final = numpy.array(engine.sim_final(start, steps))\n    # This is determined by setting s\\dot = 0, which solves to 1 = x\/L + q\/r e\n    steady_one = numpy.dot(final, [1\/600, 5\/4])\n\n    if steady:\n        assert_allclose(steady_one, 1, atol=steady_accuracy)\n\n        # This is the most profitable steady state -- x = L\/2 + c\/2pq\n        profit_max_steady = numpy.array([[302.5, 0.39667]])\n        assert_allclose(final, profit_max_steady, rtol=optim_accuracy)\n    else:\n        assert steady_one > 1 + steady_accuracy\n"}
{"prompt":"class CountryFactory\n\nclass StateFactory\n\nclass LocalityFactory\n\nclass AddressFactory\n\nclass PhoneContactMethodFactory\n\nclass EmailContactMethodFactory\n\nclass CoopTypeFactory\n\nclass CoopFactory\n\nclass PersonFactory\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom django.test import TestCase\nfrom .factories import CoopTypeFactory, CoopFactory, AddressFactory, PhoneContactMethodFactory \nfrom directory.models import Coop, CoopType\n\n\nclass ModelTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        print(\"setUpTestData: Run once to set up non-modified data for all class methods.\")\n        #management.call_command('loaddata', 'test_data.yaml', verbosity=0)\n        pass\n\n    @pytest.mark.django_db\n    def test_phone_create(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"7739441467\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone\n        assert phone.id is not None\n\n    @pytest.mark.django_db\n    def test_phone_create_invalid_num(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"abcdefsfdsf\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone  \n        assert phone.id is not None\n        print(\"\\n\\n\\n\\n-------------id is \", id) \n\n    @pytest.mark.django_db\n    def test_coop_type_create(self):\n        \"\"\" Test coop type model \"\"\"    # create customer model instance\n        coop_type = CoopTypeFactory(name=\"Test Coop Type Name\")\n        assert coop_type.name == \"Test Coop Type Name\"\n\n    @pytest.mark.django_db\n    def test_address_create(self):\n        \"\"\" Test address model \"\"\"    # create customer model instance\n        address = AddressFactory()\n        assert address is not None\n\n    @pytest.mark.django_db\n    def test_coop_create(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop = Coop.objects.create(name='test')\n        coop.addresses.set(coop_from_factory.addresses.all()) \n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_existing_type(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop_types = coop_from_factory.types\n        coop = CoopFactory.create(types=[coop_types.all().first()], addresses=coop_from_factory.addresses.all())\n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_no_types(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        print(\"\\n\\n\\n\\n**********-------- starting test ....\\n\")\n        coop = CoopFactory.build(types=[])\n        print(\"phone:\",coop.phone.phone)\n        print(\"email:\",coop.email.email)\n        coop.full_clean()\n        self.assertIsNotNone(coop)\n        self.assertIsNone( coop.id )\n\n    def test_search_coops_wo_coords(self):\n        \"\"\"\n        Look for coops with addresses without latitude\/longitude coords\n        \"\"\"\n        address = AddressFactory(latitude=None, longitude=None)\n        coop_from_factory = CoopFactory(addresses=[address])\n        # Verify coop appears when we search for those without a lat\/lon\n        coops = Coop.objects.find_wo_coords()\n        results = list(coops)\n        assert len(results) > 0, \"Failed to find any matching results.\"\n        assert coop_from_factory in list(coops), \"Failed to find coop.\"\n \n\n"}
{"prompt":"class User\n\nclass UserChangeForm\n\nclass UserCreationForm\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom djcutter.users.forms import UserCreationForm\nfrom djcutter.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"}
{"prompt":"fn splunk_single(service, search)\n\nfn insert_char(string, char, integer)\n\nfn removeZero(tz)\n\nfn time_operations(dt)\n\nfn sendsingle(message, host, port)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https:\/\/opensource.org\/licenses\/BSD-2-Clause\n\nfrom jinja2 import Environment\n\nfrom .sendmessage import *\nfrom .splunkutils import *\nfrom .timeutils import *\n\nimport pytest\n\nenv = Environment()\n\n# time format for Apr  5 22:51:54 2021\n# <187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\n# <187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat \/mswitch\/sap\/mips64.ari failed: No such file or directory.\n# <188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\n# <191>{{ arubadate }} 10.10.10.10 dnsmasq: reading \/etc\/resolv.conf\n\ntestdata = [\n    \"<187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\",\n    \"<187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat \/mswitch\/sap\/mips64.ari failed: No such file or directory.\",\n    \"<188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\",\n    \"<188>{{ arubadate }} {{ host }} sapd[1362]: <127037> <WARN> |AP 00:0b:86:eb:4e:32@10.10.10.10 sapd| |ids-ap| AP(04:bd:88:8a:3a:60): Station Associated to Rogue AP: An AP detected a client a4:8d:3b:ae:68:68 associated to a rogue access point (BSSID 98:1e:19:31:63:b6 and SSID MySpectrumWiFib0-2G on CHANNEL 11).\",\n]\n\n\n@pytest.mark.parametrize(\"event\", testdata)\ndef test_aruba(\n    record_property, setup_wordlist, get_host_key, setup_splunk, setup_sc4s, event\n):\n    host = get_host_key\n\n    dt = datetime.datetime.now()\n    iso, bsd, time, date, tzoffset, tzname, epoch = time_operations(dt)\n    arubadate = dt.strftime(\"%b %d %H:%M:%S %Y\")\n\n    # Tune time functions\n    epoch = epoch[:-7]\n\n    mt = env.from_string(event + \"\\n\")\n    message = mt.render(mark=\"<188>\", bsd=bsd, host=host, arubadate=arubadate)\n\n    sendsingle(message, setup_sc4s[0], setup_sc4s[1][514])\n\n    st = env.from_string(\n        'search index=netops _time={{ epoch }} sourcetype=\"aruba:syslog\" host={{ host }}'\n    )\n    search = st.render(epoch=epoch, host=host)\n\n    resultCount, eventCount = splunk_single(setup_splunk, search)\n\n    record_property(\"host\", host)\n    record_property(\"resultCount\", resultCount)\n    record_property(\"message\", message)\n\n    assert resultCount == 1\n"}
{"prompt":"class Result\n\nclass Failure\n\nclass Success\n\n\"\"\"Decorator to convert exception-throwing function to ``Result`` container.\n\nShould be used with care, since it only catches ``Exception`` subclasses.\nIt does not catch ``BaseException`` subclasses.\n\nIf you need to mark ``async`` function as ``safe``,\nuse :func:`returns.future.future_safe` instead.\nThis decorator only works with sync functions. Example:\n\n.. code:: python\n\n  >>> from returns.result import Result, Success, safe\n\n  >>> @safe\n  ... def might_raise(arg: int) -> float:\n  ...     return 1 \/ arg\n\n  >>> assert might_raise(1) == Success(1.0)\n  >>> assert isinstance(might_raise(0), Result.failure_type)\n\nSimilar to :func:`returns.io.impure_safe`\nand :func:`returns.future.future_safe` decorators.\n\nRequires our :ref:`mypy plugin <mypy-plugins>`.\"\"\"\nfn safe(function: Callable[(..., _ValueType)]) -> Callable[(..., ResultE[_ValueType])]\n\n\"\"\"Determines if a container was successful or not.\n\n.. code:: python\n\n  >>> from returns.maybe import Some, Nothing\n  >>> from returns.result import Failure, Success\n  >>> from returns.io import IOSuccess, IOFailure\n\n  >>> assert is_successful(Some(1))\n  >>> assert not is_successful(Nothing)\n\n  >>> assert is_successful(Success(1))\n  >>> assert not is_successful(Failure(1))\n\n  >>> assert is_successful(IOSuccess(1))\n  >>> assert not is_successful(IOFailure(1))\n\nThis function can work with containers\nthat are instance of :class:`returns.interfaces.unwrappable.Unwrappable`.\"\"\"\nfn is_successful(container: Unwrappable) -> bool\n\nclass IO\n\n\"\"\"Decorator to mark function that it returns :class:`~IO` container.\n\nIf you need to mark ``async`` function as impure,\nuse :func:`returns.future.future` instead.\nThis decorator only works with sync functions. Example:\n\n.. code:: python\n\n  >>> from returns.io import IO, impure\n\n  >>> @impure\n  ... def function(arg: int) -> int:\n  ...     return arg + 1  # this action is pure, just an example\n  ...\n\n  >>> assert function(1) == IO(2)\n\nRequires our :ref:`mypy plugin <mypy-plugins>`.\"\"\"\nfn impure(function: Callable[(..., _NewValueType)]) -> Callable[(..., IO[_NewValueType])]\n\nclass IOResult\n\nclass IOFailure\n\nclass IOSuccess\n\n\"\"\"Decorator to mark function that it returns :class:`~IOResult` container.\n\nShould be used with care, since it only catches ``Exception`` subclasses.\nIt does not catch ``BaseException`` subclasses.\n\nIf you need to mark ``async`` function as impure,\nuse :func:`returns.future.future_safe` instead.\nThis decorator only works with sync functions. Example:\n\n.. code:: python\n\n  >>> from returns.io import IOSuccess, impure_safe\n\n  >>> @impure_safe\n  ... def function(arg: int) -> float:\n  ...     return 1 \/ arg\n  ...\n\n  >>> assert function(1) == IOSuccess(1.0)\n  >>> assert function(0).failure()\n\nSimilar to :func:`returns.future.future_safe`\nand :func:`returns.result.safe` decorators.\n\nRequires our :ref:`mypy plugin <mypy-plugins>`.\"\"\"\nfn impure_safe(function: Callable[(..., _NewValueType)]) -> Callable[(..., IOResultE[_NewValueType])]\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"from typing import List, Tuple\n\nimport pytest\n\nfrom returns.io import IOFailure, IOResult, IOSuccess\nfrom returns.pipeline import managed\nfrom returns.result import Failure, Result, Success\n\n_acquire_success = IOSuccess('acquire success')\n_acquire_failure = IOFailure('acquire failure')\n\n\ndef _use_success(inner_value: str) -> IOResult[str, str]:\n    return IOSuccess('use success')\n\n\ndef _use_failure(inner_value: str) -> IOResult[str, str]:\n    return IOFailure('use failure')\n\n\nclass _ReleaseSuccess(object):\n    def __init__(self, logs: List[Tuple[str, Result[str, str]]]) -> None:\n        self._logs = logs\n\n    def __call__(\n        self,\n        inner_value: str,\n        use_result: Result[str, str],\n    ) -> IOResult[None, str]:\n        self._logs.append((inner_value, use_result))\n        return IOSuccess(None)\n\n\nclass _ReleaseFailure(object):\n    def __init__(self, logs: List[Tuple[str, Result[str, str]]]) -> None:\n        self._logs = logs\n\n    def __call__(\n        self,\n        inner_value: str,\n        use_result: Result[str, str],\n    ) -> IOResult[None, str]:\n        return IOFailure('release failure')\n\n\n@pytest.mark.parametrize(('acquire', 'use', 'release', 'final_result', 'log'), [\n    # Acquire success:\n    (\n        _acquire_success,\n        _use_success,\n        _ReleaseSuccess,\n        IOSuccess('use success'),\n        [('acquire success', Success('use success'))],\n    ),\n    (\n        _acquire_success,\n        _use_success,\n        _ReleaseFailure,\n        IOFailure('release failure'),\n        [],\n    ),\n    (\n        _acquire_success,\n        _use_failure,\n        _ReleaseSuccess,\n        IOFailure('use failure'),\n        [('acquire success', Failure('use failure'))],\n    ),\n    (\n        _acquire_success,\n        _use_failure,\n        _ReleaseFailure,\n        IOFailure('release failure'),\n        [],\n    ),\n\n    # Acquire failure:\n    (\n        _acquire_failure,\n        _use_success,\n        _ReleaseSuccess,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_failure,\n        _ReleaseSuccess,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_success,\n        _ReleaseFailure,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_failure,\n        _ReleaseFailure,\n        IOFailure('acquire failure'),\n        [],\n    ),\n])\ndef test_all_success(acquire, use, release, final_result, log):\n    \"\"\"Ensures that managed works as intended.\"\"\"\n    pipeline_logs: List[Tuple[str, Result[str, str]]] = []\n    pipeline_result = managed(\n        use,\n        release(pipeline_logs),\n    )(acquire)\n\n    assert pipeline_result == final_result\n    assert pipeline_logs == log\n\n\ndef test_full_typing():\n    \"\"\"This test is here to be a case for typing.\"\"\"\n    logs: List[Tuple[str, Result[str, str]]] = []\n    pipeline_result = managed(\n        _use_success,\n        _ReleaseSuccess(logs),\n    )(_acquire_success)\n\n    assert pipeline_result == IOSuccess('use success')\n    assert logs == [('acquire success', Success('use success'))]\n"}
{"prompt":"fn check_common_metrics(aggregator, expected_tags, count)\n\nfn check_bgw_metrics(aggregator, expected_tags)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# (C) Datadog, Inc. 2021-present\n# All rights reserved\n# Licensed under Simplified BSD License (see LICENSE)\nimport pytest\n\nfrom datadog_checks.postgres.relationsmanager import ALL_SCHEMAS, IDX_METRICS, LOCK_METRICS, RelationsManager\n\nfrom .common import SCHEMA_NAME\n\npytestmark = pytest.mark.unit\n\n\n@pytest.mark.parametrize(\n    'relations_config,expected_filter',\n    [\n        (\n            [\n                {'relation_regex': 'ix.*', 'schemas': ['public', 's1', 's2']},\n                {'relation_regex': 'ibx.*', 'schemas': ['public']},\n                {'relation_regex': 'icx.*', 'schemas': ['public']},\n            ],\n            \"( relname ~ 'ix.*' AND schemaname = ANY(array['public','s1','s2']::text[]) ) \"\n            \"OR ( relname ~ 'ibx.*' AND schemaname = ANY(array['public']::text[]) ) \"\n            \"OR ( relname ~ 'icx.*' AND schemaname = ANY(array['public']::text[]) )\",\n        ),\n        (\n            [\n                {'relation_regex': '.+_archive'},\n            ],\n            \"( relname ~ '.+_archive' )\",\n        ),\n        (\n            [\n                {'relation_name': 'my_table', 'schemas': ['public', 'app'], 'relkind': ['r']},  # relkind ignored\n                {'relation_name': 'my_table2', 'relkind': ['p', 'r']},  # relkind ignored\n                {'relation_regex': 'table.*'},\n            ],\n            \"( relname = 'my_table' AND schemaname = ANY(array['public','app']::text[]) ) \"\n            \"OR ( relname = 'my_table2' ) \"\n            \"OR ( relname ~ 'table.*' )\",\n        ),\n        (\n            ['table1', 'table2'],\n            \"( relname = 'table1' ) OR ( relname = 'table2' )\",\n        ),\n    ],\n)\ndef test_relations_cases(relations_config, expected_filter):\n    query = '{relations}'\n    relations = RelationsManager(relations_config)\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == expected_filter\n\n\ndef test_relation_filter():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'breed', 'schemas': ['public']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert (\n        query_filter == \"Select foo from bar where ( relname = 'breed' AND schemaname = ANY(array['public']::text[]) )\"\n    )\n\n\ndef test_relation_filter_no_schemas():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'persons', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname = 'persons' )\"\n\n\ndef test_relation_filter_regex():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname ~ 'b.*' )\"\n\n\ndef test_relation_filter_relkind():\n    query = LOCK_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r', 't']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert \"AND relkind = ANY(array['r','t'])\" in query_filter\n\n\ndef test_relkind_does_not_apply_to_index_metrics():\n    query = IDX_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert 'relkind' not in query_filter\n"}
