{"prompt":"\n\n### python\/engine\/functions\/orbit_derived_parameters.py ###\n\nfrom sympy import pi, sqrt\nfrom sympy.physics.units import gravitational_constant as G\n\n\ndef OrbitalPeriod(\n    primary_mass, secondary_mass, semimajor_axis, gravitational_constant=G\n):\n    mean_angular_motion = sqrt(\n        gravitational_constant * (primary_mass + secondary_mass) \/ (semimajor_axis ** 3)\n    )\n    return 2 * pi \/ mean_angular_motion\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom engine.constants import G\nfrom pytest import param as p\n\nfrom .orbit_derived_parameters import OrbitalPeriod\n\n\n@pytest.mark.parametrize(\n    (\"primary_mass\", \"secondary_mass\", \"semimajor_axis\", \"expected\"),\n    [p(10e10, 100, 10, 76.9102, id=\"arbitrary period\")],\n)\ndef test_orbital_period(primary_mass, secondary_mass, semimajor_axis, expected):\n    assert OrbitalPeriod(\n        primary_mass, secondary_mass, semimajor_axis, G\n    ).evalf() == pytest.approx(expected, 1e-3)\n"}
{"prompt":"\n\n### djcookie_demo_proj\/users\/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for djcookie-demo-proj.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### djcookie_demo_proj\/users\/tests\/factories.py ###\n\nfrom typing import Any, Sequence\n\nfrom django.contrib.auth import get_user_model\nfrom factory import Faker, post_generation\nfrom factory.django import DjangoModelFactory\n\n\nclass UserFactory(DjangoModelFactory):\n\n    username = Faker(\"user_name\")\n    email = Faker(\"email\")\n    name = Faker(\"name\")\n\n    @post_generation\n    def password(self, create: bool, extracted: Sequence[Any], **kwargs):\n        password = (\n            extracted\n            if extracted\n            else Faker(\n                \"password\",\n                length=42,\n                special_chars=True,\n                digits=True,\n                upper_case=True,\n                lower_case=True,\n            ).evaluate(None, None, extra={\"locale\": None})\n        )\n        self.set_password(password)\n\n    class Meta:\n        model = get_user_model()\n        django_get_or_create = [\"username\"]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom djcookie_demo_proj.users.models import User\nfrom djcookie_demo_proj.users.tests.factories import UserFactory\n\n\n@pytest.fixture(autouse=True)\ndef media_storage(settings, tmpdir):\n    settings.MEDIA_ROOT = tmpdir.strpath\n\n\n@pytest.fixture\ndef user() -> User:\n    return UserFactory()\n"}
{"prompt":"\n\n### receptor\/router.py ###\n\nimport datetime\nimport heapq\nimport logging\nimport random\nimport uuid\nfrom collections import defaultdict\n\nfrom .exceptions import ReceptorBufferError, UnrouteableError\nfrom .messages import envelope\nfrom .stats import route_counter, route_info\n\nlogger = logging.getLogger(__name__)\n\n\nclass MeshRouter:\n    _nodes = set()\n    _edges = set()\n    response_registry = dict()\n\n    def __init__(self, receptor):\n        self.receptor = receptor\n        self.node_id = receptor.node_id\n        route_info.info(dict(edges=\"()\"))\n\n    def node_is_known(self, node_id):\n        return node_id in self._nodes or node_id == self.node_id\n\n    def find_edge(self, left, right):\n        node_actual = sorted([left, right])\n        for edge in self._edges:\n            if node_actual[0] == edge[0] and node_actual[1] == edge[1]:\n                return edge\n        return None\n\n    def add_edges(self, edges):\n        for edge in edges:\n            existing_edge = self.find_edge(edge[0], edge[1])\n            if existing_edge and existing_edge[2] > edge[2]:\n                self.update_node(edge[0], edge[1], edge[2])\n            else:\n                self.register_edge(*edge)\n\n    def register_edge(self, left, right, cost):\n        if left != self.node_id:\n            self._nodes.add(left)\n        if right != self.node_id:\n            self._nodes.add(right)\n        edge = self.update_node(left, right, cost)\n        if not edge:\n            self._edges.add((*sorted([left, right]), cost))\n        route_info.info(dict(edges=str(self._edges)))\n\n    def update_node(self, left, right, cost):\n        edge = self.find_edge(left, right)\n        if edge:\n            new_edge = (edge[0], edge[1], cost)\n            self._edges.remove(edge)\n            self._edges.add(new_edge)\n            return edge\n        return None\n\n    def remove_node(self, node):\n        edge = self.find_edge(self.node_id, node)\n        if edge:\n            self._edges.remove(edge)\n            return edge\n        return None\n\n    def get_edges(self):\n        \"\"\"Returns set of edges\"\"\"\n        return list(self._edges)\n\n    def get_nodes(self):\n        return self._nodes\n\n    async def ping_node(self, node_id, expected_response=True):\n        logger.info(f'Sending ping to node {node_id}')\n        now = datetime.datetime.utcnow().isoformat()\n        ping_envelope = envelope.Inner(\n            receptor=self.receptor,\n            message_id=str(uuid.uuid4()),\n            sender=self.node_id,\n            recipient=node_id,\n            message_type='directive',\n            timestamp=now,\n            raw_payload=now,\n            directive='receptor:ping',\n            ttl=15\n        )\n        return await self.send(ping_envelope, expected_response)\n\n    def find_shortest_path(self, to_node_id):\n        \"\"\"Implementation of Dijkstra algorithm\"\"\"\n        cost_map = defaultdict(list)\n        for left, right, cost in self._edges:\n            cost_map[left].append((cost, right))\n            cost_map[right].append((cost, left))\n\n        heap, seen, mins = [(0, self.node_id, [])], set(), {self.node_id: 0}\n        while heap:\n            (cost, vertex, path) = heapq.heappop(heap)\n            if vertex not in seen:\n                seen.add(vertex)\n                path = [vertex] + path\n                if vertex == to_node_id:\n                    logger.debug(f'Shortest path to {to_node_id} with cost {cost} is {path}')\n                    return path\n                cost_map_for_vertex = cost_map.get(vertex, ())\n                random.shuffle(cost_map_for_vertex)\n                for next_cost, next_vertex in cost_map.get(vertex, ()):\n                    if next_vertex in seen:\n                        continue\n                    min_so_far = mins.get(next_vertex, None)\n                    next_total_cost = cost + next_cost\n                    if min_so_far is None or next_total_cost < min_so_far:\n                        mins[next_vertex] = next_total_cost\n                        heapq.heappush(heap, (next_total_cost, next_vertex, path))\n\n    async def forward(self, msg, next_hop):\n        \"\"\"\n        Forward a message on to the next hop closer to its destination\n        \"\"\"\n        buffer_mgr = self.receptor.config.components_buffer_manager\n        buffer_obj = buffer_mgr.get_buffer_for_node(next_hop, self.receptor)\n        msg.header[\"route_list\"].append(self.node_id)\n        logger.debug(f'Forwarding frame {msg.msg_id} to {next_hop}')\n        try:\n            route_counter.inc()\n            await buffer_obj.put(msg.serialize())\n        except ReceptorBufferError as e:\n            logger.exception(\"Receptor Buffer Write Error forwarding message to {}: {}\".format(next_hop, e))\n            # TODO: Possible to find another route? This might be a hard failure\n        except Exception as e:\n            logger.exception(\"Error trying to forward message to {}: {}\".format(next_hop, e))\n\n    def next_hop(self, recipient):\n        \"\"\"\n        Return the node ID of the next hop for routing a message to the\n        given recipient. If the current node is the recipient or there is\n        no path, then return None.\n        \"\"\"\n        if recipient == self.node_id:\n            return None\n        path = self.find_shortest_path(recipient)\n        if path:\n            return path[-2]\n\n    async def send(self, inner_envelope, expected_response=False):\n        \"\"\"\n        Send a new message with the given outer envelope.\n        \"\"\"\n        next_node_id = self.next_hop(inner_envelope.recipient)\n        if not next_node_id:\n            # TODO: This probably needs to emit an error response\n            raise UnrouteableError(f'No route found to {inner_envelope.recipient}')\n        signed = await inner_envelope.sign_and_serialize()\n        header = {\n            \"sender\": self.node_id,\n            \"recipient\": inner_envelope.recipient,\n            \"route_list\": [self.node_id]\n        }\n        msg = envelope.FramedMessage(msg_id=uuid.uuid4().int, header=header, payload=signed)\n        logger.debug(f'Sending {inner_envelope.message_id} to {inner_envelope.recipient} via {next_node_id}')\n        if expected_response and inner_envelope.message_type == 'directive':\n            self.response_registry[inner_envelope.message_id] = dict(message_sent_time=inner_envelope.timestamp)\n        await self.forward(msg, next_node_id)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom receptor.router import MeshRouter\n\ntest_networks = [\n    (\n        [\n            (\"a\", \"b\", 1),\n            (\"a\", \"d\", 1),\n            (\"a\", \"f\", 1),\n            (\"b\", \"d\", 1),\n            (\"b\", \"c\", 1),\n            (\"c\", \"e\", 1),\n            (\"c\", \"h\", 1),\n            (\"c\", \"j\", 1),\n            (\"e\", \"f\", 1),\n            (\"e\", \"g\", 1),\n            (\"e\", \"h\", 1),\n            (\"f\", \"g\", 1),\n            (\"g\", \"h\", 1),\n            (\"h\", \"j\", 1),\n            (\"h\", \"k\", 1),\n            (\"j\", \"k\", 1),\n            (\"j\", \"m\", 1),\n            (\"l\", \"m\", 1),\n        ],\n        [(\"a\", \"f\", \"f\"), (\"a\", \"m\", \"b\"), (\"h\", \"d\", \"c\")],\n        [(\"a\", {\"b\", \"d\", \"f\"}), (\"f\", {\"a\", \"e\", \"g\"}), (\"j\", {\"c\", \"h\", \"k\", \"m\"})],\n    ),\n    (\n        [(\"a\", \"b\", 1), (\"b\", \"c\", 1), (\"c\", \"d\", 1), (\"d\", \"e\", 1), (\"e\", \"f\", 1)],\n        [(\"a\", \"f\", \"b\"), (\"c\", \"a\", \"b\"), (\"f\", \"c\", \"e\")],\n        [(\"a\", {\"b\"}), (\"f\", {\"e\"}), (\"c\", {\"b\", \"d\"})],\n    ),\n]\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_next_hop(edges, expected_next_hops, expected_neighbors):\n    for node_id, remote, enh in expected_next_hops:\n        r = MeshRouter(node_id=node_id)\n        r.add_or_update_edges(edges)\n        assert r.next_hop(remote) == enh\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_neighbors(edges, expected_next_hops, expected_neighbors):\n    r = MeshRouter(node_id=edges[0][0])\n    r.add_or_update_edges(edges)\n    for node_id, neighbors in expected_neighbors:\n        assert r.get_neighbors(node_id) == neighbors\n"}
{"prompt":"\n\n### async_lru.py ###\n\nimport asyncio\nfrom collections import OrderedDict\nfrom functools import _CacheInfo, _make_key, partial, wraps\nfrom time import time\n\ntry:\n    from asyncio import ensure_future\nexcept ImportError:  # pragma: no cover\n    ensure_future = getattr(asyncio, 'async')\n\n__version__ = '1.0.1'\n\n__all__ = ('alru_cache',)\n\n\ndef create_future(*, loop):\n    try:\n        return loop.create_future()\n    except AttributeError:\n        return asyncio.Future(loop=loop)\n\n\ndef unpartial(fn):\n    while hasattr(fn, 'func'):\n        fn = fn.func\n\n    return fn\n\n\ndef _done_callback(fut, task):\n    if task.cancelled():\n        fut.cancel()\n        return\n\n    exc = task.exception()\n    if exc is not None:\n        fut.set_exception(exc)\n        return\n\n    fut.set_result(task.result())\n\n\ndef _cache_invalidate(wrapped, typed, *args, **kwargs):\n    key = _make_key(args, kwargs, typed)\n\n    exists = key in wrapped._cache\n\n    if exists:\n        wrapped._cache.pop(key)\n\n    return exists\n\n\ndef _cache_clear(wrapped):\n    wrapped.hits = wrapped.misses = 0\n    wrapped._cache = OrderedDict()\n    wrapped.tasks = set()\n\n\ndef _open(wrapped):\n    if not wrapped.closed:\n        raise RuntimeError('alru_cache is not closed')\n\n    was_closed = (\n        wrapped.hits ==\n        wrapped.misses ==\n        len(wrapped.tasks) ==\n        len(wrapped._cache) ==\n        0\n    )\n\n    if not was_closed:\n        raise RuntimeError('alru_cache was not closed correctly')\n\n    wrapped.closed = False\n\n\ndef _close(wrapped, *, cancel=False, return_exceptions=True, loop=None):\n    if wrapped.closed:\n        raise RuntimeError('alru_cache is closed')\n\n    wrapped.closed = True\n\n    if cancel:\n        for task in wrapped.tasks:\n            if not task.done():  # not sure is it possible\n                task.cancel()\n\n    return _wait_closed(\n        wrapped,\n        return_exceptions=return_exceptions,\n        loop=loop\n    )\n\n\n@asyncio.coroutine\ndef _wait_closed(wrapped, *, return_exceptions, loop):\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    wait_closed = asyncio.gather(\n        *wrapped.tasks,\n        return_exceptions=return_exceptions,\n        loop=loop\n    )\n\n    wait_closed.add_done_callback(partial(_close_waited, wrapped))\n\n    ret = yield from wait_closed\n\n    # hack to get _close_waited callback to be executed\n    yield from asyncio.sleep(0, loop=loop)\n\n    return ret\n\n\ndef _close_waited(wrapped, _):\n    wrapped.cache_clear()\n\n\ndef _cache_info(wrapped, maxsize):\n    return _CacheInfo(\n        wrapped.hits,\n        wrapped.misses,\n        maxsize,\n        len(wrapped._cache),\n    )\n\n\ndef __cache_touch(wrapped, key):\n    try:\n        wrapped._cache.move_to_end(key)\n    except KeyError:  # not sure is it possible\n        pass\n\n\ndef _cache_hit(wrapped, key):\n    wrapped.hits += 1\n    __cache_touch(wrapped, key)\n\n\ndef _cache_miss(wrapped, key):\n    wrapped.misses += 1\n    __cache_touch(wrapped, key)\n\n\ndef _get_loop(cls, kwargs, fn, fn_args, fn_kwargs, *, loop):\n    if isinstance(loop, str):\n        assert cls ^ kwargs, 'choose self.loop or kwargs[\"loop\"]'\n\n        if cls:\n            _self = getattr(fn, '__self__', None)\n\n            if _self is None:\n                assert fn_args, 'seems not unbound function'\n                _self = fn_args[0]\n\n            _loop = getattr(_self, loop)\n        else:\n            _loop = fn_kwargs[loop]\n    elif loop is None:\n        _loop = asyncio.get_event_loop()\n    else:\n        _loop = loop\n\n    return _loop\n\n\ndef alru_cache(\n    fn=None,\n    maxsize=128,\n    typed=False,\n    expiration_time=None,\n    *,\n    cls=False,\n    kwargs=False,\n    cache_exceptions=True,\n    loop=None\n):\n    def wrapper(fn):\n        _origin = unpartial(fn)\n\n        if not asyncio.iscoroutinefunction(_origin):\n            raise RuntimeError(\n                'Coroutine function is required, got {}'.format(fn))\n\n        # functools.partialmethod support\n        if hasattr(fn, '_make_unbound_method'):\n            fn = fn._make_unbound_method()\n\n        @wraps(fn)\n        @asyncio.coroutine\n        def wrapped(*fn_args, **fn_kwargs):\n            if wrapped.closed:\n                raise RuntimeError(\n                    'alru_cache is closed for {}'.format(wrapped))\n\n            _loop = _get_loop(\n                cls,\n                kwargs,\n                wrapped._origin,\n                fn_args,\n                fn_kwargs,\n                loop=loop\n            )\n\n            key = _make_key(fn_args, fn_kwargs, typed)\n\n            if wrapped._cache.get(key) is not None:\n                if expiration_time is None:\n                    fut = wrapped._cache.get(key)\n\n                    if not fut.done():\n                        _cache_hit(wrapped, key)\n                        return (yield from asyncio.shield(fut, loop=_loop))\n\n                    exc = fut._exception\n\n                    if exc is None or cache_exceptions:\n                        _cache_hit(wrapped, key)\n                        return fut.result()\n\n                    # exception here and cache_exceptions == False\n                    wrapped._cache.pop(key)\n\n                else:\n                    fut = wrapped._cache.get(key).get(\"fut\")\n                    fut_time = wrapped._cache.get(key).get(\"time\")\n\n                    if not fut.done():\n                        _cache_hit(wrapped, key)\n                        return (yield from asyncio.shield(fut, loop=_loop))\n\n                    exc = fut._exception\n\n                    if (\n                        exc is None or cache_exceptions\n                    ) and time() - fut_time < expiration_time:\n                        _cache_hit(wrapped, key)\n                        return fut.result()\n\n                    # exception here and cache_exceptions == False\n                    # or result expires\n                    wrapped._cache.pop(key)\n\n            fut = create_future(loop=_loop)\n            coro = fn(*fn_args, **fn_kwargs)\n            task = ensure_future(coro, loop=_loop)\n            task.add_done_callback(partial(_done_callback, fut))\n\n            wrapped.tasks.add(task)\n            task.add_done_callback(wrapped.tasks.remove)\n\n            if expiration_time is None:\n                wrapped._cache[key] = task\n            else:\n                wrapped._cache[key] = {\"fut\": task, \"time\": time()}\n\n            if maxsize is not None and len(wrapped._cache) > maxsize:\n                wrapped._cache.popitem(last=False)\n\n            _cache_miss(wrapped, key)\n            return (yield from asyncio.shield(fut, loop=_loop))\n\n        _cache_clear(wrapped)\n        wrapped._origin = _origin\n        wrapped.closed = False\n        wrapped.cache_info = partial(_cache_info, wrapped, maxsize)\n        wrapped.cache_clear = partial(_cache_clear, wrapped)\n        wrapped.invalidate = partial(_cache_invalidate, wrapped, typed)\n        wrapped.close = partial(_close, wrapped)\n        wrapped.open = partial(_open, wrapped)\n\n        return wrapped\n\n    if fn is None:\n        return wrapper\n\n    if callable(fn) or hasattr(fn, '_make_unbound_method'):\n        return wrapper(fn)\n\n    raise NotImplementedError('{} decorating is not supported'.format(fn))\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import asyncio\nimport time\n\nimport pytest\n\nfrom async_lru import alru_cache\n\npytestmark = pytest.mark.asyncio\n\n\nasync def test_expiration(check_lru, loop):\n    @alru_cache(maxsize=4, expiration_time=2, loop=loop)\n    async def coro(val):\n        return val\n\n    inputs = [1, 2, 3]\n    coros = [coro(v) for v in inputs]\n    ret = await asyncio.gather(*coros, loop=loop)\n    assert ret == inputs\n    check_lru(coro, hits=0, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(1)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(3)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=4, cache=3, tasks=0, maxsize=4)\n"}
{"prompt":"\n\n### openpyxl\/pivot\/tests\/test_fields.py ###\n\n# Copyright (c) 2010-2019 openpyxl\nimport pytest\n\nfrom datetime import datetime\n\nfrom openpyxl.xml.functions import fromstring, tostring\nfrom openpyxl.tests.helper import compare_xml\n\n@pytest.fixture\ndef Error():\n    from ..record import Error\n    return Error\n\n\nclass TestError:\n\n    def test_ctor(self, Error):\n        error = Error(v=\"error\")\n        xml = tostring(error.to_tree())\n        expected = \"\"\"\n        <e v=\"error\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Error):\n        src = \"\"\"\n        <e v=\"error\" \/>\n        \"\"\"\n        node = fromstring(src)\n        error = Error.from_tree(node)\n        assert error == Error(v=\"error\")\n\n\n@pytest.fixture\ndef Boolean():\n    from ..record import Boolean\n    return Boolean\n\n\nclass TestBoolean:\n\n    def test_ctor(self, Boolean):\n        boolean = Boolean()\n        xml = tostring(boolean.to_tree())\n        expected = \"\"\"\n        <b v=\"0\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Boolean):\n        src = \"\"\"\n        <b \/>\n        \"\"\"\n        node = fromstring(src)\n        boolean = Boolean.from_tree(node)\n        assert boolean == Boolean()\n\n\n@pytest.fixture\ndef Missing():\n    from ..record import Missing\n    return Missing\n\n\nclass TestMissing:\n\n    def test_ctor(self, Missing):\n        missing = Missing()\n        xml = tostring(missing.to_tree())\n        expected = \"\"\"\n        <m \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Missing):\n        src = \"\"\"\n        <m \/>\n        \"\"\"\n        node = fromstring(src)\n        missing = Missing.from_tree(node)\n        assert missing == Missing()\n\n\n@pytest.fixture\ndef Number():\n    from ..record import Number\n    return Number\n\n\nclass TestNumber:\n\n    def test_ctor(self, Number):\n        number = Number(v=24)\n        xml = tostring(number.to_tree())\n        expected = \"\"\"\n        <n v=\"24\"\/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Number):\n        src = \"\"\"\n        <n v=\"15\" \/>\n        \"\"\"\n        node = fromstring(src)\n        number = Number.from_tree(node)\n        assert number == Number(v=15)\n\n\n@pytest.fixture\ndef Text():\n    from ..record import Text\n    return Text\n\n\nclass TestText:\n\n    def test_ctor(self, Text):\n        text = Text(v=\"UCLA\")\n        xml = tostring(text.to_tree())\n        expected = \"\"\"\n        <s v=\"UCLA\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Text):\n        src = \"\"\"\n        <s v=\"UCLA\" \/>\n        \"\"\"\n        node = fromstring(src)\n        text = Text.from_tree(node)\n        assert text == Text(v=\"UCLA\")\n\n@pytest.fixture\ndef Index():\n    from ..record import Index\n    return Index\n\n\nclass TestIndex:\n\n    def test_ctor(self, Index):\n        record = Index()\n        xml = tostring(record.to_tree())\n        expected = \"\"\"\n        <x v=\"0\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Index):\n        src = \"\"\"\n        <x v=\"1\" \/>\n        \"\"\"\n        node = fromstring(src)\n        record = Index.from_tree(node)\n        assert record == Index(v=1)\n\n\n@pytest.fixture\ndef DateTimeField():\n    from ..record import DateTimeField\n    return DateTimeField\n\n\nclass TestDateTimeField:\n\n    def test_ctor(self, DateTimeField):\n        record = DateTimeField(v=datetime(2016, 3, 24))\n        xml = tostring(record.to_tree())\n        expected = \"\"\"\n        <d v=\"2016-03-24T00:00:00\"\/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, DateTimeField):\n        src = \"\"\"\n        <d v=\"2016-03-24T00:00:00\"\/>\n        \"\"\"\n        node = fromstring(src)\n        record = DateTimeField.from_tree(node)\n        assert record == DateTimeField(v=datetime(2016, 3, 24))\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright (c) 2010-2019 openpyxl\nimport pytest\n\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nfrom openpyxl.packaging.manifest import Manifest\nfrom openpyxl.xml.functions import fromstring, tostring\nfrom openpyxl.tests.helper import compare_xml\n\nfrom .test_fields import (\n    Index,\n    Number,\n    Text,\n)\n\n@pytest.fixture\ndef Record():\n    from ..record import Record\n    return Record\n\n\nclass TestRecord:\n\n    def test_ctor(self, Record, Number, Text, Index):\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = n + s + x\n        field = Record(_fields=fields)\n        xml = tostring(field.to_tree())\n        expected = \"\"\"\n        <r>\n          <n v=\"1\"\/>\n          <n v=\"25\"\/>\n          <s v=\"2014-03-24\"\/>\n          <x v=\"0\"\/>\n          <x v=\"0\"\/>\n          <x v=\"0\"\/>\n        <\/r>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Record, Number, Text, Index):\n        src = \"\"\"\n        <r>\n          <n v=\"1\"\/>\n          <x v=\"0\"\/>\n          <s v=\"2014-03-24\"\/>\n          <x v=\"0\"\/>\n          <n v=\"25\"\/>\n          <x v=\"0\"\/>\n        <\/r>\n        \"\"\"\n        node = fromstring(src)\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = [\n            Number(v=1),\n            Index(),\n            Text(v=\"2014-03-24\"),\n            Index(),\n            Number(v=25),\n            Index(),\n        ]\n        field = Record.from_tree(node)\n        assert field == Record(_fields=fields)\n\n\n@pytest.fixture\ndef RecordList():\n    from ..record import RecordList\n    return RecordList\n\n\nclass TestRecordList:\n\n    def test_ctor(self, RecordList):\n        cache = RecordList()\n        xml = tostring(cache.to_tree())\n        expected = \"\"\"\n        <pivotCacheRecords xmlns=\"http:\/\/schemas.openxmlformats.org\/spreadsheetml\/2006\/main\"\n           count=\"0\" \/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, RecordList):\n        src = \"\"\"\n        <pivotCacheRecords count=\"0\" \/>\n        \"\"\"\n        node = fromstring(src)\n        cache = RecordList.from_tree(node)\n        assert cache == RecordList()\n\n\n    def test_write(self, RecordList):\n        out = BytesIO()\n        archive = ZipFile(out, mode=\"w\")\n        manifest = Manifest()\n\n        records = RecordList()\n        xml = tostring(records.to_tree())\n        records._write(archive, manifest)\n        manifest.append(records)\n\n        assert archive.namelist() == [records.path[1:]]\n        assert manifest.find(records.mime_type)\n"}
{"prompt":"\n\n### localstack\/utils\/objects.py ###\n\nimport re\nfrom typing import Any, Callable, Dict, List, Optional, Set, Type, Union\n\nfrom .collections import ensure_list\nfrom .strings import first_char_to_lower\n\nComplexType = Union[List, Dict, object]\n\n\nclass ArbitraryAccessObj:\n    \"\"\"Dummy object that can be arbitrarily accessed - any attributes, as a callable, item assignment, ...\"\"\"\n\n    def __init__(self, name=None):\n        self.name = name\n\n    def __getattr__(self, name, *args, **kwargs):\n        return ArbitraryAccessObj(name)\n\n    def __call__(self, *args, **kwargs):\n        if self.name in [\"items\", \"keys\", \"values\"] and not args and not kwargs:\n            return []\n        return ArbitraryAccessObj()\n\n    def __getitem__(self, *args, **kwargs):\n        return ArbitraryAccessObj()\n\n    def __setitem__(self, *args, **kwargs):\n        return ArbitraryAccessObj()\n\n\nclass Mock(object):\n    \"\"\"Dummy class that can be used for mocking custom attributes.\"\"\"\n\n    pass\n\n\nclass ObjectIdHashComparator:\n    \"\"\"Simple wrapper class that allows us to create a hashset using the object id(..) as the entries' hash value\"\"\"\n\n    def __init__(self, obj):\n        self.obj = obj\n        self._hash = id(obj)\n\n    def __hash__(self):\n        return self._hash\n\n    def __eq__(self, other):\n        # assumption here is that we're comparing only against ObjectIdHash instances!\n        return self.obj == other.obj\n\n\nclass SubtypesInstanceManager:\n    \"\"\"Simple instance manager base class that scans the subclasses of a base type for concrete named\n    implementations, and lazily creates and returns (singleton) instances on demand.\"\"\"\n\n    _instances: Dict[str, \"SubtypesInstanceManager\"]\n\n    @classmethod\n    def get(cls, subtype_name: str, raise_if_missing: bool = True):\n        instances = cls.instances()\n        base_type = cls.get_base_type()\n        instance = instances.get(subtype_name)\n        if instance is None:\n            # lazily load subtype instance (required if new plugins are dynamically loaded at runtime)\n            for clazz in get_all_subclasses(base_type):\n                impl_name = clazz.impl_name()\n                if impl_name not in instances:\n                    instances[impl_name] = clazz()\n            instance = instances.get(subtype_name)\n        if not instance and raise_if_missing:\n            raise NotImplementedError(\n                f\"Unable to find implementation named '{subtype_name}' for base type {base_type}\"\n            )\n        return instance\n\n    @classmethod\n    def instances(cls) -> Dict[str, \"SubtypesInstanceManager\"]:\n        base_type = cls.get_base_type()\n        if not hasattr(base_type, \"_instances\"):\n            base_type._instances = {}\n        return base_type._instances\n\n    @staticmethod\n    def impl_name() -> str:\n        \"\"\"Name of this concrete subtype - to be implemented by subclasses.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def get_base_type(cls) -> Type:\n        \"\"\"Get the base class for which instances are being managed - can be customized by subtypes.\"\"\"\n        return cls\n\n\n# this requires that all subclasses have been imported before(!)\ndef get_all_subclasses(clazz: Type) -> Set[Type]:\n    \"\"\"Recursively get all subclasses of the given class.\"\"\"\n    result = set()\n    subs = clazz.__subclasses__()\n    for sub in subs:\n        result.add(sub)\n        result.update(get_all_subclasses(sub))\n    return result\n\n\ndef fully_qualified_class_name(klass: Type) -> str:\n    return f\"{klass.__module__}.{klass.__name__}\"\n\n\ndef not_none_or(value: Optional[Any], alternative: Any) -> Any:\n    \"\"\"Return 'value' if it is not None, or 'alternative' otherwise.\"\"\"\n    return value if value is not None else alternative\n\n\ndef recurse_object(obj: ComplexType, func: Callable, path: str = \"\") -> ComplexType:\n    \"\"\"Recursively apply `func` to `obj` (might be a list, dict, or other object).\"\"\"\n    obj = func(obj, path=path)\n    if isinstance(obj, list):\n        for i in range(len(obj)):\n            tmp_path = \"%s[%s]\" % (path or \".\", i)\n            obj[i] = recurse_object(obj[i], func, tmp_path)\n    elif isinstance(obj, dict):\n        for k, v in obj.items():\n            tmp_path = \"%s%s\" % (f\"{path}.\" if path else \"\", k)\n            obj[k] = recurse_object(v, func, tmp_path)\n    return obj\n\n\ndef keys_to_lower(obj: ComplexType, skip_children_of: List[str] = None) -> ComplexType:\n    \"\"\"Recursively changes all dict keys to first character lowercase. Skip children\n    of any elements whose names are contained in skip_children_of (e.g., ['Tags'])\"\"\"\n    skip_children_of = ensure_list(skip_children_of or [])\n\n    def fix_keys(o, path=\"\", **kwargs):\n        if any(re.match(r\"(^|.*\\.)%s($|[.\\[].*)\" % k, path) for k in skip_children_of):\n            return o\n        if isinstance(o, dict):\n            for k, v in dict(o).items():\n                o.pop(k)\n                o[first_char_to_lower(k)] = v\n        return o\n\n    result = recurse_object(obj, fix_keys)\n    return result\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom localstack.utils.objects import SubtypesInstanceManager\n\n\ndef test_subtypes_instance_manager():\n    class BaseClass(SubtypesInstanceManager):\n        def foo(self):\n            pass\n\n    class C1(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c1\"\n\n        def foo(self):\n            return \"bar\"\n\n    instance1 = BaseClass.get(\"c1\")\n    assert instance1\n    assert BaseClass.get(\"c1\") == instance1\n    assert instance1.foo() == \"bar\"\n    with pytest.raises(Exception):\n        assert BaseClass.get(\"c2\")\n\n    class C2(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c2\"\n\n        def foo(self):\n            return \"baz\"\n\n    instance2 = BaseClass.get(\"c2\")\n    assert BaseClass.get(\"c2\") == instance2\n    assert instance2.foo() == \"baz\"\n"}
{"prompt":"\n\n### my_blog\/users\/forms.py ###\n\nfrom django.contrib.auth import forms as admin_forms\nfrom django.contrib.auth import get_user_model\nfrom django.utils.translation import gettext_lazy as _\n\nUser = get_user_model()\n\n\nclass UserChangeForm(admin_forms.UserChangeForm):\n    class Meta(admin_forms.UserChangeForm.Meta):\n        model = User\n\n\nclass UserCreationForm(admin_forms.UserCreationForm):\n    class Meta(admin_forms.UserCreationForm.Meta):\n        model = User\n\n        error_messages = {\n            \"username\": {\"unique\": _(\"This username has already been taken.\")}\n        }\n\n\n### my_blog\/users\/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for My Blog.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom my_blog.users.forms import UserCreationForm\nfrom my_blog.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"}
{"prompt":"\n\n### migri\/backends\/postgresql.py ###\n\nimport re\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Optional\n\nimport asyncpg\n\nfrom migri.elements import Query\nfrom migri.interfaces import ConnectionBackend, TransactionBackend\n\n\n@dataclass\nclass PostgreSQLConnection(ConnectionBackend):\n    _dialect = \"postgresql\"\n    connection: Optional[asyncpg.Connection] = None\n\n    @staticmethod\n    def _compile(query: Query) -> dict:\n        q = query.statement\n        v = []\n\n        if query.placeholders:\n            keys = list(query.values.keys())\n            v = [query.values[k] for k in keys]\n\n            for p in set(query.placeholders):\n                # Find index of key and add 1\n                replacement = f\"${keys.index(p.replace('$', '')) + 1}\"\n\n                # Substitute\n                q = re.sub(f\"\\\\{p}\", replacement, q)\n\n        return {\"query\": q, \"values\": v}\n\n    async def connect(self):\n        if not self.db:\n            if self.connection is not None:\n                self.db = self.connection\n            else:\n                self.db = await asyncpg.connect(\n                    host=self.db_host,\n                    port=self.db_port,\n                    user=self.db_user,\n                    password=self.db_pass,\n                    database=self.db_name,\n                )\n\n    async def disconnect(self):\n        if self.connection is None:\n            # don't close the connection if we didn't create it\n            await self.db.close()\n\n    async def execute(self, query: Query):\n        q = self._compile(query)\n        await self.db.execute(q[\"query\"], *q[\"values\"])\n\n    async def fetch(self, query: Query) -> Dict[str, Any]:\n        q = self._compile(query)\n        res = await self.db.fetchrow(q[\"query\"], *q[\"values\"])\n        return dict(res)\n\n    async def fetch_all(self, query: Query) -> List[Dict[str, Any]]:\n        q = self._compile(query)\n        res = await self.db.fetch(q[\"query\"], *q[\"values\"])\n\n        return [dict(r) for r in res]\n\n    def transaction(self) -> TransactionBackend:\n        return PostgreSQLTransaction(self)\n\n\nclass PostgreSQLTransaction(TransactionBackend):\n    def __init__(self, connection: ConnectionBackend):\n        super().__init__(connection)\n        self._committed = False\n        self._transaction = None\n\n    async def start(self):\n        self._transaction = self._connection.database.transaction()\n        await self._transaction.start()\n\n    async def commit(self):\n        await self._transaction.commit()\n        self._committed = True\n\n    async def rollback(self):\n        if not self._committed:\n            await self._transaction.rollback()\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom migri.backends.postgresql import PostgreSQLConnection\nfrom test import QUERIES\n\n\n@pytest.mark.parametrize(\n    \"query_element,expected_query,expected_values\",\n    [\n        (QUERIES[0], \"INSERT INTO mytable (a) VALUES ($1), ($2)\", [150, 300]),\n        (QUERIES[1], \"UPDATE tbl SET info=$2 WHERE id=$1\", [39, \"ok\"]),\n        (QUERIES[2], \"SELECT * FROM school\", []),\n        (\n            QUERIES[3],\n            \"SELECT * FROM val WHERE (value < $1 AND status = $3) \"\n            \"OR (value > $2 AND status = $3)\",\n            [20, 100, \"ok\"],\n        ),\n    ],\n)\ndef test_compile(query_element, expected_query, expected_values):\n    backend = PostgreSQLConnection(\"postgres\")\n    assert backend._compile(query_element) == {\n        \"query\": expected_query,\n        \"values\": expected_values,\n    }\n"}
{"prompt":"\n\n### pytest_selenium_enhancer\/pytest_selenium_enhancer.py ###\n\n# pylint: disable=function-redefined\n# pylint: disable=import-outside-toplevel\n# pylint: disable=no-member\n# pylint: disable=too-many-statements\n# pylint: disable=unused-variable\n\nimport base64\nfrom io import BytesIO\nimport cv2\nimport numpy\nfrom PIL import Image\nfrom selenium.common.exceptions import WebDriverException\n\n\ndef add_custom_commands():\n    from selenium.webdriver.remote.webdriver import WebDriver\n    from selenium.webdriver.remote.webelement import WebElement\n\n    @add_method(WebDriver)\n    def get_full_page_screenshot_as_base64(self, elements_to_hide=None, ios_offset=0):\n        \"\"\"Gets full page screenshot of current page by automatically scroll the full width and height of the page\n                NOTE:\n                    - Does not work for infinite scrolling pages\n\n            Returns:\n            PIL.Image.Image: returns the image as Image object\n\n        \"\"\"\n        stitched_image = __take_full_page_screenshot(self, elements_to_hide, ios_offset)\n        return cv2.cvtColor(numpy.array(stitched_image), cv2.COLOR_RGB2BGR)\n\n    @add_method(WebDriver)\n    def get_full_page_screenshot_as_png(self, image_path, elements_to_hide=None, ios_offset=0):\n        \"\"\"Gets full page screenshot of current page by automatically scroll the full width and height of the page\n                NOTE:\n                    - Does not work for infinite scrolling pages\n\n            Returns:\n            PIL.Image.Image: returns the image as Image object\n\n        \"\"\"\n        stitched_image = __take_full_page_screenshot(self, elements_to_hide, ios_offset)\n        from os import makedirs\n        makedirs(image_path[:image_path.rfind('\/')], exist_ok=True)\n        stitched_image.save(image_path)\n        return cv2.imread(image_path)\n\n    @add_method(WebDriver)\n    def shadow_find_element(self, css_selector):\n        \"\"\"Returns an element by given CSS selector\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        return self.execute_script('return document.shadowRoot.querySelector(arguments[0])', css_selector)\n\n    @add_method(WebDriver)\n    def shadow_cascade_find_element(self, *args):\n        \"\"\"Returns an element by given list of CSS selectors\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        script = 'return document'\n        for arg in args:\n            script += '.querySelector(\"%s\").shadowRoot' % arg\n        script = script[:-11] + ';'\n        return self.execute_script(script)\n\n    @add_method(WebDriver)\n    def shadow_find_elements(self, css_selector):\n        \"\"\"Returns a list of elements by given of CSS selector\n\n            Returns:\n            list<WebElement>: returns the element as WebElement\n        \"\"\"\n        return self.execute_script('return document.shadowRoot.querySelectorAll(arguments[0])', css_selector)\n\n    @add_method(WebElement)\n    def shadow_find_element(self, css_selector):\n        \"\"\"Returns an element by given CSS selector\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        return self.parent.execute_script('return arguments[0].shadowRoot.querySelector(arguments[1])', self,\n                                          css_selector)\n\n    @add_method(WebElement)\n    def shadow_cascade_find_element(self, *args):\n        \"\"\"Returns an element by given list of CSS selectors\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        script = 'return arguments[0].shadowRoot'\n        for arg in args:\n            script += '.querySelector(\"%s\").shadowRoot' % arg\n        script = script[:-11] + ';'\n        return self.parent.execute_script(script, self)\n\n    @add_method(WebElement)\n    def shadow_find_elements(self, css_selector):\n        \"\"\"Returns a list of elements by given of CSS selector\n\n            Returns:\n            list<WebElement>: returns the element as WebElement\n        \"\"\"\n        return self.parent.execute_script('return arguments[0].shadowRoot.querySelectorAll(arguments[1])', self,\n                                          css_selector)\n\n    def __take_full_page_screenshot(selenium, elements_to_hide, ios_offset=0):\n        if elements_to_hide is None:\n            elements_to_hide = {\"start\": [], \"all\": [], \"end\": []}\n        device_pixel_ratio = selenium.execute_script('return ratio = window.devicePixelRatio || 1;')\n        total_width = round(\n            selenium.execute_script(\"return document.body.scrollWidth * arguments[0];\", device_pixel_ratio))\n        total_height = round(\n            selenium.execute_script(\"return document.body.scrollHeight * arguments[0];\", device_pixel_ratio))\n        viewport_width = round(\n            selenium.execute_script(\"return document.body.parentNode.clientWidth * arguments[0];\", device_pixel_ratio))\n        viewport_height = round(\n            selenium.execute_script(\"return document.body.parentNode.clientHeight * arguments[0];\", device_pixel_ratio))\n\n        rectangles = []\n        i = 0\n        while i < total_height:\n            ii = 0\n            top_height = i + viewport_height\n            if top_height > total_height:\n                top_height = total_height\n            while ii < total_width:\n                top_width = ii + viewport_width\n                if top_width > total_width:\n                    top_width = total_width\n                rectangles.append((ii, i, top_width, top_height))\n                ii = ii + viewport_width\n            i = i + viewport_height - ios_offset\n        stitched_image = Image.new('RGB', (total_width, total_height))\n        previous = None\n        i = 1\n\n        __hide_elements(selenium, elements_to_hide['all'])\n        for rectangle in rectangles:\n            if i == 1 != rectangles.__len__():\n                __hide_elements(selenium, elements_to_hide['end'])\n            if rectangle[1] != 0:\n                __hide_elements(selenium, elements_to_hide['start'])\n            if i == rectangles.__len__():\n                __show_elements(selenium, elements_to_hide['end'])\n            if previous is not None:\n                selenium.execute_script(\"window.scrollTo({0}, {1})\".format(round(rectangle[0] \/ device_pixel_ratio),\n                                                                           round(rectangle[1] \/ device_pixel_ratio)))\n                import time\n                time.sleep(3)\n            offset = (rectangle[0], rectangle[1])\n\n            image_base_64 = selenium.get_screenshot_as_base64()\n            screenshot = Image.open(BytesIO(base64.b64decode(image_base_64)))\n            screenshot = screenshot.crop((0, ios_offset, screenshot.size[0], screenshot.size[1]))\n            if viewport_width < total_width < rectangle[0] + viewport_width \\\n                    and viewport_height < total_height < rectangle[1] + viewport_height:\n                offset = (total_width - viewport_width, total_height - viewport_height)\n            elif viewport_width < total_width < rectangle[0] + viewport_width:\n                offset = (total_width - viewport_width, rectangle[1])\n            elif viewport_height < total_height < rectangle[1] + viewport_height:\n                offset = (rectangle[0], total_height - viewport_height)\n            # screenshot.save('\/Users\/spopescu\/PersonalDev\/pytest-selenium-enhancer\/tests\/screenshots\/actual\/a.png')\n            # stitched_image.save('\/Users\/spopescu\/PersonalDev\/pytest-selenium-enhancer\/tests\/screenshots\/actual\/b.png')\n            stitched_image.paste(screenshot, offset)\n            del screenshot\n            previous = rectangle\n            i += 1\n\n        return stitched_image\n\n    def __show_elements(selenium, elements):\n        \"\"\"\n        Usage:\n            Hide elements from web page\n        Args:\n            selenium(str) : WebDriver \/ Appium instance\n            elements (list) : The element on web page to be hide\n        Returns:\n            N\/A\n        Raises:\n            N\/A\n        \"\"\"\n        if elements is not None:\n            try:\n                for element in elements:\n                    selenium.execute_script(\"arguments[0].setAttribute('style', 'opacity:1;');\", element)\n            except WebDriverException as error:\n                print('Error : ', str(error))\n\n    def __hide_elements(selenium, elements):\n        \"\"\"\n        Usage:\n            Hide elements from web page\n        Args:\n            selenium(str) : WebDriver \/ Appium instance\n            elements (list) : The element on web page to be hide\n        Returns:\n            N\/A\n        Raises:\n            N\/A\n        \"\"\"\n        if elements is not None:\n            try:\n                for element in elements:\n                    selenium.execute_script(\"arguments[0].setAttribute('style', 'opacity:0;');\", element)\n            except WebDriverException as error:\n                print('Error : ', str(error))\n\n\ndef add_method(cls):\n    def decorator(func):\n        from functools import wraps\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            return func(self, *args, **kwargs)\n\n        setattr(cls, func.__name__, wrapper)\n        # Note we are not binding func, but wrapper which accepts self but does exactly the same as func\n        return func  # returning func means func can still be used normally\n\n    return decorator\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"Pytest plugin entry point. Used for any fixtures needed.\"\"\"\nimport pytest\nfrom .pytest_selenium_enhancer import add_custom_commands\n\n\n@pytest.fixture(scope='session')\ndef selenium_patcher():\n    \"\"\"Add custom .\"\"\"\n    add_custom_commands()\n"}
{"prompt":"\n\n### tickit\/devices\/eiger\/eiger_status.py ###\n\nfrom dataclasses import dataclass, field, fields\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, List\n\n\nclass State(Enum):\n    \"\"\"Possible states of the Eiger detector.\"\"\"\n\n    NA = \"na\"\n    READY = \"ready\"\n    INITIALIZE = \"initialize\"\n    CONFIGURE = \"configure\"\n    ACQUIRE = \"acquire\"\n    IDLE = \"idle\"\n    TEST = \"test\"\n    ERROR = \"error\"\n\n\n@dataclass\nclass EigerStatus:\n    \"\"\"Stores the status parameters of the Eiger detector.\"\"\"\n\n    state: State = field(default=State.NA)\n    errors: List[str] = field(default_factory=list)\n    th0_temp: float = field(default=24.5)\n    th0_humidity: float = field(default=0.2)\n    time: datetime = field(default=datetime.now())\n    dcu_buffer_free: float = field(default=0.5)\n\n    def __getitem__(self, key: str) -> Any:  # noqa: D105\n        f = {}\n        for field_ in fields(self):\n            f[field_.name] = vars(self)[field_.name]\n        return f[key]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nfrom tickit.devices.eiger.eiger_status import EigerStatus\n\n# # # # # EigerStatus Tests # # # # #\n\n\n@pytest.fixture\ndef eiger_status() -> EigerStatus:\n    return EigerStatus()\n\n\ndef test_eiger_status_constructor():\n    EigerStatus()\n\n\ndef test_eiger_status_getitem(eiger_status):\n    assert 24.5 == eiger_status[\"th0_temp\"]\n"}
{"prompt":"\n\n### sinergym\/utils\/rewards.py ###\n\n\"\"\"Implementation of different types of rewards.\"\"\"\n\nfrom datetime import datetime\nfrom math import exp\nfrom typing import Dict, List, Tuple\n\nfrom ..utils.common import get_season_comfort_range\n\n\nclass LinearReward():\n\n    def __init__(self,\n                 energy_weight: float = 0.5,\n                 lambda_energy: float = 1e-4,\n                 lambda_temperature: float = 1.0\n                 ):\n        \"\"\"Simple reward considering absolute difference to temperature comfort.\n\n        .. math::\n            R = - W * lambda_E * power - (1 - W) * lambda_T * (max(T - T_{low}, 0) + max(T_{up} - T, 0))\n\n        Args:\n            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n            lambda_energy (float, optional): Constant for removing dimensions from power(1\/W). Defaults to 1e-4.\n            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1\/C). Defaults to 1.0.\n        \"\"\"\n\n        # Variables\n        self.W_energy = energy_weight\n        self.lambda_energy = lambda_energy\n        self.lambda_temp = lambda_temperature\n\n    def calculate(self,\n                  power: float,\n                  temperatures: List[float],\n                  month: int,\n                  day: int) \\\n            -> Tuple[float, Dict[str, float]]:\n        \"\"\"Reward calculus.\n\n        Args:\n            power (float): Power consumption.\n            temperatures (List[float]): Indoor temperatures (one per zone).\n            month (int): Current month.\n            day (int): Current day.\n\n        Returns:\n            Tuple[float, Dict[str, float]]: Reward value.\n        \"\"\"\n        # Energy term\n        reward_energy = - self.lambda_energy * power\n\n        # Comfort term\n        range_T = get_season_comfort_range(month, day)\n        delta_T = 0.0\n        for temperature in temperatures:\n            delta_T += 0.0 if temperature >= range_T[0] and temperature <= range_T[1] else min(\n                abs(range_T[0] - temperature), abs(temperature - range_T[1]))\n        reward_comfort = - self.lambda_temp * delta_T\n\n        # Weighted sum of both terms\n        reward = self.W_energy * reward_energy + \\\n            (1.0 - self.W_energy) * reward_comfort\n        terms = {'reward_energy': reward_energy,\n                 'reward_comfort': reward_comfort}\n\n        return reward, terms\n\n\nclass ExpReward():\n\n    def __init__(self,\n                 energy_weight: float = 0.5,\n                 lambda_energy: float = 1e-4,\n                 lambda_temperature: float = 1.0\n                 ):\n        \"\"\"Reward considering exponential absolute difference to temperature comfort.\n\n        .. math::\n            R = - W * lambda_E * power - (1 - W) * lambda_T * exp( (max(T - T_{low}, 0) + max(T_{up} - T, 0)) )\n\n        Args:\n            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n            lambda_energy (float, optional): Constant for removing dimensions from power(1\/W). Defaults to 1e-4.\n            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1\/C). Defaults to 1.0.\n        \"\"\"\n\n        # Variables\n        self.W_energy = energy_weight\n        self.lambda_energy = lambda_energy\n        self.lambda_temp = lambda_temperature\n\n    def calculate(self, power: float, temperatures: List[float],\n                  month: int, day: int) -> Tuple[float, Dict[str, float]]:\n        \"\"\"Reward calculus.\n\n        Args:\n            power (float): Power consumption.\n            temperatures (List[float]): Indoor temperatures (one per zone).\n            month (int): Current month.\n            day (int): Current day.\n\n        Returns:\n            Tuple[float, Dict[str, float]]: Reward value.\n        \"\"\"\n        # Energy term\n        reward_energy = - self.lambda_energy * power\n\n        # Comfort term\n        range_T = get_season_comfort_range(month, day)\n        delta_T = 0.0\n        for temperature in temperatures:\n            delta_T += 0.0 if temperature >= range_T[0] and temperature <= range_T[1] else exp(\n                min(abs(range_T[0] - temperature), abs(temperature - range_T[1])))\n        reward_comfort = - self.lambda_temp * delta_T\n\n        # Weighted sum of both terms\n        reward = self.W_energy * reward_energy + \\\n            (1.0 - self.W_energy) * reward_comfort\n        terms = {'reward_energy': reward_energy,\n                 'reward_comfort': reward_comfort}\n\n        return reward, terms\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\n\nimport sinergym.utils.rewards as R\n\n\n@pytest.mark.parametrize(\n    'power,temperatures,month,day,reward,reward_energy,reward_comfort',\n    [\n        # Input 1\n        (\n            186.5929171535975,\n            [22.16742570092868],\n            3,\n            31,\n            -0.009329645857679876,\n            -0.018659291715359752,\n            -0.0\n        ),\n        # Input 2\n        (\n            688.0477550424935,\n            [26.7881162590194],\n            3,\n            30,\n            -1.6784605172618248,\n            -0.06880477550424935,\n            -3.2881162590194\n        ),\n        # Input 3\n        (\n            23168.30752221127,\n            [20.37505026953311],\n            2,\n            25,\n            -1.1584153761105636,\n            -2.316830752221127,\n            -0.0\n        ),\n    ]\n)\ndef test_calculate(\n        simple_reward,\n        power,\n        temperatures,\n        month,\n        day,\n        reward,\n        reward_energy,\n        reward_comfort):\n    result = simple_reward.calculate(power, temperatures, month, day)\n    assert result[0] == reward\n    assert result[1]['reward_energy'] == reward_energy\n    assert result[1]['reward_comfort'] == reward_comfort\n"}
{"prompt":"\n\n### bokeh\/_testing\/util\/api.py ###\n\n#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n''' Provide utility classes and functions useful for testing Bokeh itself.\n\n'''\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nimport logging\nlog = logging.getLogger(__name__)\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Standard library imports\nimport importlib\n\n# External imports\nimport pytest\n\n# Bokeh imports\n\n#-----------------------------------------------------------------------------\n# Globals and constants\n#-----------------------------------------------------------------------------\n\n__all__ = (\n    'verify_all',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\ndef verify_all(module, ALL):\n    '''\n\n    '''\n    class Test___all__(object):\n        def test___all__(self):\n            if isinstance(module, str):\n                mod = importlib.import_module(module)\n            else:\n                mod = module\n            assert hasattr(mod, \"__all__\")\n            assert mod.__all__ == ALL, \"for module %s, expected: %r, actual: %r\" % (mod.__name__, set(ALL)-set(mod.__all__), set(mod.__all__)-set(ALL))\n\n        @pytest.mark.parametrize('name', ALL)\n        @pytest.mark.unit\n        def test_contents(self, name):\n            if isinstance(module, str):\n                mod = importlib.import_module(module)\n            else:\n                mod = module\n            assert hasattr(mod, name)\n    return Test___all__\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nimport pytest ; pytest\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Standard library imports\n\n# External imports\n\n# Bokeh imports\nfrom bokeh._testing.util.api import verify_all\n\n# Module under test\n#import bokeh.sampledata.glucose as bsg\n\n#-----------------------------------------------------------------------------\n# Setup\n#-----------------------------------------------------------------------------\n\nALL = (\n    'data',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\nTest___all__ = pytest.mark.sampledata(verify_all(\"bokeh.sampledata.glucose\", ALL))\n\n@pytest.mark.sampledata\ndef test_data(pd):\n    import bokeh.sampledata.glucose as bsg\n    assert isinstance(bsg.data, pd.DataFrame)\n\n    # don't check detail for external data\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n"}
{"prompt":"\n\n### qualle\/label_calibration\/simple.py ###\n\n#  Copyright 2021 ZBW  – Leibniz Information Centre for Economics\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\nfrom typing import List\n\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils.validation import check_is_fitted\n\nfrom stwfsapy.text_features import mk_text_features\n\n\nclass LabelCalibrator(BaseEstimator, RegressorMixin):\n\n    def __init__(self, regressor=ExtraTreesRegressor()):\n        self.regressor = regressor\n\n    def fit(self, X: List[str], y):\n        features = mk_text_features()\n        self.pipeline_ = Pipeline(\n            [(\"features\", features), (\"regressor\", self.regressor)]\n        )\n        self.pipeline_.fit(X, y)\n        return self\n\n    def predict(self, X: List[str]):\n        check_is_fitted(self)\n        return self.pipeline_.predict(X)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"#  Copyright 2021 ZBW  – Leibniz Information Centre for Economics\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n\nimport numpy as np\nimport pytest\nfrom sklearn.exceptions import NotFittedError\nfrom stwfsapy.text_features import mk_text_features\n\nfrom qualle.label_calibration.simple import LabelCalibrator\nfrom tests.common import DummyRegressor\n\n\n@pytest.fixture\ndef calibrator():\n    return LabelCalibrator(DummyRegressor())\n\n\ndef test_lc_predict(calibrator, X):\n    calibrator.fit(X, [3, 5])\n    assert np.array_equal(calibrator.predict(X), [0, 1])\n\n\ndef test_lc_predict_without_fit_raises_exc(calibrator, X):\n    with pytest.raises(NotFittedError):\n        calibrator.predict(X)\n\n\ndef test_lc_fit_fits_regressor_with_txt_features(calibrator, X, mocker):\n    y = [3, 5]\n    txt_features = mk_text_features().fit(X)\n    X_transformed = txt_features.transform(X)\n\n    spy = mocker.spy(calibrator.regressor, 'fit')\n    calibrator.fit(X, y)\n    spy.assert_called_once()\n    assert (spy.call_args[0][0].toarray() == X_transformed.toarray()).all()\n    assert spy.call_args[0][1] == y\n"}
{"prompt":"\n\n### cem\/backend.py ###\n\n#######################################################\n# Author: Qixin Hu\n# Email:  hqx11@hust.edu.cn\n# Version: 1.0\n#######################################################\n# The backends contain Numpy and CuPy(optional).\n# Default one is Numpy, you can choose:\n#   1. numpy\n#   2. cupy (GPU if it's available)\n# we use int64 and float64 as our data type.\n#######################################################\n# Usage: In the fdtd main program, call:\n#\n#     from .backend import backend as bd\n#\n# Then replace np\/cp with bd, e.g:\n# 1. a = np.array([1,2,3]) ---> a = bd.array([1,2,3])\n# 2. np.sin(a)             ---> bd.sin(a)\n# 3. np.exp(a)             ---> bd.exp(a)\n#\n# You can change different backend by call:\n# bd.set_backend('cupy') or bd.set_backend('numpy')\n#######################################################\n\n# Basic(default) numpy backend\nimport numpy\n\n# Optional cupy backend\ntry:\n    import cupy\n    CUPY_AVAILABLE = True\nexcept ImportError:\n    CUPY_AVAILABLE = False\n\n# You can add other backend here (e.g: Pytorch, TensorFlow, Mars...)\n\n\nclass Backend:\n    \"\"\" Basic backend class \"\"\"\n\n    def __repr__(self):\n        return self.__class__.__name__\n\n\n    def set_backend(self, name: str):\n        \"\"\"\n        Set backend to FDTD simulation program.\n        Two backends: 'cupy' and 'numpy'\n        \"\"\"\n\n        # check if cupy is installed.\n        if name == 'cupy' and not CUPY_AVAILABLE:\n            raise RuntimeError(\n                \"\"\"\n                CuPy backend is not available. Have you installed cupy?\n                Please check https:\/\/docs.cupy.dev\/en\/stable\/install.html \n                to see how to install cupy on your device.\n                \"\"\"\n            )\n\n        if name == 'numpy':\n            self.__class__ = NumpyBackend\n        elif name == 'cupy':\n            self.__class__ = CuPyBackend\n        else:\n            raise RuntimeError(r'unknown backend \"{}\"'.format(name))\n        #\n\n# numpy backend\nclass NumpyBackend(Backend):\n    \"\"\"\n    Numpy backend class,\n    here we use np.ndarray as our bd.ndarray\n    \"\"\"\n\n    # Types\n    int = numpy.int64\n    float = numpy.float64\n\n    # Math calculation\n    # you can add more if needed\n    exp = staticmethod(numpy.exp)\n    sin = staticmethod(numpy.sin)\n    cos = staticmethod(numpy.cos)\n    sqrt = staticmethod(numpy.sqrt)\n\n    # Create array\n    # you can add more if needed\n    array = staticmethod(numpy.array)\n    ones = staticmethod(numpy.ones)\n    zeros = staticmethod(numpy.zeros)\n    arange = staticmethod(numpy.arange)\n\n    @staticmethod\n    def is_array(arr):\n        \"\"\" check if arr is a numpy ndarray.\"\"\"\n        return isinstance(arr, numpy.ndarray)\n\n    def numpy(self, arr):\n        \"\"\" if the arr is numpy.ndarray, return it. Or raise TypeError\"\"\"\n        if self.is_array(arr):\n            return arr\n        else:\n            raise TypeError(\"The input should be a numpy.ndarray.\")\n\n\nif CUPY_AVAILABLE:\n    class CuPyBackend(Backend):\n        \"\"\"\n        CuPy backend class, GPU accelerate.\n        \"\"\"\n\n        # Types\n        int = cupy.int64\n        float = cupy.float64\n\n        # Math calculation\n        # you can add more if needed\n        exp = staticmethod(cupy.exp)\n        sin = staticmethod(cupy.sin)\n        cos = staticmethod(cupy.cos)\n        sqrt = staticmethod(cupy.sqrt)\n\n        # Create array\n        array = staticmethod(cupy.array)\n        ones = staticmethod(cupy.ones)\n        zeros = staticmethod(cupy.zeros)\n        arange = staticmethod(cupy.arange)\n\n        @staticmethod\n        def is_array(arr):\n            \"\"\" check if arr is a cupy ndarray.\"\"\"\n            return isinstance(arr, cupy.ndarray)\n\n        def numpy(self, arr):\n            \"\"\"\n            Convert cupy.ndarray into numpy.ndarray.\n            The data will transfer between CPU and the GPU,\n            which is costly in terms of performance. So I\n            recommend call this function after all computation.\n            \"\"\"\n            if self.is_array(arr):\n                return cupy.asnumpy(arr)\n            else:\n                raise TypeError(\"The input should be a cupy.ndarray.\")\n\n# Default Backend: numpy\n# All the data types and operations is based on the backend.\n# User should choose backend at the very beginning.\n# By calling bd.set_backend('cupy') to set cupy as backend.\nbackend = NumpyBackend()\n\n# Test Unit\nif __name__ == '__main__':\n\n    import matplotlib.pyplot as plt\n\n    bd = backend\n    print(bd)\n    # a = bd.ones((10, 10)\n    # plt.imshow()\n    # plt.show()\n    bd.set_backend('abc')\n    print(bd)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nimport numpy as np\nimport random\n\nfrom cem.backend import backend, NumpyBackend\n\ntry:\n    from cem.backend import CuPyBackend\n    import cupy as cp\n    skip_cupy_test = False\nexcept ImportError:\n    skip_cupy_test = True\n\n\ndef test_numpy_backend():\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, NumpyBackend)\n    assert isinstance(zeros, np.ndarray)\n    assert isinstance(ones, np.ndarray)\n    assert backend.int == np.int64\n    assert backend.float == np.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).any() == np.sin(ones).any()\n    assert backend.cos(ones).any() == np.cos(ones).any()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_cupy_backend():\n    backend.set_backend('cupy')\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, CuPyBackend)\n    assert isinstance(zeros, cp.ndarray)\n    assert isinstance(ones, cp.ndarray)\n    assert backend.int == cp.int64\n    assert backend.float == cp.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).all() == cp.sin(ones).all()\n    assert backend.cos(ones).all() == cp.cos(ones).all()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_set_backend():\n    backend.set_backend('numpy')\n    assert isinstance(backend, NumpyBackend)\n    backend.set_backend('cupy')\n    assert isinstance(backend, CuPyBackend)\n"}
{"prompt":"\n\n### pymemcache\/test\/utils.py ###\n\n\"\"\"\nUseful testing utilities.\n\nThis module is considered public API.\n\n\"\"\"\n\nimport time\n\nimport six\n\nfrom pymemcache.exceptions import MemcacheIllegalInputError\nfrom pymemcache.serde import LegacyWrappingSerde\n\n\nclass MockMemcacheClient(object):\n    \"\"\"\n    A (partial) in-memory mock for Clients.\n\n    \"\"\"\n\n    def __init__(self,\n                 server=None,\n                 serde=None,\n                 serializer=None,\n                 deserializer=None,\n                 connect_timeout=None,\n                 timeout=None,\n                 no_delay=False,\n                 ignore_exc=False,\n                 default_noreply=True,\n                 allow_unicode_keys=False,\n                 encoding='ascii'):\n\n        self._contents = {}\n\n        self.serde = serde or LegacyWrappingSerde(serializer, deserializer)\n        self.allow_unicode_keys = allow_unicode_keys\n\n        # Unused, but present for interface compatibility\n        self.server = server\n        self.connect_timeout = connect_timeout\n        self.timeout = timeout\n        self.no_delay = no_delay\n        self.ignore_exc = ignore_exc\n        self.encoding = encoding\n\n    def clear(self):\n        \"\"\"Method used to clear\/reset mock cache\"\"\"\n        self._contents.clear()\n\n    def get(self, key, default=None):\n        if not self.allow_unicode_keys:\n            if isinstance(key, six.string_types):\n                try:\n                    if isinstance(key, bytes):\n                        key = key.decode().encode('ascii')\n                    else:\n                        key = key.encode('ascii')\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n\n        if key not in self._contents:\n            return default\n\n        expire, value, flags = self._contents[key]\n        if expire and expire < time.time():\n            del self._contents[key]\n            return default\n\n        return self.serde.deserialize(key, value, flags)\n\n    def get_many(self, keys):\n        out = {}\n        for key in keys:\n            value = self.get(key)\n            if value is not None:\n                out[key] = value\n        return out\n\n    get_multi = get_many\n\n    def set(self, key, value, expire=0, noreply=True, flags=0):\n        if not self.allow_unicode_keys:\n            if isinstance(key, six.string_types):\n                try:\n                    if isinstance(key, bytes):\n                        key = key.decode().encode()\n                    else:\n                        key = key.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n        if (isinstance(value, six.string_types) and\n                not isinstance(value, six.binary_type)):\n            try:\n                value = value.encode(self.encoding)\n            except (UnicodeEncodeError, UnicodeDecodeError):\n                raise MemcacheIllegalInputError\n\n        value, flags = self.serde.serialize(key, value)\n\n        if expire:\n            expire += time.time()\n\n        self._contents[key] = expire, value, flags\n        return True\n\n    def set_many(self, values, expire=None, noreply=True):\n        for key, value in six.iteritems(values):\n            self.set(key, value, expire, noreply)\n        return []\n\n    set_multi = set_many\n\n    def incr(self, key, value, noreply=False):\n        current = self.get(key)\n        present = current is not None\n        if present:\n            self.set(key, current + value, noreply=noreply)\n        return None if noreply or not present else current + value\n\n    def decr(self, key, value, noreply=False):\n        current = self.get(key)\n        if current is None:\n            return\n\n        self.set(key, current - value, noreply=noreply)\n        return current - value\n\n    def add(self, key, value, expire=None, noreply=True):\n        current = self.get(key)\n        present = current is not None\n        if not present:\n            self.set(key, value, expire, noreply)\n        return not present\n\n    def delete(self, key, noreply=True):\n        current = self._contents.pop(key, None)\n        present = current is not None\n        return noreply or present\n\n    def delete_many(self, keys, noreply=True):\n        for key in keys:\n            self.delete(key, noreply)\n        return True\n\n    def prepend(self, key, value, expire=0, noreply=None, flags=None):\n        current = self.get(key)\n        if current is not None:\n            if (isinstance(value, six.string_types) and\n                    not isinstance(value, six.binary_type)):\n                try:\n                    value = value.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n            self.set(key, value + current)\n        return True\n\n    def append(self, key, value, expire=0, noreply=None, flags=None):\n        current = self.get(key)\n        if current is not None:\n            if (isinstance(value, six.string_types) and\n                    not isinstance(value, six.binary_type)):\n                try:\n                    value = value.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n            self.set(key, current + value)\n        return True\n\n    delete_multi = delete_many\n\n    def stats(self):\n        # I make no claim that these values make any sense, but the format\n        # of the output is the same as for pymemcache.client.Client.stats()\n        return {\n            \"version\": \"MockMemcacheClient\",\n            \"rusage_user\": 1.0,\n            \"rusage_system\": 1.0,\n            \"hash_is_expanding\": False,\n            \"slab_reassign_running\": False,\n            \"inter\": \"in-memory\",\n            \"evictions\": False,\n            \"growth_factor\": 1.0,\n            \"stat_key_prefix\": \"\",\n            \"umask\": 0o644,\n            \"detail_enabled\": False,\n            \"cas_enabled\": False,\n            \"auth_enabled_sasl\": False,\n            \"maxconns_fast\": False,\n            \"slab_reassign\": False,\n            \"slab_automove\": False,\n        }\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import six\nimport pytest\n\nfrom pymemcache.test.utils import MockMemcacheClient\n\n\n@pytest.mark.unit()\ndef test_get_set():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(b\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_unicide_key():\n    client = MockMemcacheClient()\n    assert client.get(u\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(u\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_non_ascii_value():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    # This is the value of msgpack.packb('non_ascii')\n    non_ascii_str = b'\\xa9non_ascii'\n    client.set(b\"hello\", non_ascii_str)\n    assert client.get(b\"hello\") == non_ascii_str\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many():\n    client = MockMemcacheClient()\n    client.set(b\"h\", 1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": 1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(dict(h=1, e=2, z=3)))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many_non_ascii_values():\n    client = MockMemcacheClient()\n\n    # These are the values of calling msgpack.packb() on '1', '2', and '3'\n    non_ascii_1 = b'\\xa11'\n    non_ascii_2 = b'\\xa12'\n    non_ascii_3 = b'\\xa13'\n    client.set(b\"h\", non_ascii_1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": non_ascii_1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(\n                dict(h=non_ascii_1, e=non_ascii_2, z=non_ascii_3)\n             ))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_add():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.add(b\"k\", 25)\n    assert client.get(b\"k\") == 2\n\n\n@pytest.mark.unit()\ndef test_delete():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.delete(b\"k\")\n    assert client.get(b\"k\") is None\n\n\n@pytest.mark.unit()\ndef test_incr_decr():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n\n    client.incr(b\"k\", 4)\n    assert client.get(b\"k\") == 6\n\n    client.decr(b\"k\", 2)\n    assert client.get(b\"k\") == 4\n\n\n@pytest.mark.unit()\ndef test_prepand_append():\n    client = MockMemcacheClient()\n\n    client.set(b\"k\", '1')\n    client.append(b\"k\", 'a')\n    client.prepend(b\"k\", 'p')\n    assert client.get(b\"k\") == b'p1a'\n"}
{"prompt":"\n\n### infsocsol\/helpers.py ###\n\n# Copyright 2019 Alastair Pharo\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport matlab.engine\nimport numpy\nimport oct2py\nimport os\n\n# Adds the root of the project to the *lab path\ndef setroot(engine, root=None):\n    engine.addpath(os.path.join(*[p for p in [os.path.dirname(os.path.dirname(__file__)), root] if p]))\n\n# This enables engine-agnostic callbacks in the test code\nclass OctaveWithMatlabInterface:\n    def __init__(self, engine):\n        self.engine = engine\n\n    def __getattr__(self, name):\n        keymap = {\n            'nargout': 'nout'\n        }\n\n        def _feval(*args, **kwargs):\n            _kwargs = { keymap[k]: v for k, v in kwargs.items() if keymap[k] }\n            return self.engine.feval(name, *args, **_kwargs)\n\n        return _feval\n\ndef octave_engine(root=None):\n    engine = oct2py.Oct2Py()\n    setroot(engine, root)\n    return OctaveWithMatlabInterface(engine)\n\ndef matlab_engine(root=None):\n    engine = matlab.engine.start_matlab()\n    setroot(engine, root)\n    return engine\n\ndef matrix(engine, obj):\n    if engine.__class__ == OctaveWithMatlabInterface:\n        return numpy.array(obj)\n    else:\n        return matlab.double(obj)\n\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright 2019 Alastair Pharo\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nimport numpy\nimport os\nimport scipy\nfrom numpy.testing import assert_allclose\nfrom infsocsol.helpers import matrix\n\n@pytest.fixture(scope=\"module\", params=[\n    # engine    states time_step start         steps  steady steady_accuracy optim_accuracy\n    ( 'matlab', 10,    1,        (100.0, 0.5), 100,   True,  0.01,           0.009 ),\n    ( 'matlab', 20,    0.5,      (600.0, 0.6), 200,   True,  0.01,           0.015 ),\n    ( 'matlab', 40,    0.25,     (60.0, 0.1),  300,   True,  0.01,           0.018 ),\n    ( 'matlab', 10,    1,        (600.0, 1.0), 200,   False, 0.001,          None  ),\n    ( 'octave', 10,    1,        (100.0, 0.5), 100,   True,  0.001,          0.009 ),\n    ( 'octave', 20,    0.5,      (600.0, 0.6), 200,   True,  0.001,          0.015 )\n])\ndef fisheries_scenario(request):\n    return request.param\n\ndef test_fisheries_det_basic(engines, fisheries_scenario):\n    _engine, states, time_step, _start, steps, steady, steady_accuracy, optim_accuracy = fisheries_scenario\n    engine = engines[_engine]\n    start = matrix(engine, _start)\n    engine.cd(os.path.join(os.path.dirname(__file__), \"fisheries_det_basic\"))\n\n    engine.solve(float(states), float(time_step), nargout=0)\n    final = numpy.array(engine.sim_final(start, steps))\n    # This is determined by setting s\\dot = 0, which solves to 1 = x\/L + q\/r e\n    steady_one = numpy.dot(final, [1\/600, 5\/4])\n\n    if steady:\n        assert_allclose(steady_one, 1, atol=steady_accuracy)\n\n        # This is the most profitable steady state -- x = L\/2 + c\/2pq\n        profit_max_steady = numpy.array([[302.5, 0.39667]])\n        assert_allclose(final, profit_max_steady, rtol=optim_accuracy)\n    else:\n        assert steady_one > 1 + steady_accuracy\n"}
{"prompt":"\n\n### web\/tests\/factories.py ###\n\nimport factory\nfrom django.db import models\nfrom directory.models import CoopType, Coop, ContactMethod, Person\nfrom address.models import AddressField, Address\nfrom phonenumber_field.modelfields import PhoneNumberField\nfrom address.models import State, Country, Locality\nfrom faker import Faker\n\nmyFactory = Faker()\n\nclass CountryFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Country Factory\n    \"\"\"\n    class Meta:\n        model = Country\n\n    name = myFactory.name() \n    code = \"NN\"\n\n\nclass StateFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define State Factory\n    \"\"\"\n    class Meta:\n        model = State \n\n    name = \"Narnia\"\n    code = \"NN\"\n    country = factory.SubFactory(CountryFactory) \n\n\nclass LocalityFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Locality Factory\n    \"\"\"\n    class Meta:\n        model = Locality \n\n    name = \"Narnia\"\n    postal_code = \"60605\"\n    state = factory.SubFactory(StateFactory) \n\n\nclass AddressFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Address Factory\n    \"\"\"\n\n    class Meta:\n        model = 'address.Address'\n\n    street_number = \"123\"\n    route = \"Rd\"\n    raw = \"123 Fake Rd\" \n    formatted = \"123 Fake Rd.\" \n    latitude = 87.1234\n    longitude = -100.12342\n    locality = factory.SubFactory(LocalityFactory)\n\n\nclass PhoneContactMethodFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Contact Method Factory for a phone number \n    \"\"\"\n    class Meta:\n        model = ContactMethod\n\n    type = ContactMethod.ContactTypes.EMAIL\n    phone = \"8005551234\"\n\n\nclass EmailContactMethodFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Contact Method Factory for emails \n    \"\"\"\n    class Meta:\n        model = ContactMethod\n\n    type = ContactMethod.ContactTypes.EMAIL\n    email = \"test@example.com\"\n\n\nclass CoopTypeFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Coop Type Factory\n    \"\"\"\n    class Meta:\n        model = CoopType\n\n    name = \"test name\"\n\n\nclass CoopFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Coop Factory\n    \"\"\"\n    class Meta:\n        model = Coop\n\n    name = \"test model\"\n    enabled = True\n    phone = factory.SubFactory(PhoneContactMethodFactory)\n    email = factory.SubFactory(EmailContactMethodFactory) \n    web_site = \"http:\/\/www.hello.com\"\n\n    @factory.post_generation\n    def addresses(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted:\n            # A list of types were passed in, use them\n            for address in extracted:\n                self.addresses.add(address)\n        else:\n            address = AddressFactory()\n            self.addresses.add( address )\n\n    @factory.post_generation\n    def types(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted is not None:\n        #if extracted:\n            # A list of types were passed in, use them\n            #for _ in range(extracted):\n            for type in extracted:\n                self.types.add(CoopTypeFactory())\n        #else:\n        #    print(\"Creating type ...\\n\")\n        #    type = CoopTypeFactory()\n        #    self.types.add( type )\n\n\nclass PersonFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Person Factory\n    \"\"\"\n    class Meta:\n        model = Person\n\n    first_name = \"first name\"\n    last_name = \"last name\"\n\n    @factory.post_generation\n    def contact_methods(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted:\n            # A list of contact methods were passed in, use them\n            for contact_method in extracted:\n                self.contact_methods.add(contact_method)\n        else:\n            contact_method = EmailContactMethodFactory()\n            self.contact_methods.add( contact_method )\n\n    @factory.post_generation\n    def coops(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted is not None:\n        #if extracted:\n            print(\"calling this branch ...\")\n            # A list of coops were passed in, use them\n            for _ in range(extracted):\n            #for coop in extracted:\n                self.coops.add(coop)\n        else:\n            coop = CoopFactory()\n            self.coops.add( coop )\n\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"import pytest\nfrom django.test import TestCase\nfrom .factories import CoopTypeFactory, CoopFactory, AddressFactory, PhoneContactMethodFactory \nfrom directory.models import Coop, CoopType\n\n\nclass ModelTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        print(\"setUpTestData: Run once to set up non-modified data for all class methods.\")\n        #management.call_command('loaddata', 'test_data.yaml', verbosity=0)\n        pass\n\n    @pytest.mark.django_db\n    def test_phone_create(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"7739441467\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone\n        assert phone.id is not None\n\n    @pytest.mark.django_db\n    def test_phone_create_invalid_num(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"abcdefsfdsf\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone  \n        assert phone.id is not None\n        print(\"\\n\\n\\n\\n-------------id is \", id) \n\n    @pytest.mark.django_db\n    def test_coop_type_create(self):\n        \"\"\" Test coop type model \"\"\"    # create customer model instance\n        coop_type = CoopTypeFactory(name=\"Test Coop Type Name\")\n        assert coop_type.name == \"Test Coop Type Name\"\n\n    @pytest.mark.django_db\n    def test_address_create(self):\n        \"\"\" Test address model \"\"\"    # create customer model instance\n        address = AddressFactory()\n        assert address is not None\n\n    @pytest.mark.django_db\n    def test_coop_create(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop = Coop.objects.create(name='test')\n        coop.addresses.set(coop_from_factory.addresses.all()) \n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_existing_type(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop_types = coop_from_factory.types\n        coop = CoopFactory.create(types=[coop_types.all().first()], addresses=coop_from_factory.addresses.all())\n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_no_types(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        print(\"\\n\\n\\n\\n**********-------- starting test ....\\n\")\n        coop = CoopFactory.build(types=[])\n        print(\"phone:\",coop.phone.phone)\n        print(\"email:\",coop.email.email)\n        coop.full_clean()\n        self.assertIsNotNone(coop)\n        self.assertIsNone( coop.id )\n\n    def test_search_coops_wo_coords(self):\n        \"\"\"\n        Look for coops with addresses without latitude\/longitude coords\n        \"\"\"\n        address = AddressFactory(latitude=None, longitude=None)\n        coop_from_factory = CoopFactory(addresses=[address])\n        # Verify coop appears when we search for those without a lat\/lon\n        coops = Coop.objects.find_wo_coords()\n        results = list(coops)\n        assert len(results) > 0, \"Failed to find any matching results.\"\n        assert coop_from_factory in list(coops), \"Failed to find coop.\"\n \n\n"}
{"prompt":"\n\n### djcutter\/users\/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for djcutter.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### djcutter\/users\/forms.py ###\n\nfrom django.contrib.auth import forms as admin_forms\nfrom django.contrib.auth import get_user_model\nfrom django.utils.translation import gettext_lazy as _\n\nUser = get_user_model()\n\n\nclass UserChangeForm(admin_forms.UserChangeForm):\n    class Meta(admin_forms.UserChangeForm.Meta):\n        model = User\n\n\nclass UserCreationForm(admin_forms.UserCreationForm):\n    class Meta(admin_forms.UserCreationForm.Meta):\n        model = User\n\n        error_messages = {\n            \"username\": {\"unique\": _(\"This username has already been taken.\")}\n        }\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom djcutter.users.forms import UserCreationForm\nfrom djcutter.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"}
{"prompt":"\n\n### tests\/splunkutils.py ###\n\n# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https:\/\/opensource.org\/licenses\/BSD-2-Clause\nfrom time import sleep\n\n\ndef splunk_single(service, search):\n    kwargs_normalsearch = {\"exec_mode\": \"normal\"}\n    tried = 0\n    while True:\n        job = service.jobs.create(search, **kwargs_normalsearch)\n\n        # A normal search returns the job's SID right away, so we need to poll for completion\n        while True:\n            while not job.is_ready():\n                pass\n            stats = {\n                \"isDone\": job[\"isDone\"],\n                \"doneProgress\": float(job[\"doneProgress\"]) * 100,\n                \"scanCount\": int(job[\"scanCount\"]),\n                \"eventCount\": int(job[\"eventCount\"]),\n                \"resultCount\": int(job[\"resultCount\"]),\n            }\n\n            if stats[\"isDone\"] == \"1\":\n                break\n            else:\n                sleep(2)\n\n        # Get the results and display them\n        resultCount = stats[\"resultCount\"]\n        eventCount = stats[\"eventCount\"]\n        if resultCount > 0 or tried > 5:\n            break\n        else:\n            tried += 1\n            sleep(5)\n    return resultCount, eventCount\n\n\n### tests\/sendmessage.py ###\n\n# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https:\/\/opensource.org\/licenses\/BSD-2-Clause\n\nimport socket\nfrom time import sleep\nimport os\n\n\ndef sendsingle(message, host, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_address = (host, port)\n\n    tried = 0\n    while True:\n        try:\n            sock.connect(server_address)\n            break\n        except socket:\n            tried += 1\n            if tried > 90:\n                raise\n            sleep(1)\n    sock.sendall(str.encode(message))\n    sock.close()\n\n\n### tests\/timeutils.py ###\n\nimport re\nimport datetime\n\n# Helper functions\n# Insert a character at given location in string (e.g space between ms and TZ offset 2020-02-12 12:46:39.323 -08:00)\ndef insert_char(string, char, integer):\n    return string[0:integer] + char + string[integer:]\n\n\ndef removeZero(tz):\n    return re.sub(r\"\\b0+(\\d)(?=:)\", r\"\\1\", tz)\n\n\ndef time_operations(dt):\n    # Generate an ISO 8601 (RFC 5424) compliant timestamp with local timezone offset (2020-02-12T12:46:39.323-08:00)\n    # See https:\/\/stackoverflow.com\/questions\/2150739\/iso-time-iso-8601-in-python\n    iso = dt.astimezone().isoformat(sep=\"T\", timespec=\"microseconds\")\n    # Generate an BSD-style (RFC 3164) compliant timestamp with no timezone (Oct 25 13:08:00)\n    bsd = dt.strftime(\"%b %d %H:%M:%S\")\n\n    # Other variants of timestamps needed for this log sample\n    time = dt.strftime(\"%H:%M:%S.%f\")\n    date = dt.strftime(\"%Y-%m-%d\")\n    # Insert colon in tzoffset string; normally just 'tzoffset = dt.astimezone().strftime(\"%z\")'\n    # Could use helper function above; e.g. 'tzoffset = insert_char(dt.astimezone().strftime(\"%z\"), \":\", 3)'\n    tzoffset = dt.astimezone().strftime(\"%z\")\n    tzname = dt.astimezone().strftime(\"%Z\")\n\n    # Derive epoch timestamp for use in search string\n    # NOTE:  There are caveats with 'strftime(\"%s\")', see references below\n\n    # See https:\/\/stackoverflow.com\/questions\/11743019\/convert-python-datetime-to-epoch-with-strftime\n    # See https:\/\/docs.python.org\/3\/library\/datetime.html#datetime-objects\n    # Basically: Don't use 'utcnow()'\n\n    # Strict way to get epoch as a string (rather than float) avoiding naive objects\n    # epoch = dt.fromtimestamp(dt.timestamp()).strftime('%s')\n\n    # Since datetime.now().astimezone() is aware, strftime() should be safe and form below OK\n    # Trim last 3 or 7 characters of microsecond resolution to obtain milliseconds or whole seconds, respectively\n    epoch = dt.astimezone().strftime(\"%s.%f\")\n\n    return iso, bsd, time, date, tzoffset, tzname, epoch\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https:\/\/opensource.org\/licenses\/BSD-2-Clause\n\nfrom jinja2 import Environment\n\nfrom .sendmessage import *\nfrom .splunkutils import *\nfrom .timeutils import *\n\nimport pytest\n\nenv = Environment()\n\n# time format for Apr  5 22:51:54 2021\n# <187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\n# <187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat \/mswitch\/sap\/mips64.ari failed: No such file or directory.\n# <188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\n# <191>{{ arubadate }} 10.10.10.10 dnsmasq: reading \/etc\/resolv.conf\n\ntestdata = [\n    \"<187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\",\n    \"<187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat \/mswitch\/sap\/mips64.ari failed: No such file or directory.\",\n    \"<188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\",\n    \"<188>{{ arubadate }} {{ host }} sapd[1362]: <127037> <WARN> |AP 00:0b:86:eb:4e:32@10.10.10.10 sapd| |ids-ap| AP(04:bd:88:8a:3a:60): Station Associated to Rogue AP: An AP detected a client a4:8d:3b:ae:68:68 associated to a rogue access point (BSSID 98:1e:19:31:63:b6 and SSID MySpectrumWiFib0-2G on CHANNEL 11).\",\n]\n\n\n@pytest.mark.parametrize(\"event\", testdata)\ndef test_aruba(\n    record_property, setup_wordlist, get_host_key, setup_splunk, setup_sc4s, event\n):\n    host = get_host_key\n\n    dt = datetime.datetime.now()\n    iso, bsd, time, date, tzoffset, tzname, epoch = time_operations(dt)\n    arubadate = dt.strftime(\"%b %d %H:%M:%S %Y\")\n\n    # Tune time functions\n    epoch = epoch[:-7]\n\n    mt = env.from_string(event + \"\\n\")\n    message = mt.render(mark=\"<188>\", bsd=bsd, host=host, arubadate=arubadate)\n\n    sendsingle(message, setup_sc4s[0], setup_sc4s[1][514])\n\n    st = env.from_string(\n        'search index=netops _time={{ epoch }} sourcetype=\"aruba:syslog\" host={{ host }}'\n    )\n    search = st.render(epoch=epoch, host=host)\n\n    resultCount, eventCount = splunk_single(setup_splunk, search)\n\n    record_property(\"host\", host)\n    record_property(\"resultCount\", resultCount)\n    record_property(\"message\", message)\n\n    assert resultCount == 1\n"}
{"prompt":"\n\n### postgres\/tests\/common.py ###\n\n# (C) Datadog, Inc. 2010-present\n# All rights reserved\n# Licensed under Simplified BSD License (see LICENSE)\nimport os\nfrom sys import maxsize\n\nimport pytest\n\nfrom datadog_checks.dev import get_docker_hostname\n\nHOST = get_docker_hostname()\nPORT = '5432'\nUSER = 'datadog'\nPASSWORD = 'datadog'\nDB_NAME = 'datadog_test'\nPOSTGRES_VERSION = os.environ.get('POSTGRES_VERSION', None)\nPOSTGRES_IMAGE = \"alpine\"\n\nUSING_LATEST = False\n\nif POSTGRES_VERSION is not None:\n    USING_LATEST = POSTGRES_VERSION.endswith('latest')\n    POSTGRES_IMAGE = POSTGRES_VERSION + \"-alpine\"\n\nif USING_LATEST is True:\n    POSTGRES_VERSION = str(maxsize)\n    POSTGRES_IMAGE = \"alpine\"\n\nSCHEMA_NAME = 'schemaname'\n\nCOMMON_METRICS = [\n    'postgresql.before_xid_wraparound',\n    'postgresql.commits',\n    'postgresql.rollbacks',\n    'postgresql.disk_read',\n    'postgresql.buffer_hit',\n    'postgresql.rows_returned',\n    'postgresql.rows_fetched',\n    'postgresql.rows_inserted',\n    'postgresql.rows_updated',\n    'postgresql.rows_deleted',\n    'postgresql.database_size',\n    'postgresql.deadlocks',\n    'postgresql.temp_bytes',\n    'postgresql.temp_files',\n]\n\nDBM_MIGRATED_METRICS = [\n    'postgresql.connections',\n]\n\nCOMMON_BGW_METRICS = [\n    'postgresql.bgwriter.checkpoints_timed',\n    'postgresql.bgwriter.checkpoints_requested',\n    'postgresql.bgwriter.buffers_checkpoint',\n    'postgresql.bgwriter.buffers_clean',\n    'postgresql.bgwriter.maxwritten_clean',\n    'postgresql.bgwriter.buffers_backend',\n    'postgresql.bgwriter.buffers_alloc',\n    'postgresql.bgwriter.buffers_backend_fsync',\n    'postgresql.bgwriter.write_time',\n    'postgresql.bgwriter.sync_time',\n]\n\nCOMMON_BGW_METRICS_PG_ABOVE_94 = ['postgresql.archiver.archived_count', 'postgresql.archiver.failed_count']\n\nrequires_static_version = pytest.mark.skipif(USING_LATEST, reason='Version `latest` is ever-changing, skipping')\n\n\ndef check_common_metrics(aggregator, expected_tags, count=1):\n    for name in COMMON_METRICS:\n        aggregator.assert_metric(name, count=count, tags=expected_tags)\n\n\ndef check_bgw_metrics(aggregator, expected_tags):\n    for name in COMMON_BGW_METRICS:\n        aggregator.assert_metric(name, count=1, tags=expected_tags)\n\n    if float(POSTGRES_VERSION) >= 9.4:\n        for name in COMMON_BGW_METRICS_PG_ABOVE_94:\n            aggregator.assert_metric(name, count=1, tags=expected_tags)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n","completion":"# (C) Datadog, Inc. 2021-present\n# All rights reserved\n# Licensed under Simplified BSD License (see LICENSE)\nimport pytest\n\nfrom datadog_checks.postgres.relationsmanager import ALL_SCHEMAS, IDX_METRICS, LOCK_METRICS, RelationsManager\n\nfrom .common import SCHEMA_NAME\n\npytestmark = pytest.mark.unit\n\n\n@pytest.mark.parametrize(\n    'relations_config,expected_filter',\n    [\n        (\n            [\n                {'relation_regex': 'ix.*', 'schemas': ['public', 's1', 's2']},\n                {'relation_regex': 'ibx.*', 'schemas': ['public']},\n                {'relation_regex': 'icx.*', 'schemas': ['public']},\n            ],\n            \"( relname ~ 'ix.*' AND schemaname = ANY(array['public','s1','s2']::text[]) ) \"\n            \"OR ( relname ~ 'ibx.*' AND schemaname = ANY(array['public']::text[]) ) \"\n            \"OR ( relname ~ 'icx.*' AND schemaname = ANY(array['public']::text[]) )\",\n        ),\n        (\n            [\n                {'relation_regex': '.+_archive'},\n            ],\n            \"( relname ~ '.+_archive' )\",\n        ),\n        (\n            [\n                {'relation_name': 'my_table', 'schemas': ['public', 'app'], 'relkind': ['r']},  # relkind ignored\n                {'relation_name': 'my_table2', 'relkind': ['p', 'r']},  # relkind ignored\n                {'relation_regex': 'table.*'},\n            ],\n            \"( relname = 'my_table' AND schemaname = ANY(array['public','app']::text[]) ) \"\n            \"OR ( relname = 'my_table2' ) \"\n            \"OR ( relname ~ 'table.*' )\",\n        ),\n        (\n            ['table1', 'table2'],\n            \"( relname = 'table1' ) OR ( relname = 'table2' )\",\n        ),\n    ],\n)\ndef test_relations_cases(relations_config, expected_filter):\n    query = '{relations}'\n    relations = RelationsManager(relations_config)\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == expected_filter\n\n\ndef test_relation_filter():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'breed', 'schemas': ['public']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert (\n        query_filter == \"Select foo from bar where ( relname = 'breed' AND schemaname = ANY(array['public']::text[]) )\"\n    )\n\n\ndef test_relation_filter_no_schemas():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'persons', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname = 'persons' )\"\n\n\ndef test_relation_filter_regex():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname ~ 'b.*' )\"\n\n\ndef test_relation_filter_relkind():\n    query = LOCK_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r', 't']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert \"AND relkind = ANY(array['r','t'])\" in query_filter\n\n\ndef test_relkind_does_not_apply_to_index_metrics():\n    query = IDX_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert 'relkind' not in query_filter\n"}
