[
  {
    "prompt": "\n\n### tests/users/factories.py ###\n\nfrom collections import namedtuple\n\nimport factory\nfrom django.contrib.auth import get_user_model\nfrom django.contrib.auth.models import Group\n\nUser = get_user_model()\nBranch = namedtuple(\n    'Branch', ['listing', 'article', 'group', 'user', 'client']\n)\nTwoBranchesWithEditorModeratorAdmin = namedtuple(\n    'TwoBranchesWithEditorModeratorAdmin', [\n        'admins',\n        'admin',\n        'admin_client',\n        'home_1',\n        'landing_1',\n        'listing_1',\n        'article_1',\n        'editors_1',\n        'editor_1',\n        'editor_1_client',\n        'moderators_1',\n        'moderator_1',\n        'moderator_1_client',\n        'home_2',\n        'landing_2',\n        'listing_2',\n        'article_2',\n        'editors_2',\n        'editor_2',\n        'editor_2_client',\n        'moderators_2',\n        'moderator_2',\n        'moderator_2_client',\n    ]\n)\n\n\nclass GroupFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = Group\n\n    name = factory.Sequence(lambda n: \"group %s\" % n)\n\n\nclass UserFactory(factory.django.DjangoModelFactory):\n    class Meta:\n        model = User\n\n    username = factory.Sequence(lambda n: \"user %s\" % n)\n    first_name = factory.Faker('first_name')\n    last_name = factory.Faker('last_name')\n    is_superuser = False\n    is_staff = False\n    email = factory.Faker('email')\n\n    @factory.post_generation\n    def groups(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted:\n            # A list of groups were passed in, use them\n            for group in extracted:\n                self.groups.add(group)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "from importlib import import_module, reload\nimport pytest\nimport sys\nfrom unittest.mock import patch\n\nfrom rest_framework import status\n\nfrom django.contrib.auth.models import Permission, Group\nfrom django.conf import settings\nfrom django.urls import clear_url_caches\nfrom django.urls import reverse\n\nfrom .factories import UserFactory\nfrom groups.models import GroupInfo\nfrom users.models import UserProfile\n\nBLANK_CHOICE = ('', '---------')\n\nUSER_DETAILS = {\n    'username': 'test',\n    'email': 'test@test.com',\n    'first_name': 'Foo',\n    'last_name': 'Bar',\n}\n\nUSER_DETAILS_CREATE = USER_DETAILS.copy()\nUSER_DETAILS_CREATE.update(password1='pass', password2='pass')\n\nUSER_DETAILS_CHANGING = {\n    'username': 'johnsmith',\n    'email': 'john@smiths.com',\n    'first_name': 'John',\n    'last_name': 'Smith',\n}\n\n\n@pytest.mark.django_db\ndef test_create_user_view_get(admin_client):\n    url = reverse('wagtailusers_users:add')\n    response = admin_client.get(url)\n    assert response.status_code == status.HTTP_200_OK\n\n\n@pytest.mark.django_db\ndef test_create_user_view(admin_client):\n    url = reverse('wagtailusers_users:add')\n\n    response = admin_client.post(url, data=USER_DETAILS_CREATE)\n\n    assert response.context['message'] == 'User test created.'\n    assert response.status_code == status.HTTP_302_FOUND\n    assert response.url == reverse('wagtailusers_users:index')\n\n\n@pytest.mark.django_db\ndef test_create_user_view_invalid_form(admin_client):\n    url = reverse('wagtailusers_users:add')\n\n    post_data = USER_DETAILS.copy()\n    post_data.update(email='This is not an email address')\n    response = admin_client.post(url, post_data)\n\n    message = response.context['message']\n    assert message == 'The user could not be created due to errors.'\n    assert response.status_code == status.HTTP_200_OK\n\n\n@pytest.mark.django_db\ndef test_get_edit_user_view(admin_client):\n    user = UserFactory(**USER_DETAILS)\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n    response = admin_client.get(url)\n    assert response.status_code == status.HTTP_200_OK\n    assert response.context['can_delete'] is True\n\n\n@pytest.mark.django_db\ndef test_edit_user_view(team_leaders_group, admin_client):\n    user = UserFactory(**USER_DETAILS)\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n\n    # We'll add the user to a group, as well as changing their details\n    post_data = USER_DETAILS_CHANGING.copy()\n    post_data['groups'] = [team_leaders_group.pk]\n    response = admin_client.post(url, data=post_data)\n\n    assert response.context['message'] == 'User johnsmith updated.'\n    assert response.status_code == status.HTTP_302_FOUND\n    assert response.url == reverse('wagtailusers_users:index')\n\n    # The user's details should have changed to reflect the posted values\n    user.refresh_from_db()\n    for field_name, changed_value in USER_DETAILS_CHANGING.items():\n        assert getattr(user, field_name) == changed_value\n\n    # And they should have been added to a group\n    group_ids = set(user.groups.values_list('id', flat=True))\n    assert group_ids == {team_leaders_group.pk}\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_invalid_form(admin_client, approved_user):\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': approved_user.pk})\n\n    post_data = USER_DETAILS.copy()\n    post_data.update(email='This is not an email address')\n\n    response = admin_client.post(url, post_data)\n\n    message = response.context['message']\n    assert message == 'The user could not be saved due to errors.'\n    assert response.status_code == status.HTTP_200_OK\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_cannot_change_personal_details_when_sso_enforced(\n    admin_client\n):\n    # Set this flag to True and repeat previous test\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = True\n\n    user = UserFactory(**USER_DETAILS)\n\n    # Post changes to the view\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n    admin_client.post(url, data=USER_DETAILS_CHANGING)\n\n    # The users details should remain unchanged, because the\n    # personal detail fields should all be disabled\n    user.refresh_from_db()\n    for field_name, original_value in USER_DETAILS.items():\n        assert getattr(user, field_name) == original_value\n\n    # Change this back to avoid cross-test pollution\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = False\n    reload_urlconf()\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_preserves_ability_to_update_is_active(admin_client):\n    # Set this flag to True and actions if previous test\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = True\n\n    # Create an 'inactive' user to test with\n    user = UserFactory(**USER_DETAILS)\n    user.is_active = False\n    user.save()\n\n    # Post using the same details + 'is_active=on'\n    post_data = USER_DETAILS.copy()\n    post_data.update(is_active='on')\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n    admin_client.post(url, data=post_data)\n\n    # The change to 'is_active' should have been applied, because that field\n    # is not disabled along with the personal detail ones\n    user.refresh_from_db()\n    assert user.is_active is True\n\n    # Reset flag to avoid cross-test pollution\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = False\n    reload_urlconf()\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_warns_administrator_if_user_is_awaiting_approval(\n    admin_client, user_awaiting_approval\n):\n    # This flag must be set for the warning to show\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = True\n\n    user = user_awaiting_approval\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n    response = admin_client.get(url)\n\n    message = response.context['message']\n    assert \"This user is awaiting approval\" in message\n    assert \"requested to be added to the 'Moderators' group\" in message\n\n    # Reset flag to avoid cross-test pollution\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = False\n    reload_urlconf()\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_marks_user_as_approved_if_added_to_group(\n    admin_client, admin_user, user_awaiting_approval\n):\n    # This flag must be set for the warning to show\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = True\n\n    user = user_awaiting_approval\n    profile = user_awaiting_approval.userprofile\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n\n    group = Group.objects.get(pk=profile.self_assigned_group_id)\n    group.permissions.add(Permission.objects.get(codename='access_admin'))\n\n    with patch('users.views.notify_user_of_access_request_approval', autospec=True) as mocked_method:\n        response = admin_client.post(url, {\n            'username': user.username,\n            'first_name': user.first_name,\n            'last_name': user.last_name,\n            'email': user.email,\n            'is_active': True,\n            'groups': [group.pk],\n        })\n\n    # Ensure the post was successful\n    assert response.context['message'] == 'User %s updated.' % user.username\n    assert response.status_code == status.HTTP_302_FOUND\n    assert response.url == reverse('wagtailusers_users:index')\n\n    # The UserProfile should have been updated\n    profile.refresh_from_db()\n    assert profile.assignment_status == UserProfile.STATUS_APPROVED\n    assert profile.approved_by_id == admin_user.id\n    assert profile.approved_at is not None\n\n    # A notification should have been triggered for the user\n    expected_call_args = dict(\n        request=response.wsgi_request,\n        user_email=user.email,\n        user_name=user.first_name,\n        reviewer_name=admin_user.get_full_name(),\n    )\n    mocked_method.assert_called_with(**expected_call_args)\n\n    # Reset flag to avoid cross-test pollution\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = False\n    reload_urlconf()\n\n\n@pytest.mark.django_db\ndef test_edit_user_view_does_not_mark_user_as_approved_if_not_added_to_a_group(admin_client, groups_with_info):\n    user = UserFactory(username='some-user')\n    profile = user.userprofile\n    profile.assignment_status = UserProfile.STATUS_AWAITING_APPROVAL\n    profile.self_assigned_group_id = groups_with_info[0].id\n    profile.save()\n    url = reverse('wagtailusers_users:edit', kwargs={'pk': user.pk})\n\n    with patch(\n        'users.views.notify_user_of_access_request_approval'\n    ) as mocked_method:\n        response = admin_client.post(url, {\n            'username': user.username,\n            'first_name': user.first_name,\n            'last_name': user.last_name,\n            'email': user.email,\n            'is_active': True,\n        })\n\n    # Ensure the post was successful\n    assert response.context['message'] == 'User %s updated.' % user.username\n    assert response.status_code == status.HTTP_302_FOUND\n    assert response.url == reverse('wagtailusers_users:index')\n\n    # The UserProfile should NOT have been updated\n    profile.refresh_from_db()\n    assert profile.assignment_status == UserProfile.STATUS_AWAITING_APPROVAL\n    assert profile.approved_by_id is None\n    assert profile.approved_at is None\n\n    # no notification should have been triggered\n    mocked_method.assert_not_called()\n\n\ndef reload_urlconf(urlconf=None):\n    clear_url_caches()\n    if urlconf is None:\n        urlconf = settings.ROOT_URLCONF\n    if urlconf in sys.modules:\n        reload(sys.modules[urlconf])\n    else:\n        import_module(urlconf)\n\n\n@pytest.mark.django_db\ndef test_force_staff_sso(client):\n    \"\"\"Test that URLs and redirects are in place.\"\"\"\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = True\n    settings.AUTHBROKER_CLIENT_ID = 'debug'\n    settings.AUTHBROKER_CLIENT_SECRET = 'debug'\n    settings.AUTHBROKER_URL = 'https://test.com'\n    reload_urlconf()\n\n    assert reverse('authbroker_client:login') == '/auth/login/'\n    assert reverse('authbroker_client:callback') == '/auth/callback/'\n    response = client.get('/admin/login/')\n    assert response.status_code == 302\n    assert response.url == '/auth/login/'\n\n    settings.FEATURE_FLAGS['ENFORCE_STAFF_SSO_ON'] = False\n    reload_urlconf()\n\n\n@pytest.mark.parametrize('assignment_status, expected_status_code', (\n    (UserProfile.STATUS_CREATED, 200),\n    (UserProfile.STATUS_AWAITING_APPROVAL, 302),\n    (UserProfile.STATUS_APPROVED, 302)\n))\n@pytest.mark.django_db\ndef test_ssorequestaccessview_responds_based_on_assignment_status(\n    admin_client, admin_user, assignment_status, expected_status_code\n):\n    url = reverse('sso:request_access')\n    profile = admin_user.userprofile\n    profile.assignment_status = assignment_status\n    profile.save()\n    response = admin_client.get(url)\n    assert response.status_code == expected_status_code\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_shows_unlimited_visibilty_groups_only(\n    admin_client, groups_with_info\n):\n    url = reverse('sso:request_access')\n\n    # Visbility is set to 'unrestricted' for all groups in `groups_with_info`,\n    # so choices should reflect that by default\n    expected_choices = tuple(\n        (g.id, g.info.name_singular) for g in groups_with_info\n    )\n\n    # Confirm the choices in the form are as expected\n    response = admin_client.get(url)\n    group_field = response.context['form']['self_assigned_group'].field\n    actual_choices = tuple(group_field.choices)\n    assert actual_choices == expected_choices\n\n    # Change the visibility of groups and try again\n    GroupInfo.objects.all().update(\n        visibility=GroupInfo.VISIBILITY_MANAGERS_ONLY)\n\n    # Choices should be empty now\n    response = admin_client.get(url)\n    group_field = response.context['form']['self_assigned_group'].field\n    assert tuple(group_field.choices) == ()\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_with_no_team_leaders_group(admin_client):\n    # If no 'team leaders group' has been designated, the 'team_leaders'\n    # field should only have a 'blank' option\n    url = reverse('sso:request_access')\n    response = admin_client.get(url)\n    team_leader_field = response.context['form']['team_leader'].field\n    assert tuple(team_leader_field.choices) == (BLANK_CHOICE,)\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_with_team_leaders_group_but_no_members(\n    admin_client, team_leaders_group\n):\n    # If the designated 'team leaders group' has no members, the 'team_leaders'\n    # field should only have a 'blank' option\n    url = reverse('sso:request_access')\n    response = admin_client.get(url)\n    team_leader_field = response.context['form']['team_leader'].field\n    assert team_leaders_group.user_set.all().exists() is False\n    assert tuple(team_leader_field.choices) == (BLANK_CHOICE,)\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_with_team_leaders(\n    admin_client, team_leaders_group, team_leaders\n):\n    url = reverse('sso:request_access')\n\n    # When team leaders are defined, they will appear as choices\n    # for the 'team_leaders' field\n    expected_choices = [BLANK_CHOICE]\n    expected_choices.extend(list(\n        (tl.id, \"{} <{}>\".format(tl.get_full_name(), tl.email))\n        for tl in team_leaders\n    ))\n\n    # Confirm the choices in the form are as expected\n    response = admin_client.get(url)\n    team_leader_field = response.context['form']['team_leader'].field\n    actual_choices = list(team_leader_field.choices)\n    assert actual_choices == expected_choices\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_fails_validation_if_form_incomplete(\n    admin_client, groups_with_info, team_leaders\n):\n    url = reverse('sso:request_access')\n    response = admin_client.post(url, data={})\n\n    # Should still be on the same view\n    assert response.status_code == 200\n\n    # Both form fields should have errors\n    assert 'self_assigned_group' in response.context['form'].errors\n    assert 'team_leader' in response.context['form'].errors\n\n\n@pytest.mark.django_db\ndef test_ssorequestaccessview_post_with_complete_data(\n    admin_client, admin_user, groups_with_info, team_leaders\n):\n    group = groups_with_info[0]\n    team_leader = team_leaders[0]\n\n    with patch(\n        'users.views.notify_team_leader_of_pending_access_request',\n        autospec=True\n    ) as mocked_method:\n        response = admin_client.post(\n            reverse('sso:request_access'),\n            data={\n                'self_assigned_group': group.id,\n                'team_leader': team_leader.id,\n            }\n        )\n\n    # Should be redirected to the success url\n    success_url = reverse('sso:request_access_success')\n    assert response.url == success_url\n\n    # The UserProfile for `admin_user` should have been updated\n    profile = admin_user.userprofile\n    assert profile.self_assigned_group_id == group.id\n    assert profile.team_leader_id == team_leader.id\n    assert profile.assignment_status == UserProfile.STATUS_AWAITING_APPROVAL # noqa\n\n    # A notification should have been triggered for the user\n    expected_call_args = dict(\n        request=response.wsgi_request,\n        team_leader_email=team_leader.email,\n        team_leader_name=team_leader.first_name,\n        user_id=admin_user.id,\n        user_name=admin_user.get_full_name(),\n        user_email=admin_user.email,\n        user_role=group.info.name_singular,\n    )\n    mocked_method.assert_called_with(**expected_call_args)\n\n\n@pytest.mark.django_db\n@pytest.mark.parametrize('url', (\n    reverse('sso:request_access'),\n    reverse('sso:request_access_success'),\n))\ndef test_ssorequestaccess_views_only_available_to_authenticated_users(\n    client, admin_client, url\n):\n    # When not authenticated, the user is redirected to the login page\n    response = client.get(url)\n    assert response.status_code == 302\n    assert response.url.startswith(settings.LOGIN_URL)\n\n    # When authenticated, things work fine\n    response = admin_client.get(url)\n    assert response.status_code == 200\n"
  },
  {
    "prompt": "\n\n### nesta/packages/geo_utils/geocode.py ###\n\n'''\ngeocode\n=======\n\nTools for geocoding.\n'''\n\nimport logging\nimport pandas as pd\nimport requests\nfrom retrying import retry\n\nfrom nesta.packages.decorators.ratelimit import ratelimit\n\n\ndef geocode(**request_kwargs):\n    '''\n    Geocoder using the Open Street Map Nominatim API.\n\n    If there are multiple results the first one is returned (they are ranked by importance).\n    The API usage policy allows maximum 1 request per second and no multithreading:\n    https://operations.osmfoundation.org/policies/nominatim/\n\n    Args:\n        request_kwargs (dict): Parameters for OSM API.\n    Returns:\n        JSON from API response.\n    '''\n    # Explictly require json for ease of use\n    request_kwargs[\"format\"] = \"json\"\n    response = requests.get(\"https://nominatim.openstreetmap.org/search\",\n                            params=request_kwargs,\n                            headers={'User-Agent': 'Nesta health data geocode'})\n    response.raise_for_status()\n    geo_data = response.json()\n    if len(geo_data) == 0:\n        raise ValueError(f\"No geocode match for {request_kwargs}\")\n    return geo_data\n\n\ndef retry_if_not_value_error(exception):\n    \"\"\"Forces retry to exit if a valueError is returned. Supplied to the\n    'retry_on_exception' argument in the retry decorator.\n\n    Args:\n        exception (Exception): the raised exception, to check\n\n    Returns:\n        (bool): False if a ValueError, else True\n    \"\"\"\n    return not isinstance(exception, ValueError)\n\n\n@retry(stop_max_attempt_number=10, retry_on_exception=retry_if_not_value_error)\n@ratelimit(max_per_second=0.5)\ndef _geocode(q=None, **kwargs):\n    '''Extension of geocode to catch invalid requests to the api and handle errors.\n    failure.\n\n    Args:\n        q (str): query string, multiple words should be separated with +\n        kwargs (str): name and value of any other valid query parameters\n\n    Returns:\n        dict: lat and lon\n    '''\n    valid_kwargs = ['street', 'city', 'county', 'state', 'country', 'postalcode']\n    if not all(kwarg in valid_kwargs for kwarg in kwargs):\n        raise ValueError(f\"Invalid query parameter. Not in: {valid_kwargs}\")\n    if q and kwargs:\n        raise ValueError(\"Supply either q OR other query parameters, they cannot be combined.\")\n    if not q and not kwargs:\n        raise ValueError(\"No query parameters supplied\")\n\n    query_kwargs = {'q': q} if q else kwargs\n    try:\n        geo_data = geocode(**query_kwargs)\n    except ValueError:\n        logging.debug(f\"Unable to geocode {query_kwargs}\")\n        return None  # converts to null which is accepted in elasticsearch\n\n    lat = geo_data[0]['lat']\n    lon = geo_data[0]['lon']\n    logging.debug(f\"Successfully geocoded {query_kwargs} to {lat, lon}\")\n\n    return {'lat': lat, 'lon': lon}\n\n\ndef geocode_dataframe(df):\n    '''\n    A wrapper for the geocode function to process a supplied dataframe using\n    the city and country.\n\n    Args:\n        df (dataframe): a dataframe containing city and country fields.\n    Returns:\n        a dataframe with a 'coordinates' column appended.\n    '''\n    in_cols = ['city', 'country']\n    out_col = 'coordinates'\n    # Only geocode unique city/country combos\n    _df = df[in_cols].drop_duplicates()\n    _df.replace('', pd.np.nan, inplace=True)\n    _df = _df.dropna()\n    if len(_df) == 0:        \n        df[out_col] = None\n        return df\n\n    # Attempt to geocode with city and country\n    _df[out_col] = _df[in_cols].apply(lambda row: _geocode(**row), axis=1)\n    # Attempt to geocode with query for those which failed\n    null = pd.isnull(_df[out_col])\n    if null.sum() > 0:\n        query = \"{city} {country}\"\n        _df.loc[null, out_col] = _df.loc[null, in_cols].apply(lambda row:\n                                                              _geocode(query.format(**row)),\n                                                              axis=1)\n    # Merge the results again\n    return pd.merge(df, _df, how='left', left_on=in_cols, right_on=in_cols)\n\n\ndef geocode_batch_dataframe(df, city='city', country='country',\n                            latitude='latitude', longitude='longitude',\n                            query_method='both'):\n    \"\"\"Geocodes a dataframe, first by supplying the city and country to the api, if this\n    fails a second attempt is made supplying the combination using the q= method.\n    The supplied dataframe df is returned with additional columns appended, containing\n    the latitude and longitude as floats.\n\n    Args:\n        df (:obj:`pandas.DataFrame`): input dataframe\n        city (str): name of the input column containing the city\n        country (str): name of the input column containing the country\n        latitude (str): name of the output column containing the latitude\n        longitude (str): name of the output column containing the longitude\n        query_method (int): query methods to attempt:\n                                    'city_country_only': city and country only\n                                    'query_only': q method only\n                                    'both': city, country with fallback to q method\n\n    Returns:\n        (:obj:`pandas.DataFrame`): original dataframe with lat and lon appended as floats\n    \"\"\"\n    if query_method not in ['city_country_only', 'query_only', 'both']:\n        raise ValueError(\"Invalid query method, must be 'city_country_only', 'query_only' or 'both'\")\n\n    df[latitude], df[longitude] = None, None\n\n    for idx, row in df.iterrows():\n        location = None\n        if query_method in ['city_country_only', 'both']:\n            location = _geocode(city=row[city], country=row[country])\n        if location is None and query_method in ['query_only', 'both']:\n            query = f\"{row[city]} {row[country]}\"\n            location = _geocode(q=query)\n        if location is not None:\n            df.loc[idx, latitude] = float(location['lat'])\n            df.loc[idx, longitude] = float(location['lon'])\n    return df\n\n\ndef generate_composite_key(city=None, country=None):\n    \"\"\"Generates a composite key to use as the primary key for the geographic data.\n\n    Args:\n        city (str): name of the city\n        country (str): name of the country\n\n    Returns:\n        (str): composite key\n    \"\"\"\n    try:\n        city = city.replace(' ', '-').lower()\n        country = country.replace(' ', '-').lower()\n    except AttributeError:\n        raise ValueError(f\"Invalid city or country name. City: {city} | Country: {country}\")\n    return '_'.join([city, country])\n\n\n### nesta/packages/geo_utils/country_iso_code.py ###\n\n'''\ncountry iso codes\n=================\n\ntools for lookup of iso codes for countries\n'''\n\nimport pycountry\n\nfrom nesta.packages.geo_utils.alpha2_to_continent import alpha2_to_continent_mapping\n\n\ndef country_iso_code(country):\n    '''\n    Look up the ISO 3166 codes for countries.\n    https://www.iso.org/glossary-for-iso-3166.html\n\n    Wraps the pycountry module to attempt lookup with all name options.\n\n    Args:\n        country (str): name of the country to lookup\n    Returns:\n        Country object from the pycountry module\n    '''\n    country = str(country).title()\n    for name_type in ['name', 'common_name', 'official_name']:\n        query = {name_type: country}\n        try:\n            return pycountry.countries.get(**query)\n        except KeyError:\n            pass\n\n    raise KeyError(f\"{country} not found\")\n\n\ndef country_iso_code_dataframe(df, country='country'):\n    '''\n    A wrapper for the country_iso_code function to apply it to a whole dataframe,\n    using the country name. Also appends the continent code based on the country.\n\n    Args:\n        df (:obj:`pandas.DataFrame`): a dataframe containing a country field.\n        country (str): field in df containing the country name\n    Returns:\n        a dataframe with country_alpha_2, country_alpha_3, country_numeric, and\n        continent columns appended.\n    '''\n    df['country_alpha_2'], df['country_alpha_3'], df['country_numeric'] = None, None, None\n    df['continent'] = None\n\n    continents = alpha2_to_continent_mapping()\n\n    for idx, row in df.iterrows():\n        try:\n            country_codes = country_iso_code(row[country])\n        except KeyError:\n            # some fallback method could go here\n            pass\n        else:\n            df.at[idx, 'country_alpha_2'] = country_codes.alpha_2\n            df.at[idx, 'country_alpha_3'] = country_codes.alpha_3\n            df.at[idx, 'country_numeric'] = country_codes.numeric\n            df.at[idx, 'continent'] = continents.get(country_codes.alpha_2)\n\n    return df\n\n\ndef country_iso_code_to_name(code, iso2=False):\n    \"\"\"Converts country alpha_3 into name and catches error so this can be used with\n       pd.apply.\n\n    Args:\n        code (str): iso alpha 3 code\n        iso2 (bool): use alpha 2 code instead\n    Returns:\n        str: name of the country or None if not valid\n    \"\"\"\n    try:        \n        if iso2:\n            return pycountry.countries.get(alpha_2=code).name\n        else:\n            return pycountry.countries.get(alpha_3=code).name\n    except (KeyError, AttributeError):\n        return None\n\n\n### nesta/packages/geo_utils/lookup.py ###\n\nimport requests\nimport pandas as pd\nfrom io import StringIO\n\ndef get_eu_countries():\n    \"\"\"\n    All EU ISO-2 codes\n    \n    Returns:\n        data (list): List of ISO-2 codes)\n    \"\"\"\n    url = 'https://restcountries.eu/rest/v2/regionalbloc/eu'\n    r = requests.get(url)        \n    return [row['alpha2Code'] for row in r.json()]\n\n\ndef get_continent_lookup():\n    \"\"\"\n    Retrieves continent ISO2 code to continent name mapping from a static open URL.\n\n    Returns:\n        data (dict): Key-value pairs of continent-codes and names.\n    \"\"\"\n\n    url = (\"https://nesta-open-data.s3.eu-west\"\n           \"-2.amazonaws.com/rwjf-viz/\"\n           \"continent_codes_names.json\")\n    continent_lookup = {row[\"Code\"]: row[\"Name\"]\n                        for row in requests.get(url).json()}\n    continent_lookup[None] = None\n    continent_lookup[''] = None\n    return continent_lookup\n\ndef get_country_region_lookup():\n    \"\"\"\n    Retrieves subregions (around 18 in total)\n    lookups for all world countries, by ISO2 code,\n    form a static open URL.\n\n    Returns:\n        data (dict): Values are country_name-region_name pairs.\n    \"\"\"\n    url = (\"https://datahub.io/core/country-codes\"\n           \"/r/country-codes.csv\")\n    r = requests.get(url)\n    r.raise_for_status()\n    with StringIO(r.text) as csv:        \n        df = pd.read_csv(csv, usecols=['official_name_en', 'ISO3166-1-Alpha-2',\n                                       'Sub-region Name'])\n    data = {row['ISO3166-1-Alpha-2']: (row['official_name_en'],\n                                       row['Sub-region Name'])\n            for _, row in df.iterrows()\n            if not pd.isnull(row['official_name_en'])\n            and not pd.isnull(row['ISO3166-1-Alpha-2'])}\n    data['XK'] = ('Kosovo', 'Southern Europe')\n    data['TW'] = ('Kosovo', 'Eastern Asia')\n    return data\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pandas as pd\nfrom pandas.testing import assert_frame_equal\nimport pytest\nfrom unittest import mock\n\nfrom nesta.packages.geo_utils.geocode import geocode\nfrom nesta.packages.geo_utils.geocode import _geocode\nfrom nesta.packages.geo_utils.geocode import geocode_dataframe\nfrom nesta.packages.geo_utils.geocode import geocode_batch_dataframe\nfrom nesta.packages.geo_utils.geocode import generate_composite_key\nfrom nesta.packages.geo_utils.country_iso_code import country_iso_code\nfrom nesta.packages.geo_utils.country_iso_code import country_iso_code_dataframe\nfrom nesta.packages.geo_utils.country_iso_code import country_iso_code_to_name\nfrom nesta.packages.geo_utils.lookup import get_continent_lookup\nfrom nesta.packages.geo_utils.lookup import get_country_region_lookup\nfrom nesta.packages.geo_utils.lookup import get_country_continent_lookup\n\nREQUESTS = 'nesta.packages.geo_utils.geocode.requests.get'\nPYCOUNTRY = 'nesta.packages.geo_utils.country_iso_code.pycountry.countries.get'\nGEOCODE = 'nesta.packages.geo_utils.geocode.geocode'\n_GEOCODE = 'nesta.packages.geo_utils.geocode._geocode'\nCOUNTRY_ISO_CODE = 'nesta.packages.geo_utils.country_iso_code.country_iso_code'\n\n\nclass TestGeocoding():\n    @staticmethod\n    @pytest.fixture\n    def mocked_osm_response():\n        mocked_response = mock.Mock()\n        mocked_response.json.return_value = [{'lat': '12.923432', 'lon': '-75.234569'}]\n        return mocked_response\n\n    def test_error_raised_when_arguments_missing(self):\n        with pytest.raises(ValueError) as e:\n            geocode()\n        assert \"No geocode match\" in str(e.value)\n\n    @mock.patch(REQUESTS)\n    def test_request_includes_user_agent_in_header(self, mocked_request, mocked_osm_response):\n        mocked_request.return_value = mocked_osm_response\n        geocode(something='a')\n        assert mocked_request.call_args[1]['headers'] == {'User-Agent': 'Nesta health data geocode'}\n\n    @mock.patch(REQUESTS)\n    def test_url_correct_with_city_and_country(self, mocked_request, mocked_osm_response):\n        mocked_request.return_value = mocked_osm_response\n        kwargs = dict(city='london', country='UK')\n        geocode(**kwargs)\n        assert mocked_request.call_args[1]['params'] == dict(format=\"json\", **kwargs)\n\n    @mock.patch(REQUESTS)\n    def test_url_correct_with_query(self, mocked_request, mocked_osm_response):\n        mocked_request.return_value = mocked_osm_response\n        kwargs = dict(q='my place')\n        geocode(**kwargs)\n        assert mocked_request.call_args[1]['params'] == dict(format=\"json\", **kwargs)\n\n    @mock.patch(REQUESTS)\n    def test_error_returned_if_no_match(self, mocked_request):\n        mocked_response = mock.Mock()\n        mocked_response.json.return_value = []\n        mocked_request.return_value = mocked_response\n        with pytest.raises(ValueError) as e:\n            geocode(q=\"Something bad\")\n        assert \"No geocode match\" in str(e.value)\n\n    @mock.patch(REQUESTS)\n    def test_coordinates_extracted_from_json_with_one_result(self, mocked_request, mocked_osm_response):\n        mocked_request.return_value = mocked_osm_response\n        assert geocode(q='somewhere') == [{'lat': '12.923432', 'lon': '-75.234569'}]\n\n    @mock.patch(GEOCODE)\n    def test_geocode_wrapper_rejects_invalid_query_parameters(self, mocked_geocode):\n        with pytest.raises(ValueError) as e:\n            _geocode(cat='dog', city='Nice')\n        assert \"Invalid query parameter\" in str(e.value)\n\n    @mock.patch(GEOCODE)\n    def test_geocode_wrapper_rejects_both_q_and_kwargs_supplied(self, mocked_geocode):\n        with pytest.raises(ValueError) as e:\n            _geocode(city='London', q='somewhere')\n        assert \"Supply either q OR other query parameters, they cannot be combined.\" in str(e.value)\n\n    @mock.patch(GEOCODE)\n    def test_geocode_wrapper_errors_if_no_query_parameters_supplied(self, mocked_geocode):\n        with pytest.raises(ValueError) as e:\n            _geocode()\n        assert \"No query parameters supplied\" in str(e.value)\n\n    @mock.patch(GEOCODE)\n    def test_geocode_wrapper_calls_geocode_properly(self, mocked_geocode):\n        mocked_geocode.return_value = [{'lat': 1.1, 'lon': 2.2}]\n\n        _geocode('my place')\n        _geocode(q='somewhere')\n        _geocode(city='London', country='UK')\n        _geocode(postalcode='ABC 123')\n\n        expected_calls = [mock.call(q='my place'),\n                          mock.call(q='somewhere'),\n                          mock.call(city='London', country='UK'),\n                          mock.call(postalcode='ABC 123')\n                          ]\n        assert mocked_geocode.mock_calls == expected_calls\n\n\nclass TestGeocodeDataFrame():\n    @staticmethod\n    @pytest.fixture\n    def test_dataframe():\n        df = pd.DataFrame({'index': [0, 1, 2],\n                           'city': ['London', 'Sheffield', 'Brussels'],\n                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                           })\n        return df\n\n    @mock.patch(_GEOCODE)\n    def test_underlying_geocoding_function_called_with_city_country(self, mocked_geocode,\n                                                                    test_dataframe):\n        # Generate dataframe using a mocked output\n        mocked_geocode.side_effect = ['cat', 'dog', 'squirrel']\n        geocoded_dataframe = geocode_dataframe(test_dataframe)\n\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'coordinates': ['cat', 'dog', 'squirrel']\n                                           })\n        expected_calls = [mock.call(city='London', country='UK'),\n                          mock.call(city='Sheffield', country='United Kingdom'),\n                          mock.call(city='Brussels', country='Belgium')]\n\n        # Check expected behaviours\n        assert geocoded_dataframe.to_dict(orient=\"records\") == expected_dataframe.to_dict(orient=\"records\")\n        assert mocked_geocode.mock_calls == expected_calls\n\n    @mock.patch(_GEOCODE)\n    def test_underlying_geocoding_function_called_with_query_fallback(self, mocked_geocode,\n                                                                      test_dataframe):\n        mocked_geocode.side_effect = [None, None, None, 'dog', 'cat', 'squirrel']\n        geocoded_dataframe = geocode_dataframe(test_dataframe)\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'coordinates': ['dog', 'cat', 'squirrel']\n                                           })\n        expected_calls = [mock.call(city='London', country='UK'),\n                          mock.call(city='Sheffield', country='United Kingdom'),\n                          mock.call(city='Brussels', country='Belgium'),\n                          mock.call('London UK'),\n                          mock.call('Sheffield United Kingdom'),\n                          mock.call('Brussels Belgium')]\n\n        # Check expected behaviours\n        assert geocoded_dataframe.to_dict(orient=\"records\") == expected_dataframe.to_dict(orient=\"records\")\n        assert mocked_geocode.mock_calls == expected_calls\n\n    @mock.patch(_GEOCODE)\n    def test_duplicates_are_only_geocoded_once(self, mocked_geocode):\n        test_dataframe = pd.DataFrame({'index': [0, 1, 2, 3],\n                                       'city': ['London', 'Brussels', 'London', 'Brussels'],\n                                       'country': ['UK', 'Belgium', 'UK', 'Belgium']\n                                       })\n\n        mocked_geocode.side_effect = ['LON', 'BRU']\n        geocoded_dataframe = geocode_dataframe(test_dataframe)\n\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2, 3],\n                                           'city': ['London', 'Brussels', 'London', 'Brussels'],\n                                           'country': ['UK', 'Belgium', 'UK', 'Belgium'],\n                                           'coordinates': ['LON', 'BRU', 'LON', 'BRU']\n                                           })\n\n        assert geocoded_dataframe.to_dict(orient=\"records\") == expected_dataframe.to_dict(orient=\"records\")\n        assert mocked_geocode.call_count == 2\n\n\nclass TestGeocodeBatchDataframe():\n    @staticmethod\n    @pytest.fixture\n    def test_dataframe():\n        df = pd.DataFrame({'index': [0, 1, 2],\n                           'city': ['London', 'Sheffield', 'Brussels'],\n                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                           })\n        return df\n\n    @mock.patch(_GEOCODE)\n    def test_underlying_geocoding_function_called_with_city_country(self, mocked_geocode,\n                                                                    test_dataframe):\n        # Generate dataframe using a mocked output\n        mocked_geocode.side_effect = [{'lat': '12.923432', 'lon': '-75.234569'},\n                                      {'lat': '99.999999', 'lon': '-88.888888'},\n                                      {'lat': '-2.202022', 'lon': '0.000000'}\n                                      ]\n\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'latitude': [12.923432, 99.999999, -2.202022],\n                                           'longitude': [-75.234569, -88.888888, 0.0]\n                                           })\n        expected_calls = [mock.call(city='London', country='UK'),\n                          mock.call(city='Sheffield', country='United Kingdom'),\n                          mock.call(city='Brussels', country='Belgium')]\n\n        geocoded_dataframe = geocode_batch_dataframe(test_dataframe)\n\n        # Check expected behaviours\n        assert_frame_equal(geocoded_dataframe, expected_dataframe,\n                           check_like=True, check_dtype=False)\n        assert mocked_geocode.mock_calls == expected_calls\n\n    @mock.patch(_GEOCODE)\n    def test_underlying_geocoding_function_called_with_query_fallback(self,\n                                                                      mocked_geocode,\n                                                                      test_dataframe):\n        mocked_geocode.side_effect = [None,\n                                      {'lat': 1, 'lon': 4},\n                                      None,\n                                      {'lat': 2, 'lon': 5},\n                                      None,\n                                      {'lat': 3, 'lon': 6}\n                                      ]\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'latitude': [1.0, 2.0, 3.0],\n                                           'longitude': [4.0, 5.0, 6.0],\n                                           })\n        expected_calls = [mock.call(city='London', country='UK'),\n                          mock.call(q='London UK'),\n                          mock.call(city='Sheffield', country='United Kingdom'),\n                          mock.call(q='Sheffield United Kingdom'),\n                          mock.call(city='Brussels', country='Belgium'),\n                          mock.call(q='Brussels Belgium')]\n\n        geocoded_dataframe = geocode_batch_dataframe(test_dataframe, query_method='both')\n\n        # Check expected behaviours\n        assert_frame_equal(geocoded_dataframe, expected_dataframe,\n                           check_like=True, check_dtype=False)\n        assert mocked_geocode.mock_calls == expected_calls\n\n    @mock.patch(_GEOCODE)\n    def test_underlying_geocoding_function_called_with_query_method_only(self,\n                                                                         mocked_geocode,\n                                                                         test_dataframe):\n        mocked_geocode.side_effect = [{'lat': 1, 'lon': 4},\n                                      {'lat': 2, 'lon': 5},\n                                      {'lat': 3, 'lon': 6}\n                                      ]\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'latitude': [1.0, 2.0, 3.0],\n                                           'longitude': [4.0, 5.0, 6.0],\n                                           })\n        expected_calls = [mock.call(q='London UK'),\n                          mock.call(q='Sheffield United Kingdom'),\n                          mock.call(q='Brussels Belgium')]\n\n        geocoded_dataframe = geocode_batch_dataframe(test_dataframe, query_method='query_only')\n\n        # Check expected behaviours\n        assert_frame_equal(geocoded_dataframe, expected_dataframe,\n                           check_like=True, check_dtype=False)\n        assert mocked_geocode.mock_calls == expected_calls\n\n    @mock.patch(_GEOCODE)\n    def test_valueerror_raised_when_invalid_query_method_passed(self,\n                                                                mocked_geocode,\n                                                                test_dataframe):\n        with pytest.raises(ValueError):\n            geocode_batch_dataframe(test_dataframe, query_method='cats')\n\n        with pytest.raises(ValueError):\n            geocode_batch_dataframe(test_dataframe, query_method='test')\n\n        with pytest.raises(ValueError):\n            geocode_batch_dataframe(test_dataframe, query_method=1)\n\n    @mock.patch(_GEOCODE)\n    def test_output_column_names_are_applied(self, mocked_geocode, test_dataframe):\n\n        # Generate dataframe using a mocked output\n        mocked_geocode.side_effect = [{'lat': '12.923432', 'lon': '-75.234569'},\n                                      {'lat': '99.999999', 'lon': '-88.888888'},\n                                      {'lat': '-2.202022', 'lon': '0.000000'}\n                                      ]\n\n        # Expected outputs\n        expected_dataframe = pd.DataFrame({'index': [0, 1, 2],\n                                           'city': ['London', 'Sheffield', 'Brussels'],\n                                           'country': ['UK', 'United Kingdom', 'Belgium'],\n                                           'lat': [12.923432, 99.999999, -2.202022],\n                                           'lon': [-75.234569, -88.888888, 0.0]\n                                           })\n\n        geocoded_dataframe = geocode_batch_dataframe(test_dataframe,\n                                                     latitude='lat',\n                                                     longitude='lon')\n\n        # Check expected behaviours\n        assert_frame_equal(geocoded_dataframe, expected_dataframe,\n                           check_like=True, check_dtype=False)\n\n\nclass TestCountryIsoCode():\n    @mock.patch(PYCOUNTRY)\n    def test_lookup_via_name(self, mocked_pycountry):\n        mocked_pycountry.return_value = 'country_object'\n        expected_calls = [mock.call(name='United Kingdom')]\n\n        assert country_iso_code('United Kingdom') == 'country_object'\n        assert mocked_pycountry.mock_calls == expected_calls\n        assert mocked_pycountry.call_count == 1\n        country_iso_code.cache_clear()\n\n    @mock.patch(PYCOUNTRY)\n    def test_lookup_via_common_name(self, mocked_pycountry):\n        mocked_pycountry.side_effect = [KeyError(), 'country_object']\n        expected_calls = [mock.call(name='United Kingdom'),\n                          mock.call(common_name='United Kingdom')\n                          ]\n\n        assert country_iso_code('United Kingdom') == 'country_object'\n        assert mocked_pycountry.mock_calls == expected_calls\n        assert mocked_pycountry.call_count == 2\n        country_iso_code.cache_clear()\n\n    @mock.patch(PYCOUNTRY)\n    def test_lookup_via_official_name(self, mocked_pycountry):\n        mocked_pycountry.side_effect = [KeyError(), KeyError(), 'country_object']\n        expected_calls = [mock.call(name='United Kingdom'),\n                          mock.call(common_name='United Kingdom'),\n                          mock.call(official_name='United Kingdom')\n                          ]\n\n        assert country_iso_code('United Kingdom') == 'country_object'\n        assert mocked_pycountry.mock_calls == expected_calls\n        assert mocked_pycountry.call_count == 3\n        country_iso_code.cache_clear()\n\n    @mock.patch(PYCOUNTRY)\n    def test_invalid_lookup_raises_keyerror(self, mocked_pycountry):\n        mocked_pycountry.side_effect = [KeyError(), KeyError(), KeyError()]*2\n\n        with pytest.raises(KeyError) as e:\n            country_iso_code('Fake Country')\n        assert 'Fake Country not found' in str(e.value)\n        country_iso_code.cache_clear()\n\n    @mock.patch(PYCOUNTRY)\n    def test_title_case_is_applied(self, mocked_pycountry):\n        expected_calls = []\n        names = ['united kingdom', 'UNITED KINGDOM',\n                 'United kingdom']\n        mocked_pycountry.side_effect = [KeyError(), KeyError(), KeyError(), 'blah'] * len(names)\n        for name in names:\n            country_iso_code(name)  # Find the iso codes\n            raw_call = mock.call(name=name)\n            common_call = mock.call(common_name=name)\n            official_call = mock.call(official_name=name)\n            title_call = mock.call(name='United Kingdom')\n            expected_calls.append(raw_call)  # The initial call\n            expected_calls.append(common_call)  # Tries common name call\n            expected_calls.append(official_call)  # Tries official name\n            expected_calls.append(title_call) # The title case call\n        assert mocked_pycountry.mock_calls == expected_calls\n    country_iso_code.cache_clear()\n\n\nclass TestCountryIsoCodeDataframe():\n    @staticmethod\n    def _mocked_response(alpha_2, alpha_3, numeric, continent):\n        '''Builds a mocked response for the patched country_iso_code function.'''\n        response = mock.Mock()\n        response.alpha_2 = alpha_2\n        response.alpha_3 = alpha_3\n        response.numeric = numeric\n        response.continent = continent\n        return response\n\n    @mock.patch(COUNTRY_ISO_CODE)\n    def test_valid_countries_coded(self, mocked_country_iso_code):\n        test_df = pd.DataFrame({'index': [0, 1, 2],\n                                'country': ['United Kingdom', 'Belgium', 'United States']\n                                })\n        mocked_response_uk = self._mocked_response('GB', 'GBR', '123', 'EU')\n        mocked_response_be = self._mocked_response('BE', 'BEL', '875', 'EU')\n        mocked_response_us = self._mocked_response('US', 'USA', '014', 'NA')\n        mocked_country_iso_code.side_effect = [mocked_response_uk,\n                                               mocked_response_be,\n                                               mocked_response_us\n                                               ]\n        expected_dataframe = pd.DataFrame(\n                            {'index': [0, 1, 2],\n                             'country': ['United Kingdom', 'Belgium', 'United States'],\n                             'country_alpha_2': ['GB', 'BE', 'US'],\n                             'country_alpha_3': ['GBR', 'BEL', 'USA'],\n                             'country_numeric': ['123', '875', '014'],\n                             'continent': ['EU', 'EU', 'NA']\n                             })\n        coded_df = country_iso_code_dataframe(test_df)\n        assert coded_df.to_dict(orient=\"records\") == expected_dataframe.to_dict(orient=\"records\")\n\n    @mock.patch(COUNTRY_ISO_CODE)\n    def test_invalid_countries_data_is_none(self, mocked_country_iso_code):\n        test_df = pd.DataFrame({'index': [0, 1, 2],\n                                'country': ['United Kingdom', 'Belgium', 'United States']\n                                })\n        mocked_country_iso_code.side_effect = KeyError\n        expected_dataframe = pd.DataFrame(\n                            {'index': [0, 1, 2],\n                             'country': ['United Kingdom', 'Belgium', 'United States'],\n                             'country_alpha_2': [None, None, None],\n                             'country_alpha_3': [None, None, None],\n                             'country_numeric': [None, None, None],\n                             'continent': [None, None, None]\n                             })\n        coded_df = country_iso_code_dataframe(test_df)\n        assert coded_df.to_dict(orient=\"records\") == expected_dataframe.to_dict(orient=\"records\")\n\n\nclass TestCountryIsoCodeToName():\n    def test_valid_iso_code_returns_name(self):\n        assert country_iso_code_to_name('ITA') == 'Italy'\n        assert country_iso_code_to_name('DEU') == 'Germany'\n        assert country_iso_code_to_name('GBR') == 'United Kingdom'\n\n    def test_invalid_iso_code_returns_none(self):\n        assert country_iso_code_to_name('FOO') is None\n        assert country_iso_code_to_name('ABC') is None\n        assert country_iso_code_to_name('ZZZ') is None\n\n\ndef test_generate_composite_key():\n    assert generate_composite_key('London', 'United Kingdom') == 'london_united-kingdom'\n    assert generate_composite_key('Paris', 'France') == 'paris_france'\n    assert generate_composite_key('Name-with hyphen', 'COUNTRY') == 'name-with-hyphen_country'\n\n\ndef test_generate_composite_key_raises_error_with_invalid_input():\n    with pytest.raises(ValueError):\n        generate_composite_key(None, 'UK')\n\n    with pytest.raises(ValueError):\n        generate_composite_key('city_only')\n\n    with pytest.raises(ValueError):\n        generate_composite_key(1, 2)\n\n\ndef test_get_continent_lookup():\n    continents = get_continent_lookup()\n    assert None in continents\n    assert '' in continents\n    assert continents['NA'] == 'North America'\n    assert len(continents) == 9  # 2 nulls + 7 continents\n\ndef test_get_country_region_lookup():\n    countries = get_country_region_lookup()\n    assert len(countries) > 100\n    assert len(countries) < 1000\n    assert all(len(k) == 2 for k in countries.keys())\n    assert all(type(v) is tuple for v in countries.values())\n    assert all(len(v) == 2 for v in countries.values())\n    all_regions = {v[1] for v in countries.values()}\n    assert len(all_regions) == 18\n\n\ndef test_country_continent_lookup():\n    lookup = get_country_continent_lookup()\n    non_nulls = {k: v for k, v in lookup.items()\n                 if k is not None and k != ''}\n    # All iso2, so length == 2\n    assert all(len(k) == 2 for k in non_nulls.items())\n    assert all(len(v) == 2 for v in non_nulls.values())\n    # Either strings or Nones\n    country_types = set(type(v) for v in lookup.values())\n    assert country_types == {str, type(None)}\n    # Right ball-park of country and continent numbers\n    assert len(non_nulls) > 100  # num countries\n    assert len(non_nulls) < 1000 # num countries\n    assert len(set(non_nulls.values())) == 7 # num continents\n"
  },
  {
    "prompt": "\n\n### pycamunda/incident.py ###\n\n# -*- coding: utf-8 -*-\n\n\"\"\"This module provides access to the incident REST api of Camunda.\"\"\"\n\nfrom __future__ import annotations\nimport datetime as dt\nimport dataclasses\nimport enum\nimport typing\n\nimport pycamunda.variable\nimport pycamunda.base\nfrom pycamunda.request import QueryParameter, PathParameter\n\nURL_SUFFIX = '/incident'\n\n\n__all__ = ['IncidentType', 'Get', 'GetList', 'Resolve']\n\n\nclass IncidentType(enum.Enum):\n    failed_job = 'failedJob'\n    failed_external_task = 'failedExternalTask'\n\n\n@dataclasses.dataclass\nclass IncidentTypeCount:\n    \"\"\"Data class of incident type count as returned by the REST api of Camunda.\"\"\"\n    incident_type: IncidentType\n    incident_count: int\n\n    @classmethod\n    def load(cls, data) -> IncidentTypeCount:\n        return cls(\n            incident_type=IncidentType(data['incidentType']),\n            incident_count=data['incidentCount']\n        )\n\n\n@dataclasses.dataclass\nclass Incident:\n    \"\"\"Data class of incident as returned by the REST api of Camunda.\"\"\"\n    id_: str\n    process_definition_id: str\n    process_instance_id: str\n    execution_id: str\n    incident_type: IncidentType\n    activity_id: str\n    cause_incident_id: str\n    root_cause_incident_id: str\n    configuration: str\n    tenant_id: str\n    incident_message: str\n    job_definition_id: str\n    incident_timestamp: dt.datetime = None\n\n    @classmethod\n    def load(cls, data: typing.Mapping[str, typing.Any]) -> Incident:\n        incident = cls(\n            id_=data['id'],\n            process_definition_id=data['processDefinitionId'],\n            process_instance_id=data['processInstanceId'],\n            execution_id=data['executionId'],\n            incident_type=IncidentType(data['incidentType']),\n            activity_id=data['activityId'],\n            cause_incident_id=data['causeIncidentId'],\n            root_cause_incident_id=data['rootCauseIncidentId'],\n            configuration=data['configuration'],\n            tenant_id=data['tenantId'],\n            incident_message=data['incidentMessage'],\n            job_definition_id=data['jobDefinitionId']\n        )\n        if data['incidentTimestamp'] is not None:\n            incident.incident_timestamp = pycamunda.base.from_isoformat(\n                data['incidentTimestamp']\n            )\n\n        return incident\n\n\nclass Get(pycamunda.base.CamundaRequest):\n\n    id_ = PathParameter('id')\n\n    def __init__(self, url: str, id_: str):\n        \"\"\"Get an incident.\n\n        :param url: Camunda Rest engine URL.\n        :param id_: Id of the incident.\n        \"\"\"\n        super().__init__(url=url + URL_SUFFIX + '/{id}')\n        self.id_ = id_\n\n    def __call__(self, *args, **kwargs) -> Incident:\n        \"\"\"Send the request.\"\"\"\n        response = super().__call__(pycamunda.base.RequestMethod.GET, *args, **kwargs)\n\n        return Incident.load(response.json())\n\n\nclass GetList(pycamunda.base.CamundaRequest):\n\n    incident_id = QueryParameter('incidentId')\n    incident_type = QueryParameter('incidentType')\n    incident_message = QueryParameter('incidentMessage')\n    process_definition_id = QueryParameter('processDefinitionId')\n    process_definition_key_in = QueryParameter('processDefinitionKeyIn')\n    process_instance_id = QueryParameter('processInstanceId')\n    execution_id = QueryParameter('executionId')\n    activity_id = QueryParameter('activityId')\n    cause_incident_id = QueryParameter('causeIncidentId')\n    root_cause_incident_id = QueryParameter('rootCauseIncidentId')\n    configuration = QueryParameter('configuration')\n    tenant_id_in = QueryParameter('tenantIdIn')\n    job_definition_id_in = QueryParameter('jobDefinitionIdIn')\n    sort_by = QueryParameter(\n        'sortBy',\n        mapping={\n            'incident_id': 'incidentId',\n            'incident_message': 'incidentMessage',\n            'incident_timestamp': 'incidentTimestamp',\n            'incident_type': 'incidentType',\n            'execution_id': 'executionId',\n            'activity_id': 'activityId',\n            'process_instance_id': 'processInstanceId',\n            'process_definition_id': 'processDefinitionId',\n            'cause_incident_id': 'causeIncidentId',\n            'root_cause_incident_id': 'rootCauseIncidentId',\n            'configuration': 'configuration',\n            'tenant_id': 'tenantId'\n        }\n    )\n    ascending = QueryParameter(\n        'sortOrder',\n        mapping={True: 'asc', False: 'desc'},\n        provide=lambda self, obj, obj_type: vars(obj).get('sort_by', None) is not None\n    )\n\n    def __init__(\n        self,\n        url: str,\n        incident_id: str = None,\n        incident_type: str = None,\n        incident_message: str = None,\n        process_definition_id: str = None,\n        process_definition_key_in: typing.Iterable[str] = None,\n        process_instance_id: str = None,\n        execution_id: str = None,\n        activity_id: str = None,\n        cause_incident_id: str = None,\n        root_cause_incident_id: str = None,\n        configuration: str = None,\n        tenant_id_in: typing.Iterable[str] = None,\n        job_definition_id_in: typing.Iterable[str] = None,\n        sort_by: str = None,\n        ascending: bool = True\n    ):\n        \"\"\"Get a list of incidents.\n\n        :param url: Camunda Rest engine URL.\n        :param incident_id: Filter by incident id.\n        :param incident_type: Filter by incident type. Valid values are 'failedJob' and\n                              'failedExternalTask'\n        :param incident_message: Filter by incident message.\n        :param process_definition_id: Filter by process definition id.\n        :param process_definition_key_in: Filter whether the process definition key is one of\n                                          multiple ones.\n        :param process_instance_id: Filter by process instance id.\n        :param execution_id: Filter by execution id.\n        :param activity_id: Filter by activity id.\n        :param cause_incident_id: Filter by cause incident id.\n        :param root_cause_incident_id: Filter by root cause incident id.\n        :param configuration: Filter by configuration.\n        :param tenant_id_in: Filter whether the tenant id is one of multiple ones.\n        :param job_definition_id_in: Filter whether the job definition id is one of multiple ones.\n        :param sort_by: Sort the results by 'incident_id', 'incident_message', incident_timestamp',\n                        'incident_type', 'execution_id', 'activity_id', 'process_instance_id',\n                        'process_definition_id', 'cause_incident_id', 'root_cause_incident_id',\n                        'configuration' or 'tenant_id'.\n        :param ascending: Sort order.\n        \"\"\"\n        super().__init__(url=url + URL_SUFFIX)\n        self.incident_id = incident_id\n        self.incident_type = incident_type\n        self.incident_message = incident_message\n        self.process_definition_id = process_definition_id\n        self.process_definition_key_in = process_definition_key_in\n        self.process_instance_id = process_instance_id\n        self.execution_id = execution_id\n        self.activity_id = activity_id\n        self.cause_incident_id = cause_incident_id\n        self.root_cause_incident_id = root_cause_incident_id\n        self.configuration = configuration\n        self.tenant_id_in = tenant_id_in\n        self.job_definition_id_in = job_definition_id_in\n        self.sort_by = sort_by\n        self.ascending = ascending\n\n    def __call__(self, *args, **kwargs) -> typing.Tuple[Incident]:\n        \"\"\"Send the request.\"\"\"\n        response = super().__call__(pycamunda.base.RequestMethod.GET, *args, **kwargs)\n\n        return tuple(Incident.load(incident_json) for incident_json in response.json())\n\n\nclass Resolve(pycamunda.base.CamundaRequest):\n\n    id_ = PathParameter('id')\n\n    def __init__(self, url: str, id_: str):\n        \"\"\"Resolve an incident.\n\n        :param url: Camunda Rest engine URL.\n        :param id_: Id of the incident.\n        \"\"\"\n        super().__init__(url=url + URL_SUFFIX + '/{id}')\n        self.id_ = id_\n\n    def __call__(self, *args, **kwargs) -> None:\n        \"\"\"Send the request.\"\"\"\n        response = super().__call__(pycamunda.base.RequestMethod.DELETE, *args, **kwargs)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# -*- coding: utf-8 -*-\n\nimport unittest.mock\n\nimport pytest\n\nimport pycamunda.incident\nfrom tests.mock import raise_requests_exception_mock, not_ok_response_mock\n\n\ndef test_get_params(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n\n    assert get_incident.url == engine_url + '/incident/anId'\n    assert get_incident.query_parameters() == {}\n    assert get_incident.body_parameters() == {}\n\n\n@unittest.mock.patch('pycamunda.incident.Incident.load', unittest.mock.MagicMock())\n@unittest.mock.patch('requests.Session.request')\ndef test_get_calls_requests(mock, engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    get_incident()\n\n    assert mock.called\n    assert mock.call_args[1]['method'].upper() == 'GET'\n\n\n@unittest.mock.patch('requests.Session.request', raise_requests_exception_mock)\ndef test_get_raises_pycamunda_exception(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    with pytest.raises(pycamunda.PyCamundaException):\n        get_incident()\n\n\n@unittest.mock.patch('requests.Session.request', not_ok_response_mock)\n@unittest.mock.patch('pycamunda.incident.Incident', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.base._raise_for_status')\ndef test_get_raises_for_status(mock, engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    get_incident()\n\n    assert mock.called\n\n\n@unittest.mock.patch('requests.Session.request', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.base.from_isoformat', unittest.mock.MagicMock())\n@unittest.mock.patch('pycamunda.incident.IncidentType', unittest.mock.MagicMock())\ndef test_get_returns_incident(engine_url):\n    get_incident = pycamunda.incident.Get(url=engine_url, id_='anId')\n    incident = get_incident()\n\n    assert isinstance(incident, pycamunda.incident.Incident)\n"
  },
  {
    "prompt": "\n\n### treeherder/model/models.py ###\n\nimport datetime\nimport itertools\nimport logging\nimport re\nimport time\nfrom hashlib import sha1\nfrom typing import List\n\nimport newrelic.agent\nfrom django.contrib.auth.models import User\nfrom django.core.cache import cache\nfrom django.core.exceptions import ObjectDoesNotExist\nfrom django.core.validators import MinLengthValidator\nfrom django.db import models, transaction\nfrom django.db.models import Count, Max, Min, Q, Subquery\nfrom django.db.utils import ProgrammingError\nfrom django.forms import model_to_dict\nfrom django.utils import timezone\n\nfrom treeherder.webapp.api.utils import REPO_GROUPS, to_timestamp\n\nlogger = logging.getLogger(__name__)\n\n# MySQL Full Text Search operators, based on:\n# https://dev.mysql.com/doc/refman/5.7/en/fulltext-boolean.html\nmysql_fts_operators_re = re.compile(r'[-+@<>()~*\"]')\n\n\nclass FailuresQuerySet(models.QuerySet):\n    def by_bug(self, bug_id):\n        return self.filter(bug_id=int(bug_id))\n\n    def by_date(self, startday, endday):\n        return self.select_related('push', 'job').filter(job__push__time__range=(startday, endday))\n\n    def by_repo(self, name, bugjobmap=True):\n        if name in REPO_GROUPS:\n            repo = REPO_GROUPS[name]\n            return (\n                self.filter(job__repository_id__in=repo)\n                if bugjobmap\n                else self.filter(repository_id__in=repo)\n            )\n        elif name == 'all':\n            return self\n        else:\n            return (\n                self.filter(job__repository__name=name)\n                if bugjobmap\n                else self.filter(repository__name=name)\n            )\n\n\nclass NamedModel(models.Model):\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=100, unique=True)\n\n    class Meta:\n        abstract = True\n\n    def __str__(self):\n        return self.name\n\n\nclass Product(NamedModel):\n    class Meta:\n        db_table = 'product'\n\n\nclass BuildPlatform(models.Model):\n    id = models.AutoField(primary_key=True)\n    os_name = models.CharField(max_length=25)\n    platform = models.CharField(max_length=100, db_index=True)\n    architecture = models.CharField(max_length=25, blank=True, db_index=True)\n\n    class Meta:\n        db_table = 'build_platform'\n        unique_together = (\"os_name\", \"platform\", \"architecture\")\n\n    def __str__(self):\n        return \"{0} {1} {2}\".format(self.os_name, self.platform, self.architecture)\n\n\nclass Option(NamedModel):\n    class Meta:\n        db_table = 'option'\n\n\nclass RepositoryGroup(NamedModel):\n\n    description = models.TextField(blank=True)\n\n    class Meta:\n        db_table = 'repository_group'\n\n\nclass Repository(models.Model):\n    id = models.AutoField(primary_key=True)\n    repository_group = models.ForeignKey('RepositoryGroup', on_delete=models.CASCADE)\n    name = models.CharField(max_length=50, unique=True, db_index=True)\n    dvcs_type = models.CharField(max_length=25, db_index=True)\n    url = models.CharField(max_length=255)\n    branch = models.CharField(max_length=255, null=True, db_index=True)\n    codebase = models.CharField(max_length=50, blank=True, db_index=True)\n    description = models.TextField(blank=True)\n    active_status = models.CharField(max_length=7, blank=True, default='active', db_index=True)\n    performance_alerts_enabled = models.BooleanField(default=False)\n    expire_performance_data = models.BooleanField(default=True)\n    is_try_repo = models.BooleanField(default=False)\n    tc_root_url = models.CharField(max_length=255, null=False, db_index=True)\n\n    class Meta:\n        db_table = 'repository'\n        verbose_name_plural = 'repositories'\n\n    @classmethod\n    def fetch_all_names(cls) -> List[str]:\n        return cls.objects.values_list('name', flat=True)\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.name, self.repository_group)\n\n\nclass Push(models.Model):\n    \"\"\"\n    A push to a repository\n\n    A push should contain one or more commit objects, representing\n    the changesets that were part of the push\n    \"\"\"\n\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    revision = models.CharField(max_length=40, db_index=True)\n    author = models.CharField(max_length=150)\n    time = models.DateTimeField(db_index=True)\n\n    failures = FailuresQuerySet.as_manager()\n    objects = models.Manager()\n\n    class Meta:\n        db_table = 'push'\n        unique_together = ('repository', 'revision')\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.repository.name, self.revision)\n\n    def get_status(self):\n        \"\"\"\n        Gets a summary of what passed/failed for the push\n        \"\"\"\n        jobs = (\n            Job.objects.filter(push=self)\n            .filter(\n                Q(failure_classification__isnull=True)\n                | Q(failure_classification__name='not classified')\n            )\n            .exclude(tier=3)\n        )\n\n        status_dict = {'completed': 0, 'pending': 0, 'running': 0}\n        for (state, result, total) in jobs.values_list('state', 'result').annotate(\n            total=Count('result')\n        ):\n            if state == 'completed':\n                status_dict[result] = total\n                status_dict[state] += total\n            else:\n                status_dict[state] = total\n        if 'superseded' in status_dict:\n            # backward compatability for API consumers\n            status_dict['coalesced'] = status_dict['superseded']\n\n        return status_dict\n\n\nclass Commit(models.Model):\n    \"\"\"\n    A single commit in a push\n    \"\"\"\n\n    push = models.ForeignKey(Push, on_delete=models.CASCADE, related_name='commits')\n    revision = models.CharField(max_length=40, db_index=True)\n    author = models.CharField(max_length=150)\n    comments = models.TextField()\n\n    class Meta:\n        db_table = 'commit'\n        unique_together = ('push', 'revision')\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.push.repository.name, self.revision)\n\n\nclass MachinePlatform(models.Model):\n    id = models.AutoField(primary_key=True)\n    os_name = models.CharField(max_length=25)\n    platform = models.CharField(max_length=100, db_index=True)\n    architecture = models.CharField(max_length=25, blank=True, db_index=True)\n\n    class Meta:\n        db_table = 'machine_platform'\n        unique_together = (\"os_name\", \"platform\", \"architecture\")\n\n    def __str__(self):\n        return \"{0} {1} {2}\".format(self.os_name, self.platform, self.architecture)\n\n\nclass Bugscache(models.Model):\n    id = models.PositiveIntegerField(primary_key=True)\n    status = models.CharField(max_length=64, db_index=True)\n    resolution = models.CharField(max_length=64, blank=True, db_index=True)\n    # Is covered by a FULLTEXT index created via a migrations RunSQL operation.\n    summary = models.CharField(max_length=255)\n    crash_signature = models.TextField(blank=True)\n    keywords = models.TextField(blank=True)\n    os = models.CharField(max_length=64, blank=True)\n    modified = models.DateTimeField()\n    whiteboard = models.CharField(max_length=100, blank=True, default='')\n\n    class Meta:\n        db_table = 'bugscache'\n        verbose_name_plural = 'bugscache'\n\n    def __str__(self):\n        return \"{0}\".format(self.id)\n\n    @classmethod\n    def search(cls, search_term):\n        max_size = 50\n\n        # 365 days ago as limit for recent bugs which get suggested by default\n        # if they are not resolved. Other bugs, both older or resolved, are\n        # hidden by default with a \"Show / Hide More\" link.\n        time_limit = datetime.datetime.now() - datetime.timedelta(days=365)\n\n        # Replace MySQL's Full Text Search Operators with spaces so searching\n        # for errors that have been pasted in still works.\n        sanitised_term = re.sub(mysql_fts_operators_re, \" \", search_term)\n\n        # Wrap search term so it is used as a phrase in the full-text search.\n        search_term_fulltext = '\"%s\"' % sanitised_term\n\n        # Substitute escape and wildcard characters, so the search term is used\n        # literally in the LIKE statement.\n        search_term_like = search_term.replace('=', '==').replace('%', '=%').replace('_', '=_')\n\n        recent_qs = cls.objects.raw(\n            \"\"\"\n            SELECT id, summary, crash_signature, keywords, os, resolution, status,\n             MATCH (`summary`) AGAINST (%s IN BOOLEAN MODE) AS relevance\n              FROM bugscache\n             WHERE 1\n               AND resolution = ''\n               AND `summary` LIKE CONCAT ('%%%%', %s, '%%%%') ESCAPE '='\n               AND modified >= %s\n          ORDER BY relevance DESC\n             LIMIT 0,%s\n            \"\"\",\n            [search_term_fulltext, search_term_like, time_limit, max_size],\n        )\n\n        try:\n            open_recent = [model_to_dict(item, exclude=[\"modified\"]) for item in recent_qs]\n        except ProgrammingError as e:\n            newrelic.agent.record_exception()\n            logger.error(\n                'Failed to execute FULLTEXT search on Bugscache, error={}, SQL={}'.format(\n                    e, recent_qs.query.__str__()\n                )\n            )\n            open_recent = []\n\n        all_others_qs = cls.objects.raw(\n            \"\"\"\n            SELECT id, summary, crash_signature, keywords, os, resolution, status,\n             MATCH (`summary`) AGAINST (%s IN BOOLEAN MODE) AS relevance\n              FROM bugscache\n             WHERE 1\n               AND `summary` LIKE CONCAT ('%%%%', %s, '%%%%') ESCAPE '='\n               AND (modified < %s OR resolution <> '')\n          ORDER BY relevance DESC\n             LIMIT 0,%s\n            \"\"\",\n            [search_term_fulltext, search_term_like, time_limit, max_size],\n        )\n\n        try:\n            all_others = [model_to_dict(item, exclude=[\"modified\"]) for item in all_others_qs]\n        except ProgrammingError as e:\n            newrelic.agent.record_exception()\n            logger.error(\n                'Failed to execute FULLTEXT search on Bugscache, error={}, SQL={}'.format(\n                    e, recent_qs.query.__str__()\n                )\n            )\n            all_others = []\n\n        return {\"open_recent\": open_recent, \"all_others\": all_others}\n\n\nclass Machine(NamedModel):\n    class Meta:\n        db_table = 'machine'\n\n\nclass JobGroup(models.Model):\n    id = models.AutoField(primary_key=True)\n    symbol = models.CharField(max_length=25, default='?', db_index=True)\n    name = models.CharField(max_length=100)\n    description = models.TextField(blank=True)\n\n    class Meta:\n        db_table = 'job_group'\n        unique_together = ('name', 'symbol')\n\n    def __str__(self):\n        return \"{0} ({1})\".format(self.name, self.symbol)\n\n\nclass OptionCollectionManager(models.Manager):\n    cache_key = 'option_collection_map'\n    '''\n    Convenience function to determine the option collection map\n    '''\n\n    def get_option_collection_map(self):\n        option_collection_map = cache.get(self.cache_key)\n\n        if option_collection_map:\n            return option_collection_map\n\n        option_collection_map = {}\n        for (hash, option_name) in OptionCollection.objects.values_list(\n            'option_collection_hash', 'option__name'\n        ):\n            if not option_collection_map.get(hash):\n                option_collection_map[hash] = option_name\n            else:\n                option_collection_map[hash] += ' ' + option_name\n\n        # Caches for the default of 5 minutes.\n        cache.set(self.cache_key, option_collection_map)\n        return option_collection_map\n\n\nclass OptionCollection(models.Model):\n    id = models.AutoField(primary_key=True)\n    option_collection_hash = models.CharField(max_length=40)\n    option = models.ForeignKey(Option, on_delete=models.CASCADE, db_index=True)\n\n    objects = OptionCollectionManager()\n\n    @staticmethod\n    def calculate_hash(options):\n        \"\"\"returns an option_collection_hash given a list of options\"\"\"\n        options = sorted(list(options))\n        sha_hash = sha1()\n        # equivalent to loop over the options and call sha_hash.update()\n        sha_hash.update(''.join(options).encode('utf-8'))\n        return sha_hash.hexdigest()\n\n    class Meta:\n        db_table = 'option_collection'\n        unique_together = ('option_collection_hash', 'option')\n\n    def __str__(self):\n        return \"{0}\".format(self.option)\n\n\nclass JobType(models.Model):\n    id = models.AutoField(primary_key=True)\n    symbol = models.CharField(max_length=25, default='?', db_index=True)\n    name = models.CharField(max_length=140)\n    description = models.TextField(blank=True)\n\n    class Meta:\n        db_table = 'job_type'\n        unique_together = (('name', 'symbol'),)\n\n    def __str__(self):\n        return \"{0} ({1})\".format(self.name, self.symbol)\n\n\nclass FailureClassification(NamedModel):\n    class Meta:\n        db_table = 'failure_classification'\n\n\nclass ReferenceDataSignatures(models.Model):\n\n    \"\"\"\n    A collection of all the possible combinations of reference data,\n    populated on data ingestion. signature is a hash of the data it refers to\n    build_system_type is buildbot by default\n\n    TODO: Rename to 'ReferenceDataSignature'.\n    \"\"\"\n\n    name = models.CharField(max_length=255)\n    signature = models.CharField(max_length=50, db_index=True)\n    build_os_name = models.CharField(max_length=25, db_index=True)\n    build_platform = models.CharField(max_length=100, db_index=True)\n    build_architecture = models.CharField(max_length=25, db_index=True)\n    machine_os_name = models.CharField(max_length=25, db_index=True)\n    machine_platform = models.CharField(max_length=100, db_index=True)\n    machine_architecture = models.CharField(max_length=25, db_index=True)\n    job_group_name = models.CharField(max_length=100, blank=True, db_index=True)\n    job_group_symbol = models.CharField(max_length=25, blank=True, db_index=True)\n    job_type_name = models.CharField(max_length=140, db_index=True)\n    job_type_symbol = models.CharField(max_length=25, blank=True, db_index=True)\n    option_collection_hash = models.CharField(max_length=64, blank=True, db_index=True)\n    build_system_type = models.CharField(max_length=25, blank=True, db_index=True)\n    repository = models.CharField(max_length=50, db_index=True)\n    first_submission_timestamp = models.IntegerField(db_index=True)\n\n    class Meta:\n        db_table = 'reference_data_signatures'\n        # Remove if/when the model is renamed to 'ReferenceDataSignature'.\n        verbose_name_plural = 'reference data signatures'\n        unique_together = ('name', 'signature', 'build_system_type', 'repository')\n\n\nclass JobManager(models.Manager):\n    \"\"\"\n    Convenience functions for operations on groups of jobs\n    \"\"\"\n\n    def cycle_data(self, cycle_interval, chunk_size, sleep_time):\n        \"\"\"\n        Delete data older than cycle_interval, splitting the target data into\n        chunks of chunk_size size. Returns the number of result sets deleted\n        \"\"\"\n        jobs_max_timestamp = datetime.datetime.now() - cycle_interval\n\n        jobs_cycled = 0\n        while True:\n            min_id = Job.objects.aggregate(Min(\"id\"))[\"id__min\"]\n            if min_id is None:\n                return jobs_cycled\n            max_id = min_id + chunk_size\n            max_chunk = Job.objects.filter(id__lt=max_id).aggregate(\n                submit_time=Max(\"submit_time\"), id=Max(\"id\"), count=Count(\"id\")\n            )\n            if max_chunk[\"count\"] == 0 or max_chunk[\"submit_time\"] > jobs_max_timestamp:\n                # this next chunk is too young, we are done\n                return jobs_cycled\n\n            logger.warning(\n                \"Pruning jobs: chunk of {} older than {}\".format(\n                    max_chunk[\"count\"], jobs_max_timestamp.strftime(\"%b %d %Y\")\n                )\n            )\n\n            # Remove ORM entries for these jobs that don't currently have a\n            # foreign key relation\n            logger.warning(\"deleting FailureLines\")\n            delete_guid = list(\n                Job.objects.filter(id__lt=max_id).only(\"guid\").values_list(\"guid\", flat=True)\n            )\n            FailureLine.objects.filter(job_guid__in=delete_guid).only(\"id\").delete()\n\n            # cycle jobs *after* related data has been deleted, to be sure\n            # we don't have any orphan data\n            logger.warning(\"delete jobs\")\n            self.filter(id__lt=max_id).only(\"id\").delete()\n\n            jobs_cycled += max_chunk[\"count\"]\n\n            if sleep_time:\n                # Allow some time for other queries to get through\n                time.sleep(sleep_time)\n\n\nclass Job(models.Model):\n    \"\"\"\n    This class represents a build or test job in Treeherder\n    \"\"\"\n\n    failures = FailuresQuerySet.as_manager()\n    objects = JobManager()\n\n    id = models.BigAutoField(primary_key=True)\n\n    PENDING = 0\n    CROSSREFERENCED = 1\n    AUTOCLASSIFIED = 2\n    SKIPPED = 3\n    FAILED = 255\n\n    AUTOCLASSIFY_STATUSES = (\n        (PENDING, 'pending'),\n        (CROSSREFERENCED, 'crossreferenced'),\n        (AUTOCLASSIFIED, 'autoclassified'),\n        (SKIPPED, 'skipped'),\n        (FAILED, 'failed'),\n    )\n\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    guid = models.CharField(max_length=50, unique=True)\n    project_specific_id = models.PositiveIntegerField(null=True)  # unused, see bug 1328985\n    # TODO: Remove autoclassify_status next time jobs table is modified (bug 1594822)\n    autoclassify_status = models.IntegerField(choices=AUTOCLASSIFY_STATUSES, default=PENDING)\n\n    # TODO: Remove coalesced_to_guid next time the jobs table is modified (bug 1402992)\n    coalesced_to_guid = models.CharField(max_length=50, null=True, default=None)\n    signature = models.ForeignKey(ReferenceDataSignatures, on_delete=models.CASCADE)\n    build_platform = models.ForeignKey(BuildPlatform, on_delete=models.CASCADE, related_name='jobs')\n    machine_platform = models.ForeignKey(MachinePlatform, on_delete=models.CASCADE)\n    machine = models.ForeignKey(Machine, on_delete=models.CASCADE)\n    option_collection_hash = models.CharField(max_length=64)\n    job_type = models.ForeignKey(JobType, on_delete=models.CASCADE, related_name='jobs')\n    job_group = models.ForeignKey(JobGroup, on_delete=models.CASCADE, related_name='jobs')\n    product = models.ForeignKey(Product, on_delete=models.CASCADE)\n    failure_classification = models.ForeignKey(\n        FailureClassification, on_delete=models.CASCADE, related_name='jobs'\n    )\n    who = models.CharField(max_length=50)\n    reason = models.CharField(max_length=125)\n    result = models.CharField(max_length=25)\n    state = models.CharField(max_length=25)\n\n    submit_time = models.DateTimeField()\n    start_time = models.DateTimeField()\n    end_time = models.DateTimeField()\n    last_modified = models.DateTimeField(auto_now=True, db_index=True)\n    # TODO: Remove next time we add/drop another field.\n    running_eta = models.PositiveIntegerField(null=True, default=None)\n    tier = models.PositiveIntegerField()\n\n    push = models.ForeignKey(Push, on_delete=models.CASCADE, related_name='jobs')\n\n    class Meta:\n        db_table = 'job'\n        index_together = [\n            # these speed up the various permutations of the \"similar jobs\"\n            # queries\n            ('repository', 'job_type', 'start_time'),\n            ('repository', 'build_platform', 'job_type', 'start_time'),\n            ('repository', 'option_collection_hash', 'job_type', 'start_time'),\n            ('repository', 'build_platform', 'option_collection_hash', 'job_type', 'start_time'),\n            # this is intended to speed up queries for specific platform /\n            # option collections on a push\n            ('machine_platform', 'option_collection_hash', 'push'),\n            # speed up cycle data\n            ('repository', 'submit_time'),\n        ]\n\n    def __str__(self):\n        return \"{0} {1} {2}\".format(self.id, self.repository, self.guid)\n\n    def get_platform_option(self, option_collection_map=None):\n        if not hasattr(self, 'platform_option'):\n            self.platform_option = ''\n            option_hash = self.option_collection_hash\n            if option_hash:\n                if not option_collection_map:\n                    option_collection_map = OptionCollection.objects.get_option_collection_map()\n                self.platform_option = option_collection_map.get(option_hash)\n\n        return self.platform_option\n\n    def save(self, *args, **kwargs):\n        self.last_modified = datetime.datetime.now()\n        super().save(*args, **kwargs)\n\n    def get_manual_classification_line(self):\n        \"\"\"\n        If this Job has a single TextLogError line, return that TextLogError.\n\n        Some Jobs only have one related TextLogError.  This\n        method checks if this Job is one of those (returning None if not) by:\n        * checking the number of related TextLogErrors\n        * counting the number of search results for the single TextLogError\n        * checking there is a related FailureLine\n        * checking the related FailureLine is in a given state\n\n        If all these checks pass the TextLogError is returned, any failure returns None.\n        \"\"\"\n        try:\n            text_log_error = TextLogError.objects.get(job=self)\n        except (TextLogError.DoesNotExist, TextLogError.MultipleObjectsReturned):\n            return None\n\n        # Can this TextLogError be converted into a single \"useful search\"?\n        # FIXME: what is the significance of only one search result here?\n        from treeherder.model.error_summary import get_useful_search_results\n\n        search_results = get_useful_search_results(self)\n        if len(search_results) != 1:\n            return None\n\n        # Check that we have a related FailureLine\n        failure_line = text_log_error.get_failure_line()\n        if failure_line is None:\n            return None\n\n        # Check our FailureLine is in a state we expect for\n        # auto-classification.\n        if not (\n            failure_line.action == \"test_result\"\n            and failure_line.test\n            and failure_line.status\n            and failure_line.expected\n        ):\n            return None\n\n        return text_log_error\n\n    def fetch_associated_decision_job(self):\n        decision_type = JobType.objects.filter(name=\"Gecko Decision Task\", symbol=\"D\")\n        return Job.objects.get(\n            repository_id=self.repository_id,\n            job_type_id=Subquery(decision_type.values('id')[:1]),\n            push_id=self.push_id,\n        )\n\n    @staticmethod\n    def get_duration(submit_time, start_time, end_time):\n        endtime = end_time if to_timestamp(end_time) else datetime.datetime.now()\n        starttime = start_time if to_timestamp(start_time) else submit_time\n        seconds = max((endtime - starttime).total_seconds(), 60)\n        return max(round(seconds / 60), 1)\n\n\nclass TaskclusterMetadata(models.Model):\n    \"\"\"\n    Taskcluster-specific metadata associated with a taskcluster job\n    \"\"\"\n\n    job = models.OneToOneField(\n        Job, on_delete=models.CASCADE, primary_key=True, related_name='taskcluster_metadata'\n    )\n\n    task_id = models.CharField(max_length=22, validators=[MinLengthValidator(22)], db_index=True)\n    retry_id = models.PositiveIntegerField()\n\n    class Meta:\n        db_table = \"taskcluster_metadata\"\n\n\nclass JobLog(models.Model):\n    \"\"\"\n    Represents a log associated with a job\n\n    There can be more than one of these associated with each job\n    \"\"\"\n\n    PENDING = 0\n    PARSED = 1\n    FAILED = 2\n    SKIPPED_SIZE = 3\n\n    STATUSES = (\n        (PENDING, 'pending'),\n        (PARSED, 'parsed'),\n        (FAILED, 'failed'),\n        (SKIPPED_SIZE, 'skipped-size'),\n    )\n\n    job = models.ForeignKey(Job, on_delete=models.CASCADE, related_name=\"job_log\")\n    name = models.CharField(max_length=50)\n    url = models.URLField(max_length=255)\n    status = models.IntegerField(choices=STATUSES, default=PENDING)\n\n    class Meta:\n        db_table = \"job_log\"\n        unique_together = ('job', 'name', 'url')\n\n    def __str__(self):\n        return \"{0} {1} {2} {3}\".format(self.id, self.job.guid, self.name, self.status)\n\n    def update_status(self, status):\n        self.status = status\n        self.save(update_fields=['status'])\n\n\nclass BugJobMap(models.Model):\n    \"\"\"\n    Maps job_ids to related bug_ids\n\n    Mappings can be made manually through a UI or from doing lookups in the\n    BugsCache\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n\n    job = models.ForeignKey(Job, on_delete=models.CASCADE)\n    bug_id = models.PositiveIntegerField(db_index=True)\n    created = models.DateTimeField(default=timezone.now)\n    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True)  # null if autoclassified\n\n    failures = FailuresQuerySet.as_manager()\n    objects = models.Manager()\n\n    class Meta:\n        db_table = \"bug_job_map\"\n        unique_together = ('job', 'bug_id')\n\n    @property\n    def who(self):\n        if self.user:\n            return self.user.email\n        else:\n            return \"autoclassifier\"\n\n    @classmethod\n    def create(cls, job_id, bug_id, user=None):\n        bug_map = BugJobMap.objects.create(\n            job_id=job_id,\n            bug_id=bug_id,\n            user=user,\n        )\n\n        if not user:\n            return bug_map\n\n        # We have a user so this wasn't triggered by auto-classification.\n        # However we need to update the ClassifiedFailure with the bug number\n        # we just used to create the BugJobMap.\n\n        text_log_error = bug_map.job.get_manual_classification_line()\n        if text_log_error is None:\n            return bug_map\n\n        classification = (\n            text_log_error.metadata.best_classification if text_log_error.metadata else None\n        )\n\n        if classification is None:\n            return bug_map  # no classification to update\n\n        if classification.bug_number:\n            return bug_map  # classification already has a bug number\n\n        classification.set_bug(bug_id)\n\n        return bug_map\n\n    def __str__(self):\n        return \"{0} {1} {2} {3}\".format(self.id, self.job.guid, self.bug_id, self.user)\n\n\nclass JobNote(models.Model):\n    \"\"\"\n    Associates a Failure type with a Job and optionally a text comment from a User.\n\n    Generally these are generated manually in the UI.\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n\n    job = models.ForeignKey(Job, on_delete=models.CASCADE)\n    failure_classification = models.ForeignKey(FailureClassification, on_delete=models.CASCADE)\n    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True)  # null if autoclassified\n    text = models.TextField()\n    created = models.DateTimeField(default=timezone.now)\n\n    class Meta:\n        db_table = \"job_note\"\n\n    @property\n    def who(self):\n        if self.user:\n            return self.user.email\n        return \"autoclassifier\"\n\n    def _update_failure_type(self):\n        \"\"\"\n        Updates the failure type of this Note's Job.\n\n        Set the linked Job's failure type to that of the most recent JobNote or\n        set to Not Classified if there are no JobNotes.\n\n        This is called when JobNotes are created (via .save()) and deleted (via\n        .delete()) and is used to resolved the FailureClassification which has\n        been denormalised onto Job.\n        \"\"\"\n        # update the job classification\n        note = JobNote.objects.filter(job=self.job).order_by('-created').first()\n        if note:\n            self.job.failure_classification_id = note.failure_classification.id\n        else:\n            self.job.failure_classification_id = FailureClassification.objects.get(\n                name='not classified'\n            ).id\n        self.job.save()\n\n    def _ensure_classification(self):\n        \"\"\"\n        Ensures a single TextLogError's related bugs have Classifications.\n\n        If the linked Job has a single meaningful TextLogError:\n         - find the bugs currently related to it via a Classification\n         - find the bugs mapped to the job related to this note\n         - find the bugs that are mapped but not classified\n         - link this subset of bugs to Classifications\n         - if there's only one new bug and no existing ones, verify it\n        \"\"\"\n        # if this note was automatically filed, don't update the auto-classification information\n        if not self.user:\n            return\n\n        # if the failure type isn't intermittent, ignore\n        if self.failure_classification.name not in [\"intermittent\", \"intermittent needs filing\"]:\n            return\n\n        # if the linked Job has more than one TextLogError, ignore\n        text_log_error = self.job.get_manual_classification_line()\n        if not text_log_error:\n            return\n\n        # evaluate the QuerySet here so it can be used when creating new_bugs below\n        existing_bugs = list(\n            ClassifiedFailure.objects.filter(\n                error_matches__text_log_error=text_log_error\n            ).values_list('bug_number', flat=True)\n        )\n\n        new_bugs = self.job.bugjobmap_set.exclude(bug_id__in=existing_bugs).values_list(\n            'bug_id', flat=True\n        )\n\n        if not new_bugs:\n            return\n\n        # Create Match instances for each new bug\n        for bug_number in new_bugs:\n            classification, _ = ClassifiedFailure.objects.get_or_create(bug_number=bug_number)\n            text_log_error.create_match(\"ManualDetector\", classification)\n\n        # if there's only one new bug and no existing ones, verify it\n        if len(new_bugs) == 1 and not existing_bugs:\n            text_log_error.verify_classification(classification)\n\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)\n        self._update_failure_type()\n        self._ensure_classification()\n\n    def delete(self, *args, **kwargs):\n        super().delete(*args, **kwargs)\n        self._update_failure_type()\n        self._ensure_classification()\n\n    def __str__(self):\n        return \"{0} {1} {2} {3}\".format(\n            self.id, self.job.guid, self.failure_classification, self.who\n        )\n\n\nclass FailureLine(models.Model):\n    # We make use of prefix indicies for several columns in this table which\n    # can't be expressed in django syntax so are created with raw sql in migrations.\n    STATUS_LIST = ('PASS', 'FAIL', 'OK', 'ERROR', 'TIMEOUT', 'CRASH', 'ASSERT', 'SKIP', 'NOTRUN')\n    # Truncated is a special action that we use to indicate that the list of failure lines\n    # was truncated according to settings.FAILURE_LINES_CUTOFF.\n    ACTION_LIST = (\"test_result\", \"log\", \"crash\", \"truncated\", \"group_result\")\n    LEVEL_LIST = (\"critical\", \"error\", \"warning\", \"info\", \"debug\")\n\n    # Python 3's zip produces an iterable rather than a list, which Django's `choices` can't handle.\n    ACTION_CHOICES = list(zip(ACTION_LIST, ACTION_LIST))\n    STATUS_CHOICES = list(zip(STATUS_LIST, STATUS_LIST))\n    LEVEL_CHOICES = list(zip(LEVEL_LIST, LEVEL_LIST))\n\n    id = models.BigAutoField(primary_key=True)\n    job_guid = models.CharField(max_length=50)\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    job_log = models.ForeignKey(\n        JobLog, on_delete=models.CASCADE, null=True, related_name=\"failure_line\"\n    )\n    action = models.CharField(max_length=15, choices=ACTION_CHOICES)\n    line = models.PositiveIntegerField()\n    test = models.TextField(blank=True, null=True)\n    subtest = models.TextField(blank=True, null=True)\n    status = models.CharField(max_length=7, choices=STATUS_CHOICES)\n    expected = models.CharField(max_length=7, choices=STATUS_CHOICES, blank=True, null=True)\n    message = models.TextField(blank=True, null=True)\n    signature = models.TextField(blank=True, null=True)\n    level = models.CharField(max_length=8, choices=STATUS_CHOICES, blank=True, null=True)\n    stack = models.TextField(blank=True, null=True)\n    stackwalk_stdout = models.TextField(blank=True, null=True)\n    stackwalk_stderr = models.TextField(blank=True, null=True)\n\n    # Note that the case of best_classification = None and best_is_verified = True\n    # has the special semantic that the line is ignored and should not be considered\n    # for future autoclassifications.\n    best_classification = models.ForeignKey(\n        \"ClassifiedFailure\",\n        related_name=\"best_for_lines\",\n        null=True,\n        db_index=True,\n        on_delete=models.SET_NULL,\n    )\n\n    best_is_verified = models.BooleanField(default=False)\n\n    created = models.DateTimeField(auto_now_add=True)\n    modified = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        db_table = 'failure_line'\n        index_together = (\n            ('job_guid', 'repository'),\n            # Prefix index: test(50), subtest(25), status, expected, created\n            ('test', 'subtest', 'status', 'expected', 'created'),\n            # Prefix index: signature(25), test(50), created\n            ('signature', 'test', 'created'),\n        )\n        unique_together = ('job_log', 'line')\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.id, Job.objects.get(guid=self.job_guid).id)\n\n    @property\n    def error(self):\n        # Return the related text-log-error or None if there is no related field.\n        try:\n            return self.text_log_error_metadata.text_log_error\n        except TextLogErrorMetadata.DoesNotExist:\n            return None\n\n    def _serialized_components(self):\n        if self.action == \"test_result\":\n            return [\"TEST-UNEXPECTED-%s\" % self.status.upper(), self.test]\n        if self.action == \"log\":\n            return [self.level.upper(), self.message.split(\"\\n\")[0]]\n\n    def unstructured_bugs(self):\n        \"\"\"\n        Get bugs that match this line in the Bug Suggestions artifact for this job.\n        \"\"\"\n        components = self._serialized_components()\n        if not components:\n            return []\n\n        from treeherder.model.error_summary import get_useful_search_results\n\n        job = Job.objects.get(guid=self.job_guid)\n        rv = []\n        ids_seen = set()\n        for item in get_useful_search_results(job):\n            if all(component in item[\"search\"] for component in components):\n                for suggestion in itertools.chain(\n                    item[\"bugs\"][\"open_recent\"], item[\"bugs\"][\"all_others\"]\n                ):\n                    if suggestion[\"id\"] not in ids_seen:\n                        ids_seen.add(suggestion[\"id\"])\n                        rv.append(suggestion)\n\n        return rv\n\n    def to_dict(self):\n        try:\n            metadata = self.text_log_error_metadata\n        except ObjectDoesNotExist:\n            metadata = None\n\n        return {\n            'id': self.id,\n            'job_guid': self.job_guid,\n            'repository': self.repository_id,\n            'job_log': self.job_log_id,\n            'action': self.action,\n            'line': self.line,\n            'test': self.test,\n            'subtest': self.subtest,\n            'status': self.status,\n            'expected': self.expected,\n            'message': self.message,\n            'signature': self.signature,\n            'level': self.level,\n            'stack': self.stack,\n            'stackwalk_stdout': self.stackwalk_stdout,\n            'stackwalk_stderr': self.stackwalk_stderr,\n            'best_classification': metadata.best_classification_id if metadata else None,\n            'best_is_verified': metadata.best_is_verified if metadata else False,\n            'created': self.created,\n            'modified': self.modified,\n        }\n\n    def to_mozlog_format(self):\n        \"\"\"Convert a FailureLine into a mozlog formatted dictionary.\"\"\"\n        data = {\n            \"action\": self.action,\n            \"line_number\": self.line,\n            \"test\": self.test,\n            \"subtest\": self.subtest,\n            \"status\": self.status,\n            \"expected\": self.expected,\n            \"message\": self.message,\n            \"signature\": self.signature,\n            \"level\": self.level,\n            \"stack\": self.stack,\n            \"stackwalk_stdout\": self.stackwalk_stdout,\n            \"stackwalk_stderr\": self.stackwalk_stderr,\n        }\n\n        # Remove empty values\n        data = {k: v for k, v in data.items() if v is not None}\n\n        return data\n\n\nclass Group(models.Model):\n    \"\"\"\n    The test harness group.\n\n    This is most often a manifest file.  But in some instances where a suite\n    doesn't have manifests, or a test suite isn't logging its data properly,\n    this can simply be \"default\"\n\n    Note: This is not to be confused with JobGroup which is Treeherder specific.\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n    name = models.CharField(max_length=255, unique=True)\n    job_logs = models.ManyToManyField(\"JobLog\", through='GroupStatus', related_name='groups')\n\n    def __str__(self):\n        return self.name\n\n    class Meta:\n        db_table = 'group'\n\n\nclass GroupStatus(models.Model):\n    OK = 1\n    ERROR = 2\n    SKIP = 3\n    UNSUPPORTED = 10\n    STATUS_MAP = {\"OK\": OK, \"ERROR\": ERROR, \"SKIP\": SKIP}\n    STATUS_LOOKUP = {OK: \"OK\", ERROR: \"ERROR\", SKIP: \"SKIP\"}\n\n    status = models.SmallIntegerField()\n    job_log = models.ForeignKey(JobLog, on_delete=models.CASCADE, related_name=\"group_result\")\n    group = models.ForeignKey(Group, on_delete=models.CASCADE, related_name=\"group_result\")\n\n    @staticmethod\n    def get_status(status_str):\n        return (\n            GroupStatus.STATUS_MAP[status_str]\n            if status_str in GroupStatus.STATUS_MAP\n            else GroupStatus.UNSUPPORTED\n        )\n\n    class Meta:\n        db_table = 'group_status'\n\n\nclass ClassifiedFailure(models.Model):\n    \"\"\"\n    Classifies zero or more TextLogErrors as a failure.\n\n    Optionally linked to a bug.\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n    text_log_errors = models.ManyToManyField(\n        \"TextLogError\", through='TextLogErrorMatch', related_name='classified_failures'\n    )\n    # Note that we use a bug number of 0 as a sentinel value to indicate lines that\n    # are not actually symptomatic of a real bug\n    bug_number = models.PositiveIntegerField(blank=True, null=True, unique=True)\n    created = models.DateTimeField(auto_now_add=True)\n    modified = models.DateTimeField(auto_now=True)\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.id, self.bug_number)\n\n    def bug(self):\n        # Putting this here forces one query per object; there should be a way\n        # to make things more efficient\n        return Bugscache.objects.filter(id=self.bug_number).first()\n\n    def set_bug(self, bug_number):\n        \"\"\"\n        Set the bug number of this Classified Failure\n\n        If an existing ClassifiedFailure exists with the same bug number\n        replace this instance with the existing one.\n        \"\"\"\n        if bug_number == self.bug_number:\n            return self\n\n        other = ClassifiedFailure.objects.filter(bug_number=bug_number).first()\n        if not other:\n            self.bug_number = bug_number\n            self.save(update_fields=['bug_number'])\n            return self\n\n        self.replace_with(other)\n\n        return other\n\n    @transaction.atomic\n    def replace_with(self, other):\n        \"\"\"\n        Replace this instance with the given other.\n\n        Deletes stale Match objects and updates related TextLogErrorMetadatas'\n        best_classifications to point to the given other.\n        \"\"\"\n        match_ids_to_delete = list(self.update_matches(other))\n        TextLogErrorMatch.objects.filter(id__in=match_ids_to_delete).delete()\n\n        # Update best classifications\n        self.best_for_errors.update(best_classification=other)\n\n        self.delete()\n\n    def update_matches(self, other):\n        \"\"\"\n        Update this instance's Matches to point to the given other's Matches.\n\n        Find Matches with the same TextLogError as our Matches, updating their\n        score if less than ours and mark our matches for deletion.\n\n        If there are no other matches, update ours to point to the other\n        ClassifiedFailure.\n        \"\"\"\n        for match in self.error_matches.all():\n            other_matches = TextLogErrorMatch.objects.filter(\n                classified_failure=other,\n                text_log_error=match.text_log_error,\n            )\n\n            if not other_matches:\n                match.classified_failure = other\n                match.save(update_fields=['classified_failure'])\n                continue\n\n            # if any of our matches have higher scores than other's matches,\n            # overwrite with our score.\n            other_matches.filter(score__lt=match.score).update(score=match.score)\n\n            yield match.id  # for deletion\n\n    class Meta:\n        db_table = 'classified_failure'\n\n\n# TODO delete table once backfill of jobs in TextLogError table has been completed\nclass TextLogStep(models.Model):\n    \"\"\"\n    An individual step in the textual (unstructured) log\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n\n    job = models.ForeignKey(Job, on_delete=models.CASCADE, related_name=\"text_log_step\")\n\n    # these are presently based off of buildbot results\n    # (and duplicated in treeherder/etl/buildbot.py)\n    SUCCESS = 0\n    TEST_FAILED = 1\n    BUSTED = 2\n    SKIPPED = 3\n    EXCEPTION = 4\n    RETRY = 5\n    USERCANCEL = 6\n    UNKNOWN = 7\n    SUPERSEDED = 8\n\n    RESULTS = (\n        (SUCCESS, 'success'),\n        (TEST_FAILED, 'testfailed'),\n        (BUSTED, 'busted'),\n        (SKIPPED, 'skipped'),\n        (EXCEPTION, 'exception'),\n        (RETRY, 'retry'),\n        (USERCANCEL, 'usercancel'),\n        (UNKNOWN, 'unknown'),\n        (SUPERSEDED, 'superseded'),\n    )\n\n    name = models.CharField(max_length=200)\n    started = models.DateTimeField(null=True)\n    finished = models.DateTimeField(null=True)\n    started_line_number = models.PositiveIntegerField()\n    finished_line_number = models.PositiveIntegerField()\n    result = models.IntegerField(choices=RESULTS)\n\n    class Meta:\n        db_table = \"text_log_step\"\n        unique_together = ('job', 'started_line_number', 'finished_line_number')\n\n\nclass TextLogError(models.Model):\n    \"\"\"\n    A detected error line in the textual (unstructured) log\n    \"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n    job = models.ForeignKey(Job, on_delete=models.CASCADE, related_name='text_log_error', null=True)\n    line = models.TextField()\n    line_number = models.PositiveIntegerField()\n\n    # TODO delete this field and unique_together once backfill of jobs in TextLogError table has been completed\n    step = models.ForeignKey(\n        TextLogStep, on_delete=models.CASCADE, related_name='errors', null=True\n    )\n\n    class Meta:\n        db_table = \"text_log_error\"\n        unique_together = ('step', 'line_number')\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.id, self.job.id)\n\n    @property\n    def metadata(self):\n        try:\n            return self._metadata\n        except TextLogErrorMetadata.DoesNotExist:\n            return None\n\n    def bug_suggestions(self):\n        from treeherder.model import error_summary\n\n        return error_summary.bug_suggestions_line(self)\n\n    def create_match(self, matcher_name, classification):\n        \"\"\"\n        Create a TextLogErrorMatch instance\n\n        Typically used for manual \"matches\" or tests.\n        \"\"\"\n        if classification is None:\n            classification = ClassifiedFailure.objects.create()\n\n        TextLogErrorMatch.objects.create(\n            text_log_error=self,\n            classified_failure=classification,\n            matcher_name=matcher_name,\n            score=1,\n        )\n\n    def verify_classification(self, classification):\n        \"\"\"\n        Mark the given ClassifiedFailure as verified.\n\n        Handles the classification not currently being related to this\n        TextLogError and no Metadata existing.\n        \"\"\"\n        if classification not in self.classified_failures.all():\n            self.create_match(\"ManualDetector\", classification)\n\n        # create a TextLogErrorMetadata instance for this TextLogError if it\n        # doesn't exist.  We can't use update_or_create here since OneToOne\n        # relations don't use an object manager so a missing relation is simply\n        # None as opposed to RelatedManager.\n        if self.metadata is None:\n            TextLogErrorMetadata.objects.create(\n                text_log_error=self, best_classification=classification, best_is_verified=True\n            )\n        else:\n            self.metadata.best_classification = classification\n            self.metadata.best_is_verified = True\n            self.metadata.save(update_fields=['best_classification', 'best_is_verified'])\n\n        # Send event to NewRelic when a verifing an autoclassified failure.\n        match = self.matches.filter(classified_failure=classification).first()\n        if not match:\n            return\n\n        newrelic.agent.record_custom_event(\n            'user_verified_classification',\n            {\n                'matcher': match.matcher_name,\n                'job_id': self.id,\n            },\n        )\n\n    def get_failure_line(self):\n        \"\"\"Get a related FailureLine instance if one exists.\"\"\"\n        try:\n            return self.metadata.failure_line\n        except AttributeError:\n            return None\n\n\nclass TextLogErrorMetadata(models.Model):\n    \"\"\"\n    Link matching TextLogError and FailureLine instances.\n\n    Tracks best classification and verificiation of a classification.\n\n    TODO: Merge into TextLogError.\n    \"\"\"\n\n    text_log_error = models.OneToOneField(\n        TextLogError, primary_key=True, related_name=\"_metadata\", on_delete=models.CASCADE\n    )\n\n    failure_line = models.OneToOneField(\n        FailureLine, on_delete=models.CASCADE, related_name=\"text_log_error_metadata\", null=True\n    )\n\n    # Note that the case of best_classification = None and best_is_verified = True\n    # has the special semantic that the line is ignored and should not be considered\n    # for future autoclassifications.\n    best_classification = models.ForeignKey(\n        ClassifiedFailure, related_name=\"best_for_errors\", null=True, on_delete=models.SET_NULL\n    )\n    best_is_verified = models.BooleanField(default=False)\n\n    class Meta:\n        db_table = \"text_log_error_metadata\"\n\n    def __str__(self):\n        args = (self.text_log_error_id, self.failure_line_id)\n        return 'TextLogError={} FailureLine={}'.format(*args)\n\n\nclass TextLogErrorMatch(models.Model):\n    \"\"\"Association table between TextLogError and ClassifiedFailure, containing\n    additional data about the association including the matcher that was used\n    to create it and a score in the range 0-1 for the goodness of match.\"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n    text_log_error = models.ForeignKey(\n        TextLogError, related_name=\"matches\", on_delete=models.CASCADE\n    )\n    classified_failure = models.ForeignKey(\n        ClassifiedFailure, related_name=\"error_matches\", on_delete=models.CASCADE\n    )\n\n    matcher_name = models.CharField(max_length=255)\n    score = models.DecimalField(max_digits=3, decimal_places=2, blank=True, null=True)\n\n    class Meta:\n        db_table = 'text_log_error_match'\n        verbose_name_plural = 'text log error matches'\n        unique_together = ('text_log_error', 'classified_failure', 'matcher_name')\n\n    def __str__(self):\n        return \"{0} {1}\".format(self.text_log_error.id, self.classified_failure.id)\n\n\nclass InvestigatedTests(models.Model):\n    \"\"\"Tests that have been marked as investigated in the Push health UI.  These act like\n    completed To Do List items.\"\"\"\n\n    id = models.BigAutoField(primary_key=True)\n    job_type = models.ForeignKey(JobType, related_name=\"investigated\", on_delete=models.CASCADE)\n    test = models.CharField(max_length=350)\n    push = models.ForeignKey(Push, on_delete=models.CASCADE)\n\n    class Meta:\n        unique_together = [\"job_type\", \"test\", \"push\"]\n        db_table = 'investigated_tests'\n\n\n### treeherder/perf/auto_perf_sheriffing/secretary_tool.py ###\n\nimport logging\nfrom datetime import datetime, timedelta\n\nimport simplejson as json\nfrom django.conf import settings as django_settings\n\nfrom treeherder.perf.models import BackfillRecord, BackfillReport, PerformanceSettings\nfrom treeherder.utils import default_serializer\nfrom treeherder.perf.auto_perf_sheriffing.outcome_checker import OutcomeChecker, OutcomeStatus\n\nlogger = logging.getLogger(__name__)\n\n\n# TODO: update the backfill status using data (bug 1626548)\n# TODO: consider making this a singleton (bug 1639112)\nclass SecretaryTool:\n    \"\"\"\n    * marks which records can be backfilled\n    * provides & maintains backfill limits\n    * notes outcome of backfills (successful/unsuccessful)\n    \"\"\"\n\n    TIME_TO_MATURE = timedelta(hours=4)\n\n    def __init__(self, outcome_checker: OutcomeChecker = None):\n        self.outcome_checker = outcome_checker or OutcomeChecker()\n\n    @classmethod\n    def validate_settings(cls):\n        perf_sheriff_settings, created = PerformanceSettings.objects.get_or_create(\n            name=\"perf_sheriff_bot\",\n            defaults={\"settings\": cls._get_default_settings()},\n        )\n\n        if created:\n            logger.info(\n                \"Performance settings for perf_sheriff_bot not found. Creating with defaults.\"\n            )\n            return\n\n        # reset limits if the settings expired\n        settings = json.loads(perf_sheriff_settings.settings)\n        if cls.are_expired(settings):\n            logger.info(f\"Settings are expired. Expired settings: {settings}\")\n\n            perf_sheriff_settings.settings = cls._get_default_settings()\n            perf_sheriff_settings.save()\n\n    @classmethod\n    def mark_reports_for_backfill(cls):\n        # get the backfill reports that are mature, but not frozen\n        mature_date_limit = datetime.utcnow() - cls.TIME_TO_MATURE\n        mature_reports = BackfillReport.objects.filter(\n            frozen=False, last_updated__lte=mature_date_limit\n        )\n\n        for report in mature_reports:\n            should_freeze = False\n            for record in report.records.all():\n                if record.status == BackfillRecord.PRELIMINARY:\n                    record.status = BackfillRecord.READY_FOR_PROCESSING\n                    record.save()\n                    should_freeze = True\n\n            if should_freeze:\n                report.frozen = True\n                report.save()\n\n    @classmethod\n    def are_expired(cls, settings):\n        last_reset_date = datetime.fromisoformat(settings[\"last_reset_date\"])\n        return datetime.utcnow() > last_reset_date + django_settings.RESET_BACKFILL_LIMITS\n\n    def backfills_left(self, on_platform: str) -> int:\n        if on_platform != 'linux':\n            raise ValueError(f\"Unsupported platform: {on_platform}.\")\n\n        perf_sheriff_settings = PerformanceSettings.objects.get(name=\"perf_sheriff_bot\")\n        settings = json.loads(perf_sheriff_settings.settings)\n        return settings['limits'][on_platform]\n\n    def consume_backfills(self, on_platform: str, amount: int) -> int:\n        if on_platform != 'linux':\n            raise ValueError(f\"Unsupported platform: {on_platform}.\")\n\n        perf_sheriff_settings = PerformanceSettings.objects.get(name=\"perf_sheriff_bot\")\n\n        settings = json.loads(perf_sheriff_settings.settings)\n\n        _backfills_left = left = settings['limits'][on_platform] - amount\n        _backfills_left = left if left > 0 else 0\n\n        settings['limits'][on_platform] = _backfills_left\n\n        perf_sheriff_settings.set_settings(settings)\n        perf_sheriff_settings.save()\n        return _backfills_left\n\n    def check_outcome(self):\n        # fetch all records in backfilled state\n        # we assume that BackfillRecord with BACKFILLED status were backfilled only for accepted platforms\n        backfilled_records = BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED)\n\n        for record in backfilled_records:\n            # ensure each push in push range has at least one job of job type\n            outcome = self.outcome_checker.check(record)\n            # if outcome is IN_PROGRESS the BackfillRecord state will remain BACKFILLED to be checked again later\n            if outcome == OutcomeStatus.SUCCESSFUL:\n                record.status = BackfillRecord.SUCCESSFUL\n            elif outcome == OutcomeStatus.FAILED:\n                record.status = BackfillRecord.FAILED\n            record.save()\n\n    @classmethod\n    def _get_default_settings(cls, as_json=True):\n        default_settings = {\n            'limits': django_settings.MAX_BACKFILLS_PER_PLATFORM,\n            'last_reset_date': datetime.utcnow(),\n        }\n\n        return (\n            json.dumps(default_settings, default=default_serializer)\n            if as_json\n            else default_settings\n        )\n\n\n### treeherder/perf/models.py ###\n\nimport datetime\nimport json\nfrom typing import List\n\nfrom django.contrib.auth.models import User\nfrom django.core.exceptions import ValidationError\nfrom django.core.validators import MinLengthValidator\nfrom django.db import models\nfrom django.utils.timezone import now as django_now\n\nfrom treeherder.model.models import (\n    Job,\n    MachinePlatform,\n    OptionCollection,\n    Push,\n    Repository,\n    JobType,\n)\nfrom treeherder.utils import default_serializer\n\nSIGNATURE_HASH_LENGTH = 40\n\n\nclass PerformanceFramework(models.Model):\n    name = models.SlugField(max_length=255, unique=True)\n    enabled = models.BooleanField(default=False)\n\n    class Meta:\n        db_table = 'performance_framework'\n\n    @classmethod\n    def fetch_all_names(cls) -> List[str]:\n        return cls.objects.values_list('name', flat=True)\n\n    def __str__(self):\n        return self.name\n\n\nclass PerformanceSignature(models.Model):\n    signature_hash = models.CharField(\n        max_length=SIGNATURE_HASH_LENGTH, validators=[MinLengthValidator(SIGNATURE_HASH_LENGTH)]\n    )\n\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    framework = models.ForeignKey(PerformanceFramework, on_delete=models.CASCADE)\n    platform = models.ForeignKey(MachinePlatform, on_delete=models.CASCADE)\n    option_collection = models.ForeignKey(OptionCollection, on_delete=models.CASCADE)\n    suite = models.CharField(max_length=80)\n    test = models.CharField(max_length=80, blank=True)\n    application = models.CharField(\n        max_length=10,\n        default='',\n        help_text=\"Application that runs the signature's tests. \"\n        \"Generally used to record browser's name, but not necessarily.\",\n    )\n    lower_is_better = models.BooleanField(default=True)\n    last_updated = models.DateTimeField(db_index=True)\n    parent_signature = models.ForeignKey(\n        'self', on_delete=models.CASCADE, related_name='subtests', null=True, blank=True\n    )\n    has_subtests = models.BooleanField()\n\n    # we treat suite & test as human unreadable identifiers\n    #  these are their human readable form\n    suite_public_name = models.CharField(max_length=30, null=True)\n    test_public_name = models.CharField(max_length=30, null=True)\n\n    # free form tags which data producers can specify;\n    # enhances semantic labeling & search capabilities,\n    # without decoupling perf data\n    tags = models.CharField(max_length=360, blank=True)\n\n    # extra options to distinguish the test (that don't fit into\n    # option collection for whatever reason)\n    # generous max_length permits up to 8 verbose option names\n    extra_options = models.CharField(max_length=422, blank=True)\n\n    # TODO: reduce length to minimum value\n    # TODO: make this nonnullable, once we demand\n    #  all PERFHERDER_DATA dumps to provide the unit field\n    measurement_unit = models.CharField(max_length=50, null=True)\n\n    # these properties override the default settings for how alert\n    # generation works\n    ALERT_PCT = 0\n    ALERT_ABS = 1\n    ALERT_CHANGE_TYPES = ((ALERT_PCT, 'percentage'), (ALERT_ABS, 'absolute'))\n\n    should_alert = models.BooleanField(null=True)\n    alert_change_type = models.IntegerField(choices=ALERT_CHANGE_TYPES, null=True)\n    alert_threshold = models.FloatField(null=True)\n    min_back_window = models.IntegerField(null=True)\n    max_back_window = models.IntegerField(null=True)\n    fore_window = models.IntegerField(null=True)\n\n    @staticmethod\n    def _get_alert_change_type(alert_change_type_input):\n        \"\"\"\n        Maps a schema-specified alert change type to the internal index\n        value\n        \"\"\"\n        for (idx, enum_val) in PerformanceSignature.ALERT_CHANGE_TYPES:\n            if enum_val == alert_change_type_input:\n                return idx\n        return None\n\n    def has_performance_data(self):\n        return PerformanceDatum.objects.filter(\n            repository_id=self.repository_id,  # leverages (repository, signature) compound index\n            signature_id=self.id,\n        ).exists()\n\n    class Meta:\n        db_table = 'performance_signature'\n\n        unique_together = (\n            # ensure there is only one signature per repository with a\n            # particular set of properties\n            (\n                'repository',\n                'suite',\n                'test',\n                'framework',\n                'platform',\n                'option_collection',\n                'extra_options',\n                'last_updated',\n                'application',\n            ),\n            # suite_public_name/test_public_name must be unique\n            # and different than suite/test\n            (\n                'repository',\n                'suite_public_name',\n                'test_public_name',\n                'framework',\n                'platform',\n                'option_collection',\n                'extra_options',\n            ),\n            # ensure there is only one signature of any hash per\n            # repository (same hash in different repositories is allowed)\n            ('repository', 'framework', 'application', 'signature_hash'),\n        )\n\n    def __str__(self):\n        name = self.suite\n        if self.test:\n            name += \" {}\".format(self.test)\n        else:\n            name += \" summary\"\n\n        return \"{} {} {} {}\".format(self.signature_hash, name, self.platform, self.last_updated)\n\n\nclass PerformanceDatum(models.Model):\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    signature = models.ForeignKey(PerformanceSignature, on_delete=models.CASCADE)\n    value = models.FloatField()\n    push_timestamp = models.DateTimeField(db_index=True)\n\n    # job information can expire before the performance datum\n    job = models.ForeignKey(Job, null=True, default=None, on_delete=models.SET_NULL)\n    push = models.ForeignKey(Push, on_delete=models.CASCADE)\n\n    class Meta:\n        db_table = 'performance_datum'\n        index_together = [\n            # Speeds up the typical \"get a range of performance datums\" query\n            ('repository', 'signature', 'push_timestamp'),\n            # Speeds up the compare view in treeherder (we only index on\n            # repository because we currently filter on it in the query)\n            ('repository', 'signature', 'push'),\n        ]\n        unique_together = ('repository', 'job', 'push', 'push_timestamp', 'signature')\n\n    @staticmethod\n    def should_mark_as_multi_commit(is_multi_commit: bool, was_created: bool) -> bool:\n        return is_multi_commit and was_created\n\n    def save(self, *args, **kwargs):\n        super().save(*args, **kwargs)  # Call the \"real\" save() method.\n        if self.signature.last_updated < self.push_timestamp:\n            self.signature.last_updated = self.push_timestamp\n            self.signature.save()\n\n    def __str__(self):\n        return \"{} {}\".format(self.value, self.push_timestamp)\n\n\nclass MultiCommitDatum(models.Model):\n    perf_datum = models.OneToOneField(\n        PerformanceDatum,\n        on_delete=models.CASCADE,\n        primary_key=True,\n        related_name='multi_commit_datum',\n    )\n\n\nclass IssueTracker(models.Model):\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=255, blank=False)\n    task_base_url = models.URLField(max_length=512, null=False)\n\n    class Meta:\n        db_table = \"issue_tracker\"\n\n    def __str__(self):\n        return \"{} (tasks via {})\".format(self.name, self.task_base_url)\n\n\nclass PerformanceAlertSummary(models.Model):\n    \"\"\"\n    A summarization of performance alerts\n\n    A summary of \"alerts\" that the performance numbers for a specific\n    repository have changed at a particular time.\n\n    See also the :ref:`PerformanceAlert` class below.\n    \"\"\"\n\n    id = models.AutoField(primary_key=True)\n    repository = models.ForeignKey(Repository, on_delete=models.CASCADE)\n    framework = models.ForeignKey(PerformanceFramework, on_delete=models.CASCADE)\n\n    prev_push = models.ForeignKey(Push, on_delete=models.CASCADE, related_name='+')\n    push = models.ForeignKey(Push, on_delete=models.CASCADE, related_name='+')\n\n    manually_created = models.BooleanField(default=False)\n\n    notes = models.TextField(null=True, blank=True)\n    assignee = models.ForeignKey(\n        User, on_delete=models.SET_NULL, null=True, related_name='assigned_alerts'\n    )\n\n    created = models.DateTimeField(auto_now_add=True, db_index=True)\n    first_triaged = models.DateTimeField(null=True, default=None)\n    last_updated = models.DateTimeField(auto_now=True, null=True)\n\n    UNTRIAGED = 0\n    DOWNSTREAM = 1\n    REASSIGNED = 2\n    INVALID = 3\n    IMPROVEMENT = 4\n    INVESTIGATING = 5\n    WONTFIX = 6\n    FIXED = 7\n    BACKED_OUT = 8\n\n    STATUSES = (\n        (UNTRIAGED, 'Untriaged'),\n        (DOWNSTREAM, 'Downstream'),\n        (REASSIGNED, 'Reassigned'),\n        (INVALID, 'Invalid'),\n        (IMPROVEMENT, 'Improvement'),\n        (INVESTIGATING, 'Investigating'),\n        (WONTFIX, 'Won\\'t fix'),\n        (FIXED, 'Fixed'),\n        (BACKED_OUT, 'Backed out'),\n    )\n\n    status = models.IntegerField(choices=STATUSES, default=UNTRIAGED)\n\n    bug_number = models.PositiveIntegerField(null=True)\n    bug_updated = models.DateTimeField(null=True)\n\n    issue_tracker = models.ForeignKey(IssueTracker, on_delete=models.PROTECT, default=1)  # Bugzilla\n\n    def __init__(self, *args, **kwargs):\n        super(PerformanceAlertSummary, self).__init__(*args, **kwargs)\n\n        # allows updating timestamps only on new values\n        self.__prev_bug_number = self.bug_number\n\n    def save(self, *args, **kwargs):\n        if self.bug_number is not None and self.bug_number != self.__prev_bug_number:\n            self.bug_updated = datetime.datetime.now()\n        super(PerformanceAlertSummary, self).save(*args, **kwargs)\n        self.__prev_bug_number = self.bug_number\n\n    def update_status(self, using=None):\n        self.status = self.autodetermine_status()\n        self.save(using=using)\n\n    def autodetermine_status(self):\n        alerts = PerformanceAlert.objects.filter(summary=self) | PerformanceAlert.objects.filter(\n            related_summary=self\n        )\n\n        # if no alerts yet, we'll say untriaged\n        if not alerts:\n            return PerformanceAlertSummary.UNTRIAGED\n\n        # if any untriaged, then set to untriaged\n        if any(alert.status == PerformanceAlert.UNTRIAGED for alert in alerts):\n            return PerformanceAlertSummary.UNTRIAGED\n\n        # if all invalid, then set to invalid\n        if all(alert.status == PerformanceAlert.INVALID for alert in alerts):\n            return PerformanceAlertSummary.INVALID\n\n        # otherwise filter out invalid alerts\n        alerts = [a for a in alerts if a.status != PerformanceAlert.INVALID]\n\n        # if there are any \"acknowledged\" alerts, then set to investigating\n        # if not one of the resolved statuses and there are regressions,\n        # otherwise we'll say it's an improvement\n        if any(alert.status == PerformanceAlert.ACKNOWLEDGED for alert in alerts):\n            if all(\n                not alert.is_regression\n                for alert in alerts\n                if alert.status == PerformanceAlert.ACKNOWLEDGED\n            ):\n                return PerformanceAlertSummary.IMPROVEMENT\n            elif self.status not in (\n                PerformanceAlertSummary.IMPROVEMENT,\n                PerformanceAlertSummary.INVESTIGATING,\n                PerformanceAlertSummary.WONTFIX,\n                PerformanceAlertSummary.FIXED,\n                PerformanceAlertSummary.BACKED_OUT,\n            ):\n                return PerformanceAlertSummary.INVESTIGATING\n            # keep status if one of the investigating ones\n            return self.status\n\n        # at this point, we've determined that this is a summary with no valid\n        # alerts of its own: all alerts should be either reassigned,\n        # downstream, or invalid (but not all invalid, that case is covered\n        # above)\n        if any(alert.status == PerformanceAlert.REASSIGNED for alert in alerts):\n            return PerformanceAlertSummary.REASSIGNED\n\n        return PerformanceAlertSummary.DOWNSTREAM\n\n    def timestamp_first_triage(self):\n        # called for summary specific updates (e.g. notes, bug linking)\n        if self.first_triaged is None:\n            self.first_triaged = django_now()\n        return self\n\n    class Meta:\n        db_table = \"performance_alert_summary\"\n        unique_together = ('repository', 'framework', 'prev_push', 'push')\n\n    def __str__(self):\n        return \"{} {} {}-{}\".format(\n            self.framework, self.repository, self.prev_push.revision, self.push.revision\n        )\n\n\nclass PerformanceAlert(models.Model):\n    \"\"\"\n    A single performance alert\n\n    An individual \"alert\" that the numbers in a specific performance\n    series have consistently changed level at a specific time.\n\n    An alert is always a member of an alert summary, which groups all\n    the alerts associated with a particular push together. In many cases at\n    Mozilla, the original alert summary is not correct, so we allow reassigning\n    it to a different (revised) summary.\n    \"\"\"\n\n    id = models.AutoField(primary_key=True)\n    summary = models.ForeignKey(\n        PerformanceAlertSummary, on_delete=models.CASCADE, related_name='alerts'\n    )\n    related_summary = models.ForeignKey(\n        PerformanceAlertSummary, on_delete=models.CASCADE, related_name='related_alerts', null=True\n    )\n    series_signature = models.ForeignKey(PerformanceSignature, on_delete=models.CASCADE)\n    is_regression = models.BooleanField()\n    starred = models.BooleanField(default=False)\n    classifier = models.ForeignKey(\n        User, on_delete=models.CASCADE, null=True\n    )  # null if autoclassified\n\n    created = models.DateTimeField(auto_now_add=True, null=True)\n    # time when human user 1st interacted with alert\n    # IMPORTANT: workers & automated scripts mustn't update this! Dont' assign this outside setter method!\n    first_triaged = models.DateTimeField(null=True, default=None)\n    last_updated = models.DateTimeField(auto_now=True, null=True)\n\n    UNTRIAGED = 0\n    DOWNSTREAM = 1\n    REASSIGNED = 2\n    INVALID = 3\n    ACKNOWLEDGED = 4\n\n    # statuses where we relate this alert to another summary\n    RELATIONAL_STATUS_IDS = (DOWNSTREAM, REASSIGNED)\n    # statuses where this alert is related only to the summary it was\n    # originally assigned to\n    UNRELATIONAL_STATUS_IDS = (UNTRIAGED, INVALID, ACKNOWLEDGED)\n\n    STATUSES = (\n        (UNTRIAGED, 'Untriaged'),\n        (DOWNSTREAM, 'Downstream'),\n        (REASSIGNED, 'Reassigned'),\n        (INVALID, 'Invalid'),\n        (ACKNOWLEDGED, 'Acknowledged'),\n    )\n\n    status = models.IntegerField(choices=STATUSES, default=UNTRIAGED)\n\n    amount_pct = models.FloatField(help_text=\"Amount in percentage that series has changed\")\n    amount_abs = models.FloatField(help_text=\"Absolute amount that series has changed\")\n    prev_value = models.FloatField(help_text=\"Previous value of series before change\")\n    new_value = models.FloatField(help_text=\"New value of series after change\")\n    t_value = models.FloatField(\n        help_text=\"t value out of analysis indicating confidence \" \"that change is 'real'\",\n        null=True,\n    )\n\n    manually_created = models.BooleanField(default=False)\n\n    def save(self, *args, **kwargs):\n        # validate that we set a status that makes sense for presence\n        # or absence of a related summary\n        if self.related_summary and self.status not in self.RELATIONAL_STATUS_IDS:\n            raise ValidationError(\n                \"Related summary set but status not in \"\n                \"'{}'!\".format(\n                    \", \".join(\n                        [\n                            STATUS[1]\n                            for STATUS in self.STATUSES\n                            if STATUS[0] in self.RELATIONAL_STATUS_IDS\n                        ]\n                    )\n                )\n            )\n        if not self.related_summary and self.status not in self.UNRELATIONAL_STATUS_IDS:\n            raise ValidationError(\n                \"Related summary not set but status not in \"\n                \"'{}'!\".format(\n                    \", \".join(\n                        [\n                            STATUS[1]\n                            for STATUS in self.STATUSES\n                            if STATUS[0] in self.UNRELATIONAL_STATUS_IDS\n                        ]\n                    )\n                )\n            )\n\n        super().save(*args, **kwargs)\n\n        # check to see if we need to update the summary statuses\n\n        # just forward the explicit database\n        # so the summary properly updates there\n        using = kwargs.get('using', None)\n        self.summary.update_status(using=using)\n        if self.related_summary:\n            self.related_summary.update_status(using=using)\n\n    def timestamp_first_triage(self):\n        # use only on code triggered by\n        # human interaction\n        if self.first_triaged is None:\n            self.first_triaged = django_now()\n            self.summary.timestamp_first_triage().save()\n        return self\n\n    class Meta:\n        db_table = \"performance_alert\"\n        unique_together = ('summary', 'series_signature')\n\n    def __str__(self):\n        return \"{} {} {}%\".format(self.summary, self.series_signature, self.amount_pct)\n\n\nclass PerformanceTag(models.Model):\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=30, unique=True)\n    alert_summaries = models.ManyToManyField(\n        PerformanceAlertSummary, related_name='performance_tags'\n    )\n\n    class Meta:\n        db_table = \"performance_tag\"\n\n\nclass PerformanceBugTemplate(models.Model):\n    \"\"\"\n    Template for filing a bug or issue associated with a performance alert\n    \"\"\"\n\n    framework = models.OneToOneField(PerformanceFramework, on_delete=models.CASCADE)\n\n    keywords = models.CharField(max_length=255)\n    status_whiteboard = models.CharField(max_length=255)\n    default_component = models.CharField(max_length=255)\n    default_product = models.CharField(max_length=255)\n    cc_list = models.CharField(max_length=255)\n\n    text = models.TextField(max_length=4096)\n\n    class Meta:\n        db_table = \"performance_bug_template\"\n\n    def __str__(self):\n        return '{} bug template'.format(self.framework.name)\n\n\n# TODO: we actually need this name for the PerfSheriffBot' s hourly report\nclass BackfillReport(models.Model):\n    \"\"\"\n    Groups & stores all context required to retrigger/backfill\n    relevant alerts from a performance alert summary.\n    \"\"\"\n\n    summary = models.OneToOneField(\n        PerformanceAlertSummary,\n        on_delete=models.CASCADE,\n        primary_key=True,\n        related_name='backfill_report',\n    )\n\n    created = models.DateTimeField(auto_now_add=True)\n    last_updated = models.DateTimeField(auto_now=True)\n    frozen = models.BooleanField(default=False)\n\n    @property\n    def is_outdated(self):\n        # alert summary updated since last report was made\n        return self.summary.last_updated > self.last_updated\n\n    def expel_records(self):\n        BackfillRecord.objects.filter(report=self).delete()\n        self.save()  # refresh last_updated\n\n    class Meta:\n        db_table = \"backfill_report\"\n\n    def __str__(self):\n        return \"BackfillReport(summary #{}, last update {})\".format(\n            self.summary.id, self.last_updated\n        )\n\n\nclass BackfillRecord(models.Model):\n    alert = models.OneToOneField(\n        PerformanceAlert, on_delete=models.CASCADE, primary_key=True, related_name='backfill_record'\n    )\n\n    report = models.ForeignKey(BackfillReport, on_delete=models.CASCADE, related_name='records')\n\n    # all data required to retrigger/backfill\n    # associated perf alert, as JSON dump\n    # TODO: could we employ a JSONField?\n    context = models.TextField()\n    created = models.DateTimeField(auto_now_add=True)\n\n    PRELIMINARY = 0\n    READY_FOR_PROCESSING = 1\n    BACKFILLED = 2\n    SUCCESSFUL = 3\n    FAILED = 4\n\n    STATUSES = (\n        (PRELIMINARY, 'Preliminary'),\n        (READY_FOR_PROCESSING, 'Ready for processing'),\n        (BACKFILLED, 'Backfilled'),\n        (SUCCESSFUL, 'Finished'),\n        (FAILED, 'Failed'),\n    )\n\n    status = models.IntegerField(choices=STATUSES, default=PRELIMINARY)\n\n    # Backfill outcome\n    log_details = models.TextField()  # JSON expected, not supported by Django\n    job_type = models.ForeignKey(\n        JobType, null=True, on_delete=models.SET_NULL, related_name='backfill_records'\n    )\n    total_backfills_triggered = models.IntegerField(default=0)\n\n    @property\n    def id(self):\n        return self.alert\n\n    def get_context(self) -> List[dict]:\n        return json.loads(self.context)\n\n    def set_context(self, value: List[dict]):\n        self.context = json.dumps(value, default=str)\n\n    def set_log_details(self, value: dict):\n        self.log_details = json.dumps(value, default=str)\n\n    def save(self, *args, **kwargs):\n        # refresh parent's latest update time\n        super().save(*args, **kwargs)\n        self.report.save(using=kwargs.get('using'))\n\n    def delete(self, using=None, keep_parents=False):\n        super().delete(using, keep_parents)\n        self.report.save()  # refresh last_updated\n\n    class Meta:\n        db_table = \"backfill_record\"\n\n    def __str__(self):\n        return \"BackfillRecord(alert #{}, from {})\".format(self.alert.id, self.report)\n\n\nclass PerformanceSettings(models.Model):\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=255)\n    settings = models.TextField()\n\n    def set_settings(self, value: str):\n        self.settings = json.dumps(value, default=default_serializer)\n\n    class Meta:\n        db_table = \"performance_settings\"\n\n\n### treeherder/perf/auto_perf_sheriffing/outcome_checker.py ###\n\nfrom typing import List, Tuple\n\nfrom enum import Enum\n\nfrom treeherder.model.models import Job, Push\nfrom treeherder.perf.models import (\n    BackfillRecord,\n)\n\n\nclass OutcomeStatus(Enum):\n    SUCCESSFUL = 1\n    FAILED = 2\n    IN_PROGRESS = 3\n\n\n# TODO: delete this after soft launch lands (job_type will come from BackfillRecord)\ndef get_job_type(record):\n    record_context = record.get_context()\n    job_type = None\n\n    if len(record_context) >= 1:\n        job_id = record_context[0][\"job_id\"]\n        job = Job.objects.get(id=job_id)\n        if job:\n            job_type = job.job_type\n\n    return job_type\n\n\nclass OutcomeChecker:\n    \"\"\"\n    Checks outcome of backfills\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def check(self, record: BackfillRecord) -> OutcomeStatus:\n        # TODO: get job_type from record when soft launch lands ---> job_type = record.job_type\n        job_type = get_job_type(record)\n        from_time, to_time = self._get_push_timestamp_range(record.get_context())\n        repository_id = record.alert.summary.repository.id\n        pushes_in_range = self._get_pushes_in_range(from_time, to_time, repository_id)\n\n        for push in pushes_in_range:\n            # make sure it has at least one successful job of job type\n            if push.jobs.filter(job_type=job_type, result=\"success\").count() == 0:\n                # if there is no successful job of job_type in push, we check for jobs of job_type that are still running\n                if push.jobs.filter(job_type=job_type, result=\"unknown\").count() == 0:\n                    return OutcomeStatus.FAILED\n                else:\n                    return OutcomeStatus.IN_PROGRESS\n\n        return OutcomeStatus.SUCCESSFUL\n\n    @staticmethod\n    def _get_pushes_in_range(from_time, to_time, repository_id) -> List[Push]:\n        return Push.objects.filter(\n            repository_id=repository_id, time__gte=from_time, time__lte=to_time\n        ).all()\n\n    @staticmethod\n    def _get_push_timestamp_range(context: List[dict]) -> Tuple[str, str]:\n        from_time = context[0][\"push_timestamp\"]\n        to_time = context[-1][\"push_timestamp\"]\n\n        return from_time, to_time\n\n\n### treeherder/config/settings.py ###\n\nimport os\nimport platform\nimport re\nfrom datetime import timedelta\nfrom os.path import abspath, dirname, join\n\nimport environ\nfrom furl import furl\nfrom kombu import Exchange, Queue\nfrom adr import config\n\nfrom treeherder.config.utils import connection_should_use_tls, get_tls_redis_url\n\n# TODO: Switch to pathlib once using Python 3.\nSRC_DIR = dirname(dirname(dirname(abspath(__file__))))\n\nenv = environ.Env()\n\n# Checking for OS type\nIS_WINDOWS = \"windows\" in platform.system().lower()\n\n# Top Level configuration\nDEBUG = env.bool(\"TREEHERDER_DEBUG\", default=False)\nLOGGING_LEVEL = env(\"LOGGING_LEVEL\", default=\"INFO\")\n\nNEW_RELIC_INSIGHTS_API_KEY = env(\"NEW_RELIC_INSIGHTS_API_KEY\", default=None)\nNEW_RELIC_INSIGHTS_API_URL = 'https://insights-api.newrelic.com/v1/accounts/677903/query'\n\n# Make this unique, and don't share it with anybody.\nSECRET_KEY = env(\n    \"TREEHERDER_DJANGO_SECRET_KEY\",\n    default='secret-key-of-at-least-50-characters-to-pass-check-deploy',\n)\n\n# Delete the Pulse automatically when no consumers left\nPULSE_AUTO_DELETE_QUEUES = env.bool(\"PULSE_AUTO_DELETE_QUEUES\", default=False)\n\n# Changing PULSE_AUTO_DELETE_QUEUES to True when Treeherder is running inside of virtual environment\nif os.environ.get(\"VIRTUAL_ENV\"):\n    PULSE_AUTO_DELETE_QUEUES = True\n\n# Hosts\nSITE_URL = env(\"SITE_URL\", default='http://localhost:8000')\n\nSITE_HOSTNAME = furl(SITE_URL).host\n# Including localhost allows using the backend locally\nALLOWED_HOSTS = [SITE_HOSTNAME, 'localhost']\n\n# URL handling\nAPPEND_SLASH = False\nROOT_URLCONF = \"treeherder.config.urls\"\nWSGI_APPLICATION = 'treeherder.config.wsgi.application'\n\n# Send full URL within origin but only origin for cross-origin requests\nSECURE_REFERRER_POLICY = \"origin-when-cross-origin\"\n\n# We can't set X_FRAME_OPTIONS to DENY since renewal of an Auth0 token\n# requires opening the auth handler page in an invisible iframe with the\n# same origin.\nX_FRAME_OPTIONS = 'SAMEORIGIN'\n\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    # Disable Django's own staticfiles handling in favour of WhiteNoise, for\n    # greater consistency between gunicorn and `./manage.py runserver`.\n    'whitenoise.runserver_nostatic',\n    'django.contrib.staticfiles',\n    # 3rd party apps\n    'rest_framework',\n    'corsheaders',\n    'django_filters',\n    # treeherder apps\n    'treeherder.model',\n    'treeherder.webapp',\n    'treeherder.log_parser',\n    'treeherder.etl',\n    'treeherder.extract',\n    'treeherder.perf',\n    'treeherder.seta',\n    'treeherder.intermittents_commenter',\n    'treeherder.changelog',\n]\n\n# Docker/outside-of-Docker/CircleCI vs Heroku/Review-app\nif DEBUG:\n    NEW_RELIC_DEVELOPER_MODE = True\n    # This controls whether the Django debug toolbar should be shown or not\n    # https://django-debug-toolbar.readthedocs.io/en/latest/configuration.html#show-toolbar-callback\n    # \"You can provide your own function callback(request) which returns True or False.\"\n    DEBUG_TOOLBAR_CONFIG = {\n        'SHOW_TOOLBAR_CALLBACK': lambda request: DEBUG,\n    }\n    INSTALLED_APPS.append('debug_toolbar')\n    INSTALLED_APPS.append('django_extensions')\n\n# Heroku-review-app (defined in app.json)\nif env(\"HEROKU_REVIEW_APP\", default=False):\n    SITE_URL = \"https://{}.herokuapp.com\".format(env(\"HEROKU_APP_NAME\"))\n    SITE_HOSTNAME = furl(SITE_URL).host\n    ALLOWED_HOSTS = [SITE_HOSTNAME]\n\n# Middleware\nMIDDLEWARE = [\n    middleware\n    for middleware in [\n        # Adds custom New Relic annotations. Must be first so all transactions are annotated.\n        'treeherder.middleware.NewRelicMiddleware',\n        # Redirect to HTTPS/set HSTS and other security headers.\n        'django.middleware.security.SecurityMiddleware',\n        'django.middleware.clickjacking.XFrameOptionsMiddleware',\n        'corsheaders.middleware.CorsMiddleware',\n        # Allows both Django static files and those specified via `WHITENOISE_ROOT`\n        # to be served by WhiteNoise, avoiding the need for Apache/nginx on Heroku.\n        'treeherder.middleware.CustomWhiteNoise',\n        'django.middleware.gzip.GZipMiddleware',\n        'debug_toolbar.middleware.DebugToolbarMiddleware' if DEBUG else False,\n        'django.contrib.sessions.middleware.SessionMiddleware',\n        'django.middleware.common.CommonMiddleware',\n        'django.middleware.csrf.CsrfViewMiddleware',\n        'django.contrib.auth.middleware.AuthenticationMiddleware',\n    ]\n    if middleware\n]\n\n# Database\n# The database config is defined using environment variables of form:\n#\n#   'mysql://username:password@host:optional_port/database_name'\n#\n# which django-environ converts into the Django DB settings dict format.\nLOCALHOST_MYSQL_HOST = 'mysql://root@{}:3306/treeherder'.format(\n    'localhost' if IS_WINDOWS else '127.0.0.1'\n)\nDATABASES = {\n    'default': env.db_url('DATABASE_URL', default=LOCALHOST_MYSQL_HOST),\n}\n\n# Only used when syncing local database with production replicas\nUPSTREAM_DATABASE_URL = env('UPSTREAM_DATABASE_URL', default=None)\nif UPSTREAM_DATABASE_URL:\n    DATABASES['upstream'] = env.db_url_config(UPSTREAM_DATABASE_URL)\n\n# We're intentionally not using django-environ's query string options feature,\n# since it hides configuration outside of the repository, plus could lead to\n# drift between environments.\nfor alias in DATABASES:\n    # Persist database connections for 5 minutes, to avoid expensive reconnects.\n    DATABASES[alias]['CONN_MAX_AGE'] = 300\n    DATABASES[alias]['OPTIONS'] = {\n        # Override Django's default connection charset of 'utf8', otherwise it's\n        # still not possible to insert non-BMP unicode into utf8mb4 tables.\n        'charset': 'utf8mb4',\n        # From MySQL 5.7 onwards and on fresh installs of MySQL 5.6, the default value of the sql_mode\n        # option contains STRICT_TRANS_TABLES. That option escalates warnings into errors when data are\n        # truncated upon insertion, so Django highly recommends activating a strict mode for MySQL to\n        # prevent data loss (either STRICT_TRANS_TABLES or STRICT_ALL_TABLES).\n        'init_command': \"SET sql_mode='STRICT_TRANS_TABLES'\",\n    }\n    if connection_should_use_tls(DATABASES[alias]['HOST']):\n        # Use TLS when connecting to RDS.\n        # https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html#MySQL.Concepts.SSLSupport\n        # https://mysqlclient.readthedocs.io/user_guide.html#functions-and-attributes\n        DATABASES[alias]['OPTIONS']['ssl'] = {\n            'ca': 'deployment/aws/rds-combined-ca-bundle.pem',\n        }\n\n# Caches\nREDIS_URL = env('REDIS_URL', default='redis://localhost:6379')\nif connection_should_use_tls(REDIS_URL):\n    # Connect using TLS on Heroku.\n    REDIS_URL = get_tls_redis_url(REDIS_URL)\n\nCACHES = {\n    'default': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': REDIS_URL,\n        'OPTIONS': {\n            # Override the default of no timeout, to avoid connection hangs.\n            'SOCKET_CONNECT_TIMEOUT': 5,\n        },\n    },\n}\n\nconfig.update({})\n\n# Internationalization\nTIME_ZONE = \"UTC\"\nUSE_I18N = False\nUSE_L10N = True\n\n# Static files (CSS, JavaScript, Images)\nSTATIC_ROOT = join(SRC_DIR, \".django-static\")\nSTATIC_URL = \"/static/\"\n\n# Create hashed+gzipped versions of assets during collectstatic,\n# which will then be served by WhiteNoise with a suitable max-age.\n# http://whitenoise.evans.io/en/stable/django.html#add-compression-and-caching-support\nSTATICFILES_STORAGE = 'whitenoise.storage.CompressedManifestStaticFilesStorage'\n\n# Authentication\nAUTHENTICATION_BACKENDS = [\n    'django.contrib.auth.backends.ModelBackend',\n    'treeherder.auth.backends.AuthBackend',\n]\n\n# Use the cache-based backend rather than the default of database.\nSESSION_ENGINE = 'django.contrib.sessions.backends.cache'\n\n# Path to redirect to on successful login.\nLOGIN_REDIRECT_URL = '/'\n\n# Path to redirect to on unsuccessful login attempt.\nLOGIN_REDIRECT_URL_FAILURE = '/'\n\n# Path to redirect to on logout.\nLOGOUT_REDIRECT_URL = '/'\n\n# Logging\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    'filters': {\n        'require_debug_true': {\n            '()': 'django.utils.log.RequireDebugTrue',\n        },\n    },\n    'formatters': {\n        'standard': {\n            'format': \"[%(asctime)s] %(levelname)s [%(name)s:%(lineno)s] %(message)s\",\n        },\n    },\n    'handlers': {\n        'console': {'class': 'logging.StreamHandler', 'formatter': 'standard'},\n    },\n    'loggers': {\n        'django': {\n            'filters': ['require_debug_true'],\n            'handlers': ['console'],\n            'level': 'INFO',\n            'propagate': True,\n        },\n        'django.request': {\n            'handlers': ['console'],\n            'level': 'WARNING',\n            'propagate': True,\n        },\n        'treeherder': {\n            'handlers': ['console'],\n            'level': LOGGING_LEVEL,\n            'propagate': LOGGING_LEVEL != 'WARNING',\n        },\n        'kombu': {\n            'handlers': ['console'],\n            'level': 'WARNING',\n        },\n    },\n}\n\n# SECURITY\nUSE_X_FORWARDED_HOST = True\nUSE_X_FORWARDED_PORT = True\nSECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')\n\nif SITE_URL.startswith('https://'):\n    SECURE_SSL_REDIRECT = True\n    SECURE_HSTS_INCLUDE_SUBDOMAINS = True\n    SECURE_HSTS_PRELOAD = True\n    SECURE_HSTS_SECONDS = int(timedelta(days=365).total_seconds())\n    # Mark session and CSRF cookies as being HTTPS-only.\n    CSRF_COOKIE_SECURE = True\n    SESSION_COOKIE_SECURE = True\n\nSECURE_CONTENT_TYPE_NOSNIFF = True  # Set the `X-Content-Type-Options` header to `nosniff`.\nSECURE_BROWSER_XSS_FILTER = True  # Sets the `X-XSS-Protection` header.\n\n# System Checks\nSILENCED_SYSTEM_CHECKS = [\n    # We can't set CSRF_COOKIE_HTTPONLY to True since the requests to the API\n    # made using Angular's `httpProvider` require access to the cookie.\n    'security.W017',\n    'security.W019',\n]\n\n# User Agents\n# User agents which will be blocked from making requests to the site.\nDISALLOWED_USER_AGENTS = (\n    re.compile(r'^Go-http-client/'),\n    # This was the old Go http package user agent prior to Go-http-client/*\n    # https://github.com/golang/go/commit/0d1ceef9452c495b6f6d60e578886689184e5e4b\n    re.compile(r'^Go 1.1 package http'),\n    # Note: This intentionally does not match the command line curl\n    # tool's default User Agent, only the library used by eg PHP.\n    re.compile(r'^libcurl/'),\n    re.compile(r'^Python-urllib/'),\n    re.compile(r'^python-requests/'),\n)\n\n\n# THIRD PARTY APPS\n\n# Auth0 setup\nAUTH0_DOMAIN = env('AUTH0_DOMAIN', default=\"auth.mozilla.auth0.com\")\nAUTH0_CLIENTID = env('AUTH0_CLIENTID', default=\"q8fZZFfGEmSB2c5uSI8hOkKdDGXnlo5z\")\n\n# Celery\n\n# TODO: Replace the use of different log parser queues for failures vs not with the\n# RabbitMQ priority feature (since the idea behind separate queues was only to ensure\n# failures are dealt with first if there is a backlog). After that it should be possible\n# to simplify the queue configuration, by using the recommended CELERY_TASK_ROUTES instead:\n# http://docs.celeryproject.org/en/latest/userguide/routing.html#automatic-routing\nCELERY_TASK_QUEUES = [\n    Queue('default', Exchange('default'), routing_key='default'),\n    Queue('log_parser', Exchange('default'), routing_key='log_parser.normal'),\n    Queue('log_parser_fail_raw_sheriffed', Exchange('default'), routing_key='log_parser.failures'),\n    Queue(\n        'log_parser_fail_raw_unsheriffed', Exchange('default'), routing_key='log_parser.failures'\n    ),\n    Queue('log_parser_fail_json_sheriffed', Exchange('default'), routing_key='log_parser.failures'),\n    Queue(\n        'log_parser_fail_json_unsheriffed', Exchange('default'), routing_key='log_parser.failures'\n    ),\n    Queue('pushlog', Exchange('default'), routing_key='pushlog'),\n    Queue('generate_perf_alerts', Exchange('default'), routing_key='generate_perf_alerts'),\n    Queue('store_pulse_tasks', Exchange('default'), routing_key='store_pulse_tasks'),\n    Queue('store_pulse_pushes', Exchange('default'), routing_key='store_pulse_pushes'),\n    Queue('seta_analyze_failures', Exchange('default'), routing_key='seta_analyze_failures'),\n]\n\n# Force all queues to be explicitly listed in `CELERY_TASK_QUEUES` to help prevent typos\n# and so that `lints/queuelint.py` can check a corresponding worker exists in `Procfile`.\nCELERY_TASK_CREATE_MISSING_QUEUES = False\n\n# Celery broker setup\nCELERY_BROKER_URL = env('BROKER_URL', default='amqp://guest:guest@localhost:5672//')\n\n# Force Celery to use TLS when appropriate (ie if not localhost),\n# rather than relying on `CELERY_BROKER_URL` having `amqps://` or `?ssl=` set.\n# This is required since CloudAMQP's automatically defined URL uses neither.\nif connection_should_use_tls(CELERY_BROKER_URL):\n    CELERY_BROKER_USE_SSL = True\n\n# Recommended by CloudAMQP:\n# https://www.cloudamqp.com/docs/celery.html\n# Raise timeout from default of 4s, in case of Linux DNS timeouts etc.\nCELERY_BROKER_CONNECTION_TIMEOUT = 30\n# Disable heartbeats since CloudAMQP uses TCP keep-alive instead.\nCELERY_BROKER_HEARTBEAT = None\n\n# default value when no task routing info is specified\nCELERY_TASK_DEFAULT_QUEUE = 'default'\n\n# Make Celery defer the acknowledgment of a task until after the task has completed,\n# to prevent data loss in the case of celery master process crashes or infra failures.\n# https://devcenter.heroku.com/articles/celery-heroku#using-acks_late\n# http://docs.celeryproject.org/en/latest/userguide/tasks.html#Task.acks_late\nCELERY_TASK_ACKS_LATE = True\n\n# Default celery time limits in seconds. The gap between the soft and hard time limit\n# is to give the New Relic agent time to report the `SoftTimeLimitExceeded` exception.\n# NB: The per-task `soft_time_limit` must always be lower than `CELERY_TASK_TIME_LIMIT`.\nCELERY_TASK_SOFT_TIME_LIMIT = 15 * 60\nCELERY_TASK_TIME_LIMIT = CELERY_TASK_SOFT_TIME_LIMIT + 30\n\nCELERY_BEAT_SCHEDULE = {\n    # this is just a failsafe in case the Pulse ingestion misses something\n    'fetch-push-logs-every-5-minutes': {\n        'task': 'fetch-push-logs',\n        'schedule': timedelta(minutes=5),\n        'relative': True,\n        'options': {\"queue\": \"pushlog\"},\n    },\n    'seta-analyze-failures': {\n        'task': 'seta-analyze-failures',\n        'schedule': timedelta(days=1),\n        'relative': True,\n        'options': {'queue': \"seta_analyze_failures\"},\n    },\n}\n\n# CORS Headers\nCORS_ORIGIN_ALLOW_ALL = True  # allow requests from any host\n\n\n# Rest Framework\nREST_FRAMEWORK = {\n    'ALLOWED_VERSIONS': ('1.0',),\n    'DEFAULT_AUTHENTICATION_CLASSES': ('rest_framework.authentication.SessionAuthentication',),\n    'DEFAULT_FILTER_BACKENDS': ('django_filters.rest_framework.DjangoFilterBackend',),\n    'DEFAULT_PARSER_CLASSES': ('rest_framework.parsers.JSONParser',),\n    'DEFAULT_PERMISSION_CLASSES': ('rest_framework.permissions.IsAuthenticatedOrReadOnly',),\n    'DEFAULT_RENDERER_CLASSES': (\n        'rest_framework.renderers.JSONRenderer',\n        'rest_framework.renderers.BrowsableAPIRenderer',\n    ),\n    'DEFAULT_SCHEMA_CLASS': 'rest_framework.schemas.coreapi.AutoSchema',\n    'DEFAULT_VERSION': '1.0',\n    'DEFAULT_VERSIONING_CLASS': 'rest_framework.versioning.AcceptHeaderVersioning',\n    'TEST_REQUEST_DEFAULT_FORMAT': 'json',\n}\n\n# Whitenoise\n# http://whitenoise.evans.io/en/stable/django.html#available-settings\n# Files in this directory will be served by WhiteNoise at the site root.\nWHITENOISE_ROOT = join(SRC_DIR, \".build\")\n# Serve index.html for URLs ending in a trailing slash.\nWHITENOISE_INDEX_FILE = True\n# Only output the hashed filename version of static files and not the originals.\n# Halves the time spent performing Brotli/gzip compression during deploys.\nWHITENOISE_KEEP_ONLY_HASHED_FILES = True\n\n# Templating\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'APP_DIRS': True,\n        'DIRS': [WHITENOISE_ROOT],\n    }\n]\n\n# TREEHERDER\n\n# Bugzilla\n# BZ_API_URL is used to fetch bug suggestions from bugzilla\n# BUGFILER_API_URL is used when filing bugs\n# these are no longer necessarily the same so stage treeherder can submit\n# to stage bmo, while suggestions can still be fetched from prod bmo\nBZ_API_URL = \"https://bugzilla.mozilla.org\"\nBUGFILER_API_URL = env(\"BUGZILLA_API_URL\", default=BZ_API_URL)\nBUGFILER_API_KEY = env(\"BUG_FILER_API_KEY\", default=None)\nBZ_DATETIME_FORMAT = '%Y-%m-%dT%H:%M:%SZ'\n\n# For intermittents commenter\nCOMMENTER_API_KEY = env(\"BUG_COMMENTER_API_KEY\", default=None)\n\n# Log Parsing\nMAX_ERROR_LINES = 100\nFAILURE_LINES_CUTOFF = 35\n\n# Perfherder\n# Default minimum regression threshold for perfherder is 2% (otherwise\n# e.g. the build size tests will alert on every commit)\nPERFHERDER_REGRESSION_THRESHOLD = 2\n\n# Various settings for treeherder's t-test \"sliding window\" alert algorithm\nPERFHERDER_ALERTS_MIN_BACK_WINDOW = 12\nPERFHERDER_ALERTS_MAX_BACK_WINDOW = 24\nPERFHERDER_ALERTS_FORE_WINDOW = 12\n# Assess if tests should be (non)sheriffed\nQUANTIFYING_PERIOD = timedelta(weeks=24)  # how far back to look over Bugzilla data\nBUG_COOLDOWN_TIME = timedelta(weeks=2)  # time after bug is ready for assessment\n\n# Only generate alerts for data newer than this time in seconds in perfherder\nPERFHERDER_ALERTS_MAX_AGE = timedelta(weeks=2)\n# From the same job's log, ingest (or not) multiple PERFHERDER_DATA dumps\n# pertaining to the same performance signature\nPERFHERDER_ENABLE_MULTIDATA_INGESTION = env.bool(\n    'PERFHERDER_ENABLE_MULTIDATA_INGESTION', default=True\n)\n\n# Performance sheriff bot settings\nMAX_BACKFILLS_PER_PLATFORM = {\n    'linux': 200,\n}\nRESET_BACKFILL_LIMITS = timedelta(hours=24)\n\n# Taskcluster credentials for PerfSheriffBot\nPERF_SHERIFF_BOT_CLIENT_ID = env('PERF_SHERIFF_BOT_CLIENT_ID', default=None)\nPERF_SHERIFF_BOT_ACCESS_TOKEN = env('PERF_SHERIFF_BOT_ACCESS_TOKEN', default=None)\n\n# Taskcluster credentials for Notification Service\nNOTIFY_CLIENT_ID = env('NOTIFY_CLIENT_ID', default=None)\nNOTIFY_ACCESS_TOKEN = env('NOTIFY_ACCESS_TOKEN', default=None)\n\n# This is only used for removing the rate limiting. You can create your own here:\n# https://github.com/settings/tokens\nGITHUB_TOKEN = env(\"GITHUB_TOKEN\", default=None)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import uuid\nfrom datetime import datetime, timedelta\n\nimport pytest\nimport simplejson as json\nfrom django.db.models import Q\nfrom mock import Mock, patch\n\nfrom treeherder.config.settings import IS_WINDOWS\nfrom treeherder.perf.auto_perf_sheriffing.secretary_tool import SecretaryTool\nfrom treeherder.model.models import Push, Job\nfrom treeherder.perf.models import BackfillRecord, BackfillReport, PerformanceSettings\nfrom treeherder.perf.auto_perf_sheriffing.outcome_checker import OutcomeChecker, OutcomeStatus\n\n# we're testing against this (automatically provided by fixtures)\nJOB_TYPE_ID = 1\n\n\ndef get_middle_index(successful_jobs):\n    # get middle index to make sure the push is in range\n    index_in_range = int((len(successful_jobs) + 1) / 2)\n    return index_in_range\n\n\n@pytest.fixture\ndef record_backfilled(test_perf_alert, record_context_sample):\n    report = BackfillReport.objects.create(summary=test_perf_alert.summary)\n    record = BackfillRecord.objects.create(\n        alert=test_perf_alert,\n        report=report,\n        status=BackfillRecord.BACKFILLED,\n    )\n    record.set_context(record_context_sample)\n    record.save()\n    return record\n\n\n@pytest.fixture\ndef range_dates(record_context_sample):\n\n    from_date = datetime.fromisoformat(record_context_sample[0]['push_timestamp'])\n    to_date = datetime.fromisoformat(record_context_sample[-1]['push_timestamp'])\n\n    return {\n        'before_date': from_date - timedelta(days=5),\n        'from_date': from_date,\n        'in_range_date': from_date + timedelta(hours=13),\n        'to_date': to_date,\n        'after_date': to_date + timedelta(days=3),\n    }\n\n\n@pytest.fixture\ndef outcome_checking_pushes(\n    create_push, range_dates, record_context_sample, test_repository, test_repository_2\n):\n    from_push_id = record_context_sample[0]['push_id']\n    to_push_id = record_context_sample[-1]['push_id']\n\n    pushes = [\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['before_date']),\n        create_push(\n            test_repository,\n            revision=uuid.uuid4(),\n            time=range_dates['from_date'],\n            explicit_id=from_push_id,\n        ),\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['in_range_date']),\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['in_range_date']),\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['in_range_date']),\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['in_range_date']),\n        create_push(\n            test_repository,\n            revision=uuid.uuid4(),\n            time=range_dates['to_date'],\n            explicit_id=to_push_id,\n        ),\n        create_push(test_repository, revision=uuid.uuid4(), time=range_dates['after_date']),\n    ]\n\n    return pushes\n\n\n@pytest.fixture\ndef successful_jobs(outcome_checking_pushes, eleven_jobs_stored):\n    jobs = Job.objects.all()\n    _successful_jobs = []\n    pairs = zip(outcome_checking_pushes, jobs)\n    for push, job in pairs:\n        job.push = push\n        job.result = 'success'\n        job.job_type_id = JOB_TYPE_ID\n        job.save()\n        _successful_jobs.append(job)\n    return _successful_jobs\n\n\n@pytest.fixture\ndef jobs_with_one_failed(successful_jobs):\n    index_in_range = get_middle_index(successful_jobs)\n    job_to_fail = successful_jobs[index_in_range]\n    job_to_fail.result = 'testfailed'\n    job_to_fail.save()\n\n\n@pytest.fixture\ndef jobs_with_one_pending(successful_jobs):\n    index_in_range = get_middle_index(successful_jobs)\n    job_pending = successful_jobs[index_in_range]\n    job_pending.result = 'unknown'\n    job_pending.save()\n\n\n@pytest.fixture\ndef get_outcome_checker_mock():\n    def get_outcome_checker_mock(outcome: OutcomeStatus):\n        return type('', (), {'check': lambda *params: outcome})\n\n    return get_outcome_checker_mock\n\n\n@pytest.mark.skipif(IS_WINDOWS, reason=\"datetime logic does not work when OS not on GMT\")\ndef test_secretary_tool_updates_only_matured_reports(\n    test_perf_alert, test_perf_alert_2, create_record\n):\n    # create new report with records\n    create_record(test_perf_alert)\n    # create mature report with records\n    date_past = datetime.utcnow() - timedelta(hours=5)\n    with patch('django.utils.timezone.now', Mock(return_value=date_past)):\n        create_record(test_perf_alert_2)\n\n    assert BackfillRecord.objects.count() == 2\n    assert BackfillRecord.objects.filter(status=BackfillRecord.PRELIMINARY).count() == 2\n\n    SecretaryTool.mark_reports_for_backfill()\n    assert BackfillRecord.objects.filter(status=BackfillRecord.PRELIMINARY).count() == 1\n\n\ndef test_secretary_tool_uses_existing_settings(performance_settings):\n    assert PerformanceSettings.objects.count() == 1\n    last_reset_date_before = json.loads(performance_settings.settings)[\"last_reset_date\"]\n\n    SecretaryTool.validate_settings()\n\n    assert PerformanceSettings.objects.count() == 1\n    settings_after = PerformanceSettings.objects.filter(name=\"perf_sheriff_bot\").first()\n    assert json.loads(settings_after.settings)[\"last_reset_date\"] == last_reset_date_before\n\n\ndef test_secretary_tool_resets_settings_if_expired(expired_performance_settings):\n    assert PerformanceSettings.objects.count() == 1\n    expired_last_reset_date = json.loads(expired_performance_settings.settings)[\"last_reset_date\"]\n\n    SecretaryTool.validate_settings()\n\n    assert PerformanceSettings.objects.count() == 1\n    settings_after = PerformanceSettings.objects.filter(name=\"perf_sheriff_bot\").first()\n    assert json.loads(settings_after.settings)[\"last_reset_date\"] != expired_last_reset_date\n\n\ndef test_secretary_tool_creates_new_settings_if_none_exist(db):\n    assert PerformanceSettings.objects.count() == 0\n\n    SecretaryTool.validate_settings()\n\n    assert PerformanceSettings.objects.count() == 1\n\n\ndef test_check_outcome_after_success(get_outcome_checker_mock, record_backfilled):\n    outcome_checker_mock = get_outcome_checker_mock(OutcomeStatus.SUCCESSFUL)\n    secretary = SecretaryTool(outcome_checker_mock)\n\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 1\n    assert BackfillRecord.objects.filter(status=BackfillRecord.SUCCESSFUL).count() == 0\n    secretary.check_outcome()\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 0\n    assert BackfillRecord.objects.filter(status=BackfillRecord.SUCCESSFUL).count() == 1\n\n\ndef test_check_outcome_after_fail(get_outcome_checker_mock, record_backfilled):\n    outcome_checker_mock = get_outcome_checker_mock(OutcomeStatus.FAILED)\n    secretary = SecretaryTool(outcome_checker_mock)\n\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 1\n    assert BackfillRecord.objects.filter(status=BackfillRecord.FAILED).count() == 0\n    secretary.check_outcome()\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 0\n    assert BackfillRecord.objects.filter(status=BackfillRecord.FAILED).count() == 1\n\n\ndef test_no_action_when_in_progress(get_outcome_checker_mock, record_backfilled):\n    outcome_checker_mock = get_outcome_checker_mock(OutcomeStatus.IN_PROGRESS)\n    secretary = SecretaryTool(outcome_checker_mock)\n\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 1\n    secretary.check_outcome()\n    assert BackfillRecord.objects.filter(status=BackfillRecord.BACKFILLED).count() == 1\n\n\ndef test_outcome_checker_identifies_pushes_in_range(\n    record_backfilled, test_repository, test_repository_2, range_dates, outcome_checking_pushes\n):\n    # TODO: retarget this test to BackfillRecord.get_pushes_in_range()\n    outcome_checker = OutcomeChecker()\n    total_pushes = Push.objects.count()\n\n    from_time = range_dates['from_date']\n    to_time = range_dates['to_date']\n\n    total_outside_pushes = Push.objects.filter(\n        Q(repository=test_repository) & (Q(time__lt=from_time) | Q(time__gt=to_time))\n    ).count()\n\n    pushes_in_range = outcome_checker._get_pushes_in_range(from_time, to_time, test_repository.id)\n    assert len(pushes_in_range) == total_pushes - total_outside_pushes\n\n    # change repository for the first 2 pushes in range\n    assert test_repository.id != test_repository_2.id\n\n    total_changed_pushes = 2\n    for push in pushes_in_range[:total_changed_pushes]:\n        push.repository = test_repository_2\n        push.save()\n\n    total_other_repo_pushes = Push.objects.filter(repository=test_repository_2).count()\n    assert total_other_repo_pushes == total_changed_pushes\n\n    updated_pushes_in_range = outcome_checker._get_pushes_in_range(\n        from_time, to_time, test_repository.id\n    )\n\n    assert len(updated_pushes_in_range) == len(pushes_in_range) - total_other_repo_pushes\n\n\nclass TestOutcomeChecker:\n    @patch('treeherder.perf.auto_perf_sheriffing.outcome_checker.get_job_type')\n    def test_successful_jobs_mean_successful_outcome(\n        self, mock_get_job_type, record_backfilled, outcome_checking_pushes, successful_jobs\n    ):\n        # TODO: remove job type mock after soft launch lands\n        mock_get_job_type.return_value = JOB_TYPE_ID\n        outcome_checker = OutcomeChecker()\n\n        response = outcome_checker.check(record_backfilled)\n        assert response == OutcomeStatus.SUCCESSFUL\n\n    @patch('treeherder.perf.auto_perf_sheriffing.outcome_checker.get_job_type')\n    def test_failed_job_means_failed_outcome(\n        self, mock_get_job_type, record_backfilled, outcome_checking_pushes, jobs_with_one_failed\n    ):\n        mock_get_job_type.return_value = JOB_TYPE_ID\n        outcome_checker = OutcomeChecker()\n\n        response = outcome_checker.check(record_backfilled)\n        assert response == OutcomeStatus.FAILED\n\n    @patch('treeherder.perf.auto_perf_sheriffing.outcome_checker.get_job_type')\n    def test_pending_job_means_in_progress_outcome(\n        self, mock_get_job_type, record_backfilled, outcome_checking_pushes, jobs_with_one_pending\n    ):\n        mock_get_job_type.return_value = JOB_TYPE_ID\n        outcome_checker = OutcomeChecker()\n\n        response = outcome_checker.check(record_backfilled)\n        assert response == OutcomeStatus.IN_PROGRESS\n"
  },
  {
    "prompt": "\n\n### python/engine/functions/orbit_derived_parameters.py ###\n\nfrom sympy import pi, sqrt\nfrom sympy.physics.units import gravitational_constant as G\n\n\ndef OrbitalPeriod(\n    primary_mass, secondary_mass, semimajor_axis, gravitational_constant=G\n):\n    mean_angular_motion = sqrt(\n        gravitational_constant * (primary_mass + secondary_mass) / (semimajor_axis ** 3)\n    )\n    return 2 * pi / mean_angular_motion\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\nfrom engine.constants import G\nfrom pytest import param as p\n\nfrom .orbit_derived_parameters import OrbitalPeriod\n\n\n@pytest.mark.parametrize(\n    (\"primary_mass\", \"secondary_mass\", \"semimajor_axis\", \"expected\"),\n    [p(10e10, 100, 10, 76.9102, id=\"arbitrary period\")],\n)\ndef test_orbital_period(primary_mass, secondary_mass, semimajor_axis, expected):\n    assert OrbitalPeriod(\n        primary_mass, secondary_mass, semimajor_axis, G\n    ).evalf() == pytest.approx(expected, 1e-3)\n"
  },
  {
    "prompt": "\n\n### djcookie_demo_proj/users/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for djcookie-demo-proj.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### djcookie_demo_proj/users/tests/factories.py ###\n\nfrom typing import Any, Sequence\n\nfrom django.contrib.auth import get_user_model\nfrom factory import Faker, post_generation\nfrom factory.django import DjangoModelFactory\n\n\nclass UserFactory(DjangoModelFactory):\n\n    username = Faker(\"user_name\")\n    email = Faker(\"email\")\n    name = Faker(\"name\")\n\n    @post_generation\n    def password(self, create: bool, extracted: Sequence[Any], **kwargs):\n        password = (\n            extracted\n            if extracted\n            else Faker(\n                \"password\",\n                length=42,\n                special_chars=True,\n                digits=True,\n                upper_case=True,\n                lower_case=True,\n            ).evaluate(None, None, extra={\"locale\": None})\n        )\n        self.set_password(password)\n\n    class Meta:\n        model = get_user_model()\n        django_get_or_create = [\"username\"]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom djcookie_demo_proj.users.models import User\nfrom djcookie_demo_proj.users.tests.factories import UserFactory\n\n\n@pytest.fixture(autouse=True)\ndef media_storage(settings, tmpdir):\n    settings.MEDIA_ROOT = tmpdir.strpath\n\n\n@pytest.fixture\ndef user() -> User:\n    return UserFactory()\n"
  },
  {
    "prompt": "\n\n### receptor/router.py ###\n\nimport datetime\nimport heapq\nimport logging\nimport random\nimport uuid\nfrom collections import defaultdict\n\nfrom .exceptions import ReceptorBufferError, UnrouteableError\nfrom .messages import envelope\nfrom .stats import route_counter, route_info\n\nlogger = logging.getLogger(__name__)\n\n\nclass MeshRouter:\n    _nodes = set()\n    _edges = set()\n    response_registry = dict()\n\n    def __init__(self, receptor):\n        self.receptor = receptor\n        self.node_id = receptor.node_id\n        route_info.info(dict(edges=\"()\"))\n\n    def node_is_known(self, node_id):\n        return node_id in self._nodes or node_id == self.node_id\n\n    def find_edge(self, left, right):\n        node_actual = sorted([left, right])\n        for edge in self._edges:\n            if node_actual[0] == edge[0] and node_actual[1] == edge[1]:\n                return edge\n        return None\n\n    def add_edges(self, edges):\n        for edge in edges:\n            existing_edge = self.find_edge(edge[0], edge[1])\n            if existing_edge and existing_edge[2] > edge[2]:\n                self.update_node(edge[0], edge[1], edge[2])\n            else:\n                self.register_edge(*edge)\n\n    def register_edge(self, left, right, cost):\n        if left != self.node_id:\n            self._nodes.add(left)\n        if right != self.node_id:\n            self._nodes.add(right)\n        edge = self.update_node(left, right, cost)\n        if not edge:\n            self._edges.add((*sorted([left, right]), cost))\n        route_info.info(dict(edges=str(self._edges)))\n\n    def update_node(self, left, right, cost):\n        edge = self.find_edge(left, right)\n        if edge:\n            new_edge = (edge[0], edge[1], cost)\n            self._edges.remove(edge)\n            self._edges.add(new_edge)\n            return edge\n        return None\n\n    def remove_node(self, node):\n        edge = self.find_edge(self.node_id, node)\n        if edge:\n            self._edges.remove(edge)\n            return edge\n        return None\n\n    def get_edges(self):\n        \"\"\"Returns set of edges\"\"\"\n        return list(self._edges)\n\n    def get_nodes(self):\n        return self._nodes\n\n    async def ping_node(self, node_id, expected_response=True):\n        logger.info(f'Sending ping to node {node_id}')\n        now = datetime.datetime.utcnow().isoformat()\n        ping_envelope = envelope.Inner(\n            receptor=self.receptor,\n            message_id=str(uuid.uuid4()),\n            sender=self.node_id,\n            recipient=node_id,\n            message_type='directive',\n            timestamp=now,\n            raw_payload=now,\n            directive='receptor:ping',\n            ttl=15\n        )\n        return await self.send(ping_envelope, expected_response)\n\n    def find_shortest_path(self, to_node_id):\n        \"\"\"Implementation of Dijkstra algorithm\"\"\"\n        cost_map = defaultdict(list)\n        for left, right, cost in self._edges:\n            cost_map[left].append((cost, right))\n            cost_map[right].append((cost, left))\n\n        heap, seen, mins = [(0, self.node_id, [])], set(), {self.node_id: 0}\n        while heap:\n            (cost, vertex, path) = heapq.heappop(heap)\n            if vertex not in seen:\n                seen.add(vertex)\n                path = [vertex] + path\n                if vertex == to_node_id:\n                    logger.debug(f'Shortest path to {to_node_id} with cost {cost} is {path}')\n                    return path\n                cost_map_for_vertex = cost_map.get(vertex, ())\n                random.shuffle(cost_map_for_vertex)\n                for next_cost, next_vertex in cost_map.get(vertex, ()):\n                    if next_vertex in seen:\n                        continue\n                    min_so_far = mins.get(next_vertex, None)\n                    next_total_cost = cost + next_cost\n                    if min_so_far is None or next_total_cost < min_so_far:\n                        mins[next_vertex] = next_total_cost\n                        heapq.heappush(heap, (next_total_cost, next_vertex, path))\n\n    async def forward(self, msg, next_hop):\n        \"\"\"\n        Forward a message on to the next hop closer to its destination\n        \"\"\"\n        buffer_mgr = self.receptor.config.components_buffer_manager\n        buffer_obj = buffer_mgr.get_buffer_for_node(next_hop, self.receptor)\n        msg.header[\"route_list\"].append(self.node_id)\n        logger.debug(f'Forwarding frame {msg.msg_id} to {next_hop}')\n        try:\n            route_counter.inc()\n            await buffer_obj.put(msg.serialize())\n        except ReceptorBufferError as e:\n            logger.exception(\"Receptor Buffer Write Error forwarding message to {}: {}\".format(next_hop, e))\n            # TODO: Possible to find another route? This might be a hard failure\n        except Exception as e:\n            logger.exception(\"Error trying to forward message to {}: {}\".format(next_hop, e))\n\n    def next_hop(self, recipient):\n        \"\"\"\n        Return the node ID of the next hop for routing a message to the\n        given recipient. If the current node is the recipient or there is\n        no path, then return None.\n        \"\"\"\n        if recipient == self.node_id:\n            return None\n        path = self.find_shortest_path(recipient)\n        if path:\n            return path[-2]\n\n    async def send(self, inner_envelope, expected_response=False):\n        \"\"\"\n        Send a new message with the given outer envelope.\n        \"\"\"\n        next_node_id = self.next_hop(inner_envelope.recipient)\n        if not next_node_id:\n            # TODO: This probably needs to emit an error response\n            raise UnrouteableError(f'No route found to {inner_envelope.recipient}')\n        signed = await inner_envelope.sign_and_serialize()\n        header = {\n            \"sender\": self.node_id,\n            \"recipient\": inner_envelope.recipient,\n            \"route_list\": [self.node_id]\n        }\n        msg = envelope.FramedMessage(msg_id=uuid.uuid4().int, header=header, payload=signed)\n        logger.debug(f'Sending {inner_envelope.message_id} to {inner_envelope.recipient} via {next_node_id}')\n        if expected_response and inner_envelope.message_type == 'directive':\n            self.response_registry[inner_envelope.message_id] = dict(message_sent_time=inner_envelope.timestamp)\n        await self.forward(msg, next_node_id)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\nfrom receptor.router import MeshRouter\n\ntest_networks = [\n    (\n        [\n            (\"a\", \"b\", 1),\n            (\"a\", \"d\", 1),\n            (\"a\", \"f\", 1),\n            (\"b\", \"d\", 1),\n            (\"b\", \"c\", 1),\n            (\"c\", \"e\", 1),\n            (\"c\", \"h\", 1),\n            (\"c\", \"j\", 1),\n            (\"e\", \"f\", 1),\n            (\"e\", \"g\", 1),\n            (\"e\", \"h\", 1),\n            (\"f\", \"g\", 1),\n            (\"g\", \"h\", 1),\n            (\"h\", \"j\", 1),\n            (\"h\", \"k\", 1),\n            (\"j\", \"k\", 1),\n            (\"j\", \"m\", 1),\n            (\"l\", \"m\", 1),\n        ],\n        [(\"a\", \"f\", \"f\"), (\"a\", \"m\", \"b\"), (\"h\", \"d\", \"c\")],\n        [(\"a\", {\"b\", \"d\", \"f\"}), (\"f\", {\"a\", \"e\", \"g\"}), (\"j\", {\"c\", \"h\", \"k\", \"m\"})],\n    ),\n    (\n        [(\"a\", \"b\", 1), (\"b\", \"c\", 1), (\"c\", \"d\", 1), (\"d\", \"e\", 1), (\"e\", \"f\", 1)],\n        [(\"a\", \"f\", \"b\"), (\"c\", \"a\", \"b\"), (\"f\", \"c\", \"e\")],\n        [(\"a\", {\"b\"}), (\"f\", {\"e\"}), (\"c\", {\"b\", \"d\"})],\n    ),\n]\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_next_hop(edges, expected_next_hops, expected_neighbors):\n    for node_id, remote, enh in expected_next_hops:\n        r = MeshRouter(node_id=node_id)\n        r.add_or_update_edges(edges)\n        assert r.next_hop(remote) == enh\n\n\n@pytest.mark.parametrize(\"edges, expected_next_hops, expected_neighbors\", test_networks)\ndef test_neighbors(edges, expected_next_hops, expected_neighbors):\n    r = MeshRouter(node_id=edges[0][0])\n    r.add_or_update_edges(edges)\n    for node_id, neighbors in expected_neighbors:\n        assert r.get_neighbors(node_id) == neighbors\n"
  },
  {
    "prompt": "\n\n### tests/conftest.py ###\n\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at http://mozilla.org/MPL/2.0/.\nimport io\nimport json\nimport mock\nimport os\nimport pytest\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nimport time\n\nfrom glean import testing\nfrom pathlib import Path\n\nfrom mozphab.commands import submit\nfrom mozphab.git import Git\nfrom mozphab.mercurial import Mercurial\n\nfrom mozphab import (\n    arcanist,\n    conduit,\n    config as config_module,\n    environment,\n    mozphab,\n    repository,\n    simplecache,\n    updater,\n    user,\n)\n\n\nenvironment.SHOW_SPINNER = False\nenvironment.HTTP_ALLOWED = True\n\n\ndef create_temp_fn(*filenames):\n    m_temp_fn = mock.Mock()\n    if len(filenames) > 1:\n        m_temp_fn.__enter__ = mock.Mock(side_effect=filenames)\n    else:\n        m_temp_fn.__enter__ = mock.Mock(return_value=filenames[0])\n    m_temp_fn.__exit__ = mock.Mock(return_value=None)\n    return m_temp_fn\n\n\ndef search_diff(diff=1, phid=\"PHID-DIFF-1\", node=\"aaa000aaa000\"):\n    return {\n        \"id\": diff,\n        \"phid\": phid,\n        \"attachments\": {\"commits\": {\"commits\": [{\"identifier\": node}]}},\n    }\n\n\ndef search_rev(\n    rev=1,\n    phid=\"PHID-DREV-1\",\n    bug=\"1\",\n    status=\"needs-review\",\n    closed=False,\n    author=\"PHID-USER-1\",\n    diff=\"PHID-DIFF-1\",\n    reviewers=None,\n):\n    reviewers = reviewers or []\n    return {\n        \"id\": rev,\n        \"phid\": phid,\n        \"fields\": {\n            \"bugzilla.bug-id\": bug,\n            \"status\": {\"value\": status, \"closed\": closed},\n            \"authorPHID\": author,\n            \"diffPHID\": diff,\n        },\n        \"attachments\": {\n            \"reviewers\": {\"reviewers\": [{\"reviewerPHID\": r} for r in reviewers]}\n        },\n    }\n\n\ndef assert_attributes(hunk, expected):\n    for name, value in expected.items():\n        if hunk.__getattribute__(name) != value:\n            raise AssertionError(\n                \"%s: expected '%s', got '%s'\"\n                % (name, value, hunk.__getattribute__(name))\n            )\n\n\n@pytest.fixture\ndef hg_sha():\n    def ret():\n        return hg_out(\"id\", \"-i\").rstrip(\"\\n\")\n\n    return ret\n\n\n@pytest.fixture\ndef git_sha():\n    def ret():\n        return git_out(\"log\", \"--format=%H\", \"-1\").rstrip(\"\\n\")\n\n    return ret\n\n\n@pytest.fixture\ndef init_sha(in_process, git_repo_path, git_sha):\n    return git_sha()\n\n\n@pytest.fixture(autouse=True)\ndef reset_cache():\n    simplecache.cache.reset()\n\n\n@pytest.fixture()\ndef repo_phab_url():\n    with mock.patch(\"mozphab.repository.Repository._phab_url\") as xmock:\n        xmock.return_value = \"http://phab.test\"\n        yield xmock\n\n\n@pytest.fixture\ndef data_file():\n    return Path(__file__).parent / \"data\" / \"img.png\"\n\n\n@pytest.fixture\ndef git_command():\n    mozphab.config.git_command = [\"git\"]\n    return mozphab.config\n\n\n@pytest.fixture\n@mock.patch(\"mozphab.gitcommand.GitCommand.output\")\n@mock.patch(\"mozphab.git.Git._get_current_head\")\n@mock.patch(\"mozphab.repository.os.path\")\n@mock.patch(\"mozphab.helpers.which\")\n@mock.patch(\"mozphab.repository.read_json_field\")\ndef git(\n    m_read_json_field,\n    m_which,\n    m_os_path,\n    m_git_get_current_head,\n    m_git_git_out,\n    repo_phab_url,\n    git_command,\n):\n    m_read_json_field.return_value = \"TEST\"\n    m_os_path.join = os.path.join\n    m_os_path.exists.return_value = True\n    m_which.return_value = True\n    m_os_path.isfile.return_value = False\n    m_git_git_out.side_effect = (\"git version 2.25.0\",)\n    m_git_get_current_head.return_value = \"branch\"\n    git = Git(\"x\")\n    git._phab_vcs = \"git\"\n    return git\n\n\n@pytest.fixture\n@mock.patch(\"mozphab.repository.os.chdir\")\n@mock.patch(\"mozphab.mercurial.Mercurial.repository\")\n@mock.patch(\"mozphab.repository.os.path\")\n@mock.patch(\"mozphab.helpers.which\")\n@mock.patch(\"mozphab.repository.read_json_field\")\n@mock.patch(\"mozphab.mercurial.hglib.open\")\ndef hg(\n    m_hglib_open,\n    m_read_json_field,\n    m_which,\n    m_os_path,\n    m_repository,\n    m_os_chdir,\n    safe_environ,\n    repo_phab_url,\n):\n    m_read_json_field.return_value = \"TEST\"\n    m_os_path.join = os.path.join\n    m_os_path.exists.return_value = True\n    m_which.return_value = True\n    m_os_path.isfile.return_value = False\n    m_repository.version = 4, 7, 1, \"bleh\"\n    m_os_chdir.return_value = True\n    mozphab.config.hg_command = [\"hg\"]\n    hg = Mercurial(\"x\")\n    hg.use_evolve = True\n    hg.has_mq = False\n    hg._phab_vcs = \"hg\"\n    return hg\n\n\ndef hg_out(*args):\n    args = [\"hg\"] + list(args)\n    return subprocess.check_output(args, universal_newlines=True, encoding=\"utf-8\")\n\n\ndef write_text(filename, content, **kwargs):\n    # Always write LF delimited text\n    with io.open(filename, \"w\", newline=\"\\n\", **kwargs) as f:\n        f.write(content)\n\n\ndef find_script_path(name):\n    \"\"\"Return the fully qualified path to an executable, preferring those installed\n    into the current virtualenv.\"\"\"\n    bin_path = Path(sys.executable).parent\n    if sys.platform == \"win32\":\n        name = \"%s.exe\" % name\n    filename = bin_path / name\n    if filename.exists():\n        return str(filename)\n    # Check system path\n    if shutil.which(name):\n        return name\n    raise Exception(\"Failed to find script: %s\" % filename)\n\n\n@pytest.fixture\ndef hg_repo_path(monkeypatch, tmp_path):\n    \"\"\"Build a usable HG repository. Return the pathlib.Path to the repo.\"\"\"\n    phabricator_uri = \"http://example.test\"\n    repo_path = tmp_path / \"hg-repo\"\n    repo_path.mkdir()\n    monkeypatch.chdir(str(repo_path))\n    arcconfig = repo_path / \".arcconfig\"\n    arcconfig.write_text(json.dumps({\"phabricator.uri\": phabricator_uri}))\n    hg_out(\"init\")\n    hg_out(\"add\")\n    hg_out(\"commit\", \"-m\", \"init\")\n    # graphshorten changes `log --graph` output, force to false\n    with open(\".hg/hgrc\", \"a\") as f:\n        f.write(\"\\n[experimental]\\ngraphshorten = false\\n\")\n    return repo_path\n\n\n@pytest.fixture\ndef fresh_global_config(tmp_path):\n    \"\"\"Overrides global ~/.gitconfig.\n\n    Creates a tiny gitconfig file in the temp repo and sets it as the $HOME\n    \"\"\"\n    original_env = os.environ.copy()\n    env = os.environ\n    env[\"HOME\"] = str(tmp_path)\n    with open(\"{}/.gitconfig\".format(tmp_path), \"w\") as f:\n        f.write(\"[user]\\n\\tname = Developer\\n\\temail = developer@mozilla.com\\n\")\n    with open(\"{}/.hgrc\".format(tmp_path), \"w\") as f:\n        f.write(\n            \"[ui]\\nusername = Developer <developer@mozilla.com>\\n\"\n            \"[extensions]\\nevolve =\\n\"\n        )\n    yield\n    os.environ.clear()\n    os.environ.update(original_env)\n\n\ndef git_out(*args):\n    env = os.environ.copy()\n    args = [\n        \"git\",\n        \"-c\",\n        \"i18n.logOutputEncoding=UTF-8\",\n        \"-c\",\n        \"i18n.commitEncoding=UTF-8\",\n    ] + list(args)\n    env[\"DEBUG\"] = \"1\"\n    return subprocess.check_output(\n        args, env=env, universal_newlines=True, encoding=\"utf-8\"\n    )\n\n\n@pytest.fixture\ndef git_repo_path(monkeypatch, tmp_path):\n    \"\"\"Build a usable Git repository. Return the pathlib.Path to the repo.\"\"\"\n    phabricator_uri = \"http://example.test\"\n    repo_path = tmp_path / \"git-repo\"\n    repo_path.mkdir()\n    monkeypatch.chdir(str(repo_path))\n    arcconfig = repo_path / \".arcconfig\"\n    arcconfig.write_text(json.dumps({\"phabricator.uri\": phabricator_uri}))\n    git_out(\"init\")\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"--message\", \"initial commit\")\n    return repo_path\n\n\n@pytest.fixture\ndef safe_environ(monkeypatch):\n    # Make sure we preserve the system defaults.\n    monkeypatch.setattr(os, \"environ\", os.environ.copy())\n    # Disable logging to keep the testrunner output clean\n    monkeypatch.setattr(mozphab, \"init_logging\", mock.MagicMock())\n\n\n@pytest.fixture\ndef config():\n    \"\"\"Replace the original config with the fake one.\"\"\"\n    with tempfile.NamedTemporaryFile() as temp:\n        return config_module.Config(filename=temp.name)\n\n\n@pytest.fixture\ndef in_process(monkeypatch, safe_environ, request, config):\n    \"\"\"Set up an environment to run moz-phab within the current process.\"\"\"\n    monkeypatch.setattr(\"mozphab.config.config\", config)\n    monkeypatch.setattr(\"mozphab.git.config\", config)\n    monkeypatch.setattr(\"mozphab.mercurial.config\", config)\n    # Make sure other tests didn't leak and mess up the module-level\n    # global variables :/\n    monkeypatch.setattr(environment, \"DEBUG\", True)\n    monkeypatch.setattr(environment, \"HAS_ANSI\", False)\n    # Constructing the Mercurial() object modifies os.environ for all tests.\n    # Disable update checking.  It modifies the program on disk which we do /not/ want\n    # to do during a test run.\n    monkeypatch.setattr(updater, \"check_for_updates\", mock.MagicMock())\n\n    # Disable calls to sys.exit() at the end of the script.  Re-raise errors instead\n    # to make test debugging easier.\n    def reraise(*args, **kwargs):\n        raise\n\n    monkeypatch.setattr(sys, \"exit\", reraise)\n\n    # Disable uploading a new commit title and summary to Phabricator.  This operation\n    # is safe to skip and doing so makes it easier to test other conduit call sites.\n    monkeypatch.setattr(submit, \"update_revision_description\", mock.MagicMock())\n\n    def arc_ping(self, *args):\n        return True\n\n    def arc_out(self, *args, **kwargs):\n        return json.dumps(\n            {\n                \"error\": None,\n                \"errorMessage\": None,\n                \"response\": [{\"userName\": \"alice\", \"phid\": \"PHID-USER-1\"}],\n            }\n        )\n\n    # Modify user_data object to not touch the file\n    user.USER_INFO_FILE = mock.Mock()\n    user.USER_INFO_FILE.exists.return_value = False\n    user.user_data = user.UserData()\n    user.user_data.update_from_dict(\n        dict(\n            user_code=\"#\" * 32,\n            is_employee=True,\n            installation_id=\"#\" * 32,\n            last_check=time.time(),\n        )\n    )\n\n    # Allow to define the check_call_by_line function in the testing module\n    def check_call_by_line_static(*args, **kwargs):\n        return [\"Revision URI: http://example.test/D123\"]\n\n    check_call_by_line = getattr(\n        request.module, \"check_call_by_line\", check_call_by_line_static\n    )\n\n    # Allow to define the arccall_conduit function in the testing module\n    arc_call_conduit = getattr(\n        request.module, \"arc_call_conduit\", arcanist.call_conduit\n    )\n\n    # Allow to define the arc_ping function in the testing module\n    arc_ping_mock = getattr(request.module, \"arc_ping\", arc_ping)\n\n    monkeypatch.setattr(arcanist, \"arc_ping\", arc_ping_mock)\n    monkeypatch.setattr(arcanist, \"arc_out\", arc_out)\n    monkeypatch.setattr(submit, \"check_call_by_line\", check_call_by_line)\n    monkeypatch.setattr(arcanist, \"call_conduit\", arc_call_conduit)\n\n    def call_conduit_static(self, *args):\n        # Return alice as the only valid reviewer name from Phabricator.\n        # See https://phabricator.services.mozilla.com/api/user.search\n        return [{\"userName\": \"alice\"}]\n\n    call_conduit = getattr(request.module, \"call_conduit\", call_conduit_static)\n    monkeypatch.setattr(conduit.ConduitAPI, \"call\", call_conduit)\n\n    def read_json_field_local(self, *args):\n        if args[0][0] == \"phabricator.uri\":\n            return \"http://example.test\"\n        elif args[0][0] == \"repository.callsign\":\n            return \"TEST\"\n\n    read_json_field = getattr(request.module, \"read_json_field\", read_json_field_local)\n    monkeypatch.setattr(repository, \"read_json_field\", read_json_field)\n\n\n@pytest.fixture\n@mock.patch(\"mozphab.user.USER_INFO_FILE\")\ndef user_data(m_file):\n    m_file.exists.return_value = False\n    return user.UserData()\n\n\n@pytest.fixture(name=\"reset_glean\", scope=\"function\", autouse=True)\ndef fixture_reset_glean():\n    testing.reset_glean(application_id=\"mozphab\", application_version=\"0.1.86\")\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# coding=utf-8\n# This Source Code Form is subject to the terms of the Mozilla Public\n# License, v. 2.0. If a copy of the MPL was not distributed with this\n# file, You can obtain one at http://mozilla.org/MPL/2.0/.\nimport shutil\nimport mock\nimport pytest\n\nfrom callee import Contains\nfrom .conftest import git_out, search_diff, search_rev\n\nfrom mozphab import environment, exceptions, mozphab\n\n\narc_call_conduit = mock.Mock()\n\ncall_conduit = mock.Mock()\n\n\ndef by_line_mock(*args, **_kwargs):\n    # join args to catch unicode errors\n    \" \".join(*args)\n    return [\"Revision URI: http://example.test/D123\"]\n\n\ncheck_call_by_line = mock.Mock()\ncheck_call_by_line.side_effect = by_line_mock\n\ninitial_sha = None\n\n\ndef test_submit_create_arc(in_process, git_repo_path, init_sha):\n    call_conduit.side_effect = (\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        [{\"userName\": \"alice\", \"phid\": \"PHID-USER-1\"}],\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"--message\", \"A r?alice\")\n    testfile = git_repo_path / \"untracked\"\n    testfile.write_text(\"a\")\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True\n    )\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - A r?alice\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n\n\ndef test_submit_create(in_process, git_repo_path, init_sha):\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # user search\n        [dict(userName=\"alice\", phid=\"PHID-USER-1\")],\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    (git_repo_path / \"X\").write_text(u\"\u0105\\nb\\nc\\n\", encoding=\"utf-8\")\n    (git_repo_path / \"Y\").write_text(\"no line ending\")\n    git_out(\"add\", \".\")\n    (git_repo_path / \"msg\").write_text(u\"\u0104 r?alice\", encoding=\"utf-8\")\n    git_out(\"commit\", \"--file\", \"msg\")\n    (git_repo_path / \"untracked\").write_text(\"a\\n\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - \u0104 r?alice\n\nDifferential Revision: http://example.test/D123\n\n\"\"\"\n    assert log.strip() == expected.strip()\n    assert mock.call(\"conduit.ping\", {}) in call_conduit.call_args_list\n    assert (\n        mock.call(\"user.query\", dict(usernames=[\"alice\"]))\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"diffusion.repository.search\",\n            dict(limit=1, constraints=dict(callsigns=[\"TEST\"])),\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"differential.creatediff\",\n            {\n                \"sourceControlPath\": \"/\",\n                \"sourceControlSystem\": \"git\",\n                \"lintStatus\": \"none\",\n                \"sourcePath\": mock.ANY,\n                \"unitStatus\": \"none\",\n                \"sourceMachine\": \"http://example.test\",\n                \"sourceControlBaseRevision\": mock.ANY,\n                \"repositoryPHID\": \"PHID-REPO-1\",\n                \"branch\": \"HEAD\",\n                \"changes\": [\n                    {\n                        \"commitHash\": mock.ANY,\n                        \"awayPaths\": [],\n                        \"newProperties\": {\"unix:filemode\": \"100644\"},\n                        \"oldPath\": None,\n                        \"hunks\": [\n                            {\n                                \"oldOffset\": 0,\n                                \"oldLength\": 0,\n                                \"newOffset\": 1,\n                                \"newLength\": 3,\n                                \"addLines\": 3,\n                                \"delLines\": 0,\n                                \"corpus\": \"+\u0105\\n+b\\n+c\\n\",\n                                \"isMissingOldNewline\": False,\n                                \"isMissingNewNewline\": False,\n                            }\n                        ],\n                        \"oldProperties\": {},\n                        \"currentPath\": \"X\",\n                        \"fileType\": 1,\n                        \"type\": 1,\n                        \"metadata\": {},\n                    },\n                    {\n                        \"commitHash\": mock.ANY,\n                        \"awayPaths\": [],\n                        \"newProperties\": {\"unix:filemode\": \"100644\"},\n                        \"oldPath\": None,\n                        \"hunks\": [\n                            {\n                                \"oldOffset\": 0,\n                                \"oldLength\": 0,\n                                \"newOffset\": 1,\n                                \"newLength\": 1,\n                                \"addLines\": 1,\n                                \"delLines\": 0,\n                                \"corpus\": (\n                                    \"+no line ending\\n\\\\ No newline at end of file\\n\"\n                                ),\n                                \"isMissingOldNewline\": False,\n                                \"isMissingNewNewline\": True,\n                            }\n                        ],\n                        \"oldProperties\": {},\n                        \"currentPath\": \"Y\",\n                        \"fileType\": 1,\n                        \"type\": 1,\n                        \"metadata\": {},\n                    },\n                ],\n                \"creationMethod\": \"moz-phab-git\",\n            },\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"differential.setdiffproperty\",\n            {\"diff_id\": \"1\", \"name\": \"local:commits\", \"data\": ~Contains('\"rev\":')},\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        call_conduit.call_args_list.count(\n            mock.call(\"differential.setdiffproperty\", mock.ANY)\n        )\n        == 2\n    )\n\n\ndef test_submit_create_added_not_commited(in_process, git_repo_path, init_sha):\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # user search\n        [dict(userName=\"alice\", phid=\"PHID-USER-1\")],\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    (git_repo_path / \"X\").write_text(\"\u0105\\r\\nb\\nc\\n\", encoding=\"utf-8\")\n    (git_repo_path / \"Y\").write_text(\"no line ending\")\n    git_out(\"add\", \".\")\n    (git_repo_path / \"msg\").write_text(\"\u0104 r?alice\", encoding=\"utf-8\")\n    git_out(\"commit\", \"--file\", \"msg\")\n    (git_repo_path / \"untracked\").write_text(\"a\\n\")\n    git_out(\"add\", \"untracked\")\n\n    with pytest.raises(exceptions.Error) as excinfo:\n        mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    assert \"Uncommitted changes present.\" in str(excinfo.value)\n\n\ndef test_submit_create_no_bug(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # user search\n        [dict(userName=\"alice\", phid=\"PHID-USER-1\")],\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\\n\")\n    git_out(\"add\", \".\")\n    msgfile = git_repo_path / \"msg\"\n    msgfile.write_text(\"A r?alice\")\n    git_out(\"commit\", \"--file\", \"msg\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--no-bug\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nA r?alice\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n\n\ndef test_submit_create_binary_arc(in_process, git_repo_path, init_sha, data_file):\n    call_conduit.side_effect = (\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        [{\"userName\": \"alice\", \"phid\": \"PHID-USER-1\"}],\n    )\n    shutil.copyfile(str(data_file), str(git_repo_path / \"img.png\"))\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"--message\", \"IMG\")\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True\n    )\n    expected = \"\"\"\nBug 1 - IMG\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    assert log.strip() == expected.strip()\n\n\ndef test_submit_create_binary(in_process, git_repo_path, init_sha, data_file):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # file.allocate\n        dict(dict(filePHID=None, upload=True)),\n        # file.upload\n        dict(),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    shutil.copyfile(str(data_file), str(git_repo_path / \"img.png\"))\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"-m\", \"IMG\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - IMG\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n    assert (\n        mock.call(\n            \"file.allocate\",\n            {\"name\": \"img.png\", \"contentHash\": mock.ANY, \"contentLength\": 182},\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\"file.upload\", {\"data_base64\": mock.ANY, \"name\": \"img.png\"})\n        in call_conduit.call_args_list\n    )\n\n\ndef test_submit_create_binary_existing(in_process, git_repo_path, init_sha, data_file):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # file.allocate\n        dict(dict(filePHID=\"PHID-FILE-1\", upload=False)),\n        # no file.upload call\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    shutil.copyfile(str(data_file), str(git_repo_path / \"img.png\"))\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"-m\", \"IMG\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - IMG\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n    assert (\n        mock.call(\n            \"file.allocate\",\n            {\"name\": \"img.png\", \"contentHash\": mock.ANY, \"contentLength\": 182},\n        )\n        in call_conduit.call_args_list\n    )\n    assert mock.call(\"file.upload\", mock.ANY) not in call_conduit.call_args_list\n\n\ndef test_submit_create_binary_chunked(in_process, git_repo_path, init_sha, data_file):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # file.allocate\n        dict(dict(filePHID=\"PHID-FILE-1\", upload=True)),\n        # file.querychunks\n        [\n            dict(byteStart=\"0\", byteEnd=\"4194304\", complete=False),\n            dict(byteStart=\"4194304\", byteEnd=\"8388608\", complete=False),\n            dict(byteStart=\"8388608\", byteEnd=\"8425160\", complete=False),\n        ],\n        # file.uploadchunk\n        dict(),\n        # file.uploadchunk\n        dict(),\n        # file.uploadchunk\n        dict(),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    shutil.copyfile(str(data_file), str(git_repo_path / \"img.png\"))\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"-m\", \"IMG\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - IMG\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n    assert (\n        mock.call(\n            \"file.allocate\",\n            {\"name\": \"img.png\", \"contentHash\": mock.ANY, \"contentLength\": 182},\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\"file.querychunks\", {\"filePHID\": \"PHID-FILE-1\"})\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"file.uploadchunk\",\n            {\n                \"filePHID\": \"PHID-FILE-1\",\n                \"byteStart\": 0,\n                \"data\": mock.ANY,\n                \"dataEncoding\": \"base64\",\n            },\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"file.uploadchunk\",\n            {\n                \"filePHID\": \"PHID-FILE-1\",\n                \"byteStart\": 4194304,\n                \"data\": mock.ANY,\n                \"dataEncoding\": \"base64\",\n            },\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"file.uploadchunk\",\n            {\n                \"filePHID\": \"PHID-FILE-1\",\n                \"byteStart\": 8388608,\n                \"data\": mock.ANY,\n                \"dataEncoding\": \"base64\",\n            },\n        )\n        in call_conduit.call_args_list\n    )\n\n\ndef test_submit_update(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # diffusion.revision.search\n        dict(data=[search_rev(rev=123)]),\n        # diffusion.diff.search\n        dict(data=[search_diff()]),\n        # whoami\n        dict(phid=\"PHID-USER-1\"),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"\u0105\", encoding=\"utf-8\")\n    git_out(\"add\", \".\")\n    msgfile = git_repo_path / \"msg\"\n    msgfile.write_text(\n        \"\"\"\\\nBug 1 - \u0104\n\nDifferential Revision: http://example.test/D123\n\"\"\",\n        encoding=\"utf-8\",\n    )\n    git_out(\"commit\", \"--file\", \"msg\")\n\n    mozphab.main(\n        [\"submit\", \"--yes\"]\n        + [\"--bug\", \"1\"]\n        + [\"--message\", \"update message \u0107wik\u0142a\"]\n        + [init_sha],\n        is_development=True,\n    )\n\n    assert call_conduit.call_count == 9\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\\\nBug 1 - \u0104\n\nDifferential Revision: http://example.test/D123\n\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_update_no_change(in_process, git_repo_path, init_sha, git_sha):\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n    msgfile = git_repo_path / \"msg\"\n    msgfile.write_text(\n        \"\"\"\\\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    )\n    git_out(\"commit\", \"--file\", \"msg\")\n    sha = git_sha()\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # diffusion.revision.search\n        dict(data=[search_rev(rev=123)]),\n        # diffusion.diff.search\n        dict(data=[search_diff(node=sha)]),\n        # whoami\n        dict(phid=\"PHID-USER-1\"),\n    )\n\n    mozphab.main(\n        [\"submit\", \"--yes\"] + [init_sha],\n        is_development=True,\n    )\n    assert call_conduit.call_count == 5\n\n\ndef test_submit_remove_cr(in_process, git_repo_path, init_sha):\n    if environment.IS_WINDOWS:\n        pytest.skip(\"Removing CR will not work on Windows.\")\n\n    call_conduit.side_effect = (\n        # CREATE\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # user.search\n        [dict(userName=\"alice\", phid=\"PHID-USER-1\")],\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n        # UPDATE\n        # no need to ping (checked)\n        # no need to check reviewer\n        # no need to search for repository repository data is saved in .hg\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-2\", diffid=\"2\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"124\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    test_a = git_repo_path / \"X\"\n    test_a.write_text(\"a\\r\\nb\\n\")\n    git_out(\"add\", \"X\")\n    git_out(\"commit\", \"-am\", \"A r?alice\")\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n    call_conduit.reset_mock()\n    # removing CR, leaving LF\n    test_a.write_text(\"a\\nb\\n\")\n    git_out(\"commit\", \"-am\", \"B r?alice\")\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", \"HEAD~\"], is_development=True)\n\n    assert (\n        mock.call(\n            \"differential.creatediff\",\n            {\n                \"changes\": [\n                    {\n                        \"metadata\": {},\n                        \"oldPath\": \"X\",\n                        \"currentPath\": \"X\",\n                        \"awayPaths\": [],\n                        \"oldProperties\": {},\n                        \"newProperties\": {},\n                        \"commitHash\": mock.ANY,\n                        \"type\": 2,\n                        \"fileType\": 1,\n                        \"hunks\": [\n                            {\n                                \"oldOffset\": 1,\n                                \"oldLength\": 2,\n                                \"newOffset\": 1,\n                                \"newLength\": 2,\n                                \"addLines\": 1,\n                                \"delLines\": 1,\n                                \"isMissingOldNewline\": False,\n                                \"isMissingNewNewline\": False,\n                                \"corpus\": \"-a\\r\\n+a\\n b\\n\",\n                            }\n                        ],\n                    }\n                ],\n                \"sourceMachine\": \"http://example.test\",\n                \"sourceControlSystem\": \"git\",\n                \"sourceControlPath\": \"/\",\n                \"sourceControlBaseRevision\": mock.ANY,\n                \"creationMethod\": \"moz-phab-git\",\n                \"lintStatus\": \"none\",\n                \"unitStatus\": \"none\",\n                \"repositoryPHID\": \"PHID-REPO-1\",\n                \"sourcePath\": mock.ANY,\n                \"branch\": \"HEAD\",\n            },\n        )\n        in call_conduit.call_args_list\n    )\n    assert (\n        mock.call(\n            \"differential.setdiffproperty\",\n            {\n                \"diff_id\": \"2\",\n                \"name\": \"local:commits\",\n                \"data\": Contains('\"summary\": \"Bug 1 - B r?alice\"')\n                & Contains(\n                    '\"message\": \"'\n                    \"Bug 1 - B r?alice\\\\n\\\\n\"\n                    \"Summary:\\\\n\\\\n\\\\n\\\\n\\\\n\"\n                    \"Test Plan:\\\\n\\\\n\"\n                    \"Reviewers: alice\\\\n\\\\n\"\n                    \"Subscribers:\\\\n\\\\n\"\n                    'Bug #: 1\"'\n                ),\n            },\n        )\n        in call_conduit.call_args_list\n    )\n\n\ndef test_submit_single_last(in_process, git_repo_path, init_sha):\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    (git_repo_path / \"X\").write_text(\"a\\n\")\n    git_out(\"add\", \"X\")\n    git_out(\"commit\", \"-am\", \"A\")\n    (git_repo_path / \"X\").write_text(\"b\\n\")\n    git_out(\"commit\", \"-am\", \"B\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", \"--single\"], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-2\")\n    expected = \"\"\"\\\nBug 1 - B\n\nDifferential Revision: http://example.test/D123\nA\n\n\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_single_first(in_process, git_repo_path, init_sha, git_sha):\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    (git_repo_path / \"X\").write_text(\"a\\n\")\n    git_out(\"add\", \"X\")\n    git_out(\"commit\", \"-am\", \"A\")\n    sha = git_sha()\n    (git_repo_path / \"X\").write_text(\"b\\n\")\n    git_out(\"commit\", \"-am\", \"B\")\n\n    mozphab.main(\n        [\"submit\", \"--yes\", \"--bug\", \"1\", \"--single\", sha], is_development=True\n    )\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-2\")\n    expected = \"\"\"\\\nB\n\n\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_update_no_message(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        dict(data=[search_rev(rev=123)]),\n        dict(data=[search_diff()]),\n        dict(phid=\"PHID-USER-1\"),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    (git_repo_path / \"X\").write_text(u\"\u0105\", encoding=\"utf-8\")\n    git_out(\"add\", \".\")\n    (git_repo_path / \"msg\").write_text(\n        u\"\"\"\\\nBug 1 - \u0104\n\nDifferential Revision: http://example.test/D123\n\"\"\",\n        encoding=\"utf-8\",\n    )\n    git_out(\"commit\", \"--file\", \"msg\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\\\nBug 1 - \u0104\n\nDifferential Revision: http://example.test/D123\n\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_different_author_arc(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        [{\"userName\": \"alice\", \"phid\": \"PHID-USER-1\"}],\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n    git_out(\n        \"commit\",\n        \"--date\",\n        \"Tue, 22 Jan 2019 13:42:48 +0000\",\n        \"--author\",\n        \"foo <foo@bar.com>\",\n        \"--message\",\n        \"A r?alice\",\n    )\n    testfile.write_text(\"b\")\n    git_out(\n        \"commit\",\n        \"--date\",\n        \"Tue, 22 Jan 2019 13:43:48 +0000\",\n        \"--author\",\n        \"bar <bar@foo.com>\",\n        \"--all\",\n        \"--message\",\n        \"B r?alice\",\n    )\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True\n    )\n\n    log = git_out(\"log\", \"--format=%aD+++%an+++%ae\", \"-2\")\n    expected = \"\"\"\\\nTue, 22 Jan 2019 13:43:48 +0000+++bar+++bar@foo.com\nTue, 22 Jan 2019 13:42:48 +0000+++foo+++foo@bar.com\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_utf8_author_arc(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        [{\"userName\": \"alice\", \"phid\": \"PHID-USER-1\"}],\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n    git_out(\n        \"commit\",\n        \"--date\",\n        \"Tue, 22 Jan 2019 13:42:48 +0000\",\n        \"--author\",\n        \"\u0107wik\u0142a <\u0107wik\u0142a@bar.com>\",\n        \"--message\",\n        \"A r?alice\",\n    )\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True\n    )\n\n    log = git_out(\"log\", \"--format=%aD+++%an+++%ae\", \"-1\")\n    expected = \"Tue, 22 Jan 2019 13:42:48 +0000+++\u0107wik\u0142a+++\u0107wik\u0142a@bar.com\\n\"\n    assert log == expected\n\n\ndef test_submit_update_arc(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        {},  # ping\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        dict(data=[search_rev(rev=123)]),\n        dict(data=[search_diff()]),\n        dict(phid=\"PHID-USER-1\"),\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n\n    # Write out our commit message as if the program had already run and appended\n    # a Differential Revision keyword to the commit body for tracking.\n    git_out(\n        \"commit\",\n        \"--message\",\n        \"\"\"\\\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\"\"\",\n    )\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\"]\n        + [\"--bug\", \"1\"]\n        + [\"--message\", \"update message \u0107wik\u0142a\"]\n        + [init_sha],\n        is_development=True,\n    )\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\\\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\n\"\"\"\n    assert log == expected\n\n\ndef test_submit_update_bug_id_arc(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        dict(data=[search_rev(rev=123)]),\n        dict(data=[search_diff()]),\n        # get reviewers for updated revision\n        dict(phid=\"PHID-USER-1\"),\n    )\n    arc_call_conduit.reset_mock()\n    arc_call_conduit.side_effect = (\n        {},\n        {\"data\": {}},\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(\"a\")\n    git_out(\"add\", \".\")\n\n    # Write out our commit message as if the program had already run and appended\n    # a Differential Revision keyword to the commit body for tracking.\n    git_out(\n        \"commit\",\n        \"--message\",\n        \"\"\"\\\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\"\"\",\n    )\n\n    mozphab.main(\n        [\"submit\", \"--arc\", \"--yes\", \"--bug\", \"2\", init_sha], is_development=True\n    )\n\n    arc_call_conduit.assert_called_with(\n        \"differential.revision.edit\",\n        {\n            \"objectIdentifier\": \"D123\",\n            \"transactions\": [{\"type\": \"bugzilla.bug-id\", \"value\": \"2\"}],\n        },\n        mock.ANY,\n    )\n\n\ndef test_submit_update_revision_not_found(in_process, git_repo_path, init_sha):\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # response for searching D123 and D124\n        dict(data=[search_rev(rev=123)]),\n        dict(data=[search_diff()]),\n        # moz-phab asks again for D124\n        dict(data=[]),\n        # whoami\n        dict(phid=\"PHID-USER-1\"),\n        # moz-phab asks again for D124\n        dict(data=[]),\n        # moz-phab asks again for D124\n        dict(data=[]),\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.write_text(u\"\u0105\", encoding=\"utf-8\")\n    git_out(\"add\", \".\")\n    msgfile = git_repo_path / \"msg\"\n    msgfile.write_text(\n        u\"\"\"\\\nBug 1 - \u0104\n\nDifferential Revision: http://example.test/D123\n\"\"\",\n        encoding=\"utf-8\",\n    )\n    git_out(\"commit\", \"--file\", \"msg\")\n    testfile.write_text(u\"missing repo\")\n    msgfile.write_text(\n        u\"\"\"\\\nBug 1 - missing revision\n\nDifferential Revision: http://example.test/D124\n\"\"\"\n    )\n    git_out(\"commit\", \"--all\", \"--file\", \"./msg\")\n\n    with pytest.raises(exceptions.Error) as excinfo:\n        mozphab.main(\n            [\"submit\", \"--yes\"]\n            + [\"--bug\", \"1\"]\n            + [\"--message\", \"update message \u0107wik\u0142a\"]\n            + [init_sha],\n            is_development=True,\n        )\n    assert \"query result for revision D124\" in str(excinfo.value)\n\n\ndef test_empty_file(in_process, git_repo_path, init_sha):\n    # Add an empty file\n    call_conduit.side_effect = (\n        # ping\n        dict(),\n        # diffusion.repository.search\n        dict(data=[dict(phid=\"PHID-REPO-1\", fields=dict(vcs=\"git\"))]),\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-1\", diffid=\"1\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"123\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    testfile = git_repo_path / \"X\"\n    testfile.touch()\n    git_out(\"add\", \".\")\n    git_out(\"commit\", \"--message\", \"A\")\n\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", init_sha], is_development=True)\n\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - A\n\nDifferential Revision: http://example.test/D123\n\"\"\"\n    assert log.strip() == expected.strip()\n\n    # Rempve an empty file\n    call_conduit.reset_mock()\n    call_conduit.side_effect = (\n        # differential.creatediff\n        dict(dict(phid=\"PHID-DIFF-2\", diffid=\"2\")),\n        # differential.setdiffproperty\n        dict(),\n        # differential.revision.edit\n        dict(object=dict(id=\"124\")),\n        # differential.setdiffproperty\n        dict(),\n    )\n    testfile.unlink()\n    git_out(\"commit\", \"-a\", \"--message\", \"B\")\n    mozphab.main([\"submit\", \"--yes\", \"--bug\", \"1\", \"HEAD~\"], is_development=True)\n    log = git_out(\"log\", \"--format=%s%n%n%b\", \"-1\")\n    expected = \"\"\"\nBug 1 - B\n\nDifferential Revision: http://example.test/D124\n\"\"\"\n    assert log.strip() == expected.strip()\n"
  },
  {
    "prompt": "\n\n### cibuildwheel/docker_container.py ###\n\nimport io\nimport json\nimport os\nimport shlex\nimport subprocess\nimport sys\nimport uuid\nfrom pathlib import Path, PurePath\nfrom types import TracebackType\nfrom typing import IO, Dict, List, Optional, Sequence, Type, cast\n\nfrom .typing import PathOrStr, PopenBytes\n\n\nclass DockerContainer:\n    \"\"\"\n    An object that represents a running Docker container.\n\n    Intended for use as a context manager e.g.\n    `with DockerContainer('ubuntu') as docker:`\n\n    A bash shell is running in the remote container. When `call()` is invoked,\n    the command is relayed to the remote shell, and the results are streamed\n    back to cibuildwheel.\n    \"\"\"\n\n    UTILITY_PYTHON = \"/opt/python/cp38-cp38/bin/python\"\n\n    process: PopenBytes\n    bash_stdin: IO[bytes]\n    bash_stdout: IO[bytes]\n\n    def __init__(\n        self, docker_image: str, simulate_32_bit: bool = False, cwd: Optional[PathOrStr] = None\n    ):\n        if not docker_image:\n            raise ValueError(\"Must have a non-empty docker image to run.\")\n\n        self.docker_image = docker_image\n        self.simulate_32_bit = simulate_32_bit\n        self.cwd = cwd\n        self.name: Optional[str] = None\n\n    def __enter__(self) -> \"DockerContainer\":\n        self.name = f\"cibuildwheel-{uuid.uuid4()}\"\n        cwd_args = [\"-w\", str(self.cwd)] if self.cwd else []\n        shell_args = [\"linux32\", \"/bin/bash\"] if self.simulate_32_bit else [\"/bin/bash\"]\n        subprocess.run(\n            [\n                \"docker\",\n                \"create\",\n                \"--env=CIBUILDWHEEL\",\n                f\"--name={self.name}\",\n                \"--interactive\",\n                \"--volume=/:/host\",  # ignored on CircleCI\n                *cwd_args,\n                self.docker_image,\n                *shell_args,\n            ],\n            check=True,\n        )\n        self.process = subprocess.Popen(\n            [\n                \"docker\",\n                \"start\",\n                \"--attach\",\n                \"--interactive\",\n                self.name,\n            ],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n        )\n\n        assert self.process.stdin and self.process.stdout\n        self.bash_stdin = self.process.stdin\n        self.bash_stdout = self.process.stdout\n\n        # run a noop command to block until the container is responding\n        self.call([\"/bin/true\"])\n\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n\n        self.bash_stdin.close()\n        self.process.terminate()\n        self.process.wait()\n\n        assert isinstance(self.name, str)\n\n        subprocess.run([\"docker\", \"rm\", \"--force\", \"-v\", self.name], stdout=subprocess.DEVNULL)\n        self.name = None\n\n    def copy_into(self, from_path: Path, to_path: PurePath) -> None:\n        # `docker cp` causes 'no space left on device' error when\n        # a container is running and the host filesystem is\n        # mounted. https://github.com/moby/moby/issues/38995\n        # Use `docker exec` instead.\n\n        if from_path.is_dir():\n            self.call([\"mkdir\", \"-p\", to_path])\n            subprocess.run(\n                f\"tar cf - . | docker exec -i {self.name} tar -xC {shell_quote(to_path)} -f -\",\n                shell=True,\n                check=True,\n                cwd=from_path,\n            )\n        else:\n            subprocess.run(\n                f'cat {shell_quote(from_path)} | docker exec -i {self.name} sh -c \"cat > {shell_quote(to_path)}\"',\n                shell=True,\n                check=True,\n            )\n\n    def copy_out(self, from_path: PurePath, to_path: Path) -> None:\n        # note: we assume from_path is a dir\n        to_path.mkdir(parents=True, exist_ok=True)\n\n        subprocess.run(\n            f\"docker exec -i {self.name} tar -cC {shell_quote(from_path)} -f - . | tar -xf -\",\n            shell=True,\n            check=True,\n            cwd=to_path,\n        )\n\n    def glob(self, path: PurePath, pattern: str) -> List[PurePath]:\n        glob_pattern = os.path.join(str(path), pattern)\n\n        path_strs = json.loads(\n            self.call(\n                [\n                    self.UTILITY_PYTHON,\n                    \"-c\",\n                    f\"import sys, json, glob; json.dump(glob.glob({glob_pattern!r}), sys.stdout)\",\n                ],\n                capture_output=True,\n            )\n        )\n\n        return [PurePath(p) for p in path_strs]\n\n    def call(\n        self,\n        args: Sequence[PathOrStr],\n        env: Optional[Dict[str, str]] = None,\n        capture_output: bool = False,\n        cwd: Optional[PathOrStr] = None,\n    ) -> str:\n\n        chdir = f\"cd {cwd}\" if cwd else \"\"\n        env_assignments = (\n            \" \".join(f\"{shlex.quote(k)}={shlex.quote(v)}\" for k, v in env.items())\n            if env is not None\n            else \"\"\n        )\n        command = \" \".join(shlex.quote(str(a)) for a in args)\n        end_of_message = str(uuid.uuid4())\n\n        # log the command we're executing\n        print(f\"    + {command}\")\n\n        # Write a command to the remote shell. First we change the\n        # cwd, if that's required. Then, we use the `env` utility to run\n        # `command` inside the specified environment. We use `env` because it\n        # can cope with spaces and strange characters in the name or value.\n        # Finally, the remote shell is told to write a footer - this will show\n        # up in the output so we know when to stop reading, and will include\n        # the returncode of `command`.\n        self.bash_stdin.write(\n            bytes(\n                f\"\"\"(\n            {chdir}\n            env {env_assignments} {command}\n            printf \"%04d%s\\n\" $? {end_of_message}\n        )\n        \"\"\",\n                encoding=\"utf8\",\n                errors=\"surrogateescape\",\n            )\n        )\n        self.bash_stdin.flush()\n\n        if capture_output:\n            output_io: IO[bytes] = io.BytesIO()\n        else:\n            output_io = sys.stdout.buffer\n\n        while True:\n            line = self.bash_stdout.readline()\n\n            if line.endswith(bytes(end_of_message, encoding=\"utf8\") + b\"\\n\"):\n                # fmt: off\n                footer_offset = (\n                    len(line)\n                    - 1  # newline character\n                    - len(end_of_message)  # delimiter\n                    - 4  # 4 returncode decimals\n                )\n                # fmt: on\n                returncode_str = line[footer_offset : footer_offset + 4]\n                returncode = int(returncode_str)\n                # add the last line to output, without the footer\n                output_io.write(line[0:footer_offset])\n                break\n            else:\n                output_io.write(line)\n\n        if isinstance(output_io, io.BytesIO):\n            output = str(output_io.getvalue(), encoding=\"utf8\", errors=\"surrogateescape\")\n        else:\n            output = \"\"\n\n        if returncode != 0:\n            raise subprocess.CalledProcessError(returncode, args, output)\n\n        return output\n\n    def get_environment(self) -> Dict[str, str]:\n        env = json.loads(\n            self.call(\n                [\n                    self.UTILITY_PYTHON,\n                    \"-c\",\n                    \"import sys, json, os; json.dump(os.environ.copy(), sys.stdout)\",\n                ],\n                capture_output=True,\n            )\n        )\n        return cast(Dict[str, str], env)\n\n    def environment_executor(self, command: List[str], environment: Dict[str, str]) -> str:\n        # used as an EnvironmentExecutor to evaluate commands and capture output\n        return self.call(command, env=environment, capture_output=True)\n\n\ndef shell_quote(path: PurePath) -> str:\n    return shlex.quote(str(path))\n\n\n### cibuildwheel/environment.py ###\n\nfrom typing import Dict, List, Mapping, Optional\n\nimport bashlex\n\nfrom . import bashlex_eval\n\n\nclass EnvironmentParseError(Exception):\n    pass\n\n\ndef split_env_items(env_string: str) -> List[str]:\n    \"\"\"Splits space-separated variable assignments into a list of individual assignments.\n\n    >>> split_env_items('VAR=abc')\n    ['VAR=abc']\n    >>> split_env_items('VAR=\"a string\" THING=3')\n    ['VAR=\"a string\"', 'THING=3']\n    >>> split_env_items('VAR=\"a string\" THING=\\\\'single \"quotes\"\\\\'')\n    ['VAR=\"a string\"', 'THING=\\\\'single \"quotes\"\\\\'']\n    >>> split_env_items('VAR=\"dont \\\\\\\\\"forget\\\\\\\\\" about backslashes\"')\n    ['VAR=\"dont \\\\\\\\\"forget\\\\\\\\\" about backslashes\"']\n    >>> split_env_items('PATH=\"$PATH;/opt/cibw_test_path\"')\n    ['PATH=\"$PATH;/opt/cibw_test_path\"']\n    >>> split_env_items('PATH2=\"something with spaces\"')\n    ['PATH2=\"something with spaces\"']\n    \"\"\"\n    if not env_string:\n        return []\n\n    command_node = bashlex.parsesingle(env_string)\n    result = []\n\n    for word_node in command_node.parts:\n        part_string = env_string[word_node.pos[0] : word_node.pos[1]]\n        result.append(part_string)\n\n    return result\n\n\nclass EnvironmentAssignment:\n    def __init__(self, assignment: str):\n        name, equals, value = assignment.partition(\"=\")\n        if not equals:\n            raise EnvironmentParseError(assignment)\n        self.name = name\n        self.value = value\n\n    def evaluated_value(\n        self,\n        environment: Dict[str, str],\n        executor: Optional[bashlex_eval.EnvironmentExecutor] = None,\n    ) -> str:\n        \"\"\"Returns the value of this assignment, as evaluated in the environment\"\"\"\n        return bashlex_eval.evaluate(self.value, environment=environment, executor=executor)\n\n    def as_shell_assignment(self) -> str:\n        return f\"export {self.name}={self.value}\"\n\n    def __repr__(self) -> str:\n        return f\"{self.name}={self.value}\"\n\n\nclass ParsedEnvironment:\n    def __init__(self, assignments: List[EnvironmentAssignment]):\n        self.assignments = assignments\n\n    def as_dictionary(\n        self,\n        prev_environment: Mapping[str, str],\n        executor: Optional[bashlex_eval.EnvironmentExecutor] = None,\n    ) -> Dict[str, str]:\n        environment = dict(**prev_environment)\n\n        for assignment in self.assignments:\n            value = assignment.evaluated_value(environment=environment, executor=executor)\n            environment[assignment.name] = value\n\n        return environment\n\n    def as_shell_commands(self) -> List[str]:\n        return [a.as_shell_assignment() for a in self.assignments]\n\n    def __repr__(self) -> str:\n        return f\"ParsedEnvironment({[repr(a) for a in self.assignments]!r})\"\n\n\ndef parse_environment(env_string: str) -> ParsedEnvironment:\n    env_items = split_env_items(env_string)\n    assignments = [EnvironmentAssignment(item) for item in env_items]\n    return ParsedEnvironment(assignments=assignments)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import platform\nimport random\nimport shutil\nimport subprocess\nimport textwrap\nfrom pathlib import Path, PurePath\n\nimport pytest\n\nfrom cibuildwheel.docker_container import DockerContainer\nfrom cibuildwheel.environment import EnvironmentAssignment\n\n# for these tests we use manylinux2014 images, because they're available on\n# multi architectures and include python3.8\npm = platform.machine()\nif pm == \"x86_64\":\n    DEFAULT_IMAGE = \"quay.io/pypa/manylinux2014_x86_64:2020-05-17-2f8ac3b\"\nelif pm == \"aarch64\":\n    DEFAULT_IMAGE = \"quay.io/pypa/manylinux2014_aarch64:2020-05-17-2f8ac3b\"\nelif pm == \"ppc64le\":\n    DEFAULT_IMAGE = \"quay.io/pypa/manylinux2014_ppc64le:2020-05-17-2f8ac3b\"\nelif pm == \"s390x\":\n    DEFAULT_IMAGE = \"quay.io/pypa/manylinux2014_s390x:2020-05-17-2f8ac3b\"\n\n\n@pytest.mark.docker\ndef test_simple():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert container.call([\"echo\", \"hello\"], capture_output=True) == \"hello\\n\"\n\n\n@pytest.mark.docker\ndef test_no_lf():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert container.call([\"printf\", \"hello\"], capture_output=True) == \"hello\"\n\n\n@pytest.mark.docker\ndef test_environment():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assert (\n            container.call(\n                [\"sh\", \"-c\", \"echo $TEST_VAR\"], env={\"TEST_VAR\": \"1\"}, capture_output=True\n            )\n            == \"1\\n\"\n        )\n\n\n@pytest.mark.docker\ndef test_cwd():\n    with DockerContainer(DEFAULT_IMAGE, cwd=\"/cibuildwheel/working_directory\") as container:\n        assert container.call([\"pwd\"], capture_output=True) == \"/cibuildwheel/working_directory\\n\"\n        assert container.call([\"pwd\"], capture_output=True, cwd=\"/opt\") == \"/opt\\n\"\n\n\n@pytest.mark.docker\ndef test_container_removed():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        docker_containers_listing = subprocess.run(\n            \"docker container ls\",\n            shell=True,\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        ).stdout\n        assert container.name in docker_containers_listing\n        old_container_name = container.name\n\n    docker_containers_listing = subprocess.run(\n        \"docker container ls\",\n        shell=True,\n        check=True,\n        stdout=subprocess.PIPE,\n        universal_newlines=True,\n    ).stdout\n    assert old_container_name not in docker_containers_listing\n\n\n@pytest.mark.docker\ndef test_large_environment():\n    # max environment variable size is 128kB\n    long_env_var_length = 127 * 1024\n    large_environment = {\n        \"a\": \"0\" * long_env_var_length,\n        \"b\": \"0\" * long_env_var_length,\n        \"c\": \"0\" * long_env_var_length,\n        \"d\": \"0\" * long_env_var_length,\n    }\n\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # check the length of d\n        assert (\n            container.call([\"sh\", \"-c\", \"echo ${#d}\"], env=large_environment, capture_output=True)\n            == f\"{long_env_var_length}\\n\"\n        )\n\n\n@pytest.mark.docker\ndef test_binary_output():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # note: the below embedded snippets are in python2\n\n        # check that we can pass though arbitrary binary data without erroring\n        container.call(\n            [\n                \"/usr/bin/python2\",\n                \"-c\",\n                textwrap.dedent(\n                    \"\"\"\n                    import sys\n                    sys.stdout.write(''.join(chr(n) for n in range(0, 256)))\n                    \"\"\"\n                ),\n            ]\n        )\n\n        # check that we can capture arbitrary binary data\n        output = container.call(\n            [\n                \"/usr/bin/python2\",\n                \"-c\",\n                textwrap.dedent(\n                    \"\"\"\n                    import sys\n                    sys.stdout.write(''.join(chr(n % 256) for n in range(0, 512)))\n                    \"\"\"\n                ),\n            ],\n            capture_output=True,\n        )\n\n        data = bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n        for i in range(512):\n            assert data[i] == i % 256\n\n        # check that environment variables can carry binary data, except null characters\n        # (https://www.gnu.org/software/libc/manual/html_node/Environment-Variables.html)\n        binary_data = bytes(n for n in range(1, 256))\n        binary_data_string = str(binary_data, encoding=\"utf8\", errors=\"surrogateescape\")\n        output = container.call(\n            [\"python2\", \"-c\", 'import os, sys; sys.stdout.write(os.environ[\"TEST_VAR\"])'],\n            env={\"TEST_VAR\": binary_data_string},\n            capture_output=True,\n        )\n        assert output == binary_data_string\n\n\n@pytest.mark.docker\ndef test_file_operations(tmp_path: Path):\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        # test copying a file in\n        test_binary_data = bytes(random.randrange(256) for _ in range(1000))\n        original_test_file = tmp_path / \"test.dat\"\n        original_test_file.write_bytes(test_binary_data)\n\n        dst_file = PurePath(\"/tmp/test.dat\")\n\n        container.copy_into(original_test_file, dst_file)\n\n        output = container.call([\"cat\", dst_file], capture_output=True)\n        assert test_binary_data == bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n\n@pytest.mark.docker\ndef test_dir_operations(tmp_path: Path):\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        test_binary_data = bytes(random.randrange(256) for _ in range(1000))\n        original_test_file = tmp_path / \"test.dat\"\n        original_test_file.write_bytes(test_binary_data)\n\n        # test copying a dir in\n        test_dir = tmp_path / \"test_dir\"\n        test_dir.mkdir()\n        test_file = test_dir / \"test.dat\"\n        shutil.copyfile(original_test_file, test_file)\n\n        dst_dir = PurePath(\"/tmp/test_dir\")\n        dst_file = dst_dir / \"test.dat\"\n        container.copy_into(test_dir, dst_dir)\n\n        output = container.call([\"cat\", dst_file], capture_output=True)\n        assert test_binary_data == bytes(output, encoding=\"utf8\", errors=\"surrogateescape\")\n\n        # test glob\n        assert container.glob(dst_dir, \"*.dat\") == [dst_file]\n\n        # test copy dir out\n        new_test_dir = tmp_path / \"test_dir_new\"\n        container.copy_out(dst_dir, new_test_dir)\n\n        assert test_binary_data == (new_test_dir / \"test.dat\").read_bytes()\n\n\n@pytest.mark.docker\ndef test_environment_executor():\n    with DockerContainer(DEFAULT_IMAGE) as container:\n        assignment = EnvironmentAssignment(\"TEST=$(echo 42)\")\n        assert assignment.evaluated_value({}, container.environment_executor) == \"42\"\n"
  },
  {
    "prompt": "\n\n### mirgecom/euler.py ###\n\nr\"\"\":mod:`mirgecom.euler` helps solve Euler's equations of gas dynamics.\n\nEuler's equations of gas dynamics:\n\n.. math::\n\n    \\partial_t \\mathbf{Q} = -\\nabla\\cdot{\\mathbf{F}} +\n    (\\mathbf{F}\\cdot\\hat{n})_{\\partial\\Omega} + \\mathbf{S}\n\nwhere:\n\n-   state $\\mathbf{Q} = [\\rho, \\rho{E}, \\rho\\vec{V} ]$\n-   flux $\\mathbf{F} = [\\rho\\vec{V},(\\rho{E} + p)\\vec{V},\n    (\\rho(\\vec{V}\\otimes\\vec{V}) + p*\\mathbf{I})]$,\n-   domain boundary $\\partial\\Omega$,\n-   sources $\\mathbf{S} = [{(\\partial_t{\\rho})}_s,\n    {(\\partial_t{\\rho{E}})}_s, {(\\partial_t{\\rho\\vec{V}})}_s]$\n\n\nState Vector Handling\n^^^^^^^^^^^^^^^^^^^^^\n\n.. autoclass:: ConservedVars\n.. autofunction:: split_conserved\n.. autofunction:: join_conserved\n\nRHS Evaluation\n^^^^^^^^^^^^^^\n\n.. autofunction:: inviscid_flux\n.. autofunction:: inviscid_operator\n\nTime Step Computation\n^^^^^^^^^^^^^^^^^^^^^\n\n.. autofunction:: get_inviscid_timestep\n.. autofunction:: get_inviscid_cfl\n\"\"\"\n\n__copyright__ = \"\"\"\nCopyright (C) 2020 University of Illinois Board of Trustees\n\"\"\"\n\n__license__ = \"\"\"\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\n\nfrom dataclasses import dataclass\n\nimport numpy as np\nfrom meshmode.dof_array import thaw\nfrom meshmode.mesh import BTAG_ALL, BTAG_NONE  # noqa\nfrom grudge.eager import (\n    interior_trace_pair,\n    cross_rank_trace_pairs\n)\n\n\n@dataclass(frozen=True)\nclass ConservedVars:  # FIXME: Name?\n    r\"\"\"Resolve the canonical conserved quantities.\n\n    Get the canonical conserved quantities (mass, energy, momentum)\n    per unit volume = $(\\rho,\\rho{E},\\rho\\vec{V})$ from an agglomerated\n    object array.\n\n    .. attribute:: dim\n\n    .. attribute:: mass\n\n        Mass per unit volume\n\n    .. attribute:: energy\n\n        Energy per unit volume\n\n    .. attribute:: momentum\n\n        Momentum vector per unit volume\n\n    .. automethod:: join\n    .. automethod:: replace\n    \"\"\"\n\n    mass: np.ndarray\n    energy: np.ndarray\n    momentum: np.ndarray\n\n    @property\n    def dim(self):\n        \"\"\"Return the number of physical dimensions.\"\"\"\n        return len(self.momentum)\n\n    def join(self):\n        \"\"\"Call :func:`join_conserved` on *self*.\"\"\"\n        return join_conserved(\n            dim=self.dim,\n            mass=self.mass,\n            energy=self.energy,\n            momentum=self.momentum)\n\n    def replace(self, **kwargs):\n        \"\"\"Return a copy of *self* with the attributes in *kwargs* replaced.\"\"\"\n        from dataclasses import replace\n        return replace(self, **kwargs)\n\n\ndef _aux_shape(ary, leading_shape):\n    \"\"\":arg leading_shape: a tuple with which ``ary.shape`` is expected to begin.\"\"\"\n    from meshmode.dof_array import DOFArray\n    if (isinstance(ary, np.ndarray) and ary.dtype == np.object\n            and not isinstance(ary, DOFArray)):\n        naxes = len(leading_shape)\n        if ary.shape[:naxes] != leading_shape:\n            raise ValueError(\"array shape does not start with expected leading \"\n                    \"dimensions\")\n        return ary.shape[naxes:]\n    else:\n        if leading_shape != ():\n            raise ValueError(\"array shape does not start with expected leading \"\n                    \"dimensions\")\n        return ()\n\n\ndef split_conserved(dim, q):\n    \"\"\"Get the canonical conserved quantities.\n\n    Return a :class:`ConservedVars` that is the canonical conserved quantities,\n    mass, energy, and momentum from the agglomerated object array extracted\n    from the state vector *q*.\n    \"\"\"\n    assert len(q) == 2+dim\n    return ConservedVars(mass=q[0], energy=q[1], momentum=q[2:2+dim])\n\n\ndef join_conserved(dim, mass, energy, momentum):\n    \"\"\"Create an agglomerated solution array from the conserved quantities.\"\"\"\n    from pytools import single_valued\n    aux_shape = single_valued([\n        _aux_shape(mass, ()),\n        _aux_shape(energy, ()),\n        _aux_shape(momentum, (dim,))])\n\n    result = np.zeros((2+dim,) + aux_shape, dtype=object)\n    result[0] = mass\n    result[1] = energy\n    result[2:] = momentum\n    return result\n\n\ndef inviscid_flux(discr, eos, q):\n    r\"\"\"Compute the inviscid flux vectors from flow solution *q*.\n\n    The inviscid fluxes are\n    $(\\rho\\vec{V},(\\rho{E}+p)\\vec{V},\\rho(\\vec{V}\\otimes\\vec{V})+p\\mathbf{I})$\n    \"\"\"\n    dim = discr.dim\n    cv = split_conserved(dim, q)\n    p = eos.pressure(cv)\n\n    mom = cv.momentum\n    return join_conserved(dim,\n            mass=mom,\n            energy=mom * (cv.energy + p) / cv.mass,\n            momentum=np.outer(mom, mom)/cv.mass + np.eye(dim)*p)\n\n\ndef _get_wavespeed(dim, eos, cv: ConservedVars):\n    \"\"\"Return the maximum wavespeed in for flow solution *q*.\"\"\"\n    actx = cv.mass.array_context\n\n    v = cv.momentum / cv.mass\n    return actx.np.sqrt(np.dot(v, v)) + eos.sound_speed(cv)\n\n\ndef _facial_flux(discr, eos, q_tpair, local=False):\n    \"\"\"Return the flux across a face given the solution on both sides *q_tpair*.\n\n    Parameters\n    ----------\n    eos: mirgecom.eos.GasEOS\n        Implementing the pressure and temperature functions for\n        returning pressure and temperature as a function of the state q.\n\n    q_tpair: :class:`grudge.symbolic.TracePair`\n        Trace pair for the face upon which flux calculation is to be performed\n\n    local: bool\n        Indicates whether to skip projection of fluxes to \"all_faces\" or not. If\n        set to *False* (the default), the returned fluxes are projected to\n        \"all_faces.\"  If set to *True*, the returned fluxes are not projected to\n        \"all_faces\"; remaining instead on the boundary restriction.\n    \"\"\"\n    dim = discr.dim\n\n    actx = q_tpair[0].int.array_context\n\n    flux_int = inviscid_flux(discr, eos, q_tpair.int)\n    flux_ext = inviscid_flux(discr, eos, q_tpair.ext)\n\n    # Lax-Friedrichs/Rusanov after [Hesthaven_2008]_, Section 6.6\n    flux_avg = 0.5*(flux_int + flux_ext)\n\n    lam = actx.np.maximum(\n        _get_wavespeed(dim, eos=eos, cv=split_conserved(dim, q_tpair.int)),\n        _get_wavespeed(dim, eos=eos, cv=split_conserved(dim, q_tpair.ext))\n    )\n\n    normal = thaw(actx, discr.normal(q_tpair.dd))\n    flux_weak = (\n        flux_avg @ normal\n        - 0.5 * lam * (q_tpair.ext - q_tpair.int))\n\n    if local is False:\n        return discr.project(q_tpair.dd, \"all_faces\", flux_weak)\n    return flux_weak\n\n\ndef inviscid_operator(discr, eos, boundaries, q, t=0.0):\n    r\"\"\"Compute RHS of the Euler flow equations.\n\n    Returns\n    -------\n    numpy.ndarray\n        The right-hand-side of the Euler flow equations:\n\n        .. math::\n\n            \\dot{\\mathbf{q}} = \\mathbf{S} - \\nabla\\cdot\\mathbf{F} +\n                (\\mathbf{F}\\cdot\\hat{n})_{\\partial\\Omega}\n\n    Parameters\n    ----------\n    q\n        State array which expects at least the canonical conserved quantities\n        (mass, energy, momentum) for the fluid at each point.\n\n    boundaries\n        Dictionary of boundary functions, one for each valid btag\n\n    t\n        Time\n\n    eos: mirgecom.eos.GasEOS\n        Implementing the pressure and temperature functions for\n        returning pressure and temperature as a function of the state q.\n    \"\"\"\n    vol_flux = inviscid_flux(discr, eos, q)\n    dflux = discr.weak_div(vol_flux)\n\n    interior_face_flux = _facial_flux(\n        discr, eos=eos, q_tpair=interior_trace_pair(discr, q))\n\n    # Domain boundaries\n    domain_boundary_flux = sum(\n        _facial_flux(\n            discr,\n            q_tpair=boundaries[btag].boundary_pair(discr,\n                                                   eos=eos,\n                                                   btag=btag,\n                                                   t=t,\n                                                   q=q),\n            eos=eos\n        )\n        for btag in boundaries\n    )\n\n    # Flux across partition boundaries\n    partition_boundary_flux = sum(\n        _facial_flux(discr, eos=eos, q_tpair=part_pair)\n        for part_pair in cross_rank_trace_pairs(discr, q)\n    )\n\n    return discr.inverse_mass(\n        dflux - discr.face_mass(interior_face_flux + domain_boundary_flux\n                                + partition_boundary_flux)\n    )\n\n\ndef get_inviscid_cfl(discr, eos, dt, q):\n    \"\"\"Calculate and return CFL based on current state and timestep.\"\"\"\n    wanted_dt = get_inviscid_timestep(discr, eos=eos, cfl=1.0, q=q)\n    return dt / wanted_dt\n\n\ndef get_inviscid_timestep(discr, eos, cfl, q):\n    \"\"\"Routine (will) return the (local) maximum stable inviscid timestep.\n\n    Currently, it's a hack waiting for the geometric_factor helpers port\n    from grudge.\n    \"\"\"\n    dim = discr.dim\n    mesh = discr.mesh\n    order = max([grp.order for grp in discr.discr_from_dd(\"vol\").groups])\n    nelements = mesh.nelements\n    nel_1d = nelements ** (1.0 / (1.0 * dim))\n\n    # This roughly reproduces the timestep AK used in wave toy\n    dt = (1.0 - 0.25 * (dim - 1)) / (nel_1d * order ** 2)\n    return cfl * dt\n\n#    dt_ngf = dt_non_geometric_factor(discr.mesh)\n#    dt_gf  = dt_geometric_factor(discr.mesh)\n#    wavespeeds = _get_wavespeed(w,eos=eos)\n#    max_v = clmath.max(wavespeeds)\n#    return c*dt_ngf*dt_gf/max_v\n\n\n### mirgecom/eos.py ###\n\n\"\"\"\n:mod:`mirgecom.eos` provides implementations of gas equations of state.\n\nEquations of State\n^^^^^^^^^^^^^^^^^^\nThis module is designed provide Equation of State objects used to compute and\nmanage the relationships between and among state and thermodynamic variables.\n\n.. autoclass:: EOSDependentVars\n.. autoclass:: GasEOS\n.. autoclass:: IdealSingleGas\n\"\"\"\n\n__copyright__ = \"\"\"\nCopyright (C) 2020 University of Illinois Board of Trustees\n\"\"\"\n\n__license__ = \"\"\"\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\n\nfrom dataclasses import dataclass\nimport numpy as np\nfrom meshmode.mesh import BTAG_ALL, BTAG_NONE  # noqa\nfrom mirgecom.euler import ConservedVars\n\n\n@dataclass\nclass EOSDependentVars:\n    \"\"\"State-dependent quantities for :class:`GasEOS`.\n\n    Prefer individual methods for model use, use this\n    structure for visualization or probing.\n\n    .. attribute:: temperature\n    .. attribute:: pressure\n    \"\"\"\n\n    temperature: np.ndarray\n    pressure: np.ndarray\n\n\nclass GasEOS:\n    r\"\"\"Abstract interface to equation of state class.\n\n    Equation of state (EOS) classes are responsible for\n    computing relations between fluid or gas state variables.\n\n    Each interface call expects that the agglomerated\n    object array representing the state vector ($q$),\n    contains the relevant simulation state quantities. Each\n    EOS class should document its own state data requirements.\n\n    .. automethod:: pressure\n    .. automethod:: temperature\n    .. automethod:: sound_speed\n    .. automethod:: internal_energy\n    .. automethod:: gas_const\n    .. automethod:: dependent_vars\n    .. automethod:: total_energy\n    .. automethod:: kinetic_energy\n    \"\"\"\n\n    def pressure(self, cv: ConservedVars):\n        \"\"\"Get the gas pressure.\"\"\"\n        raise NotImplementedError()\n\n    def temperature(self, cv: ConservedVars):\n        \"\"\"Get the gas temperature.\"\"\"\n        raise NotImplementedError()\n\n    def sound_speed(self, cv: ConservedVars):\n        \"\"\"Get the gas sound speed.\"\"\"\n        raise NotImplementedError()\n\n    def gas_const(self, cv: ConservedVars):\n        r\"\"\"Get the specific gas constant ($R$).\"\"\"\n        raise NotImplementedError()\n\n    def internal_energy(self, cv: ConservedVars):\n        \"\"\"Get the thermal energy of the gas.\"\"\"\n        raise NotImplementedError()\n\n    def total_energy(self, cv: ConservedVars, pressure: np.ndarray):\n        \"\"\"Get the total (thermal + kinetic) energy for the gas.\"\"\"\n        raise NotImplementedError()\n\n    def kinetic_energy(self, cv: ConservedVars):\n        \"\"\"Get the kinetic energy for the gas.\"\"\"\n        raise NotImplementedError()\n\n    def dependent_vars(self, q: ConservedVars) -> EOSDependentVars:\n        \"\"\"Get an agglomerated array of the depedent variables.\"\"\"\n        return EOSDependentVars(\n            pressure=self.pressure(q),\n            temperature=self.temperature(q),\n            )\n\n\nclass IdealSingleGas(GasEOS):\n    r\"\"\"Ideal gas law single-component gas ($p = \\rho{R}{T}$).\n\n    The specific gas constant, R, defaults to the air-like 287.1 J/(kg*K),\n    but can be set according to simulation units and materials.\n\n    Each interface call expects that the agglomerated\n    object array representing the state vector ($q$),\n    contains at least the canonical conserved quantities\n    mass ($\\rho$), energy ($\\rho{E}$), and\n    momentum ($\\rho\\vec{V}$).\n\n    .. automethod:: __init__\n    .. automethod:: gamma\n\n    Inherits from (and implements) :class:`GasEOS`.\n    \"\"\"\n\n    def __init__(self, gamma=1.4, gas_const=287.1):\n        \"\"\"Initialize Ideal Gas EOS parameters.\"\"\"\n        self._gamma = gamma\n        self._gas_const = gas_const\n\n    def gamma(self):\n        \"\"\"Get specific heat ratio Cp/Cv.\"\"\"\n        return self._gamma\n\n    def gas_const(self):\n        \"\"\"Get specific gas constant R.\"\"\"\n        return self._gas_const\n\n    def kinetic_energy(self, cv: ConservedVars):\n        r\"\"\"Get kinetic (i.e. not internal) energy of gas.\n\n        The kinetic energy is calculated as:\n        .. :math::\n\n            k = \\frac{1}{2\\rho}(\\rho\\vec{V} \\cdot \\rho\\vec{V})\n        \"\"\"\n        mom = cv.momentum\n        return (0.5 * np.dot(mom, mom) / cv.mass)\n\n    def internal_energy(self, cv: ConservedVars):\n        r\"\"\"Get internal thermal energy of gas.\n\n        The internal energy (e) is calculated as:\n        .. :math::\n\n            e = \\rho{E} - \\frac{1}{2\\rho}(\\rho\\vec{V} \\cdot \\rho\\vec{V})\n        \"\"\"\n        return (cv.energy - self.kinetic_energy(cv))\n\n    def pressure(self, cv: ConservedVars):\n        r\"\"\"Get thermodynamic pressure of the gas.\n\n        Gas pressure (p) is calculated from the internal energy (e) as:\n\n        .. :math::\n\n            p = (\\gamma - 1)e\n        \"\"\"\n        return self.internal_energy(cv) * (self._gamma - 1.0)\n\n    def sound_speed(self, cv: ConservedVars):\n        r\"\"\"Get the speed of sound in the gas.\n\n        The speed of sound (c) is calculated as:\n\n        .. :math::\n\n            c = \\sqrt{\\frac{\\gamma{p}}{\\rho}}\n        \"\"\"\n        actx = cv.mass.array_context\n\n        p = self.pressure(cv)\n        c2 = self._gamma / cv.mass * p\n        return actx.np.sqrt(c2)\n\n    def temperature(self, cv: ConservedVars):\n        r\"\"\"Get the thermodynamic temperature of the gas.\n\n        The thermodynamic temperature (T) is calculated from\n        the internal energy (e) and specific gas constant (R)\n        as:\n\n        .. :math::\n\n            T = \\frac{(\\gamma - 1)e}{R\\rho}\n        \"\"\"\n        return (\n            (((self._gamma - 1.0) / self._gas_const)\n            * self.internal_energy(cv) / cv.mass)\n        )\n\n    def total_energy(self, cv, pressure):\n        r\"\"\"\n        Get gas total energy from mass, pressure, and momentum.\n\n        The total energy density (rhoE) is calculated from\n        the mass density (rho) , pressure (p) , and\n        momentum (rhoV) as:\n\n        .. :math::\n\n            \\rhoE = \\frac{p}{(\\gamma - 1)} +\n            \\frac{1}{2}\\rho(\\vec{v} \\cdot \\vec{v})\n\n        .. note::\n\n            The total_energy function computes cv.energy from pressure,\n            mass, and momentum in this case. In general in the EOS we need\n            DV = EOS(CV), and inversions CV = EOS(DV). This is one of those\n            inversion interfaces.\n        \"\"\"\n        return (pressure / (self._gamma - 1.0)\n                + self.kinetic_energy(cv))\n\n\n### mirgecom/initializers.py ###\n\n\"\"\"\n:mod:`mirgecom.initializers` helps intialize and compute flow solution fields.\n\nSolution Initializers\n^^^^^^^^^^^^^^^^^^^^^\n.. autoclass:: Vortex2D\n.. autoclass:: SodShock1D\n.. autoclass:: Lump\n.. autoclass:: Uniform\n.. autoclass:: AcousticPulse\n.. automethod: _make_pulse\n.. automethod: _make_uniform_flow\n\"\"\"\n\n__copyright__ = \"\"\"\nCopyright (C) 2020 University of Illinois Board of Trustees\n\"\"\"\n\n__license__ = \"\"\"\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\n\nimport numpy as np\nfrom pytools.obj_array import (\n    flat_obj_array,\n    make_obj_array,\n)\nfrom meshmode.dof_array import thaw\nfrom mirgecom.eos import IdealSingleGas\nfrom mirgecom.euler import split_conserved, join_conserved\n\n\ndef _make_uniform_flow(x_vec, mass=1.0, energy=2.5, pressure=1.0,\n                       velocity=None, eos=IdealSingleGas()):\n    r\"\"\"Construct uniform, constant flow.\n\n    Construct a uniform, constant flow from mass, energy, pressure, and\n    an EOS object.\n\n    Parameters\n    ----------\n    x_vec: np.ndarray\n        Nodal positions\n    mass: float\n        Value to set $\\rho$\n    energy: float\n        Optional value to set $\\rho{E}$\n    pressure: float\n        Value to use for calculating $\\rho{E}$\n    velocity: np.ndarray\n        Optional constant velocity to set $\\rho\\vec{V}$\n\n    Returns\n    -------\n    q: Object array of DOFArrays\n        Agglomerated object array with the uniform flow\n    \"\"\"\n    dim = len(x_vec)\n    if velocity is None:\n        velocity = np.zeros(shape=(dim,))\n\n    _rho = mass\n    _p = pressure\n    _velocity = velocity\n    _gamma = eos.gamma()\n\n    mom0 = _velocity * _rho\n    e0 = _p / (_gamma - 1.0)\n    ke0 = _rho * 0.5 * np.dot(_velocity, _velocity)\n\n    x_rel = x_vec[0]\n    zeros = 0.0*x_rel\n    ones = zeros + 1.0\n\n    mass = zeros + _rho\n    mom = mom0 * ones\n    energy = e0 + ke0 + zeros\n\n    return join_conserved(dim=dim, mass=mass, energy=energy, momentum=mom)\n\n\ndef _make_pulse(amp, r0, w, r):\n    r\"\"\"Create a Gaussian pulse.\n\n    The Gaussian pulse is defined by:\n\n    .. math::\n\n        G(\\vec{r}) = a_0*\\exp^{-(\\frac{(\\vec{r}-\\vec{r_0})}{\\sqrt{2}w})^{2}}\\\\\n\n    Where $\\vec{r}$ is the position, and the parameters are\n    the pulse amplitude $a_0$, the pulse location $\\vec{r_0}$, and the\n    RMS width of the pulse, $w$.\n\n    Parameters\n    ----------\n    amp: float\n        specifies the value of $\\a_0$, the pulse amplitude\n    r0: float array\n        specifies the value of $\\r_0$, the pulse location\n    w: float\n        specifies the value of $w$, the rms pulse width\n    r: Object array of DOFArrays\n        specifies the nodal coordinates\n\n    Returns\n    -------\n    G: float array\n        The values of the exponential function\n    \"\"\"\n    dim = len(r)\n    r_0 = np.zeros(dim)\n    r_0 = r_0 + r0\n    # coordinates relative to pulse center\n    rel_center = make_obj_array(\n        [r[i] - r_0[i] for i in range(dim)]\n    )\n    actx = r[0].array_context\n    rms2 = w * w\n    r2 = np.dot(rel_center, rel_center) / rms2\n    return amp * actx.np.exp(-.5 * r2)\n\n\nclass Vortex2D:\n    r\"\"\"Initializer for the isentropic vortex solution.\n\n    Implements the isentropic vortex after\n        - [Zhou_2003]_\n        - [Hesthaven_2008]_, Section 6.6\n\n    The isentropic vortex is defined by:\n\n    .. math::\n\n         u = u_0 - \\beta\\exp^{(1-r^2)}\\frac{y - y_0}{2\\pi}\\\\\n         v = v_0 + \\beta\\exp^{(1-r^2)}\\frac{x - x_0}{2\\pi}\\\\\n         \\rho =\n         ( 1 - (\\frac{\\gamma - 1}{16\\gamma\\pi^2})\\beta^2\n         \\exp^{2(1-r^2)})^{\\frac{1}{\\gamma-1}}\\\\\n         p = \\rho^{\\gamma}\n\n    A call to this object after creation/init creates\n    the isentropic vortex solution at a given time (t)\n    relative to the configured origin (center) and\n    background flow velocity (velocity).\n\n    .. automethod:: __init__\n    .. automethod:: __call__\n    \"\"\"\n\n    def __init__(\n        self, beta=5, center=[0, 0], velocity=[0, 0],\n    ):\n        \"\"\"Initialize vortex parameters.\n\n        Parameters\n        ----------\n        beta: float\n            vortex amplitude\n        center: numpy.ndarray\n            center of vortex, shape ``(2,)``\n        velocity: numpy.ndarray\n            fixed flow velocity used for exact solution at t != 0, shape ``(2,)``\n        \"\"\"\n        self._beta = beta\n        self._center = np.array(center)\n        self._velocity = np.array(velocity)\n\n    def __call__(self, t, x_vec, eos=IdealSingleGas()):\n        \"\"\"\n        Create the isentropic vortex solution at time *t* at locations *x_vec*.\n\n        Parameters\n        ----------\n        t: float\n            Current time at which the solution is desired.\n        x_vec: numpy.ndarray\n            Nodal coordinates\n        eos: :class:`mirgecom.eos.GasEOS`\n            Equation of state class to be used in construction of soln (if needed)\n        \"\"\"\n        vortex_loc = self._center + t * self._velocity\n\n        # coordinates relative to vortex center\n        x_rel = x_vec[0] - vortex_loc[0]\n        y_rel = x_vec[1] - vortex_loc[1]\n        actx = x_vec[0].array_context\n        gamma = eos.gamma()\n        r = actx.np.sqrt(x_rel ** 2 + y_rel ** 2)\n        expterm = self._beta * actx.np.exp(1 - r ** 2)\n        u = self._velocity[0] - expterm * y_rel / (2 * np.pi)\n        v = self._velocity[1] + expterm * x_rel / (2 * np.pi)\n        mass = (1 - (gamma - 1) / (16 * gamma * np.pi ** 2)\n                * expterm ** 2) ** (1 / (gamma - 1))\n        p = mass ** gamma\n\n        e = p / (gamma - 1) + mass / 2 * (u ** 2 + v ** 2)\n\n        return flat_obj_array(mass, e, mass * u, mass * v)\n\n\nclass SodShock1D:\n    r\"\"\"Solution initializer for the 1D Sod Shock.\n\n    This is Sod's 1D shock solution as explained in [Hesthaven_2008]_, Section 5.9\n    The Sod Shock setup is defined by:\n\n    .. math::\n\n         {\\rho}(x < x_0, 0) = \\rho_l\\\\\n         {\\rho}(x > x_0, 0) = \\rho_r\\\\\n         {\\rho}{V_x}(x, 0) = 0\\\\\n         {\\rho}E(x < x_0, 0) = \\frac{1}{\\gamma - 1}\\\\\n         {\\rho}E(x > x_0, 0) = \\frac{.1}{\\gamma - 1}\n\n    A call to this object after creation/init creates Sod's shock solution at a\n    given time (t) relative to the configured origin (center) and background\n    flow velocity (velocity).\n\n    .. automethod:: __init__\n    .. automethod:: __call__\n    \"\"\"\n\n    def __init__(\n            self, dim=2, xdir=0, x0=0.5, rhol=1.0, rhor=0.125, pleft=1.0, pright=0.1,\n    ):\n        \"\"\"Initialize shock parameters.\n\n        Parameters\n        ----------\n        dim: int\n           dimension of domain\n        x0: float\n           location of shock\n        rhol: float\n           density to left of shock\n        rhor: float\n           density to right of shock\n        pleft: float\n           pressure to left of shock\n        pright: float\n           pressure to right of shock\n        \"\"\"\n        self._x0 = x0\n        self._rhol = rhol\n        self._rhor = rhor\n        self._energyl = pleft\n        self._energyr = pright\n        self._dim = dim\n        self._xdir = xdir\n        if self._xdir >= self._dim:\n            self._xdir = self._dim - 1\n\n    def __call__(self, t, x_vec, eos=IdealSingleGas()):\n        \"\"\"\n        Create the 1D Sod's shock solution at locations *x_vec*.\n\n        Parameters\n        ----------\n        t: float\n            Current time at which the solution is desired (unused)\n        x_vec: numpy.ndarray\n            Nodal coordinates\n        eos: :class:`mirgecom.eos.GasEOS`\n            Equation of state class to be used in construction of soln (if needed)\n        \"\"\"\n        gm1 = eos.gamma() - 1.0\n        gmn1 = 1.0 / gm1\n        x_rel = x_vec[self._xdir]\n        actx = x_rel.array_context\n\n        zeros = 0*x_rel\n\n        rhor = zeros + self._rhor\n        rhol = zeros + self._rhol\n        x0 = zeros + self._x0\n        energyl = zeros + gmn1 * self._energyl\n        energyr = zeros + gmn1 * self._energyr\n        yesno = x_rel > x0\n        mass = actx.np.where(yesno, rhor, rhol)\n        energy = actx.np.where(yesno, energyr, energyl)\n        mom = make_obj_array(\n            [\n                0*x_rel\n                for i in range(self._dim)\n            ]\n        )\n\n        return flat_obj_array(mass, energy, mom)\n\n\nclass Lump:\n    r\"\"\"Solution initializer for N-dimensional Gaussian lump of mass.\n\n    The Gaussian lump is defined by:\n\n    .. math::\n\n         {\\rho}(r) = {\\rho}_{0} + {\\rho}_{a}\\exp^{(1-r^{2})}\\\\\n         {\\rho}\\vec{V} = {\\rho}(r)\\vec{V_0}\\\\\n         {\\rho}E = (\\frac{p_0}{(\\gamma - 1)} + \\frac{1}{2}\\rho{|V_0|}^2\n\n    Where $V_0$ is the fixed velocity specified\n    by the user at init time, and $\\gamma$ is taken\n    from the equation-of-state object (eos).\n\n    A call to this object after creation/init creates\n    the lump solution at a given time (t)\n    relative to the configured origin (center) and\n    background flow velocity (velocity).\n\n    This object also functions as a boundary condition\n    by providing the \"get_boundary_flux\" method to\n    prescribe exact field values on the given boundary.\n\n    This object also supplies the exact expected RHS\n    terms from the analytic expression in the\n    \"expected_rhs\" method.\n\n    .. automethod:: __init__\n    .. automethod:: __call__\n    .. automethod:: exact_rhs\n    \"\"\"\n\n    def __init__(\n            self, numdim=1, rho0=1.0, rhoamp=1.0,\n            p0=1.0, center=[0], velocity=[0]\n    ):\n        r\"\"\"Initialize Lump parameters.\n\n        Parameters\n        ----------\n        numdim: int\n            specify the number of dimensions for the lump\n        rho0: float\n            specifies the value of $\\rho_0$\n        rhoamp: float\n            specifies the value of $\\rho_a$\n        p0: float\n            specifies the value of $p_0$\n        center: numpy.ndarray\n            center of lump, shape ``(2,)``\n        velocity: numpy.ndarray\n            fixed flow velocity used for exact solution at t != 0,\n            shape ``(2,)``\n        \"\"\"\n        if len(center) == numdim:\n            self._center = center\n        elif len(center) > numdim:\n            numdim = len(center)\n            self._center = center\n        else:\n            self._center = np.zeros(shape=(numdim,))\n\n        if len(velocity) == numdim:\n            self._velocity = velocity\n        elif len(velocity) > numdim:\n            numdim = len(velocity)\n            self._velocity = velocity\n            new_center = np.zeros(shape=(numdim,))\n            for i in range(len(self._center)):\n                new_center[i] = self._center[i]\n            self._center = new_center\n        else:\n            self._velocity = np.zeros(shape=(numdim,))\n\n        assert len(self._velocity) == numdim\n        assert len(self._center) == numdim\n\n        self._p0 = p0\n        self._rho0 = rho0\n        self._rhoamp = rhoamp\n        self._dim = numdim\n\n    def __call__(self, t, x_vec, eos=IdealSingleGas()):\n        \"\"\"\n        Create the lump-of-mass solution at time *t* and locations *x_vec*.\n\n        Note that *t* is used to advect the mass lump under the assumption of\n        constant, and uniform velocity.\n\n        Parameters\n        ----------\n        t: float\n            Current time at which the solution is desired\n        x_vec: numpy.ndarray\n            Nodal coordinates\n        eos: :class:`mirgecom.eos.GasEOS`\n            Equation of state class to be used in construction of soln (if needed)\n        \"\"\"\n        lump_loc = self._center + t * self._velocity\n        assert len(x_vec) == self._dim\n        # coordinates relative to lump center\n        rel_center = make_obj_array(\n            [x_vec[i] - lump_loc[i] for i in range(self._dim)]\n        )\n        actx = x_vec[0].array_context\n        r = actx.np.sqrt(np.dot(rel_center, rel_center))\n\n        gamma = eos.gamma()\n        expterm = self._rhoamp * actx.np.exp(1 - r ** 2)\n        mass = expterm + self._rho0\n        mom = self._velocity * mass\n        energy = (self._p0 / (gamma - 1.0)) + np.dot(mom, mom) / (2.0 * mass)\n\n        return flat_obj_array(mass, energy, mom)\n\n    def exact_rhs(self, discr, q, t=0.0):\n        \"\"\"\n        Create the RHS for the lump-of-mass solution at time *t*, locations *x_vec*.\n\n        Note that this routine is only useful for testing under the condition of\n        uniform, and constant velocity field.\n\n        Parameters\n        ----------\n        q\n            State array which expects at least the canonical conserved quantities\n            (mass, energy, momentum) for the fluid at each point.\n        t: float\n            Time at which RHS is desired\n        \"\"\"\n        actx = q[0].array_context\n        nodes = thaw(actx, discr.nodes())\n        lump_loc = self._center + t * self._velocity\n        # coordinates relative to lump center\n        rel_center = make_obj_array(\n            [nodes[i] - lump_loc[i] for i in range(self._dim)]\n        )\n        r = actx.np.sqrt(np.dot(rel_center, rel_center))\n\n        # The expected rhs is:\n        # rhorhs  = -2*rho*(r.dot.v)\n        # rhoerhs = -rho*v^2*(r.dot.v)\n        # rhovrhs = -2*rho*(r.dot.v)*v\n        expterm = self._rhoamp * actx.np.exp(1 - r ** 2)\n        mass = expterm + self._rho0\n\n        v = self._velocity / mass\n        v2 = np.dot(v, v)\n        rdotv = np.dot(rel_center, v)\n        massrhs = -2 * rdotv * mass\n        energyrhs = -v2 * rdotv * mass\n        momrhs = v * (-2 * mass * rdotv)\n\n        return flat_obj_array(massrhs, energyrhs, momrhs)\n\n\nclass AcousticPulse:\n    r\"\"\"Solution initializer for N-dimensional Gaussian acoustic pulse.\n\n    The Gaussian pulse is defined by:\n\n    .. math::\n\n        {\\rho}E(\\vec{r}) = {\\rho}E + a_0 * G(\\vec{r})\\\\\n        G(\\vec{r}) = \\exp^{-(\\frac{(\\vec{r}-\\vec{r_0})}{\\sqrt{2}w})^{2}},\n\n    where $\\vec{r}$ are the nodal coordinates, and $\\vec{r_0}$,\n    $amplitude$, and $w$, are the the user-specified pulse location,\n    amplitude, and width, respectively.\n\n    .. automethod:: __init__\n    .. automethod:: __call__\n    \"\"\"\n\n    def __init__(self, numdim=1, amplitude=1,\n                 center=None, width=1):\n        r\"\"\"\n        Initialize acoustic pulse parameters.\n\n        Parameters\n        ----------\n        numdim: int\n            specify the number of dimensions for the pulse\n        amplitude: float\n            specifies the value of $amplitude$\n        width: float\n            specifies the rms width of the pulse\n        center: numpy.ndarray\n            pulse location, shape ``(numdim,)``\n        \"\"\"\n        if len(center) == numdim:\n            self._center = center\n        elif len(center) > numdim:\n            numdim = len(center)\n            self._center = center\n        else:\n            self._center = np.zeros(shape=(numdim,))\n\n        assert len(self._center) == numdim\n\n        self._amp = amplitude\n        self._width = width\n        self._dim = numdim\n\n    def __call__(self, x_vec, q, eos=IdealSingleGas()):\n        \"\"\"\n        Create the acoustic pulse at locations *x_vec*.\n\n        Parameters\n        ----------\n        t: float\n            Current time at which the solution is desired (unused)\n        x_vec: numpy.ndarray\n            Nodal coordinates\n        eos: :class:`mirgecom.eos.GasEOS`\n            Equation of state class to be used in construction of soln (unused)\n        \"\"\"\n        assert len(x_vec) == self._dim\n        cv = split_conserved(self._dim, q)\n        return cv.replace(\n            energy=cv.energy + _make_pulse(\n                amp=self._amp, w=self._width, r0=self._center, r=x_vec)\n            ).join()\n\n\nclass Uniform:\n    r\"\"\"Solution initializer for a uniform flow.\n\n    A uniform flow is the same everywhere and should have\n    a zero RHS.\n\n    .. automethod:: __init__\n    .. automethod:: __call__\n    .. automethod:: exact_rhs\n    \"\"\"\n\n    def __init__(\n            self, numdim=1, rho=1.0, p=1.0, e=2.5, velocity=np.zeros((1,)),\n    ):\n        r\"\"\"Initialize uniform flow parameters.\n\n        Parameters\n        ----------\n        numdim: int\n            specify the number of dimensions for the lump\n        rho: float\n            specifies the density\n        p: float\n            specifies the pressure\n        e: float\n            specifies the internal energy\n        velocity: numpy.ndarray\n            specifies the flow velocity\n        \"\"\"\n        if len(velocity) == numdim:\n            self._velocity = velocity\n        elif len(velocity) > numdim:\n            numdim = len(velocity)\n            self._velocity = velocity\n        else:\n            self._velocity = np.zeros(shape=(numdim,))\n\n        assert len(self._velocity) == numdim\n\n        self._p = p\n        self._rho = rho\n        self._e = e\n        self._dim = numdim\n\n    def __call__(self, t, x_vec, eos=IdealSingleGas()):\n        \"\"\"\n        Create a uniform flow solution at locations *x_vec*.\n\n        Parameters\n        ----------\n        t: float\n            Current time at which the solution is desired (unused)\n        x_vec: numpy.ndarray\n            Nodal coordinates\n        eos: :class:`mirgecom.eos.GasEOS`\n            Equation of state class to be used in construction of soln (unused)\n        \"\"\"\n        return _make_uniform_flow(x_vec=x_vec, mass=self._rho,\n                                  pressure=self._p, energy=self._e,\n                                  velocity=self._velocity, eos=eos)\n\n    def exact_rhs(self, discr, q, t=0.0):\n        \"\"\"\n        Create the RHS for the uniform solution. (Hint - it should be all zero).\n\n        Parameters\n        ----------\n        q\n            State array which expects at least the canonical conserved quantities\n            (mass, energy, momentum) for the fluid at each point. (unused)\n        t: float\n            Time at which RHS is desired (unused)\n        \"\"\"\n        actx = q[0].array_context\n        nodes = thaw(actx, discr.nodes())\n        mass = nodes[0].copy()\n        mass[:] = 1.0\n        massrhs = 0.0 * mass\n        energyrhs = 0.0 * mass\n        momrhs = make_obj_array([0 * mass])\n\n        return flat_obj_array(massrhs, energyrhs, momrhs)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "__copyright__ = \"\"\"\nCopyright (C) 2020 University of Illinois Board of Trustees\n\"\"\"\n\n__license__ = \"\"\"\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\n\nimport logging\nimport numpy as np\nimport numpy.linalg as la  # noqa\nimport pyopencl as cl\nimport pyopencl.clrandom\nimport pyopencl.clmath\nimport pytest\n\nfrom meshmode.array_context import PyOpenCLArrayContext\nfrom meshmode.dof_array import thaw\nfrom meshmode.mesh import BTAG_ALL, BTAG_NONE  # noqa\n\nfrom mirgecom.initializers import Vortex2D\nfrom mirgecom.initializers import Lump\nfrom mirgecom.euler import split_conserved\nfrom mirgecom.initializers import SodShock1D\nfrom mirgecom.eos import IdealSingleGas\n\nfrom grudge.eager import EagerDGDiscretization\nfrom pyopencl.tools import (  # noqa\n    pytest_generate_tests_for_pyopencl as pytest_generate_tests,\n)\n\nlogger = logging.getLogger(__name__)\n\n\ndef test_lump_init(ctx_factory):\n    \"\"\"\n    Simple test to check that Lump initializer\n    creates the expected solution field.\n    \"\"\"\n    cl_ctx = ctx_factory()\n    queue = cl.CommandQueue(cl_ctx)\n    actx = PyOpenCLArrayContext(queue)\n    dim = 2\n    nel_1d = 4\n\n    from meshmode.mesh.generation import generate_regular_rect_mesh\n\n    mesh = generate_regular_rect_mesh(\n        a=[(0.0,), (-5.0,)], b=[(10.0,), (5.0,)], n=(nel_1d,) * dim\n    )\n\n    order = 3\n    logger.info(f\"Number of elements: {mesh.nelements}\")\n\n    discr = EagerDGDiscretization(actx, mesh, order=order)\n    nodes = thaw(actx, discr.nodes())\n\n    # Init soln with Vortex\n    center = np.zeros(shape=(dim,))\n    velocity = np.zeros(shape=(dim,))\n    center[0] = 5\n    velocity[0] = 1\n    lump = Lump(center=center, velocity=velocity)\n    lump_soln = lump(0, nodes)\n\n    cv = split_conserved(dim, lump_soln)\n    p = 0.4 * (cv.energy - 0.5 * np.dot(cv.momentum, cv.momentum) / cv.mass)\n    exp_p = 1.0\n    errmax = discr.norm(p - exp_p, np.inf)\n\n    logger.info(f\"lump_soln = {lump_soln}\")\n    logger.info(f\"pressure = {p}\")\n\n    assert errmax < 1e-15\n\n\ndef test_vortex_init(ctx_factory):\n    \"\"\"\n    Simple test to check that Vortex2D initializer\n    creates the expected solution field.\n    \"\"\"\n    cl_ctx = ctx_factory()\n    queue = cl.CommandQueue(cl_ctx)\n    actx = PyOpenCLArrayContext(queue)\n    dim = 2\n    nel_1d = 4\n\n    from meshmode.mesh.generation import generate_regular_rect_mesh\n\n    mesh = generate_regular_rect_mesh(\n        a=[(0.0,), (-5.0,)], b=[(10.0,), (5.0,)], n=(nel_1d,) * dim\n    )\n\n    order = 3\n    logger.info(f\"Number of elements: {mesh.nelements}\")\n\n    discr = EagerDGDiscretization(actx, mesh, order=order)\n    nodes = thaw(actx, discr.nodes())\n\n    # Init soln with Vortex\n    vortex = Vortex2D()\n    vortex_soln = vortex(0, nodes)\n    gamma = 1.4\n    cv = split_conserved(dim, vortex_soln)\n    p = 0.4 * (cv.energy - 0.5 * np.dot(cv.momentum, cv.momentum) / cv.mass)\n    exp_p = cv.mass ** gamma\n    errmax = discr.norm(p - exp_p, np.inf)\n\n    logger.info(f\"vortex_soln = {vortex_soln}\")\n    logger.info(f\"pressure = {p}\")\n\n    assert errmax < 1e-15\n\n\ndef test_shock_init(ctx_factory):\n    \"\"\"\n    Simple test to check that Shock1D initializer\n    creates the expected solution field.\n    \"\"\"\n    cl_ctx = ctx_factory()\n    queue = cl.CommandQueue(cl_ctx)\n    actx = PyOpenCLArrayContext(queue)\n\n    nel_1d = 10\n    dim = 2\n\n    from meshmode.mesh.generation import generate_regular_rect_mesh\n\n    mesh = generate_regular_rect_mesh(\n        a=[(0.0,), (1.0,)], b=[(-0.5,), (0.5,)], n=(nel_1d,) * dim\n    )\n\n    order = 3\n    print(f\"Number of elements: {mesh.nelements}\")\n\n    discr = EagerDGDiscretization(actx, mesh, order=order)\n    nodes = thaw(actx, discr.nodes())\n\n    initr = SodShock1D()\n    initsoln = initr(t=0.0, x_vec=nodes)\n    print(\"Sod Soln:\", initsoln)\n    xpl = 1.0\n    xpr = 0.1\n    tol = 1e-15\n    nodes_x = nodes[0]\n    eos = IdealSingleGas()\n    cv = split_conserved(dim, initsoln)\n    p = eos.pressure(cv)\n\n    assert discr.norm(actx.np.where(nodes_x < 0.5, p-xpl, p-xpr), np.inf) < tol\n\n\n@pytest.mark.parametrize(\"dim\", [1, 2, 3])\ndef test_uniform(ctx_factory, dim):\n    \"\"\"\n    Simple test to check that Uniform initializer\n    creates the expected solution field.\n    \"\"\"\n    cl_ctx = ctx_factory()\n    queue = cl.CommandQueue(cl_ctx)\n    actx = PyOpenCLArrayContext(queue)\n\n    nel_1d = 2\n\n    from meshmode.mesh.generation import generate_regular_rect_mesh\n\n    mesh = generate_regular_rect_mesh(\n        a=(-0.5,) * dim, b=(0.5,) * dim, n=(nel_1d,) * dim\n    )\n\n    order = 1\n    print(f\"Number of elements: {mesh.nelements}\")\n\n    discr = EagerDGDiscretization(actx, mesh, order=order)\n    nodes = thaw(actx, discr.nodes())\n    print(f\"DIM = {dim}, {len(nodes)}\")\n    print(f\"Nodes={nodes}\")\n\n    from mirgecom.initializers import Uniform\n    initr = Uniform(numdim=dim)\n    initsoln = initr(t=0.0, x_vec=nodes)\n    tol = 1e-15\n    ssoln = split_conserved(dim, initsoln)\n\n    assert discr.norm(ssoln.mass - 1.0, np.inf) < tol\n    assert discr.norm(ssoln.energy - 2.5, np.inf) < tol\n\n    print(f\"Uniform Soln:{initsoln}\")\n    eos = IdealSingleGas()\n    cv = split_conserved(dim, initsoln)\n    p = eos.pressure(cv)\n    print(f\"Press:{p}\")\n\n    assert discr.norm(p - 1.0, np.inf) < tol\n\n\n@pytest.mark.parametrize(\"dim\", [1, 2, 3])\ndef test_pulse(ctx_factory, dim):\n    \"\"\"\n    Test of Gaussian pulse generator.\n    If it looks, walks, and quacks like a duck, then ...\n    \"\"\"\n    cl_ctx = ctx_factory()\n    queue = cl.CommandQueue(cl_ctx)\n    actx = PyOpenCLArrayContext(queue)\n\n    nel_1d = 10\n\n    from meshmode.mesh.generation import generate_regular_rect_mesh\n\n    mesh = generate_regular_rect_mesh(\n        a=(-0.5,) * dim, b=(0.5,) * dim, n=(nel_1d,) * dim\n    )\n\n    order = 1\n    print(f\"Number of elements: {mesh.nelements}\")\n\n    discr = EagerDGDiscretization(actx, mesh, order=order)\n    nodes = thaw(actx, discr.nodes())\n    print(f\"DIM = {dim}, {len(nodes)}\")\n    print(f\"Nodes={nodes}\")\n\n    tol = 1e-15\n    from mirgecom.initializers import _make_pulse\n    amp = 1.0\n    w = .1\n    rms2 = w * w\n    r0 = np.zeros(dim)\n    r2 = np.dot(nodes, nodes) / rms2\n    pulse = _make_pulse(amp=amp, r0=r0, w=w, r=nodes)\n    print(f\"Pulse = {pulse}\")\n\n    # does it return the expected exponential?\n    pulse_check = actx.np.exp(-.5 * r2)\n    print(f\"exact: {pulse_check}\")\n    pulse_resid = pulse - pulse_check\n    print(f\"pulse residual: {pulse_resid}\")\n    assert(discr.norm(pulse_resid, np.inf) < tol)\n\n    # proper scaling with amplitude?\n    amp = 2.0\n    pulse = 0\n    pulse = _make_pulse(amp=amp, r0=r0, w=w, r=nodes)\n    pulse_resid = pulse - (pulse_check + pulse_check)\n    assert(discr.norm(pulse_resid, np.inf) < tol)\n\n    # proper scaling with r?\n    amp = 1.0\n    rcheck = np.sqrt(2.0) * nodes\n    pulse = _make_pulse(amp=amp, r0=r0, w=w, r=rcheck)\n    assert(discr.norm(pulse - (pulse_check * pulse_check), np.inf) < tol)\n\n    # proper scaling with w?\n    w = w / np.sqrt(2.0)\n    pulse = _make_pulse(amp=amp, r0=r0, w=w, r=nodes)\n    assert(discr.norm(pulse - (pulse_check * pulse_check), np.inf) < tol)\n"
  },
  {
    "prompt": "\n\n### lexicon/tests/providers/integration_tests.py ###\n\n\"\"\"Base class for provider integration tests\"\"\"\n# pylint: disable=missing-docstring\nimport os\nfrom functools import wraps\nfrom importlib import import_module\n\nimport pytest\nimport vcr\nfrom lexicon.config import ConfigResolver, ConfigSource, DictConfigSource\n\n\n# Configure VCR. Parameter record_mode depends on the LEXICON_LIVE_TESTS environment variable value.\nRECORD_MODE = 'none'\nif os.environ.get('LEXICON_LIVE_TESTS', 'false') == 'true':\n    RECORD_MODE = 'once'\nPROVIDER_VCR = vcr.VCR(\n    cassette_library_dir=os.environ.get('LEXICON_VCRPY_CASSETTES_PATH',\n                                        'tests/fixtures/cassettes'),\n    record_mode=RECORD_MODE,\n    decode_compressed_response=True\n)\n\n\n# Prepare custom decorator: it will start a casette in relevant folder for current provider,\n# and using the name of the test method as the cassette's name.\ndef _vcr_integration_test(decorated):\n    @wraps(decorated)\n    def wrapper(self):\n        # pylint: disable=protected-access\n        with PROVIDER_VCR.use_cassette(\n                self._cassette_path('IntegrationTests/{0}.yaml'\n                                    .format(decorated.__name__)),\n                filter_headers=self._filter_headers(),\n                filter_query_parameters=self._filter_query_parameters(),\n                filter_post_data_parameters=self._filter_post_data_parameters(),\n                before_record_request=self._filter_request,\n                before_record_response=self._filter_response):\n            decorated(self)\n        # pylint: enable=protected-access\n    return wrapper\n\n\nclass EngineOverrideConfigSource(ConfigSource):  # pylint: disable=too-few-public-methods\n    \"\"\"Config source to override some provider parameters during tests\"\"\"\n    def __init__(self, overrides):\n        super(EngineOverrideConfigSource, self).__init__()\n        self.overrides = overrides\n\n    def resolve(self, config_key):\n        # We extract the key from existing namespace.\n        config_key = config_key.split(':')[-1]\n        return self.overrides.get(config_key)\n\n\nclass FallbackConfigSource(ConfigSource):  # pylint: disable=too-few-public-methods\n    \"\"\"Config source to provider fallback to provider parameters during tests\"\"\"\n    def __init__(self, fallback_fn):\n        super(FallbackConfigSource, self).__init__()\n        self.fallback_fn = fallback_fn\n\n    def resolve(self, config_key):\n        config_key = config_key.split(':')\n        if not config_key[-2] == 'lexicon':\n            return self.fallback_fn(config_key[-1])\n\n        return None\n\n\nclass IntegrationTestsV1(object):  # pylint: disable=useless-object-inheritance,too-many-public-methods\n    \"\"\"\n    https://stackoverflow.com/questions/26266481/pytest-reusable-tests-for-different-implementations-of-the-same-interface  # pylint: disable=line-too-long\n    Single, reusable definition of tests for the interface. Authors of\n    new implementations of the interface merely have to provide the test\n    data, as class attributes of a class which inherits\n    unittest.TestCase AND this class.\n\n    Required test data:\n    self.Provider must be set\n    self.provider_name must be set\n    self.domain must be set\n    self._filter_headers can be defined to provide a list of sensitive http headers\n    self._filter_query_parameters can be defined to provide a list of sensitive query parameters\n    self._filter_post_data_parameters can be defined to provide a list of sensitive post data parameters\n    self.provider_variant can be defined as a prefix for saving cassettes when a provider uses multiple variants\n\n    IntegrationTestsV1 is used for providers developed before IntegrationTestsV2 has been created.\n    \"\"\"\n\n    def __init__(self):\n        self.domain = None\n        self.provider_name = None\n        self.provider_module = None\n\n    def setup_method(self, _):\n        self.provider_module = import_module('lexicon.providers.{0}'.format(self.provider_name))\n\n    ###########################################################################\n    # Provider module shape\n    ###########################################################################\n    def test_provider_module_shape(self):\n        module = import_module(\n            'lexicon.providers.{0}'.format(\n                self.provider_name))\n\n        assert hasattr(module, 'provider_parser')\n        assert hasattr(module, 'Provider')\n        if self.provider_name != 'auto':\n            assert hasattr(module, 'NAMESERVER_DOMAINS')\n\n        assert callable(module.provider_parser)\n        assert callable(module.Provider)\n        if self.provider_name != 'auto':\n            assert isinstance(module.NAMESERVER_DOMAINS, list)\n\n    ###########################################################################\n    # Provider.authenticate()\n    ###########################################################################\n    @_vcr_integration_test\n    def test_provider_authenticate(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.domain_id is not None\n\n    @_vcr_integration_test\n    def test_provider_authenticate_with_unmanaged_domain_should_fail(self):\n        config = self._test_config()\n        config.add_config_source(DictConfigSource(\n            {'domain': 'thisisadomainidonotown.com'}), 0)\n        provider = self.provider_module.Provider(config)\n        with pytest.raises(Exception):\n            provider.authenticate()\n\n    ###########################################################################\n    # Provider.create_record()\n    ###########################################################################\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_for_A_with_valid_name_and_content(self):  # pylint: disable=invalid-name\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record('A', 'localhost', '127.0.0.1')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_for_CNAME_with_valid_name_and_content(self):  # pylint: disable=invalid-name\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record('CNAME', 'docs', 'docs.example.com')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_for_TXT_with_valid_name_and_content(self):  # pylint: disable=invalid-name\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', '_acme-challenge.test', 'challengetoken')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_for_TXT_with_full_name_and_content(self):  # pylint: disable=invalid-name\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.full.{0}\".format(self.domain), 'challengetoken')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_for_TXT_with_fqdn_name_and_content(self):  # pylint: disable=invalid-name\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.fqdn.{0}.\".format(self.domain), 'challengetoken')\n\n    ###########################################################################\n    # Provider.list_records()\n    ###########################################################################\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_no_arguments_should_list_all(self):\n        provider = self._construct_authenticated_provider()\n        assert isinstance(provider.list_records(), list)\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_name_filter_should_return_record(self):\n        provider = self._construct_authenticated_provider()\n        provider.create_record('TXT', 'random.test', 'challengetoken')\n        records = provider.list_records('TXT', 'random.test')\n        assert len(records) == 1\n        assert records[0]['content'] == 'challengetoken'\n        assert records[0]['type'] == 'TXT'\n        assert records[0]['name'] == 'random.test.{0}'.format(self.domain)\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_full_name_filter_should_return_record(self):\n        provider = self._construct_authenticated_provider()\n        provider.create_record('TXT', 'random.fulltest.{0}'.format(\n            self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'random.fulltest.{0}'.format(self.domain))\n        assert len(records) == 1\n        assert records[0]['content'] == 'challengetoken'\n        assert records[0]['type'] == 'TXT'\n        assert records[0]['name'] == 'random.fulltest.{0}'.format(self.domain)\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_fqdn_name_filter_should_return_record(self):\n        provider = self._construct_authenticated_provider()\n        provider.create_record('TXT', 'random.fqdntest.{0}.'.format(\n            self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'random.fqdntest.{0}.'.format(self.domain))\n        assert len(records) == 1\n        assert records[0]['content'] == 'challengetoken'\n        assert records[0]['type'] == 'TXT'\n        assert records[0]['name'] == 'random.fqdntest.{0}'.format(self.domain)\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_after_setting_ttl(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"ttl.fqdn.{0}.\".format(self.domain), 'ttlshouldbe3600')\n        records = provider.list_records(\n            'TXT', 'ttl.fqdn.{0}'.format(self.domain))\n        assert len(records) == 1\n        assert str(records[0]['ttl']) == str(3600)\n\n    @pytest.mark.skip(reason=\"not sure how to test empty list across multiple providers\")\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_should_return_empty_list_if_no_records_found(self):\n        provider = self._construct_authenticated_provider()\n        assert isinstance(provider.list_records(), list)\n\n    @pytest.mark.skip(reason=\"not sure how to test filtering across multiple providers\")\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_arguments_should_filter_list(self):\n        provider = self._construct_authenticated_provider()\n        assert isinstance(provider.list_records(), list)\n\n    ###########################################################################\n    # Provider.update_record()\n    ###########################################################################\n    @_vcr_integration_test\n    def test_provider_when_calling_update_record_should_modify_record(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record('TXT', 'orig.test', 'challengetoken')\n        records = provider.list_records('TXT', 'orig.test')\n        assert provider.update_record(records[0].get(\n            'id', None), 'TXT', 'updated.test', 'challengetoken')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_update_record_should_modify_record_name_specified(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'orig.nameonly.test', 'challengetoken')\n        assert provider.update_record(\n            None, 'TXT', 'orig.nameonly.test', 'updated')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_update_record_with_full_name_should_modify_record(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'orig.testfull.{0}'.format(self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'orig.testfull.{0}'.format(self.domain))\n        assert provider.update_record(records[0].get(\n            'id', None), 'TXT', 'updated.testfull.{0}'.format(self.domain), 'challengetoken')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_update_record_with_fqdn_name_should_modify_record(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'orig.testfqdn.{0}.'.format(self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'orig.testfqdn.{0}.'.format(self.domain))\n        assert provider.update_record(records[0].get(\n            'id', None), 'TXT', 'updated.testfqdn.{0}.'.format(self.domain), 'challengetoken')\n\n    ###########################################################################\n    # Provider.delete_record()\n    ###########################################################################\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_by_identifier_should_remove_record(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record('TXT', 'delete.testid', 'challengetoken')\n        records = provider.list_records('TXT', 'delete.testid')\n        assert provider.delete_record(records[0]['id'])\n        records = provider.list_records('TXT', 'delete.testid')\n        assert not records\n\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_by_filter_should_remove_record(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'delete.testfilt', 'challengetoken')\n        assert provider.delete_record(\n            None, 'TXT', 'delete.testfilt', 'challengetoken')\n        records = provider.list_records('TXT', 'delete.testfilt')\n        assert not records\n\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_by_filter_with_full_name_should_remove_record(self):  # pylint: disable=line-too-long\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'delete.testfull.{0}'.format(self.domain), 'challengetoken')\n        assert provider.delete_record(\n            None, 'TXT', 'delete.testfull.{0}'.format(self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'delete.testfull.{0}'.format(self.domain))\n        assert not records\n\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_by_filter_with_fqdn_name_should_remove_record(self):  # pylint: disable=line-too-long\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', 'delete.testfqdn.{0}.'.format(self.domain), 'challengetoken')\n        assert provider.delete_record(\n            None, 'TXT', 'delete.testfqdn.{0}.'.format(self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', 'delete.testfqdn.{0}.'.format(self.domain))\n        assert not records\n\n    # Private helpers, mimicking the auth_* options provided by the Client\n    # http://stackoverflow.com/questions/6229073/how-to-make-a-python-dictionary-that-returns-key-for-keys-missing-from-the-dicti\n\n    def _test_config(self):\n        \"\"\"\n        This method construct a ConfigResolver suitable for tests.\n        This will resolve any parameters required by Lexicon or the provider in the following order:\n            * parameters that matches the ones provided by _test_parameters_overrides\n            * parameters that matches existing environment variables at the time of test execution\n            * parameters processed throught the lambda provided by _test_fallback_fn.\n\n        See lexicon/providers/base.py for a full list of parameters available.\n        You should not override this method. Just override `self.domain`,\n        or use _test_parameters_overrides() to configure specific parameters for the tests.\n\n        Any parameters that you expect to be passed to the provider via the cli,\n        like --auth_username and --auth_token, will be present during the tests,\n        with a 'placeholder_' prefix.\n\n        options['auth_password'] == 'placeholder_auth_password'\n        options['auth_username'] == 'placeholder_auth_username'\n        options['unique_provider_option'] == 'placeholder_unique_provider_option'\n\n        You can change this behavior by overriding _test_fallback_fn().\n\n        \"\"\"\n        config = ConfigResolver()\n        # First we load the overrides\n        overrides = self._test_parameters_overrides()\n        overrides['domain'] = self.domain\n        overrides['provider_name'] = self.provider_name\n        config.with_config_source(EngineOverrideConfigSource(overrides))\n\n        # Then we get environment variables\n        config.with_env()\n\n        # And finally we provide the fallback function\n        config.with_config_source(\n            FallbackConfigSource(self._test_fallback_fn()))\n\n        return config\n\n    def _test_parameters_overrides(self):  # pylint: disable=no-self-use\n        \"\"\"\n        This method gives an object whose keys are some provider\n        or lexicon parameters expected during a test.\n        If a parameter match on of the key during a test,\n        the associated value will be used authoritatively.\n\n        Example:\n        {'auth_token': 'AUTH_TOKEN'} => if the provider require to use auth_token,\n                                        its value will be always AUTH_TOKEN.\n\n        By default no value is overriden.\n        \"\"\"\n        return {}\n\n    def _test_fallback_fn(self):  # pylint: disable=no-self-use\n        \"\"\"\n        This method gives a fallback lambda for any provider parameter that have not been resolved.\n        By default it will return 'placeholder_[parameter_name]' for a particular parameter\n        (eg. placeholder_auth_token for auth_token).\n        \"\"\"\n        return lambda x: 'placeholder_' + x\n\n    def _cassette_path(self, fixture_subpath):\n        \"\"\"\n        A path customized for the provider's fixture.\n        The default path is, for example:\n            {provider}/IntegrationTests\n        but if the test is a `provider_variant`, the path is customized to the variant:\n            {provider}/{variant_name}-IntegrationTests\n        \"\"\"\n        if self.provider_variant:\n            return \"{0}/{1}-{2}\".format(self.provider_name, self.provider_variant, fixture_subpath)\n        return \"{0}/{1}\".format(self.provider_name, fixture_subpath)\n\n    def _construct_authenticated_provider(self):\n        \"\"\"\n        Construct a new provider, and authenticate it against the target DNS provider API.\n        \"\"\"\n        provider = self.provider_module.Provider(self._test_config())\n        provider.authenticate()\n        return provider\n\n    # Optional. Used to identify the test variant, if any.\n    provider_variant = None\n\n    def _filter_headers(self):  # pylint: disable=no-self-use\n        return []\n\n    def _filter_query_parameters(self):  # pylint: disable=no-self-use\n        return []\n\n    def _filter_post_data_parameters(self):  # pylint: disable=no-self-use\n        return []\n\n    def _filter_request(self, request):  # pylint: disable=no-self-use\n        \"\"\"Filter any sensitive data out of the provider requests. `request`\n        is a Python object with the same structure as all the request sections\n        in the YAML recordings at tests/fixtures/cassettes/[provider]. For the\n        sake of sparing you some time the most important values are:\n\n        request['body']['string']: Contains the HTML or JSON request body.\n        request['uri']: The URI used for this request (URL + parameters)\n        response['headers']: An object whose keys are HTTP header names\n                             e.g. request['headers']['Accept'].\n        \"\"\"\n        return request\n\n    def _filter_response(self, response):  # pylint: disable=no-self-use\n        \"\"\"Filter any sensitive data out of the provider responses. `response`\n        is a Python object with the same structure as all the response sections\n        in the YAML recordings at tests/fixtures/cassettes/[provider]. For the\n        sake of sparing you some time the most important values are:\n\n        response['body']['string']: Contains the HTML or JSON response body.\n        response['headers']: An object whose keys are HTTP header names\n                             e.g. response['headers']['content-length'].\n        response['status']: An object that contains 'code' and 'message'\n                            subkeys representing the HTTP status code and\n                            status message.\n        \"\"\"\n        return response\n\n\nclass IntegrationTestsV2(IntegrationTestsV1):\n    \"\"\"\n    New version of the reusable IntegrationTests class, that includes all tests from\n    IntegrationTestsV1, plus new tests related to validation for Create Record NOOP & Record Sets.\n\n    IntegrationTestsV2 should be used for new providers, and for existing providers during\n    their refactoring.\n    \"\"\"\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_with_duplicate_records_should_be_noop(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.noop.{0}.\".format(self.domain), 'challengetoken')\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.noop.{0}.\".format(self.domain), 'challengetoken')\n        records = provider.list_records(\n            'TXT', \"_acme-challenge.noop.{0}.\".format(self.domain))\n        assert len(records) == 1\n\n    @_vcr_integration_test\n    def test_provider_when_calling_create_record_multiple_times_should_create_record_set(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.createrecordset.{0}.\".format(self.domain), 'challengetoken1')\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.createrecordset.{0}.\".format(self.domain), 'challengetoken2')\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_with_invalid_filter_should_be_empty_list(self):\n        provider = self._construct_authenticated_provider()\n        records = provider.list_records(\n            'TXT', 'filter.thisdoesnotexist.{0}'.format(self.domain))\n        assert not records\n\n    @_vcr_integration_test\n    def test_provider_when_calling_list_records_should_handle_record_sets(self):\n        provider = self._construct_authenticated_provider()\n        provider.create_record(\n            'TXT', \"_acme-challenge.listrecordset.{0}.\".format(self.domain), 'challengetoken1')\n        provider.create_record(\n            'TXT', \"_acme-challenge.listrecordset.{0}.\".format(self.domain), 'challengetoken2')\n        records = provider.list_records(\n            'TXT', '_acme-challenge.listrecordset.{0}.'.format(self.domain))\n        assert len(records) == 2\n\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_with_record_set_name_remove_all(self):\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.deleterecordset.{0}.\".format(self.domain), 'challengetoken1')\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.deleterecordset.{0}.\".format(self.domain), 'challengetoken2')\n\n        assert provider.delete_record(\n            None, 'TXT', '_acme-challenge.deleterecordset.{0}.'.format(self.domain))\n        records = provider.list_records(\n            'TXT', '_acme-challenge.deleterecordset.{0}.'.format(self.domain))\n        assert not records\n\n    @_vcr_integration_test\n    def test_provider_when_calling_delete_record_with_record_set_by_content_should_leave_others_untouched(self):  # pylint: disable=line-too-long\n        provider = self._construct_authenticated_provider()\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.deleterecordinset.{0}.\".format(self.domain), 'challengetoken1')\n        assert provider.create_record(\n            'TXT', \"_acme-challenge.deleterecordinset.{0}.\".format(self.domain), 'challengetoken2')\n\n        assert provider.delete_record(\n            None, 'TXT', '_acme-challenge.deleterecordinset.{0}.'\n            .format(self.domain), 'challengetoken1')\n        records = provider.list_records(\n            'TXT', '_acme-challenge.deleterecordinset.{0}.'.format(self.domain))\n        assert len(records) == 1\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"Integration tests for Glesys\"\"\"\nfrom unittest import TestCase\n\nimport pytest\nfrom lexicon.tests.providers.integration_tests import IntegrationTestsV1\n\n\n# Hook into testing framework by inheriting unittest.TestCase and reuse\n# the tests which *each and every* implementation of the interface must\n# pass, by inheritance from define_tests.TheTests\n# TODO: migrate to IntegrationTestsV2 and its extended test suite\nclass GlesysProviderTests(TestCase, IntegrationTestsV1):\n    \"\"\"TestCase for Glesys\"\"\"\n    provider_name = 'glesys'\n    domain = \"capsulecd.com\"\n\n    def _filter_headers(self):\n        return ['Authorization']\n\n    # TODO: enable the skipped tests\n    @pytest.mark.skip(reason=\"new test, missing recording\")\n    def test_provider_when_calling_update_record_should_modify_record_name_specified(self):\n        return\n"
  },
  {
    "prompt": "\n\n### legal-api/tests/unit/services/utils.py ###\n\n# Copyright \u00a9 2019 Province of British Columbia\n#\n# Licensed under the Apache License, Version 2.0 (the 'License');\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an 'AS IS' BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Data for the JWT tokens.\"\"\"\nfrom typing import List\n\n\nSTAFF_ROLE = 'staff'\n\n\ndef helper_create_jwt(jwt_manager, roles: List[str] = [], username: str = 'test-user'):\n    \"\"\"Create a jwt bearer token with the correct keys, roles and username.\"\"\"\n    token_header = {\n        'alg': 'RS256',\n        'typ': 'JWT',\n        'kid': 'flask-jwt-oidc-test-client'\n    }\n    claims = {\n        'iss': 'https://example.localdomain/auth/realms/example',\n        'sub': '43e6a245-0bf7-4ccf-9bd0-e7fb85fd18cc',\n        'aud': 'example',\n        'exp': 2539722391,\n        'iat': 1539718791,\n        'jti': 'flask-jwt-oidc-test-support',\n        'typ': 'Bearer',\n        'username': f'{username}',\n        'realm_access': {\n            'roles': [] + roles\n        }\n    }\n    return jwt_manager.create_jwt(claims, token_header)\n\n\ndef create_header(jwt_manager, roles: List[str] = [], username: str = 'test-user', **kwargs):\n    \"\"\"Return a header containing a JWT bearer token.\"\"\"\n    token = helper_create_jwt(jwt_manager, roles=roles, username=username)\n    headers = {**kwargs, **{'Authorization': 'Bearer ' + token}}\n    return headers\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright \u00a9 2019 Province of British Columbia\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests to assure the Authorization Services.\n\nTest-Suite to ensure that the Authorization Service is working as expected.\n\"\"\"\nfrom http import HTTPStatus\n\nimport pytest\nfrom flask import jsonify\nfrom legal_api.models.business import Business\n\nfrom legal_api.services.authz import BASIC_USER, COLIN_SVC_ROLE, STAFF_ROLE, authorized, get_allowed, is_allowed\nfrom tests import integration_authorization, not_github_ci\n\nfrom .utils import helper_create_jwt\n\n\ndef test_jwt_manager_initialized(jwt):\n    \"\"\"Assert that the jwt_manager is created as part of the fixtures.\"\"\"\n    assert jwt\n\n\n@not_github_ci\ndef test_jwt_manager_correct_test_config(app_request, jwt):\n    \"\"\"Assert that the test configuration for the JWT is working as expected.\"\"\"\n    message = 'This is a protected end-point'\n    protected_route = '/fake_jwt_route'\n\n    @app_request.route(protected_route)\n    @jwt.has_one_of_roles([STAFF_ROLE])\n    def get():\n        return jsonify(message=message)\n\n    # assert that JWT is setup correctly for a known role\n    token = helper_create_jwt(jwt, [STAFF_ROLE])\n    headers = {'Authorization': 'Bearer ' + token}\n    rv = app_request.test_client().get(protected_route, headers=headers)\n    assert rv.status_code == HTTPStatus.OK\n\n    # assert the JWT fails for an unknown role\n    token = helper_create_jwt(jwt, ['SHOULD-FAIL'])\n    headers = {'Authorization': 'Bearer ' + token}\n    rv = app_request.test_client().get(protected_route, headers=headers)\n    assert rv.status_code == HTTPStatus.UNAUTHORIZED\n\n\nTEST_AUTHZ_DATA = [\n    ('staff_role',  # test name\n     'CP1234567',  # business identifier\n     'happy-staff',  # username\n     [STAFF_ROLE],  # roles\n     ['view', 'edit'],  # allowed actions\n     ['edit'],  # requested action\n     HTTPStatus.OK),  # expected response\n    ('colin svc role', 'CP1234567', 'CP1234567', [COLIN_SVC_ROLE], ['view', 'edit'], ['edit'],\n     HTTPStatus.OK),\n    ('authorized_user', 'CP0001237', 'CP1234567', [BASIC_USER], ['view', 'edit'], ['edit'],\n     HTTPStatus.OK),\n    ('unauthorized_user', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, ['edit'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('missing_action', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, None,\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('invalid_action', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, ['scrum'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('add_comment_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['add_comment'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('court_order_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['court_order'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('registrars_notation_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['registrars_notation'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('registrars_order_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['registrars_order'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n]\n\n\n@not_github_ci\n@pytest.mark.parametrize('test_name,identifier,username,roles,allowed_actions,requested_actions,expected',\n                         TEST_AUTHZ_DATA)\ndef test_authorized_user(monkeypatch, app_request, jwt,\n                         test_name, identifier, username, roles, allowed_actions, requested_actions, expected):\n    \"\"\"Assert that the type of user authorization is correct, based on the expected outcome.\"\"\"\n    from requests import Response\n    print(test_name)\n\n    # mocks, the get and json calls for requests.Response\n    def mock_get(*args, **kwargs):  # pylint: disable=unused-argument; mocks of library methods\n        resp = Response()\n        resp.status_code = 200\n        return resp\n\n    def mock_json(self, **kwargs):  # pylint: disable=unused-argument; mocks of library methods\n        return {'roles': allowed_actions}\n\n    monkeypatch.setattr('requests.sessions.Session.get', mock_get)\n    monkeypatch.setattr('requests.Response.json', mock_json)\n\n    # setup\n    @app_request.route('/fake_jwt_route/<string:identifier>')\n    @jwt.requires_auth\n    def get_fake(identifier: str):\n        if not authorized(identifier, jwt, ['view']):\n            return jsonify(message='failed'), HTTPStatus.METHOD_NOT_ALLOWED\n        return jsonify(message='success'), HTTPStatus.OK\n\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    # test it\n    rv = app_request.test_client().get(f'/fake_jwt_route/{identifier}', headers=headers)\n\n    # check it\n    assert rv.status_code == expected\n\n\nTEST_INTEG_AUTHZ_DATA = [\n    ('staff_role',  # test name\n     'CP1234567',  # business identifier\n     'happy-staff',  # username\n     [STAFF_ROLE],  # roles\n     ['view', 'edit'],  # allowed actions\n     ['edit'],  # requested action\n     HTTPStatus.OK),  # expected response\n    ('colin svc role', 'CP1234567', 'CP1234567', [COLIN_SVC_ROLE], ['view', 'edit'], ['edit'],\n     HTTPStatus.OK),\n    ('unauthorized_user', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, ['edit'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('missing_action', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, None,\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('invalid_action', 'CP1234567', 'Not-Match-Identifier', [BASIC_USER], None, ['scrum'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('add_comment_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['add_comment'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('court_order_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['court_order'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('registrars_notation_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['registrars_notation'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n    ('registrars_order_not_allowed', 'CP0001237', 'CP1234567', [BASIC_USER], None, ['registrars_order'],\n     HTTPStatus.METHOD_NOT_ALLOWED),\n]\n\n\n@integration_authorization\n@pytest.mark.parametrize('test_name,identifier,username,roles,allowed_actions,requested_actions,expected',\n                         TEST_INTEG_AUTHZ_DATA)\ndef test_authorized_user_integ(monkeypatch, app, jwt,\n                               test_name, identifier, username, roles, allowed_actions, requested_actions, expected):\n    \"\"\"Assert that the type of user authorization is correct, based on the expected outcome.\"\"\"\n    import flask  # noqa: F401; import actually used in mock\n    # setup\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    def mock_auth(one, two):  # pylint: disable=unused-argument; mocks of library methods\n        return headers['Authorization']\n\n    with app.test_request_context():\n        monkeypatch.setattr('flask.request.headers.get', mock_auth)\n\n        rv = authorized(identifier, jwt, ['view'])\n\n# check it\n    if expected == HTTPStatus.OK:\n        assert rv\n    else:\n        assert not rv\n\n\ndef test_authorized_missing_args():\n    \"\"\"Assert that the missing args return False.\"\"\"\n    identifier = 'a corp'\n    jwt = 'fake'\n    action = 'fake'\n\n    rv = authorized(identifier, jwt, None)\n    assert not rv\n\n    rv = authorized(identifier, None, action)\n    assert not rv\n\n    rv = authorized(None, jwt, action)\n    assert not rv\n\n\ndef test_authorized_bad_url(monkeypatch, app, jwt):\n    \"\"\"Assert that an invalid auth service URL returns False.\"\"\"\n    import flask  # noqa: F401; import actually used in mock\n    # setup\n    identifier = 'CP1234567'\n    username = 'username'\n    roles = [BASIC_USER]\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    def mock_auth(one, two):  # pylint: disable=unused-argument; mocks of library methods\n        return headers['Authorization']\n\n    with app.test_request_context():\n        monkeypatch.setattr('flask.request.headers.get', mock_auth)\n        auth_svc_url = app.config['AUTH_SVC_URL']\n        app.config['AUTH_SVC_URL'] = 'http://no.way.this.works/dribble'\n\n        rv = authorized(identifier, jwt, ['view'])\n\n        app.config['AUTH_SVC_URL'] = auth_svc_url\n\n    assert not rv\n\n\ndef test_authorized_invalid_roles(monkeypatch, app, jwt):\n    \"\"\"Assert that an invalid role returns False.\"\"\"\n    import flask  # noqa: F401 ; import actually used in mock\n    # setup noqa: I003\n    identifier = 'CP1234567'\n    username = 'username'\n    roles = ['NONE']\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    def mock_auth(one, two):  # pylint: disable=unused-argument; mocks of library methods\n        return headers['Authorization']\n\n    with app.test_request_context():\n        monkeypatch.setattr('flask.request.headers.get', mock_auth)\n        rv = authorized(identifier, jwt, ['view'])\n\n    assert not rv\n\n\n@pytest.mark.parametrize(\n    'test_name,state,legal_type,username,roles,expected',\n    [\n        # active business\n        ('staff_active_cp', Business.State.ACTIVE, 'CP', 'staff', [STAFF_ROLE],\n         ['annualReport', 'changeOfAddress', 'changeOfDirectors', 'correction',\n            'courtOrder', 'dissolution', 'incorporationApplication',\n            'specialResolution', 'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_bc', Business.State.ACTIVE, 'BC', 'staff', [STAFF_ROLE],\n         ['alteration', 'courtOrder', 'dissolution', 'incorporationApplication',\n            'transition', 'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_ben', Business.State.ACTIVE, 'BEN', 'staff', [STAFF_ROLE],\n         ['alteration', 'annualReport', 'changeOfAddress', 'changeOfDirectors', 'conversion', 'correction',\n            'courtOrder', 'dissolution', 'incorporationApplication',\n            'transition', 'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_cc', Business.State.ACTIVE, 'CC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'dissolution',\n         'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_ulc', Business.State.ACTIVE, 'ULC', 'staff', [STAFF_ROLE],\n         ['alteration', 'courtOrder', 'dissolution',\n         'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_llc', Business.State.ACTIVE, 'LLC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'dissolution',\n         'registrarsNotation', 'registrarsOrder']),\n        ('staff_active_sp', Business.State.ACTIVE, 'SP', 'staff', [STAFF_ROLE],\n         ['changeOfRegistration', 'conversion', 'dissolution', 'registration']),\n        ('staff_active_gp', Business.State.ACTIVE, 'GP', 'staff', [STAFF_ROLE],\n         ['changeOfRegistration', 'conversion', 'dissolution', 'registration']),\n\n        ('user_active_cp', Business.State.ACTIVE, 'CP', 'user', [BASIC_USER],\n         ['annualReport', 'changeOfAddress', 'changeOfDirectors',\n          'dissolution', 'incorporationApplication', 'specialResolution']),\n        ('user_active_bc', Business.State.ACTIVE, 'BC', 'user', [BASIC_USER],\n         ['alteration', 'dissolution', 'incorporationApplication', 'transition']),\n        ('user_active_ben', Business.State.ACTIVE, 'BEN', 'user', [BASIC_USER],\n         ['alteration', 'annualReport', 'changeOfAddress', 'changeOfDirectors',\n            'dissolution', 'incorporationApplication', 'transition']),\n        ('user_active_cc', Business.State.ACTIVE, 'CC', 'user', [BASIC_USER], ['dissolution']),\n        ('user_active_ulc', Business.State.ACTIVE, 'ULC', 'user', [BASIC_USER], ['alteration', 'dissolution']),\n        ('user_active_llc', Business.State.ACTIVE, 'LLC', 'user', [BASIC_USER], ['dissolution']),\n        ('user_active_sp', Business.State.ACTIVE, 'SP', 'user', [BASIC_USER], ['changeOfRegistration', 'dissolution', 'registration']),\n        ('user_active_gp', Business.State.ACTIVE, 'GP', 'user', [BASIC_USER], ['changeOfRegistration', 'dissolution', 'registration']),\n\n        # historical business\n        ('staff_historical_cp', Business.State.HISTORICAL, 'CP', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration']}]),\n        ('staff_historical_bc', Business.State.HISTORICAL, 'BC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration', 'limitedRestoration']}]),\n        ('staff_historical_ben', Business.State.HISTORICAL, 'BEN', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration', 'limitedRestoration']}]),\n        ('staff_historical_cc', Business.State.HISTORICAL, 'CC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration', 'limitedRestoration']}]),\n        ('staff_historical_ulc', Business.State.HISTORICAL, 'ULC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration', 'limitedRestoration']}]),\n        ('staff_historical_llc', Business.State.HISTORICAL, 'LLC', 'staff', [STAFF_ROLE],\n         ['courtOrder', 'registrarsNotation', 'registrarsOrder',\n         {'restoration': ['fullRestoration', 'limitedRestoration']}]),\n\n        ('user_historical_llc', Business.State.HISTORICAL, 'LLC', 'user', [BASIC_USER], []),\n    ]\n)\ndef test_get_allowed(monkeypatch, app, jwt, test_name, state, legal_type, username, roles, expected):\n    \"\"\"Assert that get allowed returns valid filings.\"\"\"\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    def mock_auth(one, two):  # pylint: disable=unused-argument; mocks of library methods\n        return headers[one]\n\n    with app.test_request_context():\n        monkeypatch.setattr('flask.request.headers.get', mock_auth)\n        filing_types = get_allowed(state, legal_type, jwt)\n        assert filing_types == expected\n\n\n@pytest.mark.parametrize(\n    'test_name,state,filing_type,sub_filing_type,legal_types,username,roles,expected',\n    [\n        # active business\n        ('staff_active_allowed', Business.State.ACTIVE, 'alteration', None,\n         ['BC', 'BEN', 'ULC'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'alteration', None,\n         ['CP', 'CC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'annualReport', None,\n         ['CP', 'BEN'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'annualReport', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'changeOfAddress', None,\n         ['CP', 'BEN'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'changeOfAddress', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'changeOfDirectors', None,\n         ['CP', 'BEN'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'changeOfDirectors', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'correction', None,\n         ['CP', 'BEN'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'correction', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'courtOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'dissolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC', 'SP', 'GP'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'incorporationApplication', None,\n         ['CP', 'BC', 'BEN'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active', Business.State.ACTIVE, 'restoration', 'fullRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n        ('staff_active', Business.State.ACTIVE, 'restoration', 'limitedRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'specialResolution', None, ['CP'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'specialResolution', None,\n         ['BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'transition', None,\n         ['BC', 'BEN'], 'staff', [STAFF_ROLE], True),\n        ('staff_active', Business.State.ACTIVE, 'transition', None,\n         ['CP', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'registrarsNotation', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'registrarsOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'registration', None,\n         ['SP', 'GP'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_active_allowed', Business.State.ACTIVE, 'changeOfRegistration', None,\n         ['SP', 'GP'], 'staff', [STAFF_ROLE], True),\n\n\n        ('user_active_allowed', Business.State.ACTIVE, 'alteration', None,\n         ['BC', 'BEN', 'ULC'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'alteration', None,\n         ['CP', 'CC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'annualReport', None, ['CP', 'BEN'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'annualReport', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'changeOfAddress', None,\n         ['CP', 'BEN'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'changeOfAddress', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'changeOfDirectors', None,\n         ['CP', 'BEN'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'changeOfDirectors', None,\n         ['BC', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active', Business.State.ACTIVE, 'correction', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active', Business.State.ACTIVE, 'courtOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'dissolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC', 'SP', 'GP'], 'user', [BASIC_USER], True),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'incorporationApplication', None,\n         ['CP', 'BC', 'BEN'], 'user', [BASIC_USER], True),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'registration', None,\n         ['SP', 'GP'], 'user', [BASIC_USER], True),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'changeOfRegistration', None,\n         ['SP', 'GP'], 'user', [BASIC_USER], True),\n\n        ('user_active', Business.State.ACTIVE, 'restoration', 'fullRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active', Business.State.ACTIVE, 'restoration', 'limitedRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'specialResolution', None, ['CP'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'specialResolution', None,\n         ['BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active_allowed', Business.State.ACTIVE, 'transition', None, ['BC', 'BEN'], 'user', [BASIC_USER], True),\n        ('user_active', Business.State.ACTIVE, 'transition', None,\n         ['CP', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active', Business.State.ACTIVE, 'registrarsNotation', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_active', Business.State.ACTIVE, 'registrarsOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        # historical business\n        ('staff_historical', Business.State.HISTORICAL, 'alteration', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'annualReport', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'changeOfAddress', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'changeOfDirectors', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'correction', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical_allowed', Business.State.HISTORICAL, 'courtOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_historical', Business.State.HISTORICAL, 'dissolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC', 'SP', 'GP'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'incorporationApplication', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical_allowed', Business.State.HISTORICAL, 'restoration', 'fullRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_historical_allowed', Business.State.HISTORICAL, 'restoration', 'limitedRestoration',\n         ['BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n        ('staff_historical', Business.State.HISTORICAL, 'restoration', 'limitedRestoration',\n         ['CP'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'specialResolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'transition', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical_allowed', Business.State.HISTORICAL, 'registrarsNotation', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_historical_allowed', Business.State.HISTORICAL, 'registrarsOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'staff', [STAFF_ROLE], True),\n\n        ('staff_historical', Business.State.HISTORICAL, 'registration', None,\n         ['SP', 'GP'], 'staff', [STAFF_ROLE], False),\n\n        ('staff_historical', Business.State.HISTORICAL, 'changeOfRegistration', None,\n         ['SP', 'GP'], 'staff', [STAFF_ROLE], False),\n\n\n        ('user_historical', Business.State.HISTORICAL, 'alteration', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'annualReport', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'changeOfAddress', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'changeOfDirectors', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'correction', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'courtOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'dissolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC', 'SP', 'GP', 'SP', 'GP'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'incorporationApplication', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'restoration', 'fullRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'restoration', 'limitedRestoration',\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'specialResolution', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'transition', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'registrarsNotation', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'registrarsOrder', None,\n         ['CP', 'BC', 'BEN', 'CC', 'ULC', 'LLC'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'registration', None,\n         ['SP', 'GP'], 'user', [BASIC_USER], False),\n\n        ('user_historical', Business.State.HISTORICAL, 'changeOfRegistration', None,\n         ['SP', 'GP'], 'user', [BASIC_USER], False),\n    ]\n)\ndef test_is_allowed(monkeypatch, app, jwt, test_name, state, filing_type, sub_filing_type,\n                    legal_types, username, roles, expected):\n    \"\"\"Assert that get allowed returns valid filings.\"\"\"\n    token = helper_create_jwt(jwt, roles=roles, username=username)\n    headers = {'Authorization': 'Bearer ' + token}\n\n    def mock_auth(one, two):  # pylint: disable=unused-argument; mocks of library methods\n        return headers[one]\n\n    with app.test_request_context():\n        monkeypatch.setattr('flask.request.headers.get', mock_auth)\n        for legal_type in legal_types:\n            filing_types = is_allowed(state, filing_type, legal_type, jwt, sub_filing_type)\n            assert filing_types == expected\n"
  },
  {
    "prompt": "\n\n### async_lru.py ###\n\nimport asyncio\nfrom collections import OrderedDict\nfrom functools import _CacheInfo, _make_key, partial, wraps\nfrom time import time\n\ntry:\n    from asyncio import ensure_future\nexcept ImportError:  # pragma: no cover\n    ensure_future = getattr(asyncio, 'async')\n\n__version__ = '1.0.1'\n\n__all__ = ('alru_cache',)\n\n\ndef create_future(*, loop):\n    try:\n        return loop.create_future()\n    except AttributeError:\n        return asyncio.Future(loop=loop)\n\n\ndef unpartial(fn):\n    while hasattr(fn, 'func'):\n        fn = fn.func\n\n    return fn\n\n\ndef _done_callback(fut, task):\n    if task.cancelled():\n        fut.cancel()\n        return\n\n    exc = task.exception()\n    if exc is not None:\n        fut.set_exception(exc)\n        return\n\n    fut.set_result(task.result())\n\n\ndef _cache_invalidate(wrapped, typed, *args, **kwargs):\n    key = _make_key(args, kwargs, typed)\n\n    exists = key in wrapped._cache\n\n    if exists:\n        wrapped._cache.pop(key)\n\n    return exists\n\n\ndef _cache_clear(wrapped):\n    wrapped.hits = wrapped.misses = 0\n    wrapped._cache = OrderedDict()\n    wrapped.tasks = set()\n\n\ndef _open(wrapped):\n    if not wrapped.closed:\n        raise RuntimeError('alru_cache is not closed')\n\n    was_closed = (\n        wrapped.hits ==\n        wrapped.misses ==\n        len(wrapped.tasks) ==\n        len(wrapped._cache) ==\n        0\n    )\n\n    if not was_closed:\n        raise RuntimeError('alru_cache was not closed correctly')\n\n    wrapped.closed = False\n\n\ndef _close(wrapped, *, cancel=False, return_exceptions=True, loop=None):\n    if wrapped.closed:\n        raise RuntimeError('alru_cache is closed')\n\n    wrapped.closed = True\n\n    if cancel:\n        for task in wrapped.tasks:\n            if not task.done():  # not sure is it possible\n                task.cancel()\n\n    return _wait_closed(\n        wrapped,\n        return_exceptions=return_exceptions,\n        loop=loop\n    )\n\n\n@asyncio.coroutine\ndef _wait_closed(wrapped, *, return_exceptions, loop):\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    wait_closed = asyncio.gather(\n        *wrapped.tasks,\n        return_exceptions=return_exceptions,\n        loop=loop\n    )\n\n    wait_closed.add_done_callback(partial(_close_waited, wrapped))\n\n    ret = yield from wait_closed\n\n    # hack to get _close_waited callback to be executed\n    yield from asyncio.sleep(0, loop=loop)\n\n    return ret\n\n\ndef _close_waited(wrapped, _):\n    wrapped.cache_clear()\n\n\ndef _cache_info(wrapped, maxsize):\n    return _CacheInfo(\n        wrapped.hits,\n        wrapped.misses,\n        maxsize,\n        len(wrapped._cache),\n    )\n\n\ndef __cache_touch(wrapped, key):\n    try:\n        wrapped._cache.move_to_end(key)\n    except KeyError:  # not sure is it possible\n        pass\n\n\ndef _cache_hit(wrapped, key):\n    wrapped.hits += 1\n    __cache_touch(wrapped, key)\n\n\ndef _cache_miss(wrapped, key):\n    wrapped.misses += 1\n    __cache_touch(wrapped, key)\n\n\ndef _get_loop(cls, kwargs, fn, fn_args, fn_kwargs, *, loop):\n    if isinstance(loop, str):\n        assert cls ^ kwargs, 'choose self.loop or kwargs[\"loop\"]'\n\n        if cls:\n            _self = getattr(fn, '__self__', None)\n\n            if _self is None:\n                assert fn_args, 'seems not unbound function'\n                _self = fn_args[0]\n\n            _loop = getattr(_self, loop)\n        else:\n            _loop = fn_kwargs[loop]\n    elif loop is None:\n        _loop = asyncio.get_event_loop()\n    else:\n        _loop = loop\n\n    return _loop\n\n\ndef alru_cache(\n    fn=None,\n    maxsize=128,\n    typed=False,\n    expiration_time=None,\n    *,\n    cls=False,\n    kwargs=False,\n    cache_exceptions=True,\n    loop=None\n):\n    def wrapper(fn):\n        _origin = unpartial(fn)\n\n        if not asyncio.iscoroutinefunction(_origin):\n            raise RuntimeError(\n                'Coroutine function is required, got {}'.format(fn))\n\n        # functools.partialmethod support\n        if hasattr(fn, '_make_unbound_method'):\n            fn = fn._make_unbound_method()\n\n        @wraps(fn)\n        @asyncio.coroutine\n        def wrapped(*fn_args, **fn_kwargs):\n            if wrapped.closed:\n                raise RuntimeError(\n                    'alru_cache is closed for {}'.format(wrapped))\n\n            _loop = _get_loop(\n                cls,\n                kwargs,\n                wrapped._origin,\n                fn_args,\n                fn_kwargs,\n                loop=loop\n            )\n\n            key = _make_key(fn_args, fn_kwargs, typed)\n\n            if wrapped._cache.get(key) is not None:\n                if expiration_time is None:\n                    fut = wrapped._cache.get(key)\n\n                    if not fut.done():\n                        _cache_hit(wrapped, key)\n                        return (yield from asyncio.shield(fut, loop=_loop))\n\n                    exc = fut._exception\n\n                    if exc is None or cache_exceptions:\n                        _cache_hit(wrapped, key)\n                        return fut.result()\n\n                    # exception here and cache_exceptions == False\n                    wrapped._cache.pop(key)\n\n                else:\n                    fut = wrapped._cache.get(key).get(\"fut\")\n                    fut_time = wrapped._cache.get(key).get(\"time\")\n\n                    if not fut.done():\n                        _cache_hit(wrapped, key)\n                        return (yield from asyncio.shield(fut, loop=_loop))\n\n                    exc = fut._exception\n\n                    if (\n                        exc is None or cache_exceptions\n                    ) and time() - fut_time < expiration_time:\n                        _cache_hit(wrapped, key)\n                        return fut.result()\n\n                    # exception here and cache_exceptions == False\n                    # or result expires\n                    wrapped._cache.pop(key)\n\n            fut = create_future(loop=_loop)\n            coro = fn(*fn_args, **fn_kwargs)\n            task = ensure_future(coro, loop=_loop)\n            task.add_done_callback(partial(_done_callback, fut))\n\n            wrapped.tasks.add(task)\n            task.add_done_callback(wrapped.tasks.remove)\n\n            if expiration_time is None:\n                wrapped._cache[key] = task\n            else:\n                wrapped._cache[key] = {\"fut\": task, \"time\": time()}\n\n            if maxsize is not None and len(wrapped._cache) > maxsize:\n                wrapped._cache.popitem(last=False)\n\n            _cache_miss(wrapped, key)\n            return (yield from asyncio.shield(fut, loop=_loop))\n\n        _cache_clear(wrapped)\n        wrapped._origin = _origin\n        wrapped.closed = False\n        wrapped.cache_info = partial(_cache_info, wrapped, maxsize)\n        wrapped.cache_clear = partial(_cache_clear, wrapped)\n        wrapped.invalidate = partial(_cache_invalidate, wrapped, typed)\n        wrapped.close = partial(_close, wrapped)\n        wrapped.open = partial(_open, wrapped)\n\n        return wrapped\n\n    if fn is None:\n        return wrapper\n\n    if callable(fn) or hasattr(fn, '_make_unbound_method'):\n        return wrapper(fn)\n\n    raise NotImplementedError('{} decorating is not supported'.format(fn))\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import asyncio\nimport time\n\nimport pytest\n\nfrom async_lru import alru_cache\n\npytestmark = pytest.mark.asyncio\n\n\nasync def test_expiration(check_lru, loop):\n    @alru_cache(maxsize=4, expiration_time=2, loop=loop)\n    async def coro(val):\n        return val\n\n    inputs = [1, 2, 3]\n    coros = [coro(v) for v in inputs]\n    ret = await asyncio.gather(*coros, loop=loop)\n    assert ret == inputs\n    check_lru(coro, hits=0, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(1)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=3, cache=3, tasks=0, maxsize=4)\n\n    time.sleep(3)\n    inputs = 1\n    ret = await coro(inputs)\n    assert ret == inputs\n    check_lru(coro, hits=1, misses=4, cache=3, tasks=0, maxsize=4)\n"
  },
  {
    "prompt": "\n\n### doctr/utils/metrics.py ###\n\n# Copyright (C) 2021, Mindee.\n\n# This program is licensed under the Apache License version 2.\n# See LICENSE or go to <https://www.apache.org/licenses/LICENSE-2.0.txt> for full license details.\n\nimport numpy as np\nimport cv2\nfrom typing import List, Tuple, Dict, Optional\nfrom unidecode import unidecode\nfrom scipy.optimize import linear_sum_assignment\nfrom doctr.utils.geometry import rbbox_to_polygon\n\n__all__ = ['TextMatch', 'box_iou', 'box_ioa', 'mask_iou', 'rbox_to_mask',\n           'nms', 'LocalizationConfusion', 'OCRMetric']\n\n\ndef string_match(word1: str, word2: str) -> Tuple[bool, bool, bool, bool]:\n    \"\"\"Perform string comparison with multiple levels of tolerance\n\n    Args:\n        word1: a string\n        word2: another string\n\n    Returns:\n        a tuple with booleans specifying respectively whether the raw strings, their lower-case counterparts, their\n            unidecode counterparts and their lower-case unidecode counterparts match\n    \"\"\"\n    raw_match = (word1 == word2)\n    caseless_match = (word1.lower() == word2.lower())\n    unidecode_match = (unidecode(word1) == unidecode(word2))\n\n    # Warning: the order is important here otherwise the pair (\"EUR\", \"\u20ac\") cannot be matched\n    unicase_match = (unidecode(word1).lower() == unidecode(word2).lower())\n\n    return raw_match, caseless_match, unidecode_match, unicase_match\n\n\nclass TextMatch:\n    \"\"\"Implements text match metric (word-level accuracy) for recognition task.\n\n    The raw aggregated metric is computed as follows:\n\n    .. math::\n        \\\\forall X, Y \\\\in \\\\mathcal{W}^N,\n        TextMatch(X, Y) = \\\\frac{1}{N} \\\\sum\\\\limits_{i=1}^N f_{Y_i}(X_i)\n\n    with the indicator function :math:`f_{a}` defined as:\n\n    .. math::\n        \\\\forall a, x \\\\in \\\\mathcal{W},\n        f_a(x) = \\\\left\\\\{\n            \\\\begin{array}{ll}\n                1 & \\\\mbox{if } x = a \\\\\\\\\n                0 & \\\\mbox{otherwise.}\n            \\\\end{array}\n        \\\\right.\n\n    where :math:`\\\\mathcal{W}` is the set of all possible character sequences,\n    :math:`N` is a strictly positive integer.\n\n    Example::\n        >>> from doctr.utils import TextMatch\n        >>> metric = TextMatch()\n        >>> metric.update(['Hello', 'world'], ['hello', 'world'])\n        >>> metric.summary()\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.reset()\n\n    def update(\n        self,\n        gt: List[str],\n        pred: List[str],\n    ) -> None:\n        \"\"\"Update the state of the metric with new predictions\n\n        Args:\n            gt: list of groung-truth character sequences\n            pred: list of predicted character sequences\"\"\"\n\n        if len(gt) != len(pred):\n            raise AssertionError(\"prediction size does not match with ground-truth labels size\")\n\n        for gt_word, pred_word in zip(gt, pred):\n            _raw, _caseless, _unidecode, _unicase = string_match(gt_word, pred_word)\n            self.raw += int(_raw)\n            self.caseless += int(_caseless)\n            self.unidecode += int(_unidecode)\n            self.unicase += int(_unicase)\n\n        self.total += len(gt)\n\n    def summary(self) -> Dict[str, float]:\n        \"\"\"Computes the aggregated metrics\n\n        Returns:\n            a dictionary with the exact match score for the raw data, its lower-case counterpart, its unidecode\n            counterpart and its lower-case unidecode counterpart\n        \"\"\"\n        if self.total == 0:\n            raise AssertionError(\"you need to update the metric before getting the summary\")\n\n        return dict(\n            raw=self.raw / self.total,\n            caseless=self.caseless / self.total,\n            unidecode=self.unidecode / self.total,\n            unicase=self.unicase / self.total,\n        )\n\n    def reset(self) -> None:\n        self.raw = 0\n        self.caseless = 0\n        self.unidecode = 0\n        self.unicase = 0\n        self.total = 0\n\n\ndef box_iou(boxes_1: np.ndarray, boxes_2: np.ndarray) -> np.ndarray:\n    \"\"\"Compute the IoU between two sets of bounding boxes\n\n    Args:\n        boxes_1: bounding boxes of shape (N, 4) in format (xmin, ymin, xmax, ymax)\n        boxes_2: bounding boxes of shape (M, 4) in format (xmin, ymin, xmax, ymax)\n    Returns:\n        the IoU matrix of shape (N, M)\n    \"\"\"\n\n    iou_mat = np.zeros((boxes_1.shape[0], boxes_2.shape[0]), dtype=np.float32)\n\n    if boxes_1.shape[0] > 0 and boxes_2.shape[0] > 0:\n        l1, t1, r1, b1 = np.split(boxes_1, 4, axis=1)\n        l2, t2, r2, b2 = np.split(boxes_2, 4, axis=1)\n\n        left = np.maximum(l1, l2.T)\n        top = np.maximum(t1, t2.T)\n        right = np.minimum(r1, r2.T)\n        bot = np.minimum(b1, b2.T)\n\n        intersection = np.clip(right - left, 0, np.Inf) * np.clip(bot - top, 0, np.Inf)\n        union = (r1 - l1) * (b1 - t1) + ((r2 - l2) * (b2 - t2)).T - intersection\n        iou_mat = intersection / union\n\n    return iou_mat\n\n\ndef box_ioa(boxes_1: np.ndarray, boxes_2: np.ndarray) -> np.ndarray:\n    \"\"\"Compute the IoA (intersection over area) between two sets of bounding boxes:\n    ioa(i, j) = inter(i, j) / area(i)\n\n    Args:\n        boxes_1: bounding boxes of shape (N, 4) in format (xmin, ymin, xmax, ymax)\n        boxes_2: bounding boxes of shape (M, 4) in format (xmin, ymin, xmax, ymax)\n    Returns:\n        the IoA matrix of shape (N, M)\n    \"\"\"\n\n    ioa_mat = np.zeros((boxes_1.shape[0], boxes_2.shape[0]), dtype=np.float32)\n\n    if boxes_1.shape[0] > 0 and boxes_2.shape[0] > 0:\n        l1, t1, r1, b1 = np.split(boxes_1, 4, axis=1)\n        l2, t2, r2, b2 = np.split(boxes_2, 4, axis=1)\n\n        left = np.maximum(l1, l2.T)\n        top = np.maximum(t1, t2.T)\n        right = np.minimum(r1, r2.T)\n        bot = np.minimum(b1, b2.T)\n\n        intersection = np.clip(right - left, 0, np.Inf) * np.clip(bot - top, 0, np.Inf)\n        area = (r1 - l1) * (b1 - t1)\n        ioa_mat = intersection / area\n\n    return ioa_mat\n\n\ndef mask_iou(masks_1: np.ndarray, masks_2: np.ndarray) -> np.ndarray:\n    \"\"\"Compute the IoU between two sets of boolean masks\n\n    Args:\n        masks_1: boolean masks of shape (N, H, W)\n        masks_2: boolean masks of shape (M, H, W)\n\n    Returns:\n        the IoU matrix of shape (N, M)\n    \"\"\"\n\n    if masks_1.shape[1:] != masks_2.shape[1:]:\n        raise AssertionError(\"both boolean masks should have the same spatial shape\")\n\n    iou_mat = np.zeros((masks_1.shape[0], masks_2.shape[0]), dtype=np.float32)\n\n    if masks_1.shape[0] > 0 and masks_2.shape[0] > 0:\n        intersection = np.logical_and(masks_1[:, None, ...], masks_2[None, ...])\n        union = np.logical_or(masks_1[:, None, ...], masks_2[None, ...])\n        axes = tuple(range(2, masks_1.ndim + 1))\n        iou_mat = intersection.sum(axis=axes) / union.sum(axis=axes)\n\n    return iou_mat\n\n\ndef rbox_to_mask(boxes: np.ndarray, shape: Tuple[int, int]) -> np.ndarray:\n    \"\"\"Convert boxes to masks\n\n    Args:\n        boxes: rotated bounding boxes of shape (N, 5) in format (x, y, w, h, alpha)\n        shape: spatial shapes of the output masks\n\n    Returns:\n        the boolean masks of shape (N, H, W)\n    \"\"\"\n\n    masks = np.zeros((boxes.shape[0], *shape), dtype=np.uint8)\n\n    if boxes.shape[0] > 0:\n        # Get absolute coordinates\n        if boxes.dtype != np.int:\n            abs_boxes = boxes.copy()\n            abs_boxes[:, [0, 2]] = abs_boxes[:, [0, 2]] * shape[1]\n            abs_boxes[:, [1, 3]] = abs_boxes[:, [1, 3]] * shape[0]\n            abs_boxes = abs_boxes.round().astype(np.int)\n        else:\n            abs_boxes = boxes\n            abs_boxes[:, 2:] = abs_boxes[:, 2:] + 1\n\n        # TODO: optimize slicing to improve vectorization\n        for idx, _box in enumerate(abs_boxes):\n            box = rbbox_to_polygon(_box)\n            cv2.fillPoly(masks[idx], [np.array(box, np.int32)], 1)\n\n    return masks.astype(bool)\n\n\ndef nms(boxes: np.ndarray, thresh: float = .5) -> List[int]:\n    \"\"\"Perform non-max suppression, borrowed from <https://github.com/rbgirshick/fast-rcnn>`_.\n\n    Args:\n        boxes: np array of straight boxes: (*, 5), (xmin, ymin, xmax, ymax, score)\n        thresh: iou threshold to perform box suppression.\n\n    Returns:\n        A list of box indexes to keep\n    \"\"\"\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n    scores = boxes[:, 4]\n\n    areas = (x2 - x1) * (y2 - y1)\n    order = scores.argsort()[::-1]\n\n    keep = []\n    while order.size > 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(y2[i], y2[order[1:]])\n\n        w = np.maximum(0.0, xx2 - xx1)\n        h = np.maximum(0.0, yy2 - yy1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n\n        inds = np.where(ovr <= thresh)[0]\n        order = order[inds + 1]\n    return keep\n\n\nclass LocalizationConfusion:\n    \"\"\"Implements common confusion metrics and mean IoU for localization evaluation.\n\n    The aggregated metrics are computed as follows:\n\n    .. math::\n        \\\\forall Y \\\\in \\\\mathcal{B}^N, \\\\forall X \\\\in \\\\mathcal{B}^M, \\\\\\\\\n        Recall(X, Y) = \\\\frac{1}{N} \\\\sum\\\\limits_{i=1}^N g_{X}(Y_i) \\\\\\\\\n        Precision(X, Y) = \\\\frac{1}{M} \\\\sum\\\\limits_{i=1}^N g_{X}(Y_i) \\\\\\\\\n        meanIoU(X, Y) = \\\\frac{1}{M} \\\\sum\\\\limits_{i=1}^M \\\\max\\\\limits_{j \\\\in [1, N]}  IoU(X_i, Y_j)\n\n    with the function :math:`IoU(x, y)` being the Intersection over Union between bounding boxes :math:`x` and\n    :math:`y`, and the function :math:`g_{X}` defined as:\n\n    .. math::\n        \\\\forall y \\\\in \\\\mathcal{B},\n        g_X(y) = \\\\left\\\\{\n            \\\\begin{array}{ll}\n                1 & \\\\mbox{if } y\\\\mbox{ has been assigned to any }(X_i)_i\\\\mbox{ with an }IoU \\\\geq 0.5 \\\\\\\\\n                0 & \\\\mbox{otherwise.}\n            \\\\end{array}\n        \\\\right.\n\n    where :math:`\\\\mathcal{B}` is the set of possible bounding boxes,\n    :math:`N` (number of ground truths) and :math:`M` (number of predictions) are strictly positive integers.\n\n    Example::\n        >>> import numpy as np\n        >>> from doctr.utils import LocalizationConfusion\n        >>> metric = LocalizationConfusion(iou_thresh=0.5)\n        >>> metric.update(np.asarray([[0, 0, 100, 100]]), np.asarray([[0, 0, 70, 70], [110, 95, 200, 150]]))\n        >>> metric.summary()\n\n    Args:\n        iou_thresh: minimum IoU to consider a pair of prediction and ground truth as a match\n    \"\"\"\n\n    def __init__(\n        self,\n        iou_thresh: float = 0.5,\n        rotated_bbox: bool = False,\n        mask_shape: Tuple[int, int] = (1024, 1024),\n    ) -> None:\n        self.iou_thresh = iou_thresh\n        self.rotated_bbox = rotated_bbox\n        self.mask_shape = mask_shape\n        self.reset()\n\n    def update(self, gts: np.ndarray, preds: np.ndarray) -> None:\n\n        if preds.shape[0] > 0:\n            # Compute IoU\n            if self.rotated_bbox:\n                mask_gts = rbox_to_mask(gts, shape=self.mask_shape)\n                mask_preds = rbox_to_mask(preds, shape=self.mask_shape)\n                iou_mat = mask_iou(mask_gts, mask_preds)\n            else:\n                iou_mat = box_iou(gts, preds)\n            self.tot_iou += float(iou_mat.max(axis=1).sum())\n\n            # Assign pairs\n            gt_indices, pred_indices = linear_sum_assignment(-iou_mat)\n            self.matches += int((iou_mat[gt_indices, pred_indices] >= self.iou_thresh).sum())\n\n        # Update counts\n        self.num_gts += gts.shape[0]\n        self.num_preds += preds.shape[0]\n\n    def summary(self) -> Tuple[Optional[float], Optional[float], Optional[float]]:\n        \"\"\"Computes the aggregated metrics\n\n        Returns:\n            a tuple with the recall, precision and meanIoU scores\n        \"\"\"\n\n        # Recall\n        recall = self.matches / self.num_gts if self.num_gts > 0 else None\n\n        # Precision\n        precision = self.matches / self.num_preds if self.num_preds > 0 else None\n\n        # mean IoU\n        mean_iou = self.tot_iou / self.num_preds if self.num_preds > 0 else None\n\n        return recall, precision, mean_iou\n\n    def reset(self) -> None:\n        self.num_gts = 0\n        self.num_preds = 0\n        self.matches = 0\n        self.tot_iou = 0.\n\n\nclass OCRMetric:\n    \"\"\"Implements end-to-end OCR metric.\n\n    The aggregated metrics are computed as follows:\n\n    .. math::\n        \\\\forall (B, L) \\\\in \\\\mathcal{B}^N \\\\times \\\\mathcal{L}^N,\n        \\\\forall (\\\\hat{B}, \\\\hat{L}) \\\\in \\\\mathcal{B}^M \\\\times \\\\mathcal{L}^M, \\\\\\\\\n        Recall(B, \\\\hat{B}, L, \\\\hat{L}) = \\\\frac{1}{N} \\\\sum\\\\limits_{i=1}^N h_{B,L}(\\\\hat{B}_i, \\\\hat{L}_i) \\\\\\\\\n        Precision(B, \\\\hat{B}, L, \\\\hat{L}) = \\\\frac{1}{M} \\\\sum\\\\limits_{i=1}^N h_{B,L}(\\\\hat{B}_i, \\\\hat{L}_i) \\\\\\\\\n        meanIoU(B, \\\\hat{B}) = \\\\frac{1}{M} \\\\sum\\\\limits_{i=1}^M \\\\max\\\\limits_{j \\\\in [1, N]}  IoU(\\\\hat{B}_i, B_j)\n\n    with the function :math:`IoU(x, y)` being the Intersection over Union between bounding boxes :math:`x` and\n    :math:`y`, and the function :math:`h_{B, L}` defined as:\n\n    .. math::\n        \\\\forall (b, l) \\\\in \\\\mathcal{B} \\\\times \\\\mathcal{L},\n        h_{B,L}(b, l) = \\\\left\\\\{\n            \\\\begin{array}{ll}\n                1 & \\\\mbox{if } b\\\\mbox{ has been assigned to a given }B_j\\\\mbox{ with an } \\\\\\\\\n                & IoU \\\\geq 0.5 \\\\mbox{ and that for this assignment, } l = L_j\\\\\\\\\n                0 & \\\\mbox{otherwise.}\n            \\\\end{array}\n        \\\\right.\n\n    where :math:`\\\\mathcal{B}` is the set of possible bounding boxes,\n    :math:`\\\\mathcal{L}` is the set of possible character sequences,\n    :math:`N` (number of ground truths) and :math:`M` (number of predictions) are strictly positive integers.\n\n    Example::\n        >>> import numpy as np\n        >>> from doctr.utils import OCRMetric\n        >>> metric = OCRMetric(iou_thresh=0.5)\n        >>> metric.update(np.asarray([[0, 0, 100, 100]]), np.asarray([[0, 0, 70, 70], [110, 95, 200, 150]]),\n        ['hello'], ['hello', 'world'])\n        >>> metric.summary()\n\n    Args:\n        iou_thresh: minimum IoU to consider a pair of prediction and ground truth as a match\n    \"\"\"\n\n    def __init__(\n        self,\n        iou_thresh: float = 0.5,\n        rotated_bbox: bool = False,\n        mask_shape: Tuple[int, int] = (1024, 1024),\n    ) -> None:\n        self.iou_thresh = iou_thresh\n        self.rotated_bbox = rotated_bbox\n        self.mask_shape = mask_shape\n        self.reset()\n\n    def update(\n        self,\n        gt_boxes: np.ndarray,\n        pred_boxes: np.ndarray,\n        gt_labels: List[str],\n        pred_labels: List[str],\n    ) -> None:\n\n        if gt_boxes.shape[0] != len(gt_labels) or pred_boxes.shape[0] != len(pred_labels):\n            raise AssertionError(\"there should be the same number of boxes and string both for the ground truth \"\n                                 \"and the predictions\")\n\n        # Compute IoU\n        if pred_boxes.shape[0] > 0:\n            if self.rotated_bbox:\n                mask_gts = rbox_to_mask(gt_boxes, shape=self.mask_shape)\n                mask_preds = rbox_to_mask(pred_boxes, shape=self.mask_shape)\n                iou_mat = mask_iou(mask_gts, mask_preds)\n            else:\n                iou_mat = box_iou(gt_boxes, pred_boxes)\n\n            self.tot_iou += float(iou_mat.max(axis=1).sum())\n\n            # Assign pairs\n            gt_indices, pred_indices = linear_sum_assignment(-iou_mat)\n            is_kept = iou_mat[gt_indices, pred_indices] >= self.iou_thresh\n            # String comparison\n            for gt_idx, pred_idx in zip(gt_indices[is_kept], pred_indices[is_kept]):\n                _raw, _caseless, _unidecode, _unicase = string_match(gt_labels[gt_idx], pred_labels[pred_idx])\n                self.raw_matches += int(_raw)\n                self.caseless_matches += int(_caseless)\n                self.unidecode_matches += int(_unidecode)\n                self.unicase_matches += int(_unicase)\n\n        self.num_gts += gt_boxes.shape[0]\n        self.num_preds += pred_boxes.shape[0]\n\n    def summary(self) -> Tuple[Dict[str, Optional[float]], Dict[str, Optional[float]], Optional[float]]:\n        \"\"\"Computes the aggregated metrics\n\n        Returns:\n            a tuple with the recall & precision for each string comparison flexibility and the mean IoU\n        \"\"\"\n\n        # Recall\n        recall = dict(\n            raw=self.raw_matches / self.num_gts if self.num_gts > 0 else None,\n            caseless=self.caseless_matches / self.num_gts if self.num_gts > 0 else None,\n            unidecode=self.unidecode_matches / self.num_gts if self.num_gts > 0 else None,\n            unicase=self.unicase_matches / self.num_gts if self.num_gts > 0 else None,\n        )\n\n        # Precision\n        precision = dict(\n            raw=self.raw_matches / self.num_preds if self.num_preds > 0 else None,\n            caseless=self.caseless_matches / self.num_preds if self.num_preds > 0 else None,\n            unidecode=self.unidecode_matches / self.num_preds if self.num_preds > 0 else None,\n            unicase=self.unicase_matches / self.num_preds if self.num_preds > 0 else None,\n        )\n\n        # mean IoU (overall detected boxes)\n        mean_iou = self.tot_iou / self.num_preds if self.num_preds > 0 else None\n\n        return recall, precision, mean_iou\n\n    def reset(self) -> None:\n        self.num_gts = 0\n        self.num_preds = 0\n        self.tot_iou = 0.\n        self.raw_matches = 0\n        self.caseless_matches = 0\n        self.unidecode_matches = 0\n        self.unicase_matches = 0\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright (C) 2021, Mindee.\n\n# This program is licensed under the Apache License version 2.\n# See LICENSE or go to <https://www.apache.org/licenses/LICENSE-2.0.txt> for full license details.\n\nimport pytest\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\nfrom doctr.utils.metrics import box_iou\n\n\n@pytest.mark.asyncio\nasync def test_text_detection(test_app_asyncio, mock_detection_image):\n\n    response = await test_app_asyncio.post(\"/detection\", files={'file': mock_detection_image})\n    assert response.status_code == 200\n    json_response = response.json()\n\n    gt_boxes = np.array([[1240, 430, 1355, 470], [1360, 430, 1495, 470]], dtype=np.float32)\n    gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] / 1654\n    gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] / 2339\n\n    # Check that IoU with GT if reasonable\n    assert isinstance(json_response, list) and len(json_response) == gt_boxes.shape[0]\n    pred_boxes = np.array([elt['box'] for elt in json_response])\n    iou_mat = box_iou(gt_boxes, pred_boxes)\n    gt_idxs, pred_idxs = linear_sum_assignment(-iou_mat)\n    is_kept = iou_mat[gt_idxs, pred_idxs] >= 0.8\n    assert gt_idxs[is_kept].shape[0] == gt_boxes.shape[0]\n"
  },
  {
    "prompt": "\n\n### openpyxl/pivot/tests/test_fields.py ###\n\n# Copyright (c) 2010-2019 openpyxl\nimport pytest\n\nfrom datetime import datetime\n\nfrom openpyxl.xml.functions import fromstring, tostring\nfrom openpyxl.tests.helper import compare_xml\n\n@pytest.fixture\ndef Error():\n    from ..record import Error\n    return Error\n\n\nclass TestError:\n\n    def test_ctor(self, Error):\n        error = Error(v=\"error\")\n        xml = tostring(error.to_tree())\n        expected = \"\"\"\n        <e v=\"error\" />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Error):\n        src = \"\"\"\n        <e v=\"error\" />\n        \"\"\"\n        node = fromstring(src)\n        error = Error.from_tree(node)\n        assert error == Error(v=\"error\")\n\n\n@pytest.fixture\ndef Boolean():\n    from ..record import Boolean\n    return Boolean\n\n\nclass TestBoolean:\n\n    def test_ctor(self, Boolean):\n        boolean = Boolean()\n        xml = tostring(boolean.to_tree())\n        expected = \"\"\"\n        <b v=\"0\" />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Boolean):\n        src = \"\"\"\n        <b />\n        \"\"\"\n        node = fromstring(src)\n        boolean = Boolean.from_tree(node)\n        assert boolean == Boolean()\n\n\n@pytest.fixture\ndef Missing():\n    from ..record import Missing\n    return Missing\n\n\nclass TestMissing:\n\n    def test_ctor(self, Missing):\n        missing = Missing()\n        xml = tostring(missing.to_tree())\n        expected = \"\"\"\n        <m />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Missing):\n        src = \"\"\"\n        <m />\n        \"\"\"\n        node = fromstring(src)\n        missing = Missing.from_tree(node)\n        assert missing == Missing()\n\n\n@pytest.fixture\ndef Number():\n    from ..record import Number\n    return Number\n\n\nclass TestNumber:\n\n    def test_ctor(self, Number):\n        number = Number(v=24)\n        xml = tostring(number.to_tree())\n        expected = \"\"\"\n        <n v=\"24\"/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Number):\n        src = \"\"\"\n        <n v=\"15\" />\n        \"\"\"\n        node = fromstring(src)\n        number = Number.from_tree(node)\n        assert number == Number(v=15)\n\n\n@pytest.fixture\ndef Text():\n    from ..record import Text\n    return Text\n\n\nclass TestText:\n\n    def test_ctor(self, Text):\n        text = Text(v=\"UCLA\")\n        xml = tostring(text.to_tree())\n        expected = \"\"\"\n        <s v=\"UCLA\" />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Text):\n        src = \"\"\"\n        <s v=\"UCLA\" />\n        \"\"\"\n        node = fromstring(src)\n        text = Text.from_tree(node)\n        assert text == Text(v=\"UCLA\")\n\n@pytest.fixture\ndef Index():\n    from ..record import Index\n    return Index\n\n\nclass TestIndex:\n\n    def test_ctor(self, Index):\n        record = Index()\n        xml = tostring(record.to_tree())\n        expected = \"\"\"\n        <x v=\"0\" />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Index):\n        src = \"\"\"\n        <x v=\"1\" />\n        \"\"\"\n        node = fromstring(src)\n        record = Index.from_tree(node)\n        assert record == Index(v=1)\n\n\n@pytest.fixture\ndef DateTimeField():\n    from ..record import DateTimeField\n    return DateTimeField\n\n\nclass TestDateTimeField:\n\n    def test_ctor(self, DateTimeField):\n        record = DateTimeField(v=datetime(2016, 3, 24))\n        xml = tostring(record.to_tree())\n        expected = \"\"\"\n        <d v=\"2016-03-24T00:00:00\"/>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, DateTimeField):\n        src = \"\"\"\n        <d v=\"2016-03-24T00:00:00\"/>\n        \"\"\"\n        node = fromstring(src)\n        record = DateTimeField.from_tree(node)\n        assert record == DateTimeField(v=datetime(2016, 3, 24))\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright (c) 2010-2019 openpyxl\nimport pytest\n\nfrom io import BytesIO\nfrom zipfile import ZipFile\n\nfrom openpyxl.packaging.manifest import Manifest\nfrom openpyxl.xml.functions import fromstring, tostring\nfrom openpyxl.tests.helper import compare_xml\n\nfrom .test_fields import (\n    Index,\n    Number,\n    Text,\n)\n\n@pytest.fixture\ndef Record():\n    from ..record import Record\n    return Record\n\n\nclass TestRecord:\n\n    def test_ctor(self, Record, Number, Text, Index):\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = n + s + x\n        field = Record(_fields=fields)\n        xml = tostring(field.to_tree())\n        expected = \"\"\"\n        <r>\n          <n v=\"1\"/>\n          <n v=\"25\"/>\n          <s v=\"2014-03-24\"/>\n          <x v=\"0\"/>\n          <x v=\"0\"/>\n          <x v=\"0\"/>\n        </r>\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, Record, Number, Text, Index):\n        src = \"\"\"\n        <r>\n          <n v=\"1\"/>\n          <x v=\"0\"/>\n          <s v=\"2014-03-24\"/>\n          <x v=\"0\"/>\n          <n v=\"25\"/>\n          <x v=\"0\"/>\n        </r>\n        \"\"\"\n        node = fromstring(src)\n        n = [Number(v=1), Number(v=25)]\n        s = [Text(v=\"2014-03-24\")]\n        x = [Index(), Index(), Index()]\n        fields = [\n            Number(v=1),\n            Index(),\n            Text(v=\"2014-03-24\"),\n            Index(),\n            Number(v=25),\n            Index(),\n        ]\n        field = Record.from_tree(node)\n        assert field == Record(_fields=fields)\n\n\n@pytest.fixture\ndef RecordList():\n    from ..record import RecordList\n    return RecordList\n\n\nclass TestRecordList:\n\n    def test_ctor(self, RecordList):\n        cache = RecordList()\n        xml = tostring(cache.to_tree())\n        expected = \"\"\"\n        <pivotCacheRecords xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\"\n           count=\"0\" />\n        \"\"\"\n        diff = compare_xml(xml, expected)\n        assert diff is None, diff\n\n\n    def test_from_xml(self, RecordList):\n        src = \"\"\"\n        <pivotCacheRecords count=\"0\" />\n        \"\"\"\n        node = fromstring(src)\n        cache = RecordList.from_tree(node)\n        assert cache == RecordList()\n\n\n    def test_write(self, RecordList):\n        out = BytesIO()\n        archive = ZipFile(out, mode=\"w\")\n        manifest = Manifest()\n\n        records = RecordList()\n        xml = tostring(records.to_tree())\n        records._write(archive, manifest)\n        manifest.append(records)\n\n        assert archive.namelist() == [records.path[1:]]\n        assert manifest.find(records.mime_type)\n"
  },
  {
    "prompt": "\n\n### vdirsyncer/storage/dav.py ###\n\nimport datetime\nimport logging\nimport urllib.parse as urlparse\nimport xml.etree.ElementTree as etree\nfrom abc import abstractmethod\nfrom inspect import getfullargspec\nfrom inspect import signature\nfrom typing import Optional\nfrom typing import Type\n\nimport aiohttp\nimport aiostream\n\nfrom vdirsyncer.exceptions import Error\nfrom vdirsyncer.vobject import Item\n\nfrom .. import exceptions\nfrom .. import http\nfrom .. import utils\nfrom ..http import USERAGENT\nfrom ..http import prepare_auth\nfrom ..http import prepare_client_cert\nfrom ..http import prepare_verify\nfrom .base import Storage\nfrom .base import normalize_meta_value\n\ndav_logger = logging.getLogger(__name__)\n\nCALDAV_DT_FORMAT = \"%Y%m%dT%H%M%SZ\"\n\n\ndef _generate_path_reserved_chars():\n    for x in \"/?#[]!$&'()*+,;\":\n        x = urlparse.quote(x, \"\")\n        yield x.upper()\n        yield x.lower()\n\n\n_path_reserved_chars = frozenset(_generate_path_reserved_chars())\ndel _generate_path_reserved_chars\n\n\ndef _contains_quoted_reserved_chars(x):\n    for y in _path_reserved_chars:\n        if y in x:\n            dav_logger.debug(f\"Unsafe character: {y!r}\")\n            return True\n    return False\n\n\nasync def _assert_multistatus_success(r):\n    # Xandikos returns a multistatus on PUT.\n    try:\n        root = _parse_xml(await r.content.read())\n    except InvalidXMLResponse:\n        return\n    for status in root.findall(\".//{DAV:}status\"):\n        parts = status.text.strip().split()\n        try:\n            st = int(parts[1])\n        except (ValueError, IndexError):\n            continue\n        if st < 200 or st >= 400:\n            raise Error(f\"Server error: {st}\")\n\n\ndef _normalize_href(base, href):\n    \"\"\"Normalize the href to be a path only relative to hostname and\n    schema.\"\"\"\n    orig_href = href\n    if not href:\n        raise ValueError(href)\n\n    x = urlparse.urljoin(base, href)\n    x = urlparse.urlsplit(x).path\n\n    # Encoding issues:\n    # - https://github.com/owncloud/contacts/issues/581\n    # - https://github.com/Kozea/Radicale/issues/298\n    old_x = None\n    while old_x is None or x != old_x:\n        if _contains_quoted_reserved_chars(x):\n            break\n        old_x = x\n        x = urlparse.unquote(x)\n\n    x = urlparse.quote(x, \"/@%:\")\n\n    if orig_href == x:\n        dav_logger.debug(f\"Already normalized: {x!r}\")\n    else:\n        dav_logger.debug(f\"Normalized URL from {orig_href!r} to {x!r}\")\n\n    return x\n\n\nclass InvalidXMLResponse(exceptions.InvalidResponse):\n    pass\n\n\n_BAD_XML_CHARS = (\n    b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x0b\\x0c\\x0e\\x0f\"\n    b\"\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x1f\"\n)\n\n\ndef _clean_body(content, bad_chars=_BAD_XML_CHARS):\n    new_content = content.translate(None, bad_chars)\n    if new_content != content:\n        dav_logger.warning(\n            \"Your server incorrectly returned ASCII control characters in its \"\n            \"XML. Vdirsyncer ignores those, but this is a bug in your server.\"\n        )\n    return new_content\n\n\ndef _parse_xml(content):\n    try:\n        return etree.XML(_clean_body(content))\n    except etree.ParseError as e:\n        raise InvalidXMLResponse(\n            \"Invalid XML encountered: {}\\n\"\n            \"Double-check the URLs in your config.\".format(e)\n        )\n\n\ndef _merge_xml(items):\n    if not items:\n        return None\n    rv = items[0]\n    for item in items[1:]:\n        rv.extend(item.iter())\n    return rv\n\n\ndef _fuzzy_matches_mimetype(strict, weak):\n    # different servers give different getcontenttypes:\n    # \"text/vcard\", \"text/x-vcard\", \"text/x-vcard; charset=utf-8\",\n    # \"text/directory;profile=vCard\", \"text/directory\",\n    # \"text/vcard; charset=utf-8\"\n    if strict is None or weak is None:\n        return True\n\n    mediatype, subtype = strict.split(\"/\")\n    if subtype in weak:\n        return True\n    return False\n\n\nclass Discover:\n    @property\n    @abstractmethod\n    def _namespace(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def _resourcetype(self) -> Optional[str]:\n        pass\n\n    @property\n    @abstractmethod\n    def _homeset_xml(self) -> bytes:\n        pass\n\n    @property\n    @abstractmethod\n    def _homeset_tag(self) -> str:\n        pass\n\n    @property\n    @abstractmethod\n    def _well_known_uri(self) -> str:\n        pass\n\n    _collection_xml = b\"\"\"\n    <propfind xmlns=\"DAV:\">\n        <prop>\n            <resourcetype />\n        </prop>\n    </propfind>\n    \"\"\"\n\n    def __init__(self, session, kwargs):\n        if kwargs.pop(\"collection\", None) is not None:\n            raise TypeError(\"collection argument must not be given.\")\n\n        self.session = session\n        self.kwargs = kwargs\n\n    @staticmethod\n    def _get_collection_from_url(url):\n        _, collection = url.rstrip(\"/\").rsplit(\"/\", 1)\n        return urlparse.unquote(collection)\n\n    async def find_principal(self):\n        try:\n            return await self._find_principal_impl(\"\")\n        except (aiohttp.ClientResponseError, exceptions.Error):\n            dav_logger.debug(\"Trying out well-known URI\")\n            return await self._find_principal_impl(self._well_known_uri)\n\n    async def _find_principal_impl(self, url):\n        headers = self.session.get_default_headers()\n        headers[\"Depth\"] = \"0\"\n        body = b\"\"\"\n        <propfind xmlns=\"DAV:\">\n            <prop>\n                <current-user-principal />\n            </prop>\n        </propfind>\n        \"\"\"\n\n        response = await self.session.request(\n            \"PROPFIND\",\n            url,\n            headers=headers,\n            data=body,\n        )\n\n        root = _parse_xml(await response.content.read())\n        rv = root.find(\".//{DAV:}current-user-principal/{DAV:}href\")\n        if rv is None:\n            # This is for servers that don't support current-user-principal\n            # E.g. Synology NAS\n            # See https://github.com/pimutils/vdirsyncer/issues/498\n            dav_logger.debug(\n                \"No current-user-principal returned, re-using URL {}\".format(\n                    response.url\n                )\n            )\n            return response.url\n        return urlparse.urljoin(str(response.url), rv.text).rstrip(\"/\") + \"/\"\n\n    async def find_home(self):\n        url = await self.find_principal()\n        headers = self.session.get_default_headers()\n        headers[\"Depth\"] = \"0\"\n        response = await self.session.request(\n            \"PROPFIND\", url, headers=headers, data=self._homeset_xml\n        )\n\n        root = etree.fromstring(await response.content.read())\n        # Better don't do string formatting here, because of XML namespaces\n        rv = root.find(\".//\" + self._homeset_tag + \"/{DAV:}href\")\n        if rv is None:\n            raise InvalidXMLResponse(\"Couldn't find home-set.\")\n        return urlparse.urljoin(str(response.url), rv.text).rstrip(\"/\") + \"/\"\n\n    async def find_collections(self):\n        rv = None\n        try:\n            rv = await aiostream.stream.list(self._find_collections_impl(\"\"))\n        except (aiohttp.ClientResponseError, exceptions.Error):\n            pass\n\n        if rv:\n            return rv\n\n        dav_logger.debug(\"Given URL is not a homeset URL\")\n        return await aiostream.stream.list(\n            self._find_collections_impl(await self.find_home())\n        )\n\n    def _check_collection_resource_type(self, response):\n        if self._resourcetype is None:\n            return True\n\n        props = _merge_xml(response.findall(\"{DAV:}propstat/{DAV:}prop\"))\n        if props is None or not len(props):\n            dav_logger.debug(\"Skipping, missing <prop>: %s\", response)\n            return False\n        if props.find(\"{DAV:}resourcetype/\" + self._resourcetype) is None:\n            dav_logger.debug(\n                \"Skipping, not of resource type %s: %s\", self._resourcetype, response\n            )\n            return False\n        return True\n\n    async def _find_collections_impl(self, url):\n        headers = self.session.get_default_headers()\n        headers[\"Depth\"] = \"1\"\n        r = await self.session.request(\n            \"PROPFIND\", url, headers=headers, data=self._collection_xml\n        )\n        root = _parse_xml(await r.content.read())\n        done = set()\n        for response in root.findall(\"{DAV:}response\"):\n            if not self._check_collection_resource_type(response):\n                continue\n\n            href = response.find(\"{DAV:}href\")\n            if href is None:\n                raise InvalidXMLResponse(\"Missing href tag for collection \" \"props.\")\n            href = urlparse.urljoin(str(r.url), href.text)\n            if href not in done:\n                done.add(href)\n                yield {\"href\": href}\n\n    async def discover(self):\n        for c in await self.find_collections():\n            url = c[\"href\"]\n            collection = self._get_collection_from_url(url)\n            storage_args = dict(self.kwargs)\n            storage_args.update({\"url\": url, \"collection\": collection})\n            yield storage_args\n\n    async def create(self, collection):\n        if collection is None:\n            collection = self._get_collection_from_url(self.kwargs[\"url\"])\n\n        async for c in self.discover():\n            if c[\"collection\"] == collection:\n                return c\n\n        home = await self.find_home()\n        url = urlparse.urljoin(home, urlparse.quote(collection, \"/@\"))\n\n        try:\n            url = await self._create_collection_impl(url)\n        except (aiohttp.ClientResponseError, Error) as e:\n            raise NotImplementedError(e)\n        else:\n            rv = dict(self.kwargs)\n            rv[\"collection\"] = collection\n            rv[\"url\"] = url\n            return rv\n\n    async def _create_collection_impl(self, url):\n        data = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <mkcol xmlns=\"DAV:\">\n                <set>\n                    <prop>\n                        <resourcetype>\n                            <collection/>\n                            {}\n                        </resourcetype>\n                    </prop>\n                </set>\n            </mkcol>\n        \"\"\".format(\n            etree.tostring(etree.Element(self._resourcetype), encoding=\"unicode\")\n        ).encode(\n            \"utf-8\"\n        )\n\n        response = await self.session.request(\n            \"MKCOL\",\n            url,\n            data=data,\n            headers=self.session.get_default_headers(),\n        )\n        return str(response.url)\n\n\nclass CalDiscover(Discover):\n    _namespace = \"urn:ietf:params:xml:ns:caldav\"\n    _resourcetype = \"{%s}calendar\" % _namespace\n    _homeset_xml = b\"\"\"\n    <propfind xmlns=\"DAV:\" xmlns:c=\"urn:ietf:params:xml:ns:caldav\">\n        <prop>\n            <c:calendar-home-set />\n        </prop>\n    </propfind>\n    \"\"\"\n    _homeset_tag = \"{%s}calendar-home-set\" % _namespace\n    _well_known_uri = \"/.well-known/caldav\"\n\n\nclass CardDiscover(Discover):\n    _namespace = \"urn:ietf:params:xml:ns:carddav\"\n    _resourcetype: Optional[str] = \"{%s}addressbook\" % _namespace\n    _homeset_xml = b\"\"\"\n    <propfind xmlns=\"DAV:\" xmlns:c=\"urn:ietf:params:xml:ns:carddav\">\n        <prop>\n            <c:addressbook-home-set />\n        </prop>\n    </propfind>\n    \"\"\"\n    _homeset_tag = \"{%s}addressbook-home-set\" % _namespace\n    _well_known_uri = \"/.well-known/carddav\"\n\n\nclass DAVSession:\n    \"\"\"A helper class to connect to DAV servers.\"\"\"\n\n    connector: aiohttp.BaseConnector\n\n    @classmethod\n    def init_and_remaining_args(cls, **kwargs):\n        def is_arg(k):\n            \"\"\"Return true if ``k`` is an argument of ``cls.__init__``.\"\"\"\n            return k in argspec.args or k in argspec.kwonlyargs\n\n        argspec = getfullargspec(cls.__init__)\n        self_args, remainder = utils.split_dict(kwargs, is_arg)\n\n        return cls(**self_args), remainder\n\n    def __init__(\n        self,\n        url,\n        username=\"\",\n        password=\"\",\n        verify=True,\n        auth=None,\n        useragent=USERAGENT,\n        verify_fingerprint=None,\n        auth_cert=None,\n        *,\n        connector: aiohttp.BaseConnector,\n    ):\n        self._settings = {\n            \"cert\": prepare_client_cert(auth_cert),\n            \"auth\": prepare_auth(auth, username, password),\n        }\n        self._settings.update(prepare_verify(verify, verify_fingerprint))\n\n        self.useragent = useragent\n        self.url = url.rstrip(\"/\") + \"/\"\n        self.connector = connector\n\n    @utils.cached_property\n    def parsed_url(self):\n        return urlparse.urlparse(self.url)\n\n    async def request(self, method, path, **kwargs):\n        url = self.url\n        if path:\n            url = urlparse.urljoin(str(self.url), path)\n\n        more = dict(self._settings)\n        more.update(kwargs)\n\n        # XXX: This is a temporary hack to pin-point bad refactoring.\n        assert self.connector is not None\n        async with self._session as session:\n            return await http.request(method, url, session=session, **more)\n\n    @property\n    def _session(self):\n        \"\"\"Return a new session for requests.\"\"\"\n\n        return aiohttp.ClientSession(\n            connector=self.connector,\n            connector_owner=False,\n            # TODO use `raise_for_status=true`, though this needs traces first,\n        )\n\n    def get_default_headers(self):\n        return {\n            \"User-Agent\": self.useragent,\n            \"Content-Type\": \"application/xml; charset=UTF-8\",\n        }\n\n\nclass DAVStorage(Storage):\n    # the file extension of items. Useful for testing against radicale.\n    fileext: str\n    # mimetype of items\n    item_mimetype: str\n\n    @property\n    @abstractmethod\n    def get_multi_template(self) -> str:\n        \"\"\"XML to use when fetching multiple hrefs.\"\"\"\n\n    @property\n    @abstractmethod\n    def get_multi_data_query(self) -> str:\n        \"\"\"LXML query for extracting results in get_multi.\"\"\"\n\n    @property\n    @abstractmethod\n    def discovery_class(self) -> Type[Discover]:\n        \"\"\"Discover subclass to use.\"\"\"\n\n    # The DAVSession class to use\n    session_class = DAVSession\n\n    connector: aiohttp.TCPConnector\n\n    _repr_attributes = [\"username\", \"url\"]\n\n    _property_table = {\n        \"displayname\": (\"displayname\", \"DAV:\"),\n    }\n\n    def __init__(self, *, connector, **kwargs):\n        # defined for _repr_attributes\n        self.username = kwargs.get(\"username\")\n        self.url = kwargs.get(\"url\")\n        self.connector = connector\n\n        self.session, kwargs = self.session_class.init_and_remaining_args(\n            connector=connector,\n            **kwargs,\n        )\n        super().__init__(**kwargs)\n\n    __init__.__signature__ = signature(session_class.__init__)  # type: ignore\n    # See  https://github.com/python/mypy/issues/5958\n\n    @classmethod\n    async def discover(cls, **kwargs):\n        session, _ = cls.session_class.init_and_remaining_args(**kwargs)\n        d = cls.discovery_class(session, kwargs)\n\n        async for collection in d.discover():\n            yield collection\n\n    @classmethod\n    async def create_collection(cls, collection, **kwargs):\n        session, _ = cls.session_class.init_and_remaining_args(**kwargs)\n        d = cls.discovery_class(session, kwargs)\n        return await d.create(collection)\n\n    def _normalize_href(self, *args, **kwargs):\n        return _normalize_href(self.session.url, *args, **kwargs)\n\n    def _get_href(self, item):\n        href = utils.generate_href(item.ident)\n        return self._normalize_href(href + self.fileext)\n\n    def _is_item_mimetype(self, mimetype):\n        return _fuzzy_matches_mimetype(self.item_mimetype, mimetype)\n\n    async def get(self, href: str):\n        ((actual_href, item, etag),) = await aiostream.stream.list(\n            self.get_multi([href])\n        )\n        assert href == actual_href\n        return item, etag\n\n    async def get_multi(self, hrefs):\n        hrefs = set(hrefs)\n        href_xml = []\n        for href in hrefs:\n            if href != self._normalize_href(href):\n                raise exceptions.NotFoundError(href)\n            href_xml.append(f\"<href>{href}</href>\")\n        if href_xml:\n            data = self.get_multi_template.format(hrefs=\"\\n\".join(href_xml)).encode(\n                \"utf-8\"\n            )\n            response = await self.session.request(\n                \"REPORT\", \"\", data=data, headers=self.session.get_default_headers()\n            )\n            root = _parse_xml(\n                await response.content.read()\n            )  # etree only can handle bytes\n            rv = []\n            hrefs_left = set(hrefs)\n            for href, etag, prop in self._parse_prop_responses(root):\n                raw = prop.find(self.get_multi_data_query)\n                if raw is None:\n                    dav_logger.warning(f\"Skipping {href}, the item content is missing.\")\n                    continue\n\n                raw = raw.text or \"\"\n\n                if isinstance(raw, bytes):\n                    raw = raw.decode(response.encoding)\n                if isinstance(etag, bytes):\n                    etag = etag.decode(response.encoding)\n\n                try:\n                    hrefs_left.remove(href)\n                except KeyError:\n                    if href in hrefs:\n                        dav_logger.warning(f\"Server sent item twice: {href}\")\n                    else:\n                        dav_logger.warning(f\"Server sent unsolicited item: {href}\")\n                else:\n                    rv.append((href, Item(raw), etag))\n            for href in hrefs_left:\n                raise exceptions.NotFoundError(href)\n\n            for href, item, etag in rv:\n                yield href, item, etag\n\n    async def _put(self, href, item, etag):\n        headers = self.session.get_default_headers()\n        headers[\"Content-Type\"] = self.item_mimetype\n        if etag is None:\n            headers[\"If-None-Match\"] = \"*\"\n        else:\n            headers[\"If-Match\"] = etag\n\n        response = await self.session.request(\n            \"PUT\", href, data=item.raw.encode(\"utf-8\"), headers=headers\n        )\n\n        await _assert_multistatus_success(response)\n\n        # The server may not return an etag under certain conditions:\n        #\n        #   An origin server MUST NOT send a validator header field (Section\n        #   7.2), such as an ETag or Last-Modified field, in a successful\n        #   response to PUT unless the request's representation data was saved\n        #   without any transformation applied to the body (i.e., the\n        #   resource's new representation data is identical to the\n        #   representation data received in the PUT request) and the validator\n        #   field value reflects the new representation.\n        #\n        # -- https://tools.ietf.org/html/rfc7231#section-4.3.4\n        #\n        # In such cases we return a constant etag. The next synchronization\n        # will then detect an etag change and will download the new item.\n        etag = response.headers.get(\"etag\", None)\n        href = self._normalize_href(str(response.url))\n        return href, etag\n\n    async def update(self, href, item, etag):\n        if etag is None:\n            raise ValueError(\"etag must be given and must not be None.\")\n        href, etag = await self._put(self._normalize_href(href), item, etag)\n        return etag\n\n    async def upload(self, item: Item):\n        href = self._get_href(item)\n        rv = await self._put(href, item, None)\n        return rv\n\n    async def delete(self, href, etag):\n        href = self._normalize_href(href)\n        headers = self.session.get_default_headers()\n        if etag:  # baikal doesn't give us an etag.\n            dav_logger.warning(\"Deleting an item with no etag.\")\n            headers.update({\"If-Match\": etag})\n\n        await self.session.request(\"DELETE\", href, headers=headers)\n\n    def _parse_prop_responses(self, root, handled_hrefs=None):\n        if handled_hrefs is None:\n            handled_hrefs = set()\n        for response in root.iter(\"{DAV:}response\"):\n            href = response.find(\"{DAV:}href\")\n            if href is None:\n                dav_logger.error(\"Skipping response, href is missing.\")\n                continue\n\n            href = self._normalize_href(href.text)\n\n            if href in handled_hrefs:\n                # Servers that send duplicate hrefs:\n                # - Zimbra\n                #   https://github.com/pimutils/vdirsyncer/issues/88\n                # - Davmail\n                #   https://github.com/pimutils/vdirsyncer/issues/144\n                dav_logger.warning(f\"Skipping identical href: {href!r}\")\n                continue\n\n            props = response.findall(\"{DAV:}propstat/{DAV:}prop\")\n            if props is None or not len(props):\n                dav_logger.debug(f\"Skipping {href!r}, properties are missing.\")\n                continue\n            else:\n                props = _merge_xml(props)\n\n            if props.find(\"{DAV:}resourcetype/{DAV:}collection\") is not None:\n                dav_logger.debug(f\"Skipping {href!r}, is collection.\")\n                continue\n\n            etag = getattr(props.find(\"{DAV:}getetag\"), \"text\", \"\")\n            if not etag:\n                dav_logger.debug(f\"Skipping {href!r}, etag property is missing.\")\n                continue\n\n            contenttype = getattr(props.find(\"{DAV:}getcontenttype\"), \"text\", None)\n            if not self._is_item_mimetype(contenttype):\n                dav_logger.debug(\n                    \"Skipping {!r}, {!r} != {!r}.\".format(\n                        href, contenttype, self.item_mimetype\n                    )\n                )\n                continue\n\n            handled_hrefs.add(href)\n            yield href, etag, props\n\n    async def list(self):\n        headers = self.session.get_default_headers()\n        headers[\"Depth\"] = \"1\"\n\n        data = b\"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <propfind xmlns=\"DAV:\">\n                <prop>\n                    <resourcetype/>\n                    <getcontenttype/>\n                    <getetag/>\n                </prop>\n            </propfind>\n            \"\"\"\n\n        # We use a PROPFIND request instead of addressbook-query due to issues\n        # with Zimbra. See https://github.com/pimutils/vdirsyncer/issues/83\n        response = await self.session.request(\n            \"PROPFIND\",\n            \"\",\n            data=data,\n            headers=headers,\n        )\n        root = _parse_xml(await response.content.read())\n\n        rv = self._parse_prop_responses(root)\n        for href, etag, _prop in rv:\n            yield href, etag\n\n    async def get_meta(self, key) -> Optional[str]:\n        try:\n            tagname, namespace = self._property_table[key]\n        except KeyError:\n            raise exceptions.UnsupportedMetadataError()\n\n        xpath = f\"{{{namespace}}}{tagname}\"\n        body = f\"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <propfind xmlns=\"DAV:\">\n                <prop>\n                    {etree.tostring(etree.Element(xpath), encoding=\"unicode\")}\n                </prop>\n            </propfind>\n        \"\"\"\n        data = body.encode(\"utf-8\")\n\n        headers = self.session.get_default_headers()\n        headers[\"Depth\"] = \"0\"\n\n        response = await self.session.request(\n            \"PROPFIND\",\n            \"\",\n            data=data,\n            headers=headers,\n        )\n\n        root = _parse_xml(await response.content.read())\n\n        for prop in root.findall(\".//\" + xpath):\n            text = normalize_meta_value(getattr(prop, \"text\", None))\n            if text:\n                return text\n        return None\n\n    async def set_meta(self, key, value):\n        try:\n            tagname, namespace = self._property_table[key]\n        except KeyError:\n            raise exceptions.UnsupportedMetadataError()\n\n        lxml_selector = f\"{{{namespace}}}{tagname}\"\n        element = etree.Element(lxml_selector)\n        if value is None:\n            action = \"remove\"\n        else:\n            element.text = normalize_meta_value(value)\n            action = \"set\"\n\n        data = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <propertyupdate xmlns=\"DAV:\">\n                <{action}>\n                    <prop>\n                        {}\n                    </prop>\n                </{action}>\n            </propertyupdate>\n        \"\"\".format(\n            etree.tostring(element, encoding=\"unicode\"),\n            action=action,\n        ).encode(\n            \"utf-8\"\n        )\n\n        await self.session.request(\n            \"PROPPATCH\",\n            \"\",\n            data=data,\n            headers=self.session.get_default_headers(),\n        )\n\n        # XXX: Response content is currently ignored. Though exceptions are\n        # raised for HTTP errors, a multistatus with errorcodes inside is not\n        # parsed yet. Not sure how common those are, or how they look like. It\n        # might be easier (and safer in case of a stupid server) to just issue\n        # a PROPFIND to see if the value got actually set.\n\n\nclass CalDAVStorage(DAVStorage):\n    storage_name = \"caldav\"\n    fileext = \".ics\"\n    item_mimetype = \"text/calendar\"\n    discovery_class = CalDiscover\n\n    start_date = None\n    end_date = None\n\n    get_multi_template = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n        <C:calendar-multiget xmlns=\"DAV:\"\n            xmlns:C=\"urn:ietf:params:xml:ns:caldav\">\n            <prop>\n                <getetag/>\n                <C:calendar-data/>\n            </prop>\n            {hrefs}\n        </C:calendar-multiget>\"\"\"\n\n    get_multi_data_query = \"{urn:ietf:params:xml:ns:caldav}calendar-data\"\n\n    _property_table = dict(DAVStorage._property_table)\n    _property_table.update(\n        {\n            \"color\": (\"calendar-color\", \"http://apple.com/ns/ical/\"),\n            \"description\": (\"calendar-description\", \"urn:ietf:params:xml:ns:caldav\"),\n            \"order\": (\"calendar-order\", \"http://apple.com/ns/ical/\"),\n        }\n    )\n\n    def __init__(self, start_date=None, end_date=None, item_types=(), **kwargs):\n        super().__init__(**kwargs)\n        if not isinstance(item_types, (list, tuple)):\n            raise exceptions.UserError(\"item_types must be a list.\")\n\n        self.item_types = tuple(item_types)\n        if (start_date is None) != (end_date is None):\n            raise exceptions.UserError(\n                \"If start_date is given, \" \"end_date has to be given too.\"\n            )\n        elif start_date is not None and end_date is not None:\n            namespace = dict(datetime.__dict__)\n            namespace[\"start_date\"] = self.start_date = (\n                eval(start_date, namespace)\n                if isinstance(start_date, (bytes, str))\n                else start_date\n            )\n            self.end_date = (\n                eval(end_date, namespace)\n                if isinstance(end_date, (bytes, str))\n                else end_date\n            )\n\n    @staticmethod\n    def _get_list_filters(components, start, end):\n        if components:\n            caldavfilter = \"\"\"\n                <C:comp-filter name=\"VCALENDAR\">\n                    <C:comp-filter name=\"{component}\">\n                        {timefilter}\n                    </C:comp-filter>\n                </C:comp-filter>\n                \"\"\"\n\n            if start is not None and end is not None:\n                start = start.strftime(CALDAV_DT_FORMAT)\n                end = end.strftime(CALDAV_DT_FORMAT)\n\n                timefilter = '<C:time-range start=\"{start}\" end=\"{end}\"/>'.format(\n                    start=start, end=end\n                )\n            else:\n                timefilter = \"\"\n\n            for component in components:\n                yield caldavfilter.format(component=component, timefilter=timefilter)\n        else:\n            if start is not None and end is not None:\n                yield from CalDAVStorage._get_list_filters(\n                    (\"VTODO\", \"VEVENT\"), start, end\n                )\n\n    async def list(self):\n        caldavfilters = list(\n            self._get_list_filters(self.item_types, self.start_date, self.end_date)\n        )\n        if not caldavfilters:\n            # If we don't have any filters (which is the default), taking the\n            # risk of sending a calendar-query is not necessary. There doesn't\n            # seem to be a widely-usable way to send calendar-queries with the\n            # same semantics as a PROPFIND request... so why not use PROPFIND\n            # instead?\n            #\n            # See https://github.com/dmfs/tasks/issues/118 for backstory.\n            async for href, etag in DAVStorage.list(self):\n                yield href, etag\n\n        data = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <C:calendar-query xmlns=\"DAV:\"\n                xmlns:C=\"urn:ietf:params:xml:ns:caldav\">\n                <prop>\n                    <getcontenttype/>\n                    <getetag/>\n                </prop>\n                <C:filter>\n                {caldavfilter}\n                </C:filter>\n            </C:calendar-query>\"\"\"\n\n        headers = self.session.get_default_headers()\n        # https://github.com/pimutils/vdirsyncer/issues/166\n        # The default in CalDAV's calendar-queries is 0, but the examples use\n        # an explicit value of 1 for querying items. it is extremely unclear in\n        # the spec which values from WebDAV are actually allowed.\n        headers[\"Depth\"] = \"1\"\n\n        handled_hrefs = set()\n\n        for caldavfilter in caldavfilters:\n            xml = data.format(caldavfilter=caldavfilter).encode(\"utf-8\")\n            response = await self.session.request(\n                \"REPORT\",\n                \"\",\n                data=xml,\n                headers=headers,\n            )\n            root = _parse_xml(await response.content.read())\n            rv = self._parse_prop_responses(root, handled_hrefs)\n            for href, etag, _prop in rv:\n                yield href, etag\n\n\nclass CardDAVStorage(DAVStorage):\n    storage_name = \"carddav\"\n    fileext = \".vcf\"\n    item_mimetype = \"text/vcard\"\n    discovery_class = CardDiscover\n\n    get_multi_template = \"\"\"<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n            <C:addressbook-multiget xmlns=\"DAV:\"\n                    xmlns:C=\"urn:ietf:params:xml:ns:carddav\">\n                <prop>\n                    <getetag/>\n                    <C:address-data/>\n                </prop>\n                {hrefs}\n            </C:addressbook-multiget>\"\"\"\n\n    get_multi_data_query = \"{urn:ietf:params:xml:ns:carddav}address-data\"\n\n    _property_table = dict(DAVStorage._property_table)\n    _property_table.update(\n        {\n            \"description\": (\n                \"addressbook-description\",\n                \"urn:ietf:params:xml:ns:carddav\",\n            ),\n        }\n    )\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom vdirsyncer.storage.dav import _BAD_XML_CHARS\nfrom vdirsyncer.storage.dav import _merge_xml\nfrom vdirsyncer.storage.dav import _parse_xml\n\n\ndef test_xml_utilities():\n    x = _parse_xml(\n        b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n        <multistatus xmlns=\"DAV:\">\n            <response>\n                <propstat>\n                    <status>HTTP/1.1 404 Not Found</status>\n                    <prop>\n                        <getcontenttype/>\n                    </prop>\n                </propstat>\n                <propstat>\n                    <prop>\n                        <resourcetype>\n                            <collection/>\n                        </resourcetype>\n                    </prop>\n                </propstat>\n            </response>\n        </multistatus>\n    \"\"\"\n    )\n\n    response = x.find(\"{DAV:}response\")\n    props = _merge_xml(response.findall(\"{DAV:}propstat/{DAV:}prop\"))\n    assert props.find(\"{DAV:}resourcetype/{DAV:}collection\") is not None\n    assert props.find(\"{DAV:}getcontenttype\") is not None\n\n\n@pytest.mark.parametrize(\"char\", range(32))\ndef test_xml_specialchars(char):\n    x = _parse_xml(\n        '<?xml version=\"1.0\" encoding=\"UTF-8\" ?>'\n        \"<foo>ye{}s\\r\\n\"\n        \"hello</foo>\".format(chr(char)).encode(\"ascii\")\n    )\n\n    if char in _BAD_XML_CHARS:\n        assert x.text == \"yes\\nhello\"\n"
  },
  {
    "prompt": "\n\n### localstack/utils/objects.py ###\n\nimport re\nfrom typing import Any, Callable, Dict, List, Optional, Set, Type, Union\n\nfrom .collections import ensure_list\nfrom .strings import first_char_to_lower\n\nComplexType = Union[List, Dict, object]\n\n\nclass ArbitraryAccessObj:\n    \"\"\"Dummy object that can be arbitrarily accessed - any attributes, as a callable, item assignment, ...\"\"\"\n\n    def __init__(self, name=None):\n        self.name = name\n\n    def __getattr__(self, name, *args, **kwargs):\n        return ArbitraryAccessObj(name)\n\n    def __call__(self, *args, **kwargs):\n        if self.name in [\"items\", \"keys\", \"values\"] and not args and not kwargs:\n            return []\n        return ArbitraryAccessObj()\n\n    def __getitem__(self, *args, **kwargs):\n        return ArbitraryAccessObj()\n\n    def __setitem__(self, *args, **kwargs):\n        return ArbitraryAccessObj()\n\n\nclass Mock(object):\n    \"\"\"Dummy class that can be used for mocking custom attributes.\"\"\"\n\n    pass\n\n\nclass ObjectIdHashComparator:\n    \"\"\"Simple wrapper class that allows us to create a hashset using the object id(..) as the entries' hash value\"\"\"\n\n    def __init__(self, obj):\n        self.obj = obj\n        self._hash = id(obj)\n\n    def __hash__(self):\n        return self._hash\n\n    def __eq__(self, other):\n        # assumption here is that we're comparing only against ObjectIdHash instances!\n        return self.obj == other.obj\n\n\nclass SubtypesInstanceManager:\n    \"\"\"Simple instance manager base class that scans the subclasses of a base type for concrete named\n    implementations, and lazily creates and returns (singleton) instances on demand.\"\"\"\n\n    _instances: Dict[str, \"SubtypesInstanceManager\"]\n\n    @classmethod\n    def get(cls, subtype_name: str, raise_if_missing: bool = True):\n        instances = cls.instances()\n        base_type = cls.get_base_type()\n        instance = instances.get(subtype_name)\n        if instance is None:\n            # lazily load subtype instance (required if new plugins are dynamically loaded at runtime)\n            for clazz in get_all_subclasses(base_type):\n                impl_name = clazz.impl_name()\n                if impl_name not in instances:\n                    instances[impl_name] = clazz()\n            instance = instances.get(subtype_name)\n        if not instance and raise_if_missing:\n            raise NotImplementedError(\n                f\"Unable to find implementation named '{subtype_name}' for base type {base_type}\"\n            )\n        return instance\n\n    @classmethod\n    def instances(cls) -> Dict[str, \"SubtypesInstanceManager\"]:\n        base_type = cls.get_base_type()\n        if not hasattr(base_type, \"_instances\"):\n            base_type._instances = {}\n        return base_type._instances\n\n    @staticmethod\n    def impl_name() -> str:\n        \"\"\"Name of this concrete subtype - to be implemented by subclasses.\"\"\"\n        raise NotImplementedError\n\n    @classmethod\n    def get_base_type(cls) -> Type:\n        \"\"\"Get the base class for which instances are being managed - can be customized by subtypes.\"\"\"\n        return cls\n\n\n# this requires that all subclasses have been imported before(!)\ndef get_all_subclasses(clazz: Type) -> Set[Type]:\n    \"\"\"Recursively get all subclasses of the given class.\"\"\"\n    result = set()\n    subs = clazz.__subclasses__()\n    for sub in subs:\n        result.add(sub)\n        result.update(get_all_subclasses(sub))\n    return result\n\n\ndef fully_qualified_class_name(klass: Type) -> str:\n    return f\"{klass.__module__}.{klass.__name__}\"\n\n\ndef not_none_or(value: Optional[Any], alternative: Any) -> Any:\n    \"\"\"Return 'value' if it is not None, or 'alternative' otherwise.\"\"\"\n    return value if value is not None else alternative\n\n\ndef recurse_object(obj: ComplexType, func: Callable, path: str = \"\") -> ComplexType:\n    \"\"\"Recursively apply `func` to `obj` (might be a list, dict, or other object).\"\"\"\n    obj = func(obj, path=path)\n    if isinstance(obj, list):\n        for i in range(len(obj)):\n            tmp_path = \"%s[%s]\" % (path or \".\", i)\n            obj[i] = recurse_object(obj[i], func, tmp_path)\n    elif isinstance(obj, dict):\n        for k, v in obj.items():\n            tmp_path = \"%s%s\" % (f\"{path}.\" if path else \"\", k)\n            obj[k] = recurse_object(v, func, tmp_path)\n    return obj\n\n\ndef keys_to_lower(obj: ComplexType, skip_children_of: List[str] = None) -> ComplexType:\n    \"\"\"Recursively changes all dict keys to first character lowercase. Skip children\n    of any elements whose names are contained in skip_children_of (e.g., ['Tags'])\"\"\"\n    skip_children_of = ensure_list(skip_children_of or [])\n\n    def fix_keys(o, path=\"\", **kwargs):\n        if any(re.match(r\"(^|.*\\.)%s($|[.\\[].*)\" % k, path) for k in skip_children_of):\n            return o\n        if isinstance(o, dict):\n            for k, v in dict(o).items():\n                o.pop(k)\n                o[first_char_to_lower(k)] = v\n        return o\n\n    result = recurse_object(obj, fix_keys)\n    return result\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom localstack.utils.objects import SubtypesInstanceManager\n\n\ndef test_subtypes_instance_manager():\n    class BaseClass(SubtypesInstanceManager):\n        def foo(self):\n            pass\n\n    class C1(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c1\"\n\n        def foo(self):\n            return \"bar\"\n\n    instance1 = BaseClass.get(\"c1\")\n    assert instance1\n    assert BaseClass.get(\"c1\") == instance1\n    assert instance1.foo() == \"bar\"\n    with pytest.raises(Exception):\n        assert BaseClass.get(\"c2\")\n\n    class C2(BaseClass):\n        @staticmethod\n        def impl_name() -> str:\n            return \"c2\"\n\n        def foo(self):\n            return \"baz\"\n\n    instance2 = BaseClass.get(\"c2\")\n    assert BaseClass.get(\"c2\") == instance2\n    assert instance2.foo() == \"baz\"\n"
  },
  {
    "prompt": "\n\n### tests/test_exchange_calendar.py ###\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import annotations\n\nimport functools\nimport itertools\nimport pathlib\nimport re\nimport typing\nfrom typing import Literal\nfrom collections import abc\nfrom datetime import time\n\nimport numpy as np\nimport pandas as pd\nimport pandas.testing as tm\nimport pytest\nimport pytz\nfrom pytz import UTC\n\nfrom exchange_calendars import errors\nfrom exchange_calendars.calendar_utils import (\n    ExchangeCalendarDispatcher,\n    _default_calendar_aliases,\n    _default_calendar_factories,\n)\nfrom exchange_calendars.exchange_calendar import ExchangeCalendar, days_at_time\nfrom exchange_calendars.utils import pandas_utils\n\nfrom .test_utils import T\n\n\nclass FakeCalendar(ExchangeCalendar):\n    name = \"DMY\"\n    tz = \"Asia/Ulaanbaatar\"\n    open_times = ((None, time(11, 13)),)\n    close_times = ((None, time(11, 49)),)\n\n\nclass TestCalendarRegistration:\n    @pytest.fixture\n    def dispatcher(self) -> abc.Iterator[ExchangeCalendarDispatcher]:\n        dispatcher = ExchangeCalendarDispatcher({}, {}, {})\n        yield dispatcher\n        dispatcher.clear_calendars()\n\n    @pytest.fixture\n    def dummy_cal_type(self) -> abc.Iterator[typing.Type[FakeCalendar]]:\n        yield FakeCalendar\n\n    @pytest.fixture\n    def dummy_cal(self, dummy_cal_type) -> abc.Iterator[FakeCalendar]:\n        yield dummy_cal_type()\n\n    def test_register_calendar(self, dispatcher, dummy_cal):\n        # Try to register and retrieve dummy calendar\n        dispatcher.register_calendar(\"DMY\", dummy_cal)\n        retr_cal = dispatcher.get_calendar(\"DMY\")\n        assert dummy_cal == retr_cal\n\n        # Try to register again, expecting a name collision\n        with pytest.raises(errors.CalendarNameCollision):\n            dispatcher.register_calendar(\"DMY\", dummy_cal)\n\n        # Deregister the calendar and ensure that it is removed\n        dispatcher.deregister_calendar(\"DMY\")\n        with pytest.raises(errors.InvalidCalendarName):\n            dispatcher.get_calendar(\"DMY\")\n\n    def test_register_calendar_type(self, dispatcher, dummy_cal_type):\n        dispatcher.register_calendar_type(\"DMY\", dummy_cal_type)\n        retr_cal = dispatcher.get_calendar(\"DMY\")\n        assert dummy_cal_type == type(retr_cal)\n\n    def test_both_places_are_checked(self, dispatcher, dummy_cal):\n        # if instance is registered, can't register type with same name\n        dispatcher.register_calendar(\"DMY\", dummy_cal)\n        with pytest.raises(errors.CalendarNameCollision):\n            dispatcher.register_calendar_type(\"DMY\", type(dummy_cal))\n\n        dispatcher.deregister_calendar(\"DMY\")\n\n        # if type is registered, can't register instance with same name\n        dispatcher.register_calendar_type(\"DMY\", type(dummy_cal))\n\n        with pytest.raises(errors.CalendarNameCollision):\n            dispatcher.register_calendar(\"DMY\", dummy_cal)\n\n    def test_force_registration(self, dispatcher, dummy_cal_type):\n        dispatcher.register_calendar(\"DMY\", dummy_cal_type())\n        first_dummy = dispatcher.get_calendar(\"DMY\")\n\n        # force-register a new instance\n        dispatcher.register_calendar(\"DMY\", dummy_cal_type(), force=True)\n\n        second_dummy = dispatcher.get_calendar(\"DMY\")\n\n        assert first_dummy != second_dummy\n\n\ndef test_default_calendars():\n    \"\"\"Test dispatcher and calendar default values.\"\"\"\n    dispatcher = ExchangeCalendarDispatcher(\n        calendars={},\n        calendar_factories=_default_calendar_factories,\n        aliases=_default_calendar_aliases,\n    )\n    for alias in _default_calendar_aliases:\n        cal = dispatcher.get_calendar(alias)\n        assert cal is not None\n        dispatcher.deregister_calendar(alias)\n\n    for name, cal_cls in _default_calendar_factories.items():\n        cal = dispatcher.get_calendar(name)\n        assert cal is not None\n        assert cal.side == \"left\"\n        assert cal.first_session >= cal_cls.default_start()\n        assert cal.last_session <= cal_cls.default_end()\n        dispatcher.deregister_calendar(name)\n\n\n@pytest.mark.parametrize(\n    \"day, day_offset, time_offset, tz, expected\",\n    [\n        # NYSE standard day\n        (\n            \"2016-07-19\",\n            0,\n            time(9, 31),\n            pytz.timezone(\"America/New_York\"),\n            \"2016-07-19 9:31\",\n        ),\n        # CME standard day\n        (\n            \"2016-07-19\",\n            -1,\n            time(17, 1),\n            pytz.timezone(\"America/Chicago\"),\n            \"2016-07-18 17:01\",\n        ),\n        # CME day after DST start\n        (\n            \"2004-04-05\",\n            -1,\n            time(17, 1),\n            pytz.timezone(\"America/Chicago\"),\n            \"2004-04-04 17:01\",\n        ),\n        # ICE day after DST start\n        (\n            \"1990-04-02\",\n            -1,\n            time(19, 1),\n            pytz.timezone(\"America/Chicago\"),\n            \"1990-04-01 19:01\",\n        ),\n    ],\n)\ndef test_days_at_time(day, day_offset, time_offset, tz, expected):\n    days = pd.DatetimeIndex([pd.Timestamp(day)])\n    result = days_at_time(days, time_offset, tz, day_offset)[0]\n    expected = pd.Timestamp(expected, tz=tz).tz_convert(UTC)\n    assert result == expected\n\n\ndef get_csv(name: str) -> pd.DataFrame:\n    \"\"\"Get csv file as DataFrame for given calendar `name`.\"\"\"\n    filename = name.replace(\"/\", \"-\").lower() + \".csv\"\n    path = pathlib.Path(__file__).parent.joinpath(\"resources\", filename)\n\n    df = pd.read_csv(\n        path,\n        index_col=0,\n        parse_dates=[0, 1, 2, 3, 4],\n        infer_datetime_format=True,\n    )\n    # Necessary for csv saved prior to v4.0\n    if df.index.tz is not None:\n        df.index = df.index.tz_convert(None)\n    # Necessary for csv saved prior to v4.0\n    for col in df:\n        if df[col].dt.tz is None:\n            df[col] = df[col].dt.tz_localize(UTC)\n    return df\n\n\nclass Answers:\n    \"\"\"Inputs and expected output for testing a given calendar and side.\n\n    Inputs and expected outputs are provided by public instance methods and\n    properties. These either read directly from the corresponding .csv file\n    or are evaluated from the .csv file contents. NB Properites / methods\n    MUST NOT make evaluations by way of repeating the code of the\n    ExchangeCalendar method they are intended to test!\n\n    Parameters\n    ----------\n    calendar_name\n        Canonical name of calendar for which require answer info. For\n        example, 'XNYS'.\n\n    side {'both', 'left', 'right', 'neither'}\n        Side of sessions to treat as trading minutes.\n    \"\"\"\n\n    ONE_MIN = pd.Timedelta(1, \"T\")\n    TWO_MIN = pd.Timedelta(2, \"T\")\n    ONE_DAY = pd.Timedelta(1, \"D\")\n\n    LEFT_SIDES = [\"left\", \"both\"]\n    RIGHT_SIDES = [\"right\", \"both\"]\n\n    def __init__(\n        self,\n        calendar_name: str,\n        side: Literal[\"left\", \"right\", \"both\", \"neither\"],\n    ):\n        self._name = calendar_name.upper()\n        self._side = side\n\n    # --- Exposed constructor arguments ---\n\n    @property\n    def name(self) -> str:\n        \"\"\"Name of corresponding calendar.\"\"\"\n        return self._name\n\n    @property\n    def side(self) -> str:\n        \"\"\"Side of calendar for which answers valid.\"\"\"\n        return self._side\n\n    # --- Properties read (indirectly) from csv file ---\n\n    @functools.cached_property\n    def answers(self) -> pd.DataFrame:\n        \"\"\"Answers as correspoding csv.\"\"\"\n        return get_csv(self.name)\n\n    @property\n    def sessions(self) -> pd.DatetimeIndex:\n        \"\"\"Session labels.\"\"\"\n        return self.answers.index\n\n    @property\n    def opens(self) -> pd.Series:\n        \"\"\"Market open time for each session.\"\"\"\n        return self.answers.open\n\n    @property\n    def closes(self) -> pd.Series:\n        \"\"\"Market close time for each session.\"\"\"\n        return self.answers.close\n\n    @property\n    def break_starts(self) -> pd.Series:\n        \"\"\"Break start time for each session.\"\"\"\n        return self.answers.break_start\n\n    @property\n    def break_ends(self) -> pd.Series:\n        \"\"\"Break end time for each session.\"\"\"\n        return self.answers.break_end\n\n    # --- get and helper methods ---\n\n    def get_next_session(self, session: pd.Timestamp) -> pd.Timestamp:\n        \"\"\"Get session that immediately follows `session`.\"\"\"\n        if session == self.last_session:\n            raise IndexError(\"Cannot get session later than last answers' session.\")\n        idx = self.sessions.get_loc(session) + 1\n        return self.sessions[idx]\n\n    def get_next_sessions(self, session: pd.Timestamp, count: int) -> pd.Timestamp:\n        \"\"\"Get `count` consecutive sessions starting with `session`.\"\"\"\n        assert count >= 0, \"count can only take positive integers.\"\n        start = self.sessions.get_loc(session)\n        stop = start + count\n        if stop > len(self.sessions):\n            raise IndexError(\"Cannot get sessions later than last answers' session.\")\n        return self.sessions[start:stop]\n\n    def get_prev_sessions(self, session: pd.Timestamp, count: int) -> pd.Timestamp:\n        \"\"\"Get `count` consecutive sessions ending with `session`.\"\"\"\n        assert count >= 0, \"count can only take positive integers.\"\n        stop = self.sessions.get_loc(session) + 1\n        start = stop - count\n        if start < 0:\n            raise IndexError(\"Cannot get sessions earlier than first answers' session.\")\n        return self.sessions[start:stop]\n\n    def session_has_break(self, session: pd.Timestamp) -> bool:\n        \"\"\"Query if `session` has a break.\"\"\"\n        return session in self.sessions_with_break\n\n    @staticmethod\n    def get_sessions_sample(sessions: pd.DatetimeIndex):\n        \"\"\"Return sample of given `sessions`.\n\n        Sample includes:\n            All sessions within first two years of `sessions`.\n            All sessions within last two years of `sessions`.\n            All sessions falling:\n                within first 3 days of any month.\n                from 28th of any month.\n                from 14th through 16th of any month.\n        \"\"\"\n        if sessions.empty:\n            return sessions\n\n        mask = (\n            (sessions < sessions[0] + pd.DateOffset(years=2))\n            | (sessions > sessions[-1] - pd.DateOffset(years=2))\n            | (sessions.day <= 3)\n            | (sessions.day >= 28)\n            | (14 <= sessions.day) & (sessions.day <= 16)\n        )\n        return sessions[mask]\n\n    def get_sessions_minutes(\n        self, start: pd.Timestamp, end: pd.Timestamp | int = 1\n    ) -> pd.DatetimeIndex:\n        \"\"\"Get trading minutes for 1 or more consecutive sessions.\n\n        Parameters\n        ----------\n        start\n            Session from which to get trading minutes.\n        end\n            Session through which to get trading mintues. Can be passed as:\n                pd.Timestamp: return will include trading minutes for `end`\n                    session.\n                int: where int represents number of consecutive sessions\n                    inclusive of `start`, for which require trading\n                    minutes. Default is 1, such that by default will return\n                    trading minutes for only `start` session.\n        \"\"\"\n        idx = self.sessions.get_loc(start)\n        stop = idx + end if isinstance(end, int) else self.sessions.get_loc(end) + 1\n        indexer = slice(idx, stop)\n\n        dtis = []\n        for first, last, last_am, first_pm in zip(\n            self.first_minutes[indexer],\n            self.last_minutes[indexer],\n            self.last_am_minutes[indexer],\n            self.first_pm_minutes[indexer],\n        ):\n            if pd.isna(last_am):\n                dtis.append(pd.date_range(first, last, freq=\"T\"))\n            else:\n                dtis.append(pd.date_range(first, last_am, freq=\"T\"))\n                dtis.append(pd.date_range(first_pm, last, freq=\"T\"))\n\n        return pandas_utils.indexes_union(dtis)\n\n    def get_session_minutes(\n        self, session: pd.Timestamp\n    ) -> tuple[pd.DatetimeIndex, ...]:\n        \"\"\"Get trading minutes a single `session`.\n\n        Returns\n        -------\n        tuple[pd.DatetimeIndex, ...]\n            If `session` has a break, returns 2-tuple where:\n                [0] minutes of am session.\n                [1] minutes of pm session.\n            If `session` does not have a break, returns 1-tuple with\n            element holding minutes of session.\n        \"\"\"\n        first = self.first_minutes[session]\n        last = self.last_minutes[session]\n        last_am = self.last_am_minutes[session]\n        first_pm = self.first_pm_minutes[session]\n\n        if pd.isna(last_am):\n            return (pd.date_range(first, last, freq=\"T\"),)\n        else:\n            return (\n                pd.date_range(first, last_am, freq=\"T\"),\n                pd.date_range(first_pm, last, freq=\"T\"),\n            )\n\n    def get_session_break_minutes(self, session: pd.Timestamp) -> pd.DatetimeIndex:\n        \"\"\"Get break minutes for single `session`.\"\"\"\n        if not self.session_has_break(session):\n            return pd.DatetimeIndex([], tz=UTC)\n        else:\n            am_minutes, pm_minutes = self.get_session_minutes(session)\n        first = am_minutes[-1] + self.ONE_MIN\n        last = pm_minutes[0] - self.ONE_MIN\n        return pd.date_range(first, last, freq=\"T\")\n\n    def get_session_edge_minutes(\n        self, session: pd.Timestamp, delta: int = 0\n    ) -> pd.Timestamp:\n        \"\"\"Get edge trading minutes for a `session`.\n\n        Return will include first and last trading minutes of session and,\n        if applicable, subsessions. Passing `delta` will double length\n        of return by including trading minutes at `delta` minutes 'inwards'\n        from the standard edge minutes. NB `delta` should be less than\n        the session/subsession duration - this condition is NOT\n        VERIFIED by this method.\n        \"\"\"\n        delta = pd.Timedelta(delta, \"T\")\n        first_minute = self.first_minutes[session]\n        last_minute = self.last_minutes[session]\n        has_break = self.session_has_break(session)\n        if has_break:\n            last_am_minute = self.last_am_minutes[session]\n            first_pm_minute = self.first_pm_minutes[session]\n\n        minutes = [first_minute, last_minute]\n        if delta:\n            minutes.append(first_minute + delta)\n            minutes.append(last_minute - delta)\n        if has_break:\n            last_am_minute = self.last_am_minutes[session]\n            first_pm_minute = self.first_pm_minutes[session]\n            minutes.extend([last_am_minute, first_pm_minute])\n            if delta:\n                minutes.append(last_am_minute - delta)\n                minutes.append(first_pm_minute + delta)\n\n        return pd.DatetimeIndex(minutes)\n\n    # --- Evaluated general calendar properties ---\n\n    @functools.cached_property\n    def has_a_session_with_break(self) -> pd.DatetimeIndex:\n        \"\"\"Does any session of answers have a break.\"\"\"\n        return self.break_starts.notna().any()\n\n    @property\n    def has_a_session_without_break(self) -> bool:\n        \"\"\"Does any session of answers not have a break.\"\"\"\n        return self.break_starts.isna().any()\n\n    # --- Evaluated properties for first and last sessions ---\n\n    @property\n    def first_session(self) -> pd.Timestamp:\n        \"\"\"First session covered by answers.\"\"\"\n        return self.sessions[0]\n\n    @property\n    def last_session(self) -> pd.Timestamp:\n        \"\"\"Last session covered by answers.\"\"\"\n        return self.sessions[-1]\n\n    @property\n    def sessions_range(self) -> tuple[pd.Timestamp, pd.Timestamp]:\n        \"\"\"First and last sessions covered by answers.\"\"\"\n        return self.first_session, self.last_session\n\n    @property\n    def first_session_open(self) -> pd.Timestamp:\n        \"\"\"Open time of first session covered by answers.\"\"\"\n        return self.opens[0]\n\n    @property\n    def last_session_close(self) -> pd.Timestamp:\n        \"\"\"Close time of last session covered by answers.\"\"\"\n        return self.closes[-1]\n\n    @property\n    def first_minute(self) -> pd.Timestamp:\n        open_ = self.first_session_open\n        return open_ if self.side in self.LEFT_SIDES else open_ + self.ONE_MIN\n\n    @property\n    def last_minute(self) -> pd.Timestamp:\n        close = self.last_session_close\n        return close if self.side in self.RIGHT_SIDES else close - self.ONE_MIN\n\n    @property\n    def trading_minutes_range(self) -> tuple[pd.Timestamp, pd.Timestamp]:\n        \"\"\"First and last trading minutes covered by answers.\"\"\"\n        return self.first_minute, self.last_minute\n\n    # --- out-of-bounds properties ---\n\n    @property\n    def minute_too_early(self) -> pd.Timestamp:\n        \"\"\"Minute earlier than first trading minute.\"\"\"\n        return self.first_minute - self.ONE_MIN\n\n    @property\n    def minute_too_late(self) -> pd.Timestamp:\n        \"\"\"Minute later than last trading minute.\"\"\"\n        return self.last_minute + self.ONE_MIN\n\n    @property\n    def session_too_early(self) -> pd.Timestamp:\n        \"\"\"Date earlier than first session.\"\"\"\n        return self.first_session - self.ONE_DAY\n\n    @property\n    def session_too_late(self) -> pd.Timestamp:\n        \"\"\"Date later than last session.\"\"\"\n        return self.last_session + self.ONE_DAY\n\n    # --- Evaluated properties covering every session. ---\n\n    @functools.cached_property\n    def first_minutes(self) -> pd.Series:\n        \"\"\"First trading minute of each session (UTC).\"\"\"\n        if self.side in self.LEFT_SIDES:\n            minutes = self.opens.copy()\n        else:\n            minutes = self.opens + self.ONE_MIN\n        minutes.name = \"first_minutes\"\n        return minutes\n\n    @property\n    def first_minutes_plus_one(self) -> pd.Series:\n        \"\"\"First trading minute of each session plus one minute.\"\"\"\n        return self.first_minutes + self.ONE_MIN\n\n    @property\n    def first_minutes_less_one(self) -> pd.Series:\n        \"\"\"First trading minute of each session less one minute.\"\"\"\n        return self.first_minutes - self.ONE_MIN\n\n    @functools.cached_property\n    def last_minutes(self) -> pd.Series:\n        \"\"\"Last trading minute of each session.\"\"\"\n        if self.side in self.RIGHT_SIDES:\n            minutes = self.closes.copy()\n        else:\n            minutes = self.closes - self.ONE_MIN\n        minutes.name = \"last_minutes\"\n        return minutes\n\n    @property\n    def last_minutes_plus_one(self) -> pd.Series:\n        \"\"\"Last trading minute of each session plus one minute.\"\"\"\n        return self.last_minutes + self.ONE_MIN\n\n    @property\n    def last_minutes_less_one(self) -> pd.Series:\n        \"\"\"Last trading minute of each session less one minute.\"\"\"\n        return self.last_minutes - self.ONE_MIN\n\n    @functools.cached_property\n    def last_am_minutes(self) -> pd.Series:\n        \"\"\"Last pre-break trading minute of each session.\n\n        NaT if session does not have a break.\n        \"\"\"\n        if self.side in self.RIGHT_SIDES:\n            minutes = self.break_starts.copy()\n        else:\n            minutes = self.break_starts - self.ONE_MIN\n        minutes.name = \"last_am_minutes\"\n        return minutes\n\n    @property\n    def last_am_minutes_plus_one(self) -> pd.Series:\n        \"\"\"Last pre-break trading minute of each session plus one minute.\"\"\"\n        return self.last_am_minutes + self.ONE_MIN\n\n    @property\n    def last_am_minutes_less_one(self) -> pd.Series:\n        \"\"\"Last pre-break trading minute of each session less one minute.\"\"\"\n        return self.last_am_minutes - self.ONE_MIN\n\n    @functools.cached_property\n    def first_pm_minutes(self) -> pd.Series:\n        \"\"\"First post-break trading minute of each session.\n\n        NaT if session does not have a break.\n        \"\"\"\n        if self.side in self.LEFT_SIDES:\n            minutes = self.break_ends.copy()\n        else:\n            minutes = self.break_ends + self.ONE_MIN\n        minutes.name = \"first_pm_minutes\"\n        return minutes\n\n    @property\n    def first_pm_minutes_plus_one(self) -> pd.Series:\n        \"\"\"First post-break trading minute of each session plus one minute.\"\"\"\n        return self.first_pm_minutes + self.ONE_MIN\n\n    @property\n    def first_pm_minutes_less_one(self) -> pd.Series:\n        \"\"\"First post-break trading minute of each session less one minute.\"\"\"\n        return self.first_pm_minutes - self.ONE_MIN\n\n    # --- Evaluated session sets and ranges that meet a specific condition ---\n\n    @property\n    def _mask_breaks(self) -> pd.Series:\n        return self.break_starts.notna()\n\n    @functools.cached_property\n    def sessions_with_break(self) -> pd.DatetimeIndex:\n        return self.sessions[self._mask_breaks]\n\n    @functools.cached_property\n    def sessions_without_break(self) -> pd.DatetimeIndex:\n        return self.sessions[~self._mask_breaks]\n\n    @property\n    def sessions_without_break_run(self) -> pd.DatetimeIndex:\n        \"\"\"Longest run of consecutive sessions without a break.\"\"\"\n        s = self.break_starts.isna()\n        if s.empty:\n            return pd.DatetimeIndex([], tz=UTC)\n        return pandas_utils.longest_run(s)\n\n    @property\n    def sessions_without_break_range(self) -> tuple[pd.Timestamp, pd.Timestamp] | None:\n        \"\"\"Longest session range that does not include a session with a break.\n\n        Returns None if all sessions have a break.\n        \"\"\"\n        sessions = self.sessions_without_break_run\n        if sessions.empty:\n            return None\n        return sessions[0], sessions[-1]\n\n    @property\n    def _mask_sessions_without_gap_after(self) -> pd.Series:\n        if self.side == \"neither\":\n            # will always have gap after if neither open or close are trading\n            # minutes (assuming sessions cannot overlap)\n            return pd.Series(False, index=self.sessions)\n\n        elif self.side == \"both\":\n            # a trading minute cannot be a minute of more than one session.\n            assert not (self.closes == self.opens.shift(-1)).any()\n            # there will be no gap if next open is one minute after previous close\n            closes_plus_min = self.closes + pd.Timedelta(1, \"T\")\n            return self.opens.shift(-1) == closes_plus_min\n\n        else:\n            return self.opens.shift(-1) == self.closes\n\n    @property\n    def _mask_sessions_without_gap_before(self) -> pd.Series:\n        if self.side == \"neither\":\n            # will always have gap before if neither open or close are trading\n            # minutes (assuming sessions cannot overlap)\n            return pd.Series(False, index=self.sessions)\n\n        elif self.side == \"both\":\n            # a trading minute cannot be a minute of more than one session.\n            assert not (self.closes == self.opens.shift(-1)).any()\n            # there will be no gap if previous close is one minute before next open\n            opens_minus_one = self.opens - pd.Timedelta(1, \"T\")\n            return self.closes.shift(1) == opens_minus_one\n\n        else:\n            return self.closes.shift(1) == self.opens\n\n    @functools.cached_property\n    def sessions_without_gap_after(self) -> pd.DatetimeIndex:\n        \"\"\"Sessions not followed by a non-trading minute.\n\n        Rather, sessions immediately followed by first trading minute of\n        next session.\n        \"\"\"\n        mask = self._mask_sessions_without_gap_after\n        return self.sessions[mask][:-1]\n\n    @functools.cached_property\n    def sessions_with_gap_after(self) -> pd.DatetimeIndex:\n        \"\"\"Sessions followed by a non-trading minute.\"\"\"\n        mask = self._mask_sessions_without_gap_after\n        return self.sessions[~mask][:-1]\n\n    @functools.cached_property\n    def sessions_without_gap_before(self) -> pd.DatetimeIndex:\n        \"\"\"Sessions not preceeded by a non-trading minute.\n\n        Rather, sessions immediately preceeded by last trading minute of\n        previous session.\n        \"\"\"\n        mask = self._mask_sessions_without_gap_before\n        return self.sessions[mask][1:]\n\n    @functools.cached_property\n    def sessions_with_gap_before(self) -> pd.DatetimeIndex:\n        \"\"\"Sessions preceeded by a non-trading minute.\"\"\"\n        mask = self._mask_sessions_without_gap_before\n        return self.sessions[~mask][1:]\n\n    # times are changing...\n\n    @property\n    def sessions_unchanging_times_run(self) -> pd.DatetimeIndex:\n        \"\"\"Longest run of sessions that have unchanging times.\"\"\"\n        bv = ~self.sessions.isin(self.sessions_next_time_different)\n        s = pd.Series(bv, index=self.sessions)\n        return pandas_utils.longest_run(s)\n\n    @functools.lru_cache(maxsize=16)\n    def _get_sessions_with_times_different_to_next_session(\n        self,\n        column: Literal[\"opens\", \"closes\", \"break_starts\", \"break_ends\"],\n    ) -> list[pd.DatetimeIndex]:\n        \"\"\"For a given answers column, get session labels where time differs\n        from time of next session.\n\n        Where `column` is a break time (\"break_starts\" or \"break_ends\"), return\n        will not include sessions when next session has a different `has_break`\n        status. For example, if session_0 has a break and session_1 does not have\n        a break, or vice versa, then session_0 will not be included to return. For\n        sessions followed by a session with a different `has_break` status, see\n        `_get_sessions_with_has_break_different_to_next_session`.\n\n        Returns\n        -------\n        list of pd.Datetimeindex\n            [0] sessions with earlier next session\n            [1] sessions with later next session\n        \"\"\"\n        # column takes string to allow lru_cache (Series not hashable)\n\n        is_break_col = column[0] == \"b\"\n        column_ = getattr(self, column)\n\n        if is_break_col:\n            if column_.isna().all():\n                return [pd.DatetimeIndex([])] * 2\n            column_ = column_.fillna(method=\"ffill\").fillna(method=\"bfill\")\n\n        diff = (column_.shift(-1) - column_)[:-1]\n        remainder = diff % pd.Timedelta(hours=24)\n        mask = remainder != pd.Timedelta(0)\n        sessions = self.sessions[:-1][mask]\n        next_session_earlier_mask = remainder[mask] > pd.Timedelta(hours=12)\n        next_session_earlier = sessions[next_session_earlier_mask]\n        next_session_later = sessions[~next_session_earlier_mask]\n\n        if is_break_col:\n            mask = next_session_earlier.isin(self.sessions_without_break)\n            next_session_earlier = next_session_earlier.drop(next_session_earlier[mask])\n            mask = next_session_later.isin(self.sessions_without_break)\n            next_session_later = next_session_later.drop(next_session_later[mask])\n\n        return [next_session_earlier, next_session_later]\n\n    @property\n    def _sessions_with_opens_different_to_next_session(\n        self,\n    ) -> list[pd.DatetimeIndex]:\n        return self._get_sessions_with_times_different_to_next_session(\"opens\")\n\n    @property\n    def _sessions_with_closes_different_to_next_session(\n        self,\n    ) -> list[pd.DatetimeIndex]:\n        return self._get_sessions_with_times_different_to_next_session(\"closes\")\n\n    @property\n    def _sessions_with_break_start_different_to_next_session(\n        self,\n    ) -> list[pd.DatetimeIndex]:\n        return self._get_sessions_with_times_different_to_next_session(\"break_starts\")\n\n    @property\n    def _sessions_with_break_end_different_to_next_session(\n        self,\n    ) -> list[pd.DatetimeIndex]:\n        return self._get_sessions_with_times_different_to_next_session(\"break_ends\")\n\n    @property\n    def sessions_next_open_earlier(self) -> pd.DatetimeIndex:\n        return self._sessions_with_opens_different_to_next_session[0]\n\n    @property\n    def sessions_next_open_later(self) -> pd.DatetimeIndex:\n        return self._sessions_with_opens_different_to_next_session[1]\n\n    @property\n    def sessions_next_open_different(self) -> pd.DatetimeIndex:\n        return self.sessions_next_open_earlier.union(self.sessions_next_open_later)\n\n    @property\n    def sessions_next_close_earlier(self) -> pd.DatetimeIndex:\n        return self._sessions_with_closes_different_to_next_session[0]\n\n    @property\n    def sessions_next_close_later(self) -> pd.DatetimeIndex:\n        return self._sessions_with_closes_different_to_next_session[1]\n\n    @property\n    def sessions_next_close_different(self) -> pd.DatetimeIndex:\n        return self.sessions_next_close_earlier.union(self.sessions_next_close_later)\n\n    @property\n    def sessions_next_break_start_earlier(self) -> pd.DatetimeIndex:\n        return self._sessions_with_break_start_different_to_next_session[0]\n\n    @property\n    def sessions_next_break_start_later(self) -> pd.DatetimeIndex:\n        return self._sessions_with_break_start_different_to_next_session[1]\n\n    @property\n    def sessions_next_break_start_different(self) -> pd.DatetimeIndex:\n        earlier = self.sessions_next_break_start_earlier\n        later = self.sessions_next_break_start_later\n        return earlier.union(later)\n\n    @property\n    def sessions_next_break_end_earlier(self) -> pd.DatetimeIndex:\n        return self._sessions_with_break_end_different_to_next_session[0]\n\n    @property\n    def sessions_next_break_end_later(self) -> pd.DatetimeIndex:\n        return self._sessions_with_break_end_different_to_next_session[1]\n\n    @property\n    def sessions_next_break_end_different(self) -> pd.DatetimeIndex:\n        earlier = self.sessions_next_break_end_earlier\n        later = self.sessions_next_break_end_later\n        return earlier.union(later)\n\n    @functools.cached_property\n    def _get_sessions_with_has_break_different_to_next_session(\n        self,\n    ) -> tuple[pd.DatetimeIndex, pd.DatetimeIndex]:\n        \"\"\"Get sessions with 'has_break' different to next session.\n\n        Returns\n        -------\n        tuple[pd.DatetimeIndex, pd.DatetimeIndex]\n            [0] Sessions that have a break and are immediately followed by\n            a session which does not have a break.\n            [1] Sessions that do not have a break and are immediately\n            followed by a session which does have a break.\n        \"\"\"\n        mask = (self.break_starts.notna() & self.break_starts.shift(-1).isna())[:-1]\n        sessions_with_break_next_session_without_break = self.sessions[:-1][mask]\n\n        mask = (self.break_starts.isna() & self.break_starts.shift(-1).notna())[:-1]\n        sessions_without_break_next_session_with_break = self.sessions[:-1][mask]\n\n        return (\n            sessions_with_break_next_session_without_break,\n            sessions_without_break_next_session_with_break,\n        )\n\n    @property\n    def sessions_with_break_next_session_without_break(self) -> pd.DatetimeIndex:\n        return self._get_sessions_with_has_break_different_to_next_session[0]\n\n    @property\n    def sessions_without_break_next_session_with_break(self) -> pd.DatetimeIndex:\n        return self._get_sessions_with_has_break_different_to_next_session[1]\n\n    @functools.cached_property\n    def sessions_next_time_different(self) -> pd.DatetimeIndex:\n        \"\"\"Sessions where next session has a different time for any column.\n\n        Includes sessions where next session has a different `has_break`\n        status.\n        \"\"\"\n        return pandas_utils.indexes_union(\n            [\n                self.sessions_next_open_different,\n                self.sessions_next_close_different,\n                self.sessions_next_break_start_different,\n                self.sessions_next_break_end_different,\n                self.sessions_with_break_next_session_without_break,\n                self.sessions_without_break_next_session_with_break,\n            ]\n        )\n\n    # session blocks...\n\n    def _create_changing_times_session_block(\n        self, session: pd.Timestamp\n    ) -> pd.DatetimeIndex:\n        \"\"\"Create block of sessions with changing times.\n\n        Given a `session` known to have at least one time (open, close,\n        break_start or break_end) different from the next session, returns\n        a block of consecutive sessions ending with the first session after\n        `session` that has the same times as the session that immediately\n        preceeds it (i.e. the last two sessions of the block will have the\n        same times), or the last calendar session.\n        \"\"\"\n        start_idx = self.sessions.get_loc(session)\n        end_idx = start_idx + 1\n        while self.sessions[end_idx] in self.sessions_next_time_different:\n            end_idx += 1\n        end_idx += 2  # +1 to include session with same times, +1 to serve as end index\n        return self.sessions[start_idx:end_idx]\n\n    def _get_normal_session_block(self) -> pd.DatetimeIndex:\n        \"\"\"Block of 3 sessions with unchanged timings.\"\"\"\n        start_idx = len(self.sessions) // 3\n        end_idx = start_idx + 21\n\n        def times_equal(*s):\n            for elems in zip(*s):\n                if not set(elems) == {pd.NaT}:\n                    if not len({elem.time() for elem in elems}) == 1:\n                        return False\n            return True\n\n        for i in range(start_idx, end_idx):\n            times_1 = self.answers.iloc[i]\n            times_2 = self.answers.iloc[i + 1]\n            times_3 = self.answers.iloc[i + 2]\n            if times_equal(times_1, times_2, times_3):\n                break\n            assert i < (end_idx - 1), \"Unable to evaluate a normal session block!\"\n        return self.sessions[i : i + 3]\n\n    def _get_session_block(\n        self, from_session_of: pd.DatetimeIndex, to_session_of: pd.DatetimeIndex\n    ) -> pd.DatetimeIndex:\n        \"\"\"Get session block with bounds defined by sessions of given indexes.\n\n        Block will start with middle session of `from_session_of`.\n\n        Block will run to the nearest subsequent session of `to_session_of`\n        (or `self.final_session` if this comes first). Block will end with\n        the session that immedidately follows this session.\n        \"\"\"\n        i = len(from_session_of) // 2\n        start_session = from_session_of[i]\n\n        start_idx = self.sessions.get_loc(start_session)\n        end_idx = start_idx + 1\n        end_session = self.sessions[end_idx]\n\n        while end_session not in to_session_of and end_session != self.last_session:\n            end_idx += 1\n            end_session = self.sessions[end_idx]\n\n        return self.sessions[start_idx : end_idx + 2]\n\n    @functools.cached_property\n    def session_blocks(self) -> dict[str, pd.DatetimeIndex]:\n        \"\"\"Dictionary of session blocks of a particular behaviour.\n\n        A block comprises either a single session or multiple contiguous\n        sessions.\n\n        Keys:\n            \"normal\" - three sessions with unchanging timings.\n            \"first_three\" - answers' first three sessions.\n            \"last_three\" - answers's last three sessions.\n            \"next_open_earlier\" - session 1 open is earlier than session 0\n                open.\n            \"next_open_later\" - session 1 open is later than session 0\n                open.\n            \"next_close_earlier\" - session 1 close is earlier than session\n                0 close.\n            \"next_close_later\" - session 1 close is later than session 0\n                close.\n            \"next_break_start_earlier\" - session 1 break_start is earlier\n                than session 0 break_start.\n            \"next_break_start_later\" - session 1 break_start is later than\n                session 0 break_start.\n            \"next_break_end_earlier\" - session 1 break_end is earlier than\n                session 0 break_end.\n            \"next_break_end_later\" - session 1 break_end is later than\n                session 0 break_end.\n            \"with_break_to_without_break\" - session 0 has a break, session\n                1 does not have a break.\n            \"without_break_to_with_break\" - session 0 does not have a\n                break, session 1 does have a break.\n            \"without_gap_to_with_gap\" - session 0 is not followed by a\n                gap, session -2 is followed by a gap, session -1 is\n                preceeded by a gap.\n            \"with_gap_to_without_gap\" - session 0 is followed by a gap,\n                session -2 is not followed by a gap, session -1 is not\n                preceeded by a gap.\n            \"follows_non_session\" - one or two sessions where session 0\n                is preceeded by a date that is a non-session.\n            \"follows_non_session\" - one or two sessions where session -1\n                is followed by a date that is a non-session.\n            \"contains_non_session\" = two sessions with at least one\n                non-session date in between.\n\n        If no such session block exists for any key then value will take an\n        empty DatetimeIndex (UTC).\n        \"\"\"\n        blocks = {}\n        blocks[\"normal\"] = self._get_normal_session_block()\n        blocks[\"first_three\"] = self.sessions[:3]\n        blocks[\"last_three\"] = self.sessions[-3:]\n\n        # blocks here include where:\n        #     session 1 has at least one different time from session 0\n        #     session 0 has a break and session 1 does not (and vice versa)\n        sessions_indexes = (\n            (\"next_open_earlier\", self.sessions_next_open_earlier),\n            (\"next_open_later\", self.sessions_next_open_later),\n            (\"next_close_earlier\", self.sessions_next_close_earlier),\n            (\"next_close_later\", self.sessions_next_close_later),\n            (\"next_break_start_earlier\", self.sessions_next_break_start_earlier),\n            (\"next_break_start_later\", self.sessions_next_break_start_later),\n            (\"next_break_end_earlier\", self.sessions_next_break_end_earlier),\n            (\"next_break_end_later\", self.sessions_next_break_end_later),\n            (\n                \"with_break_to_without_break\",\n                self.sessions_with_break_next_session_without_break,\n            ),\n            (\n                \"without_break_to_with_break\",\n                self.sessions_without_break_next_session_with_break,\n            ),\n        )\n\n        for name, index in sessions_indexes:\n            if index.empty:\n                blocks[name] = pd.DatetimeIndex([])\n            else:\n                session = index[0]\n                blocks[name] = self._create_changing_times_session_block(session)\n\n        # blocks here move from session with gap to session without gap and vice versa\n        if (not self.sessions_with_gap_after.empty) and (\n            not self.sessions_without_gap_after.empty\n        ):\n            without_gap_to_with_gap = self._get_session_block(\n                self.sessions_without_gap_after, self.sessions_with_gap_after\n            )\n            with_gap_to_without_gap = self._get_session_block(\n                self.sessions_with_gap_after, self.sessions_without_gap_after\n            )\n        else:\n            without_gap_to_with_gap = pd.DatetimeIndex([])\n            with_gap_to_without_gap = pd.DatetimeIndex([])\n\n        blocks[\"without_gap_to_with_gap\"] = without_gap_to_with_gap\n        blocks[\"with_gap_to_without_gap\"] = with_gap_to_without_gap\n\n        # blocks that adjoin or contain a non_session date\n        follows_non_session = pd.DatetimeIndex([])\n        preceeds_non_session = pd.DatetimeIndex([])\n        contains_non_session = pd.DatetimeIndex([])\n        if len(self.non_sessions) > 1:\n            diff = self.non_sessions[1:] - self.non_sessions[:-1]\n            mask = diff != pd.Timedelta(\n                1, \"D\"\n            )  # non_session dates followed by a session\n            valid_non_sessions = self.non_sessions[:-1][mask]\n            if len(valid_non_sessions) > 1:\n                slce = self.sessions.slice_indexer(\n                    valid_non_sessions[0], valid_non_sessions[1]\n                )\n                sessions_between_non_sessions = self.sessions[slce]\n                block_length = min(2, len(sessions_between_non_sessions))\n                follows_non_session = sessions_between_non_sessions[:block_length]\n                preceeds_non_session = sessions_between_non_sessions[-block_length:]\n                # take session before and session after non-session\n                contains_non_session = self.sessions[slce.stop - 1 : slce.stop + 1]\n\n        blocks[\"follows_non_session\"] = follows_non_session\n        blocks[\"preceeds_non_session\"] = preceeds_non_session\n        blocks[\"contains_non_session\"] = contains_non_session\n\n        return blocks\n\n    def session_block_generator(self) -> abc.Iterator[tuple[str, pd.DatetimeIndex]]:\n        \"\"\"Generator of session blocks of a particular behaviour.\"\"\"\n        for name, block in self.session_blocks.items():\n            if not block.empty:\n                yield (name, block)\n\n    @functools.cached_property\n    def session_block_minutes(self) -> dict[str, pd.DatetimeIndex]:\n        \"\"\"Trading minutes for each `session_block`.\n\n        Key:\n            Session block name as documented to `session_blocks`.\n        Value:\n            Trading minutes of corresponding session block.\n        \"\"\"\n        d = {}\n        for name, block in self.session_blocks.items():\n            if block.empty:\n                d[name] = pd.DatetimeIndex([], tz=UTC)\n                continue\n            d[name] = self.get_sessions_minutes(block[0], len(block))\n        return d\n\n    @property\n    def sessions_sample(self) -> pd.DatetimeIndex:\n        \"\"\"Sample of normal and unusual sessions.\n\n        Sample comprises set of sessions of all `session_blocks` (see\n        `session_blocks` doc). In this way sample includes at least one\n        sample of every indentified unique circumstance.\n        \"\"\"\n        dtis = list(self.session_blocks.values())\n        return pandas_utils.indexes_union(dtis)\n\n    # non-sessions...\n\n    @functools.cached_property\n    def non_sessions(self) -> pd.DatetimeIndex:\n        \"\"\"Dates (UTC midnight) within answers range that are not sessions.\"\"\"\n        all_dates = pd.date_range(\n            start=self.first_session, end=self.last_session, freq=\"D\"\n        )\n        return all_dates.difference(self.sessions)\n\n    @property\n    def sessions_range_defined_by_non_sessions(\n        self,\n    ) -> tuple[tuple[pd.Timestamp, pd.Timestamp], pd.Datetimeindex] | None:\n        \"\"\"Range containing sessions although defined with non-sessions.\n\n        Returns\n        -------\n        tuple[tuple[pd.Timestamp, pd.Timestamp], pd.Datetimeindex]:\n            [0] tuple[pd.Timestamp, pd.Timestamp]:\n                [0] range start as non-session date.\n                [1] range end as non-session date.\n            [1] pd.DatetimeIndex:\n                Sessions in range.\n        \"\"\"\n        non_sessions = self.non_sessions\n        if len(non_sessions) <= 1:\n            return None\n        limit = len(self.non_sessions) - 2\n        i = 0\n        start, end = non_sessions[i], non_sessions[i + 1]\n        while (end - start) < pd.Timedelta(4, \"D\"):\n            i += 1\n            start, end = non_sessions[i], non_sessions[i + 1]\n            if i == limit:\n                # Unable to evaluate range from consecutive non-sessions\n                # that covers >= 3 sessions. Just go with max range...\n                start, end = non_sessions[0], non_sessions[-1]\n        slice_start, slice_end = self.sessions.searchsorted((start, end))\n        return (start, end), self.sessions[slice_start:slice_end]\n\n    @property\n    def non_sessions_run(self) -> pd.DatetimeIndex:\n        \"\"\"Longest run of non_sessions.\"\"\"\n        ser = self.sessions.to_series()\n        diff = ser.shift(-1) - ser\n        max_diff = diff.max()\n        if max_diff == pd.Timedelta(1, \"D\"):\n            return pd.DatetimeIndex([])\n        session_before_run = diff[diff == max_diff].index[-1]\n        run = pd.date_range(\n            start=session_before_run + pd.Timedelta(1, \"D\"),\n            periods=(max_diff // pd.Timedelta(1, \"D\")) - 1,\n            freq=\"D\",\n        )\n        assert run.isin(self.non_sessions).all()\n        assert run[0] > self.first_session\n        assert run[-1] < self.last_session\n        return run\n\n    @property\n    def non_sessions_range(self) -> tuple[pd.Timestamp, pd.Timestamp] | None:\n        \"\"\"Longest range covering a period without a session.\"\"\"\n        non_sessions_run = self.non_sessions_run\n        if non_sessions_run.empty:\n            return None\n        else:\n            return self.non_sessions_run[0], self.non_sessions_run[-1]\n\n    # --- Evaluated sets of minutes ---\n\n    @functools.cached_property\n    def _evaluate_trading_and_break_minutes(self) -> tuple[tuple, tuple]:\n        \"\"\"Edge trading minutes of `sessions_sample`.\n\n        Returns\n        -------\n        tuple of tuple[tuple[trading_minutes], session]\n\n            tuple[trading_minutes] includes:\n                first two trading minutes of a session.\n                last two trading minutes of a session.\n                If breaks:\n                    last two trading minutes of session's am subsession.\n                    first two trading minutes of session's pm subsession.\n\n            session\n                Session of trading_minutes\n        \"\"\"\n        sessions = self.sessions_sample\n        first_mins = self.first_minutes[sessions]\n        first_mins_plus_one = first_mins + self.ONE_MIN\n        last_mins = self.last_minutes[sessions]\n        last_mins_less_one = last_mins - self.ONE_MIN\n\n        trading_mins = []\n        break_mins = []\n\n        for session, mins_ in zip(\n            sessions,\n            zip(first_mins, first_mins_plus_one, last_mins, last_mins_less_one),\n        ):\n            trading_mins.append((mins_, session))\n\n        if self.has_a_session_with_break:\n            last_am_mins = self.last_am_minutes[sessions]\n            last_am_mins = last_am_mins[last_am_mins.notna()]\n            first_pm_mins = self.first_pm_minutes[last_am_mins.index]\n\n            last_am_mins_less_one = last_am_mins - self.ONE_MIN\n            last_am_mins_plus_one = last_am_mins + self.ONE_MIN\n            last_am_mins_plus_two = last_am_mins + self.TWO_MIN\n\n            first_pm_mins_plus_one = first_pm_mins + self.ONE_MIN\n            first_pm_mins_less_one = first_pm_mins - self.ONE_MIN\n            first_pm_mins_less_two = first_pm_mins - self.TWO_MIN\n\n            for session, mins_ in zip(\n                last_am_mins.index,\n                zip(\n                    last_am_mins,\n                    last_am_mins_less_one,\n                    first_pm_mins,\n                    first_pm_mins_plus_one,\n                ),\n            ):\n                trading_mins.append((mins_, session))\n\n            for session, mins_ in zip(\n                last_am_mins.index,\n                zip(\n                    last_am_mins_plus_one,\n                    last_am_mins_plus_two,\n                    first_pm_mins_less_one,\n                    first_pm_mins_less_two,\n                ),\n            ):\n                break_mins.append((mins_, session))\n\n        return (tuple(trading_mins), tuple(break_mins))\n\n    @property\n    def trading_minutes(self) -> tuple[tuple[tuple[pd.Timestamp], pd.Timestamp]]:\n        \"\"\"Edge trading minutes of `sessions_sample`.\n\n        Returns\n        -------\n        tuple of tuple[tuple[trading_minutes], session]\n\n            tuple[trading_minutes] includes:\n                first two trading minutes of a session.\n                last two trading minutes of a session.\n                If breaks:\n                    last two trading minutes of session's am subsession.\n                    first two trading minutes of session's pm subsession.\n\n            session\n                Session of trading_minutes\n        \"\"\"\n        return self._evaluate_trading_and_break_minutes[0]\n\n    def trading_minutes_only(self) -> abc.Iterator[pd.Timestamp]:\n        \"\"\"Generator of trading minutes of `self.trading_minutes`.\"\"\"\n        for mins, _ in self.trading_minutes:\n            for minute in mins:\n                yield minute\n\n    @property\n    def trading_minute(self) -> pd.Timestamp:\n        \"\"\"A single trading minute.\"\"\"\n        return self.trading_minutes[0][0][0]\n\n    @property\n    def break_minutes(self) -> tuple[tuple[tuple[pd.Timestamp], pd.Timestamp]]:\n        \"\"\"Sample of break minutes of `sessions_sample`.\n\n        Returns\n        -------\n        tuple of tuple[tuple[break_minutes], session]\n\n            tuple[break_minutes]:\n                first two minutes of a break.\n                last two minutes of a break.\n\n            session\n                Session of break_minutes\n        \"\"\"\n        return self._evaluate_trading_and_break_minutes[1]\n\n    def break_minutes_only(self) -> abc.Iterator[pd.Timestamp]:\n        \"\"\"Generator of break minutes of `self.break_minutes`.\"\"\"\n        for mins, _ in self.break_minutes:\n            for minute in mins:\n                yield minute\n\n    @functools.cached_property\n    def non_trading_minutes(\n        self,\n    ) -> tuple[tuple[tuple[pd.Timestamp], pd.Timestamp, pd.Timestamp]]:\n        \"\"\"non_trading_minutes that edge `sessions_sample`.\n\n        NB. Does not include break minutes.\n\n        Returns\n        -------\n        tuple of tuple[tuple[non-trading minute], previous session, next session]\n\n            tuple[non-trading minute]\n                Two non-trading minutes.\n                    [0] first non-trading minute to follow a session.\n                    [1] last non-trading minute prior to the next session.\n\n            previous session\n                Session that preceeds non-trading minutes.\n\n            next session\n                Session that follows non-trading minutes.\n\n        See Also\n        --------\n        break_minutes\n        \"\"\"\n        non_trading_mins = []\n\n        sessions = self.sessions_sample\n        sessions = prev_sessions = sessions[sessions.isin(self.sessions_with_gap_after)]\n\n        next_sessions = self.sessions[self.sessions.get_indexer(sessions) + 1]\n\n        last_mins_plus_one = self.last_minutes[sessions] + self.ONE_MIN\n        first_mins_less_one = self.first_minutes[next_sessions] - self.ONE_MIN\n\n        for prev_session, next_session, mins_ in zip(\n            prev_sessions, next_sessions, zip(last_mins_plus_one, first_mins_less_one)\n        ):\n            non_trading_mins.append((mins_, prev_session, next_session))\n\n        return tuple(non_trading_mins)\n\n    def non_trading_minutes_only(self) -> abc.Iterator[pd.Timestamp]:\n        \"\"\"Generator of non-trading minutes of `self.non_trading_minutes`.\"\"\"\n        for mins, _, _ in self.non_trading_minutes:\n            for minute in mins:\n                yield minute\n\n    # --- Evaluated minutes of a specific circumstance ---\n\n    def _trading_minute_to_break_minute(\n        self, sessions, break_sessions\n    ) -> list[pd.DatetimeIndex, pd.DatetimeIndex, pd.DatetimeIndex]:\n        times = (self.last_am_minutes[break_sessions] + pd.Timedelta(1, \"T\")).dt.time\n\n        mask = (self.first_minutes[sessions].dt.time.values < times.values) & (\n            times.values < self.last_minutes[sessions].dt.time.values\n        )\n\n        minutes = []\n        for session, break_session in zip(sessions[mask], break_sessions[mask]):\n            break_minutes = self.get_session_break_minutes(break_session)\n            trading_minutes = self.get_session_minutes(session)[0]\n            bv = np.in1d(trading_minutes.time, break_minutes.time)\n            minutes.append([trading_minutes[bv][-1], session, break_session])\n        return minutes\n\n    @property\n    def trading_minute_to_break_minute_next(\n        self,\n    ) -> list[pd.DatetimeIndex, pd.DatetimeIndex, pd.DatetimeIndex]:\n        \"\"\"Trading minutes where same minute of next session is a break minute.\n\n        Returns\n        -------\n        tuple\n            [0] trading minute\n            [1] session of which [0] ia a trading minute\n            [2] next session, i.e. session of which a minute with same time as\n                [0] is a break minute.\n        \"\"\"\n        sessions = self.sessions_without_break_next_session_with_break\n        idxr = self.sessions.get_indexer(sessions)\n        break_sessions = self.sessions[idxr + 1]\n        lst = self._trading_minute_to_break_minute(sessions, break_sessions)\n\n        sessions = self.sessions_next_break_end_later\n        idxr = self.sessions.get_indexer(sessions) + 1\n        target_sessions = self.sessions[idxr]\n        minutes = self.first_pm_minutes[sessions]\n        offset_minutes = minutes.dt.tz_convert(None) - sessions + target_sessions\n        # only include offset minute if verified as break minute of target\n        # (it wont be if the break has shifted by more than the break duration)\n        mask = offset_minutes.values > self.last_am_minutes[target_sessions].values\n        lst.extend(list(zip(minutes[mask], sessions[mask], target_sessions[mask])))\n\n        sessions = self.sessions_next_break_start_earlier\n        idxr = self.sessions.get_indexer(sessions) + 1\n        target_sessions = self.sessions[idxr]\n        minutes = self.last_am_minutes[sessions]\n        offset_minutes = minutes.dt.tz_convert(None) - sessions + target_sessions\n        # only include offset minute if verified as break minute of target\n        mask = offset_minutes.values < self.first_pm_minutes[target_sessions].values\n        lst.extend(list(zip(minutes[mask], sessions[mask], target_sessions[mask])))\n        return lst\n\n    @property\n    def trading_minute_to_break_minute_prev(\n        self,\n    ) -> list[pd.DatetimeIndex, pd.DatetimeIndex, pd.DatetimeIndex]:\n        \"\"\"Trading minutes where same minute of previous session is a break minute.\n\n        Returns\n        -------\n        tuple\n            [0] trading minute\n            [1] session of which [0] ia a trading minute\n            [2] previous session, i.e. session of which a minute with same time as\n                [0] is a break minute.\n        \"\"\"\n        break_sessions = self.sessions_with_break_next_session_without_break\n        idxr = self.sessions.get_indexer(break_sessions)\n        sessions = self.sessions[idxr + 1]\n        lst = self._trading_minute_to_break_minute(sessions, break_sessions)\n\n        target_sessions = self.sessions_next_break_end_earlier\n        idxr = self.sessions.get_indexer(target_sessions) + 1\n        sessions = self.sessions[idxr]  # previous break ends later\n        minutes = self.first_pm_minutes[sessions]\n        offset_minutes = minutes.dt.tz_convert(None) - sessions + target_sessions\n        # only include offset minute if verified as break minute of target\n        # (it wont be if the break has shifted by more than the break duration)\n        mask = offset_minutes.values > self.last_am_minutes[target_sessions].values\n        lst.extend(list(zip(minutes[mask], sessions[mask], target_sessions[mask])))\n\n        target_sessions = self.sessions_next_break_start_later\n        idxr = self.sessions.get_indexer(target_sessions) + 1\n        sessions = self.sessions[idxr]  # previous break starts earlier\n        minutes = self.last_am_minutes[sessions]\n        offset_minutes = minutes.dt.tz_convert(None) - sessions + target_sessions\n        # only include offset minute if verified as break minute of target\n        mask = offset_minutes.values < self.first_pm_minutes[target_sessions].values\n        lst.extend(list(zip(minutes[mask], sessions[mask], target_sessions[mask])))\n\n        return lst\n\n    # --- method-specific inputs/outputs ---\n\n    def prev_next_open_close_minutes(\n        self,\n    ) -> abc.Iterator[\n        tuple[\n            pd.Timestamp,\n            tuple[\n                pd.Timestamp | None,\n                pd.Timestamp | None,\n                pd.Timestamp | None,\n                pd.Timestamp | None,\n            ],\n        ]\n    ]:\n        \"\"\"Generator of test parameters for prev/next_open/close methods.\n\n        Inputs include following minutes of each session:\n            open\n            one minute prior to open (not included for first session)\n            one minute after open\n            close\n            one minute before close\n            one minute after close (not included for last session)\n\n        NB Assumed that minutes prior to first open and after last close\n        will be handled via parse_timestamp.\n\n        Yields\n        ------\n        2-tuple:\n            [0] Input a minute sd pd.Timestamp\n            [1] 4 tuple of expected output of corresponding method:\n                [0] previous_open as pd.Timestamp | None\n                [1] previous_close as pd.Timestamp | None\n                [2] next_open as pd.Timestamp | None\n                [3] next_close as pd.Timestamp | None\n\n                NB None indicates that corresponding method is expected to\n                raise a ValueError for this input.\n        \"\"\"\n        close_is_next_open_bv = self.closes == self.opens.shift(-1)\n        open_was_prev_close_bv = self.opens == self.closes.shift(+1)\n        close_is_next_open = close_is_next_open_bv[0]\n\n        # minutes for session 0\n        minute = self.opens[0]\n        yield (minute, (None, None, self.opens[1], self.closes[0]))\n\n        minute = minute + self.ONE_MIN\n        yield (minute, (self.opens[0], None, self.opens[1], self.closes[0]))\n\n        minute = self.closes[0]\n        next_open = self.opens[2] if close_is_next_open else self.opens[1]\n        yield (minute, (self.opens[0], None, next_open, self.closes[1]))\n\n        minute += self.ONE_MIN\n        prev_open = self.opens[1] if close_is_next_open else self.opens[0]\n        yield (minute, (prev_open, self.closes[0], next_open, self.closes[1]))\n\n        minute = self.closes[0] - self.ONE_MIN\n        yield (minute, (self.opens[0], None, self.opens[1], self.closes[0]))\n\n        # minutes for sessions over [1:-1] except for -1 close and 'close + one_min'\n        opens = self.opens[1:-1]\n        closes = self.closes[1:-1]\n        prev_opens = self.opens[:-2]\n        prev_closes = self.closes[:-2]\n        next_opens = self.opens[2:]\n        next_closes = self.closes[2:]\n        opens_after_next = self.opens[3:]\n        # add dummy row to equal lengths (won't be used)\n        opens_after_next = pd.concat(\n            [\n                opens_after_next,\n                pd.Series(pd.Timestamp(\"2200-01-01\", tz=UTC)),\n            ]\n        )\n        stop = closes[-1]\n\n        for (\n            open_,\n            close,\n            prev_open,\n            prev_close,\n            next_open,\n            next_close,\n            open_after_next,\n            close_is_next_open,\n            open_was_prev_close,\n        ) in zip(\n            opens,\n            closes,\n            prev_opens,\n            prev_closes,\n            next_opens,\n            next_closes,\n            opens_after_next,\n            close_is_next_open_bv[1:-2],\n            open_was_prev_close_bv[1:-2],\n        ):\n            if not open_was_prev_close:\n                # only include open minutes if not otherwise duplicating\n                # evaluations already made for prior close.\n                yield (open_, (prev_open, prev_close, next_open, close))\n                yield (open_ - self.ONE_MIN, (prev_open, prev_close, open_, close))\n                yield (open_ + self.ONE_MIN, (open_, prev_close, next_open, close))\n\n            yield (close - self.ONE_MIN, (open_, prev_close, next_open, close))\n\n            if close != stop:\n                next_open_ = open_after_next if close_is_next_open else next_open\n                yield (close, (open_, prev_close, next_open_, next_close))\n\n                open_ = next_open if close_is_next_open else open_\n                yield (close + self.ONE_MIN, (open_, close, next_open_, next_close))\n\n        # close and 'close + one_min' for session -2\n        minute = self.closes[-2]\n        next_open = None if close_is_next_open_bv[-2] else self.opens[-1]\n        yield (minute, (self.opens[-2], self.closes[-3], next_open, self.closes[-1]))\n\n        minute += self.ONE_MIN\n        prev_open = self.opens[-1] if close_is_next_open_bv[-2] else self.opens[-2]\n        yield (minute, (prev_open, self.closes[-2], next_open, self.closes[-1]))\n\n        # minutes for session -1\n        if not open_was_prev_close_bv[-1]:\n            open_ = self.opens[-1]\n            prev_open = self.opens[-2]\n            prev_close = self.closes[-2]\n            next_open = None\n            close = self.closes[-1]\n            yield (open_, (prev_open, prev_close, next_open, close))\n            yield (open_ - self.ONE_MIN, (prev_open, prev_close, open_, close))\n            yield (open_ + self.ONE_MIN, (open_, prev_close, next_open, close))\n\n        minute = self.closes[-1]\n        next_open = self.opens[2] if close_is_next_open_bv[-1] else self.opens[1]\n        yield (minute, (self.opens[-1], self.closes[-2], None, None))\n\n        minute -= self.ONE_MIN\n        yield (minute, (self.opens[-1], self.closes[-2], None, self.closes[-1]))\n\n    # dunder\n\n    def __repr__(self) -> str:\n        return f\"<Answers: calendar {self.name}, side {self.side}>\"\n\n\ndef no_parsing(f: typing.Callable):\n    \"\"\"Wrap a method under test so that it skips input parsing.\"\"\"\n    return lambda *args, **kwargs: f(*args, _parse=False, **kwargs)\n\n\nclass ExchangeCalendarTestBase:\n    \"\"\"Test base for an ExchangeCalendar.\n\n    Notes\n    -----\n\n    === Fixtures ===\n\n    In accordance with the pytest framework, whilst methods are requried to\n    have `self` as their first argument, no method should use `self`.\n    All required inputs should come by way of fixtures received to the\n    test method's arguments.\n\n    Methods that are directly or indirectly dependent on the evaluation of\n    trading minutes should be tested against the parameterized\n    `all_calendars_with_answers` fixture. This fixture will execute the\n    test against multiple calendar instances, one for each viable `side`.\n\n    The following properties directly evaluate trading minutes:\n        minutes\n        last_minutes_nanos\n        last_am_minutes_nanos\n        first_minutes_nanos\n        first_pm_minutes_nanos\n    NB this list does not include methods that indirectly evaluate methods\n    by way of calling (directly or indirectly) one of the above methods.\n\n    Methods that are not dependent on the evaluation of trading minutes\n    should only be tested against only the `default_calendar_with_answers`\n    or `default_calendar` fixture.\n\n    Calendar instances provided by fixtures should be used exclusively to\n    call the method being tested. NO TEST INPUT OR EXPECTED OUTPUT SHOULD\n    BE EVALUATED BY WAY OF CALLING A CALENDAR METHOD. Rather, test\n    inputs and expected output should be taken directly, or evaluated from,\n    properties/methods of the corresponding Answers fixture.\n\n    Subclasses are required to override a limited number of fixtures and\n    may be required to override others. Refer to the block comments.\n    \"\"\"\n\n    # subclass must override the following fixtures\n\n    @pytest.fixture(scope=\"class\")\n    def calendar_cls(self) -> abc.Iterator[typing.Type[ExchangeCalendar]]:\n        \"\"\"ExchangeCalendar class to be tested.\n\n        Examples:\n            XNYSExchangeCalendar\n            AlwaysOpenCalendar\n        \"\"\"\n        raise NotImplementedError(\"fixture must be implemented on subclass\")\n\n    @pytest.fixture\n    def max_session_hours(self) -> abc.Iterator[int | float]:\n        \"\"\"Largest number of hours that can comprise a single session.\n\n        Examples:\n            8\n            6.5\n        \"\"\"\n        raise NotImplementedError(\"fixture must be implemented on subclass\")\n\n    # if subclass has a 24h session then subclass must override this fixture.\n    # Define on subclass as is here with only difference being passing\n    # [\"left\", \"right\"] to decorator's 'params' arg (24h calendars cannot\n    # have a side defined as 'both' or 'neither'.).\n    @pytest.fixture(scope=\"class\", params=[\"both\", \"left\", \"right\", \"neither\"])\n    def all_calendars_with_answers(\n        self, request, calendars, answers\n    ) -> abc.Iterator[tuple[ExchangeCalendar, Answers]]:\n        \"\"\"Parameterized calendars and answers for each side.\"\"\"\n        yield (calendars[request.param], answers[request.param])\n\n    # subclass should override the following fixtures in the event that the\n    # default defined here does not apply.\n\n    @pytest.fixture\n    def start_bound(self) -> abc.Iterator[pd.Timestamp | None]:\n        \"\"\"Earliest date for which calendar can be instantiated, or None if\n        there is no start bound.\"\"\"\n        yield None\n\n    @pytest.fixture\n    def end_bound(self) -> abc.Iterator[pd.Timestamp | None]:\n        \"\"\"Latest date for which calendar can be instantiated, or None if\n        there is no end bound.\"\"\"\n        yield None\n\n    # Subclass can optionally override the following fixtures. By overriding\n    # a fixture the associated test will be executed with input as yielded\n    # by the fixture. Where fixtures are not overriden the associated tests\n    # will be skipped.\n\n    @pytest.fixture\n    def regular_holidays_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of known regular calendar holidays. Empty list if no holidays.\n\n        `test_regular_holidays_sample` will check that each date does not\n        represent a calendar session.\n\n        Typical test cases:\n            - All regular holidays over a full calendar year.\n            - First observance of a regular holiday which started being\n                observed from a specific year.\n            - Last observance of a regular holiday that ceased to be\n                observed from a specific year.\n            - Where a regular holiday falls on a weekend and is made up on\n                a prior Friday or following Monday, verify that holiday\n                is made up on that day.\n            - Verify bridge days fall as expected (i.e. verify Mondays or\n                Fridays that are recognised holidays due to a regular\n                bridged holiday falling on a Tuesday or Thursday\n                respectively).\n            - Verify unusual rules, for example if a holiday is only\n                observed if it falls on a Monday, check that holiday is\n                observed when it falls on a Monday.\n\n        Example yield:\n            [\"2020-12-25\", \"2021-01-01\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def non_holidays_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of known dates that are not holidays.\n\n        `test_non_holidays_sample` will check that each date represents a\n        calendar session.\n\n        Subclass should use this fixture if wishes to test edge cases, for\n        example where a session is an exception to a rule, or where session\n        preceeds/follows a holiday that is an exception to a rule.\n\n        Typical test cases:\n            - Final non-observance of a regular holiday that began\n                to be observed in a subsequent year, i.e. verify still\n                being treated as a non-holiday in this year.\n            - First non-observance of a regular holiday that ceased\n                to be observed in a prior year, i.e. verify now being\n                treated as a non-holiday in this year.\n            - Verify the first trading day following a made up holiday(s)\n                is not a holiday. For example, where a two-day holiday\n                falls over a Saturaday and Sunday, and is made up on the\n                subsequent Monday and Tuesday, verify that the Wednesday is\n                not a holiday.\n            - For holidays that fall on a weekend and are not made up,\n                test that the Friday/Monday are not holidays (i.e. verify\n                that the regular holiday is not being made up.)\n            - When a non-bridged regular holiday falls on Tuesday/Thursday,\n                verify that the prior/subsequent Monday/Friday is not a\n                holiday.\n            - Verify an irregular non-observance of a regular holiday.\n            - Verify unusual rules, for example if a holiday is only\n                observed if it falls on a Monday, check that holiday is\n                not observed when falls on other days.\n\n        Example return:\n            [\"2019-12-27\", \"2020-01-02\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def adhoc_holidays_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of adhoc calendar holidays. Empty list if no adhoc holidays.\n\n        `test_adhoc_holidays_sample` will check that each date does not\n        represent a calendar session.\n\n        Typical test cases:\n            - Closures that were not planned. For example, due to weather,\n                system errors etc.\n            - One-off holidays.\n\n        Example return:\n            [\"2015-04-17\", \"2021-09-12\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def late_opens_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of dates representing sessions with late opens.\n\n        `test_late_opens_sample` will check that each date represents a\n        session with a late open.\n\n        Typical test cases:\n            - All regular annual late opens over a year.\n            - First observance of an annual late open that started being\n                observed from a specific year.\n            - Last observance of an annual late open that ceased to be\n                observed from a specific year.\n            - Any adhoc late opens.\n\n        Example returns:\n            [\"2022-01-03\", \"2022-04-22\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def early_closes_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of dates representing sessions with early closes.\n\n        `test_early_closes_sample` will check that each date represents a\n        session with an early close.\n\n        Typical test cases:\n            - All regular annual early closes over a year.\n            - First observance of an annual early close that started being\n                observed from a specific year.\n            - Last observance of an annual early close that ceased to be\n                observed from a specific year.\n            - Any adhoc early closes.\n\n        Example returns:\n            [\"2019-12-24\", \"2019-12-31\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def early_closes_sample_time(self) -> abc.Iterator[pd.Timedelta | None]:\n        \"\"\"Local close time of sessions of `early_closes_sample` fixture.\n\n        `test_early_closes_sample_time` will check all sessions of\n        `early_closes_sample` have this close time.\n\n        Only override fixture if:\n            - `early_closes_sample` is overriden by subclass\n            - ALL sessions of `early_closes_sample` have the same local\n                close time (if sessions of `early_closes_sample` have\n                different local close times then the subclass should\n                instead check close times with a test defined on the\n                subclass).\n\n        Example returns:\n            pd.Timedelta(14, \"H\")  # 14:00 local time\n            pd.Timedelta(hours=13, minutes=15)  # 13:15 local time\n        \"\"\"\n        yield None\n\n    @pytest.fixture\n    def early_closes_weekdays(self) -> abc.Iterator[tuple(int)]:\n        \"\"\"Weekdays with non-standard close times.\n\n        `test_early_closes_weekdays` will check that all sessions on these\n        weekdays have early closes.\n\n        Example return:\n            (2, 3)  # Thursday and Friday sessions have an early close.\n            (6,)  # Sunday sessions have an early close\n        \"\"\"\n        yield tuple()\n\n    @pytest.fixture\n    def early_closes_weekdays_sample(self):\n        \"\"\"Sample of dates representing sessions with early closes due to weekday.\n\n        `test_early_closes_weekdays_time` will check that each of these\n        dates represents a session that closes at the time returned by the\n        fixture `early_closes_weekdays_sample_time`.\n\n        If the `early_closes_weekdays` fixture has length > 1 and the early\n        close time is different for the different weekdays then this sample\n        should be limited to dates representing sessions that all have\n        the same close time. (Dates representing sessions with other close\n        times should checked with a test defined on the subclass.)\n\n        Example returns:\n            [\"2022-08-21\", \"2022-08-28\", ...]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def early_closes_weekdays_sample_time(self) -> abc.Iterator[pd.Timedelta | None]:\n        \"\"\"Local close time of dates returned by `early_closes_weekdays_sample` fixture.\n\n        `test_early_closes_weekdays_time` will check that each date of\n        `early_closes_weekdays_sample` fixture represents a session that\n        closes at this time.\n\n        Only override fixture if `early_closes_weekdays_sample` is\n        overriden by subclass.\n\n        Example returns:\n            pd.Timedelta(14, \"H\")  # 14:00 local time\n            pd.Timedelta(hours=13, minutes=15)  # 13:15 local time\n        \"\"\"\n        yield None\n\n    @pytest.fixture\n    def non_early_closes_sample(self) -> abc.Iterator[list[str]]:\n        \"\"\"Sample of known calendar sessions with normal close times.\n\n        `test_non_early_closes_sample` will check each date does not\n        represent a calendar session with an early close.\n\n        Subclass should use this fixture to test edge cases, for example\n        where an otherwise early close is an exception to a rule.\n\n        Typical test cases:\n            - Where an early close is observed from a certain year, verify\n                that the closest prior year, for which the early close\n                would have been otherwise observed, was not an early\n                close.\n            - Where an early close ceases to be observed from a certain\n                year, verify that the closest following year, for which the\n                early close would have been otherwse observed, is not an\n                early close.\n\n        Example return:\n            [\"2022-12-23\", \"2022-12-30]\n        \"\"\"\n        yield []\n\n    @pytest.fixture\n    def non_early_closes_sample_time(self) -> abc.Iterator[pd.Timedelta | None]:\n        \"\"\"Local close time of sessions of `non_early_closes_sample` fixture.\n\n        `test_non_early_closes_sample_time` will check all sessions of\n        `non_early_closes_sample` have this close time.\n\n        Only override fixture if:\n            - `non_early_closes_sample` is overriden by subclass.\n            - ALL sessions of `non_early_closes_sample` have the same local\n                close time (if sessions of `non_early_closes_sample` have\n                different local close times then the subclass should\n                instead check close times with a test defined on the\n                subclass).\n\n        Example returns:\n            pd.Timedelta(17, \"H\")  # 17:00 local time\n            pd.Timedelta(hours=16, minutes=30)  # 16:30 local time\n        \"\"\"\n        yield None\n\n    # --- NO FIXTURE BELOW THIS LINE SHOULD BE OVERRIDEN ON A SUBCLASS ---\n\n    def test_testbase_integrity(self):\n        \"\"\"Ensure integrity of TestBase.\n\n        Raises error if a reserved fixture is overriden by the subclass.\n        \"\"\"\n        cls = self.__class__\n        for fixture in [\n            \"test_testbase_integrity\",\n            \"name\",\n            \"has_24h_session\",\n            \"default_side\",\n            \"sides\",\n            \"answers\",\n            \"default_answers\",\n            \"calendars\",\n            \"default_calendar\",\n            \"calendars_with_answers\",\n            \"default_calendar_with_answers\",\n            \"one_minute\",\n            \"today\",\n            \"all_directions\",\n            \"valid_overrides\",\n            \"non_valid_overrides\",\n            \"daylight_savings_dates\",\n            \"late_opens\",\n            \"early_closes\",\n        ]:\n            if getattr(cls, fixture) != getattr(ExchangeCalendarTestBase, fixture):\n                raise RuntimeError(f\"fixture '{fixture}' should not be overriden!\")\n\n    # Base class fixtures\n\n    @pytest.fixture(scope=\"class\")\n    def name(self, calendar_cls) -> abc.Iterator[str]:\n        \"\"\"Calendar name.\"\"\"\n        yield calendar_cls.name\n\n    @pytest.fixture(scope=\"class\")\n    def has_24h_session(self, name) -> abc.Iterator[bool]:\n        df = get_csv(name)\n        yield (df.close == df.open.shift(-1)).any()\n\n    @pytest.fixture(scope=\"class\")\n    def default_side(self) -> abc.Iterator[str]:\n        \"\"\"Default calendar side.\"\"\"\n        yield \"left\"\n\n    @pytest.fixture(scope=\"class\")\n    def sides(self, has_24h_session) -> abc.Iterator[list[str]]:\n        \"\"\"All valid sides options for calendar.\"\"\"\n        if has_24h_session:\n            yield [\"left\", \"right\"]\n        else:\n            yield [\"both\", \"left\", \"right\", \"neither\"]\n\n    # Calendars and answers\n\n    @pytest.fixture(scope=\"class\")\n    def answers(self, name, sides) -> abc.Iterator[dict[str, Answers]]:\n        \"\"\"Dict of answers, key as side, value as corresoponding answers.\"\"\"\n        yield {side: Answers(name, side) for side in sides}\n\n    @pytest.fixture(scope=\"class\")\n    def default_answers(self, answers, default_side) -> abc.Iterator[Answers]:\n        yield answers[default_side]\n\n    @pytest.fixture(scope=\"class\")\n    def calendars(\n        self, calendar_cls, default_answers, sides\n    ) -> abc.Iterator[dict[str, ExchangeCalendar]]:\n        \"\"\"Dict of calendars, key as side, value as corresoponding calendar.\"\"\"\n        start = default_answers.first_session\n        end = default_answers.last_session\n        yield {side: calendar_cls(start, end, side) for side in sides}\n\n    @pytest.fixture(scope=\"class\")\n    def default_calendar(\n        self, calendars, default_side\n    ) -> abc.Iterator[ExchangeCalendar]:\n        yield calendars[default_side]\n\n    @pytest.fixture(scope=\"class\")\n    def calendars_with_answers(\n        self, calendars, answers, sides\n    ) -> abc.Iterator[dict[str, tuple[ExchangeCalendar, Answers]]]:\n        \"\"\"Dict of calendars and answers, key as side.\"\"\"\n        yield {side: (calendars[side], answers[side]) for side in sides}\n\n    @pytest.fixture(scope=\"class\")\n    def default_calendar_with_answers(\n        self, calendars_with_answers, default_side\n    ) -> abc.Iterator[tuple[ExchangeCalendar, Answers]]:\n        yield calendars_with_answers[default_side]\n\n    # General use fixtures.\n\n    @pytest.fixture(scope=\"class\")\n    def one_minute(self) -> abc.Iterator[pd.Timedelta]:\n        yield pd.Timedelta(1, \"T\")\n\n    @pytest.fixture(scope=\"class\")\n    def today(self) -> abc.Iterator[pd.Timedelta]:\n        yield pd.Timestamp.now().floor(\"D\")\n\n    @pytest.fixture(scope=\"class\", params=[\"next\", \"previous\", \"none\"])\n    def all_directions(self, request) -> abc.Iterator[str]:\n        \"\"\"Parameterised fixture of direction to go if minute is not a trading minute\"\"\"\n        yield request.param\n\n    @pytest.fixture(scope=\"class\")\n    def valid_overrides(self) -> abc.Iterator[list[str]]:\n        \"\"\"Names of methods that can be overriden by a subclass.\"\"\"\n        yield [\n            \"name\",\n            \"bound_min\",\n            \"bound_max\",\n            \"_bound_min_error_msg\",\n            \"_bound_max_error_msg\",\n            \"default_start\",\n            \"default_end\",\n            \"tz\",\n            \"open_times\",\n            \"break_start_times\",\n            \"break_end_times\",\n            \"close_times\",\n            \"weekmask\",\n            \"open_offset\",\n            \"close_offset\",\n            \"regular_holidays\",\n            \"adhoc_holidays\",\n            \"special_opens\",\n            \"special_opens_adhoc\",\n            \"special_closes\",\n            \"special_closes_adhoc\",\n            \"apply_special_offsets\",\n        ]\n\n    @pytest.fixture(scope=\"class\")\n    def non_valid_overrides(self, valid_overrides) -> abc.Iterator[list[str]]:\n        \"\"\"Names of methods that cannot be overriden by a subclass.\"\"\"\n        yield [\n            name\n            for name in dir(ExchangeCalendar)\n            if name not in valid_overrides\n            and not name.startswith(\"__\")\n            and not name == \"_abc_impl\"\n        ]\n\n    @pytest.fixture(scope=\"class\")\n    def daylight_savings_dates(\n        self, default_calendar\n    ) -> abc.Iterator[list[pd.Timestamp]]:\n        \"\"\"All dates in a specific year that mark the first day of a new\n        time regime.\n\n        Yields empty list if timezone's UCT offset does not change.\n\n        Notes\n        -----\n        NB Any test that employs this fixture assumes the accuarcy of the\n        default calendar's `tz` property.\n        \"\"\"\n        cal = default_calendar\n        year = cal.last_session.year - 1\n        days = pd.date_range(str(year), str(year + 1), freq=\"D\")\n        tzinfo = pytz.timezone(cal.tz.zone)\n\n        prev_offset = tzinfo.utcoffset(days[0])\n        dates = []\n        for day in days[1:]:\n            try:\n                offset = tzinfo.utcoffset(day)\n            except pytz.NonExistentTimeError:\n                offset = tzinfo.utcoffset(day + pd.Timedelta(1, \"H\"))\n            if offset != prev_offset:\n                dates.append(day)\n                if len(dates) == 2:\n                    break\n            prev_offset = offset\n        yield dates\n\n    @pytest.fixture(scope=\"class\")\n    def late_opens(\n        self, default_calendar_with_answers\n    ) -> abc.Iterator[pd.DatetimeIndex]:\n        \"\"\"Calendar sessions with a late open.\n\n        Late opens evaluated as those that are later than the prevailing\n        open time as defined by `default_calendar.open_times`.\n\n        Notes\n        -----\n        NB Any test that employs this fixture ASSUMES the accuarcy of the\n        following calendar properties:\n            `open_times`\n            `tz`\n        \"\"\"\n        cal, ans = default_calendar_with_answers\n\n        d = dict(cal.open_times)\n        d[pd.Timestamp.min] = d.pop(None)\n        s = pd.Series(d).sort_index(ascending=False)\n\n        date_to = pd.Timestamp.max\n        dtis: list[pd.DatetimeIndex] = []\n        # For each period over which a distinct open time prevails...\n        for date_from, time_ in s.iteritems():\n            opens = ans.opens[date_from:date_to]\n            sessions = opens.index\n            td = pd.Timedelta(hours=time_.hour, minutes=time_.minute)\n            # Evaluate session opens as if were all normal open time.\n            normal_opens = sessions + pd.Timedelta(cal.open_offset, \"D\") + td\n            normal_opens_utc = normal_opens.tz_localize(cal.tz).tz_convert(UTC)\n            # Append those sessions with opens (according to answers) later than\n            # what would be normal.\n            dtis.append(sessions[opens > normal_opens_utc])\n            if date_from != pd.Timestamp.min:\n                date_to = date_from - pd.Timedelta(1, \"D\")\n\n        late_opens = pandas_utils.indexes_union(dtis)\n        yield late_opens\n\n    @pytest.fixture(scope=\"class\")\n    def early_closes(\n        self, default_calendar_with_answers\n    ) -> abc.Iterator[pd.DatetimeIndex]:\n        \"\"\"Calendar sessions with a late open.\n\n        Early closes evaluated as those that are earlier than the\n        prevailing close time as defined by `default_calendar.close_times`.\n\n        Notes\n        -----\n        NB Any test that employs this fixture ASSUMES the accuarcy of the\n        following calendar properties:\n            `close_times`\n            `tz`\n        \"\"\"\n        cal, ans = default_calendar_with_answers\n\n        d = dict(cal.close_times)\n        d[pd.Timestamp.min] = d.pop(None)\n        s = pd.Series(d).sort_index(ascending=False)\n\n        date_to = pd.Timestamp.max\n        dtis: list[pd.DatetimeIndex] = []\n        for date_from, time_ in s.iteritems():\n            closes = ans.closes[date_from:date_to]  # index to tz-naive\n            sessions = closes.index\n            td = pd.Timedelta(hours=time_.hour, minutes=time_.minute)\n            normal_closes = sessions + pd.Timedelta(cal.close_offset, \"D\") + td\n            normal_closes_utc = normal_closes.tz_localize(cal.tz).tz_convert(UTC)\n            dtis.append(sessions[closes < normal_closes_utc])\n            if date_from != pd.Timestamp.min:\n                date_to = date_from - pd.Timedelta(1, \"D\")\n\n        early_closes = pandas_utils.indexes_union(dtis)\n        yield early_closes\n\n    # --- TESTS ---\n\n    # Tests for calendar definition and construction methods.\n\n    def test_base_integrity(self, calendar_cls, non_valid_overrides):\n        cls = calendar_cls\n        for name in non_valid_overrides:\n            on_cls, on_base = getattr(cls, name), getattr(ExchangeCalendar, name)\n            # covers properties, instance methods and class mathods...\n            try:\n                assert on_cls == on_base or on_cls.__qualname__ == on_base.__qualname__\n            except AttributeError:\n                if not (cls.name == \"XKRX\" and name == \"day\"):\n                    # allow exchange_calendar_xkrx to overwrite 'day'.\n                    raise\n\n    def test_calculated_against_csv(self, default_calendar_with_answers):\n        calendar, ans = default_calendar_with_answers\n        tm.assert_index_equal(calendar.schedule.index, ans.sessions)\n\n    def test_start_end(self, default_answers, calendar_cls):\n        ans = default_answers\n        sessions = ans.session_blocks[\"normal\"]\n        start, end = sessions[0], sessions[-1]\n        cal = calendar_cls(start, end)\n        assert cal.first_session == start\n        assert cal.last_session == end\n\n        if len(ans.non_sessions) > 1:\n            # start and end as non-sessions\n            (start, end), sessions = ans.sessions_range_defined_by_non_sessions\n            cal = calendar_cls(start, end)\n            assert cal.first_session == sessions[0]\n            assert cal.last_session == sessions[-1]\n\n    def test_invalid_input(self, calendar_cls, sides, default_answers, name):\n        ans = default_answers\n\n        invalid_side = \"both\" if \"both\" not in sides else \"invalid_side\"\n        error_msg = f\"`side` must be in {sides} although received as {invalid_side}.\"\n        with pytest.raises(ValueError, match=re.escape(error_msg)):\n            calendar_cls(side=invalid_side)\n\n        start = ans.sessions[1]\n        end_same_as_start = ans.sessions[1]\n        error_msg = (\n            \"`start` must be earlier than `end` although `start` parsed as\"\n            f\" '{start}' and `end` as '{end_same_as_start}'.\"\n        )\n        with pytest.raises(ValueError, match=re.escape(error_msg)):\n            calendar_cls(start=start, end=end_same_as_start)\n\n        end_before_start = ans.sessions[0]\n        error_msg = (\n            \"`start` must be earlier than `end` although `start` parsed as\"\n            f\" '{start}' and `end` as '{end_before_start}'.\"\n        )\n        with pytest.raises(ValueError, match=re.escape(error_msg)):\n            calendar_cls(start=start, end=end_before_start)\n\n        if len(ans.non_sessions) > 1:\n            start, end = ans.non_sessions_range\n            error_msg = (\n                f\"The requested ExchangeCalendar, {name.upper()}, cannot be created as\"\n                f\" there would be no sessions between the requested `start` ('{start}')\"\n                f\" and `end` ('{end}') dates.\"\n            )\n            with pytest.raises(errors.NoSessionsError, match=re.escape(error_msg)):\n                calendar_cls(start=start, end=end)\n\n    def test_bound_min(self, calendar_cls, start_bound, today):\n        assert calendar_cls.bound_min() == start_bound\n        if start_bound is not None:\n            cal = calendar_cls(start_bound, today)\n            assert isinstance(cal, ExchangeCalendar)\n\n            start = start_bound - pd.DateOffset(days=1)\n            with pytest.raises(ValueError, match=re.escape(f\"{start}\")):\n                calendar_cls(start, today)\n        else:\n            # verify no bound imposed\n            cal = calendar_cls(pd.Timestamp(\"1902-01-01\"), today)\n            assert isinstance(cal, ExchangeCalendar)\n\n    def test_bound_max(self, calendar_cls, end_bound, today):\n        assert calendar_cls.bound_max() == end_bound\n        if end_bound is not None:\n            cal = calendar_cls(today, end_bound)\n            assert isinstance(cal, ExchangeCalendar)\n\n            end = end_bound + pd.DateOffset(days=1)\n            with pytest.raises(ValueError, match=re.escape(f\"{end}\")):\n                calendar_cls(today, end)\n        else:\n            # verify no bound imposed\n            cal = calendar_cls(today, pd.Timestamp(\"2050-01-01\"))\n            assert isinstance(cal, ExchangeCalendar)\n\n    def test_sanity_check_session_lengths(self, default_calendar, max_session_hours):\n        cal = default_calendar\n        cal_max_secs = (cal.closes_nanos - cal.opens_nanos).max()\n        assert cal_max_secs / 3600000000000 <= max_session_hours\n\n    def test_adhoc_holidays_specification(self, default_calendar):\n        \"\"\"adhoc holidays should be tz-naive (#33, #39).\"\"\"\n        dti = pd.DatetimeIndex(default_calendar.adhoc_holidays)\n        assert dti.tz is None\n\n    def test_daylight_savings(self, default_calendar, daylight_savings_dates):\n        # make sure there's no weirdness around calculating the next day's\n        # session's open time.\n        if daylight_savings_dates:\n            cal = default_calendar\n            d = dict(cal.open_times)\n            d[pd.Timestamp.min] = d.pop(None)\n            open_times = pd.Series(d)\n\n            for date in daylight_savings_dates:\n                # where `next day` is first session of new daylight savings regime\n                next_day = cal.date_to_session(T(date), \"next\")\n                open_date = next_day + pd.Timedelta(days=cal.open_offset)\n\n                the_open = cal.schedule.loc[next_day].open\n\n                localized_open = the_open.tz_convert(cal.tz)\n\n                assert open_date.year == localized_open.year\n                assert open_date.month == localized_open.month\n                assert open_date.day == localized_open.day\n\n                open_ix = open_times.index.searchsorted(date, side=\"right\")\n                if open_ix == len(open_times):\n                    open_ix -= 1\n\n                open_time = open_times.iloc[open_ix]\n                assert open_time.hour == localized_open.hour\n                assert open_time.minute == localized_open.minute\n\n    # Tests for properties covering all sessions.\n\n    def test_sessions(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        ans_sessions = ans.sessions\n        cal_sessions = cal.sessions\n        tm.assert_index_equal(ans_sessions, cal_sessions)\n\n    def test_opens_closes_break_starts_ends(self, default_calendar_with_answers):\n        \"\"\"Test `opens`, `closes, `break_starts` and `break_ends` properties.\"\"\"\n        cal, ans = default_calendar_with_answers\n        for prop in (\n            \"opens\",\n            \"closes\",\n            \"break_starts\",\n            \"break_ends\",\n        ):\n            ans_series = getattr(ans, prop)\n            cal_series = getattr(cal, prop)\n            tm.assert_series_equal(ans_series, cal_series, check_freq=False)\n\n    def test_minutes_properties(self, all_calendars_with_answers):\n        \"\"\"Test minute properties.\n\n        Tests following calendar properties:\n            all_first_minutes\n            all_last_minutes\n            all_last_am_minutes\n            all_first_pm_minutes\n        \"\"\"\n        cal, ans = all_calendars_with_answers\n\n        for prop in (\n            \"first_minutes\",\n            \"last_minutes\",\n            \"last_am_minutes\",\n            \"first_pm_minutes\",\n        ):\n            ans_minutes = getattr(ans, prop)\n            cal_minutes = getattr(cal, prop)\n            tm.assert_series_equal(ans_minutes, cal_minutes, check_freq=False)\n\n    # Tests for properties covering all minutes.\n\n    def test_minutes(self, all_calendars_with_answers, one_minute):\n        \"\"\"Test trading minutes at sessions' bounds.\"\"\"\n        calendar, ans = all_calendars_with_answers\n\n        side = ans.side\n        mins = calendar.minutes\n        assert isinstance(mins, pd.DatetimeIndex)\n        assert not mins.empty\n        mins_plus_1 = mins + one_minute\n        mins_less_1 = mins - one_minute\n\n        if side in [\"left\", \"neither\"]:\n            # Test that close and break_start not in mins,\n            # but are in mins_plus_1 (unless no gap after)\n\n            # do not test here for sessions with no gap after as for \"left\" these\n            # sessions' close IS a trading minute as it's the same as next session's\n            # open.\n            # NB For \"neither\" all sessions will have gap after.\n            closes = ans.closes[ans.sessions_with_gap_after]\n            # closes should not be in minutes\n            assert not mins.isin(closes).any()\n            # all closes should be in minutes plus 1\n            # for speed, use only subset of mins that are of interest\n            mins_plus_1_on_close = mins_plus_1[mins_plus_1.isin(closes)]\n            assert closes.isin(mins_plus_1_on_close).all()\n\n            # as noted above, if no gap after then close should be a trading minute\n            # as will be first minute of next session.\n            closes = ans.closes[ans.sessions_without_gap_after]\n            mins_on_close = mins[mins.isin(closes)]\n            assert closes.isin(mins_on_close).all()\n\n            if ans.has_a_session_with_break:\n                # break start should not be in minutes\n                assert not mins.isin(ans.break_starts).any()\n                # break start should be in minutes plus 1\n                break_starts = ans.break_starts[ans.sessions_with_break]\n                mins_plus_1_on_start = mins_plus_1[mins_plus_1.isin(break_starts)]\n                assert break_starts.isin(mins_plus_1_on_start).all()\n\n        if side in [\"left\", \"both\"]:\n            # Test that open and break_end are in mins,\n            # but not in mins_plus_1 (unless no gap before)\n            mins_on_open = mins[mins.isin(ans.opens)]\n            assert ans.opens.isin(mins_on_open).all()\n\n            opens = ans.opens[ans.sessions_with_gap_before]\n            assert not mins_plus_1.isin(opens).any()\n\n            opens = ans.opens[ans.sessions_without_gap_before]\n            mins_plus_1_on_open = mins_plus_1[mins_plus_1.isin(opens)]\n            assert opens.isin(mins_plus_1_on_open).all()\n\n            if ans.has_a_session_with_break:\n                break_ends = ans.break_ends[ans.sessions_with_break]\n                mins_on_end = mins[mins.isin(ans.break_ends)]\n                assert break_ends.isin(mins_on_end).all()\n\n        if side in [\"right\", \"neither\"]:\n            # Test that open and break_end are not in mins,\n            # but are in mins_less_1 (unless no gap before)\n            opens = ans.opens[ans.sessions_with_gap_before]\n            assert not mins.isin(opens).any()\n\n            mins_less_1_on_open = mins_less_1[mins_less_1.isin(opens)]\n            assert opens.isin(mins_less_1_on_open).all()\n\n            opens = ans.opens[ans.sessions_without_gap_before]\n            mins_on_open = mins[mins.isin(opens)]\n            assert opens.isin(mins_on_open).all()\n\n            if ans.has_a_session_with_break:\n                assert not mins.isin(ans.break_ends).any()\n                break_ends = ans.break_ends[ans.sessions_with_break]\n                mins_less_1_on_end = mins_less_1[mins_less_1.isin(break_ends)]\n                assert break_ends.isin(mins_less_1_on_end).all()\n\n        if side in [\"right\", \"both\"]:\n            # Test that close and break_start are in mins,\n            # but not in mins_less_1 (unless no gap after)\n            mins_on_close = mins[mins.isin(ans.closes)]\n            assert ans.closes.isin(mins_on_close).all()\n\n            closes = ans.closes[ans.sessions_with_gap_after]\n            assert not mins_less_1.isin(closes).any()\n\n            closes = ans.closes[ans.sessions_without_gap_after]\n            mins_less_1_on_close = mins_less_1[mins_less_1.isin(closes)]\n            assert closes.isin(mins_less_1_on_close).all()\n\n            if ans.has_a_session_with_break:\n                break_starts = ans.break_starts[ans.sessions_with_break]\n                mins_on_start = mins[mins.isin(ans.break_starts)]\n                assert break_starts.isin(mins_on_start).all()\n\n    # Tests for calendar properties.\n\n    def test_calendar_bounds_properties(self, all_calendars_with_answers):\n        \"\"\"Test calendar properties that define a calendar bound.\n\n        Tests following calendar properties:\n            first_session\n            last_session\n            first_session_open\n            last_session_close\n            first_minute\n            last_minute\n        \"\"\"\n        cal, ans = all_calendars_with_answers\n        assert ans.first_session == cal.first_session\n        assert ans.last_session == cal.last_session\n        assert ans.first_session_open == cal.first_session_open\n        assert ans.last_session_close == cal.last_session_close\n        assert ans.first_minute == cal.first_minute\n        assert ans.last_minute == cal.last_minute\n\n    def test_has_break(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        assert cal.has_break == ans.has_a_session_with_break\n\n    def test_regular_holidays_sample(self, default_calendar, regular_holidays_sample):\n        \"\"\"Test that calendar-specific sample of holidays are not sessions.\"\"\"\n        if regular_holidays_sample:\n            for holiday in regular_holidays_sample:\n                assert T(holiday) not in default_calendar.sessions\n\n    def test_adhoc_holidays_sample(self, default_calendar, adhoc_holidays_sample):\n        \"\"\"Test that calendar-specific sample of holidays are not sessions.\"\"\"\n        if adhoc_holidays_sample:\n            for holiday in adhoc_holidays_sample:\n                assert T(holiday) not in default_calendar.sessions\n\n    def test_non_holidays_sample(self, default_calendar, non_holidays_sample):\n        \"\"\"Test that calendar-specific sample of non-holidays are sessions.\"\"\"\n        if non_holidays_sample:\n            for date in non_holidays_sample:\n                assert T(date) in default_calendar.sessions\n\n    def test_late_opens_sample(self, default_calendar, late_opens_sample):\n        \"\"\"Test calendar-specific sample of sessions are included to late opens.\"\"\"\n        if late_opens_sample:\n            for date in late_opens_sample:\n                assert T(date) in default_calendar.late_opens\n\n    def test_early_closes_sample(self, default_calendar, early_closes_sample):\n        \"\"\"Test calendar-specific sample of sessions are included to early closes.\"\"\"\n        if early_closes_sample:\n            for date in early_closes_sample:\n                assert T(date) in default_calendar.early_closes\n\n    def test_early_closes_sample_time(\n        self, default_calendar, early_closes_sample, early_closes_sample_time\n    ):\n        \"\"\"Test close time of calendar-specific sample of early closing sessions.\n\n        Notes\n        -----\n        TEST RELIES ON ACCURACY OF CALENDAR PROPERTIES `closes`, `tz` and\n        `close_offset`.\n        \"\"\"\n        if early_closes_sample_time is not None:\n            cal, tz = default_calendar, default_calendar.tz\n            offset = pd.Timedelta(cal.close_offset, \"D\") + early_closes_sample_time\n            for date in early_closes_sample:\n                early_close = cal.closes[date].tz_convert(tz)\n                expected = pd.Timestamp(date, tz=tz) + offset\n                assert early_close == expected\n\n    def test_early_closes_weekdays(\n        self, default_calendar_with_answers, early_closes_weekdays\n    ):\n        \"\"\"Test weekday sessions with early closes are included to early closes.\"\"\"\n        if not early_closes_weekdays:\n            return\n        cal, ans = default_calendar_with_answers\n        bv = ans.sessions.weekday.isin(early_closes_weekdays)\n        expected = ans.sessions[bv]\n        assert expected.difference(cal.early_closes).empty\n\n    def test_early_closes_weekdays_time(\n        self,\n        default_calendar,\n        early_closes_weekdays_sample,\n        early_closes_weekdays_sample_time,\n    ):\n        \"\"\"Test weekday early close time of calendar-specific sample of sessions.\n\n        Notes\n        -----\n        TEST RELIES ON ACCURACY OF CALENDAR PROPERTIES `closes`, `tz` and\n        `close_offset`.\n        \"\"\"\n        if (\n            not early_closes_weekdays_sample\n            and early_closes_weekdays_sample_time is None\n        ):\n            return\n        cal, tz = default_calendar, default_calendar.tz\n        offset = pd.Timedelta(cal.close_offset, \"D\") + early_closes_weekdays_sample_time\n        for date in early_closes_weekdays_sample:\n            early_close = cal.closes[date].tz_convert(tz)\n            expected = pd.Timestamp(date, tz=tz) + offset\n            assert early_close == expected\n\n    def test_non_early_closes_sample(self, default_calendar, non_early_closes_sample):\n        \"\"\"Test calendar-specific sample of sessions are not early closes.\"\"\"\n        if non_early_closes_sample:\n            for date in non_early_closes_sample:\n                assert T(date) not in default_calendar.early_closes\n\n    def test_non_early_closes_sample_time(\n        self, default_calendar, non_early_closes_sample, non_early_closes_sample_time\n    ):\n        \"\"\"Test close time of calendar-specific sample of sessions with normal closes.\n\n        Notes\n        -----\n        TEST RELIES ON ACCURACY OF CALENDAR PROPERTIES `closes`, `tz` and\n        `close_offset`.\n        \"\"\"\n        if non_early_closes_sample_time is not None:\n            cal, tz = default_calendar, default_calendar.tz\n            offset = pd.Timedelta(cal.close_offset, \"D\") + non_early_closes_sample_time\n            for date in non_early_closes_sample:\n                close = cal.closes[date].tz_convert(tz)\n                expected_close = pd.Timestamp(date, tz=tz) + offset\n                assert close == expected_close\n\n    def test_late_opens(self, default_calendar, late_opens):\n        \"\"\"Test late opens.\n\n        Notes\n        -----\n        TEST RELIES ON ACCURACY OF CALENDAR PROPERTIES `open_times` and\n        `tz`. See `late_opens` fixture.\n        \"\"\"\n        tm.assert_index_equal(late_opens, default_calendar.late_opens.unique())\n\n    def test_early_closes(self, default_calendar, early_closes):\n        \"\"\"Test early closes.\n\n        Notes\n        -----\n        TEST RELIES ON ACCURACY OF CALENDAR PROPERTIES `close_times` and\n        `tz`. See `early_closes` fixture.\n        \"\"\"\n        tm.assert_index_equal(early_closes, default_calendar.early_closes.unique())\n\n    # Tests for methods that interrogate a given session.\n\n    def test_session_open_close_break_start_end(self, default_calendar_with_answers):\n        \"\"\"Test methods that get session open, close, break_start, break_end.\n\n        Tests following calendar methods:\n            session_open\n            session_close\n            session_open_close\n            session_break_start\n            session_break_end\n            session_break_start_end\n        \"\"\"\n        # considered sufficient to limit test to sessions of session blocks.\n        cal, ans = default_calendar_with_answers\n        for _, block in ans.session_block_generator():\n            for session in block:\n                ans_open = ans.opens[session]\n                ans_close = ans.closes[session]\n                assert cal.session_open(session, _parse=False) == ans_open\n                assert cal.session_close(session, _parse=False) == ans_close\n                assert cal.session_open_close(session, _parse=False) == (\n                    ans_open,\n                    ans_close,\n                )\n\n                break_start = cal.session_break_start(session, _parse=False)\n                break_end = cal.session_break_end(session, _parse=False)\n                break_start_and_end = cal.session_break_start_end(session, _parse=False)\n                ans_break_start = ans.break_starts[session]\n                ans_break_end = ans.break_ends[session]\n                if pd.isna(ans_break_start):\n                    assert pd.isna(break_start) and pd.isna(break_end)\n                    assert pd.isna(break_start_and_end[0])\n                    assert pd.isna(break_start_and_end[1])\n                else:\n                    assert break_start == ans_break_start\n                    assert break_end == ans_break_end\n                    assert break_start_and_end[0] == ans_break_start\n                    assert break_start_and_end[1] == ans_break_end\n\n    def test_session_minute_methods(self, all_calendars_with_answers):\n        \"\"\"Test methods that get a minute bound of a session or subsession.\n\n        Tests following calendar methods:\n            session_first_minute\n            session_last_minute\n            session_last_am_minute\n            session_first_pm_minute\n            session_first_last_minute\n        \"\"\"\n        # considered sufficient to limit test to sessions of session blocks.\n        cal, ans = all_calendars_with_answers\n        for _, block in ans.session_block_generator():\n            for session in block:\n                ans_first_minute = ans.first_minutes[session]\n                ans_last_minute = ans.last_minutes[session]\n                assert (\n                    cal.session_first_minute(session, _parse=False) == ans_first_minute\n                )\n                assert cal.session_last_minute(session, _parse=False) == ans_last_minute\n                assert cal.session_first_last_minute(session, _parse=False) == (\n                    ans_first_minute,\n                    ans_last_minute,\n                )\n\n                last_am_minute = cal.session_last_am_minute(session, _parse=False)\n                first_pm_minute = cal.session_first_pm_minute(session, _parse=False)\n                ans_last_am_minute = ans.last_am_minutes[session]\n                ans_first_pm_minute = ans.first_pm_minutes[session]\n                if pd.isna(ans_last_am_minute):\n                    assert pd.isna(last_am_minute) and pd.isna(first_pm_minute)\n                else:\n                    assert last_am_minute == ans_last_am_minute\n                    assert first_pm_minute == ans_first_pm_minute\n\n    def test_session_has_break(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.session_has_break)\n\n        # test every 10th session...\n        for session in ans.sessions_with_break[::10]:\n            assert f(session)\n        for session in ans.sessions_without_break[::10]:\n            assert not f(session)\n\n    def test_next_prev_session(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f_prev = no_parsing(cal.previous_session)\n        f_next = no_parsing(cal.next_session)\n\n        # NB non-sessions handled by methods via parse_session\n\n        # first session\n        match = \"Requested session would fall before the calendar's first session\"\n        with pytest.raises(errors.RequestedSessionOutOfBounds, match=match):\n            f_prev(ans.first_session)\n\n        # middle sessions (and m_prev for last session)\n        for session, next_session in zip(ans.sessions[:-1], ans.sessions[1:]):\n            assert f_next(session) == next_session\n            assert f_prev(next_session) == session\n\n        # last session\n        match = \"Requested session would fall after the calendar's last session\"\n        with pytest.raises(errors.RequestedSessionOutOfBounds, match=match):\n            f_next(ans.last_session)\n\n    def test_session_minutes(self, all_calendars_with_answers):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.session_minutes)\n\n        # Limit test to every session of each session block.\n\n        for _, block in ans.session_block_generator():\n            for session in block:\n                tm.assert_index_equal(f(session), ans.get_sessions_minutes(session))\n\n    def test_session_offset(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.session_offset)\n\n        for _, block_sessions in ans.session_block_generator():\n            num_sessions = max(len(block_sessions), 5)\n            session = block_sessions[0]\n            try:\n                sessions = ans.get_next_sessions(session, num_sessions)\n            except IndexError:\n                sessions = ans.get_next_sessions(session, len(block_sessions))\n            for i in range(len(sessions)):\n                offset_session = f(session, i)\n                assert offset_session == sessions[i]\n\n        for _, block_sessions in ans.session_block_generator():\n            num_sessions = max(len(block_sessions), 5)\n            session = block_sessions[-1]\n            try:\n                sessions = ans.get_prev_sessions(session, num_sessions)\n            except IndexError:\n                sessions = ans.get_prev_sessions(session, len(block_sessions))\n            for i in range(len(sessions)):\n                offset_session = f(session, -i)\n                assert offset_session == sessions[-(i + 1)]\n\n        # verify raises errors\n        offset_session = f(ans.first_session, 0)\n        assert offset_session == ans.first_session\n        with pytest.raises(errors.RequestedSessionOutOfBounds, match=\"before\"):\n            offset_session = f(ans.first_session, -1)\n\n        offset_session = f(ans.last_session, 0)\n        assert offset_session == ans.last_session\n        with pytest.raises(errors.RequestedSessionOutOfBounds, match=\"after\"):\n            f(ans.last_session, 1)\n\n    # Tests for methods that interrogate a date.\n\n    def test_is_session(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.is_session)\n\n        for session in ans.sessions:\n            assert f(session)\n\n        for session in ans.non_sessions:\n            assert not f(session)\n\n    def test_date_to_session(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.date_to_session)\n\n        sessions = ans.sessions\n\n        # direction as \"previous\"\n        dates = pd.date_range(sessions[0], sessions[-1], freq=\"D\")\n        date_is_session = dates.isin(sessions)\n\n        last_session = None\n        for date, is_session in zip(dates, date_is_session):\n            session_label = f(date, \"previous\")\n            if is_session:\n                assert session_label == date\n                last_session = session_label\n            else:\n                assert session_label == last_session\n\n        # direction as \"next\"\n        last_session = None\n        for date, is_session in zip(\n            dates.sort_values(ascending=False), date_is_session[::-1]\n        ):\n            session_label = f(date, \"next\")\n            if date in sessions:\n                assert session_label == date\n                last_session = session_label\n            else:\n                assert session_label == last_session\n\n        # test for non_sessions without direction\n        if not ans.non_sessions.empty:\n            for non_session in ans.non_sessions[0 : None : len(ans.non_sessions) // 9]:\n                error_msg = (\n                    f\"`date` '{non_session}' does not represent a session. Consider\"\n                    \" passing a `direction`.\"\n                )\n                with pytest.raises(ValueError, match=re.escape(error_msg)):\n                    f(non_session, \"none\")\n                # test default behaviour\n                with pytest.raises(ValueError, match=re.escape(error_msg)):\n                    f(non_session)\n\n            # non-valid direction (only raised if pass a date that is not a session)\n            error_msg = (\n                \"'not a direction' is not a valid `direction`. Valid `direction`\"\n                ' values are \"next\", \"previous\" and \"none\".'\n            )\n            with pytest.raises(ValueError, match=re.escape(error_msg)):\n                f(non_session, \"not a direction\")\n\n    # Tests for methods that interrogate a given minute (trading or non-trading)\n\n    def test_is_trading_minute(self, all_calendars_with_answers):\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.is_trading_minute)\n\n        for non_trading_min in ans.non_trading_minutes_only():\n            assert f(non_trading_min) is False\n\n        for trading_min in ans.trading_minutes_only():\n            assert f(trading_min) is True\n\n        for break_min in ans.break_minutes_only():\n            assert f(break_min) is False\n\n    def test_is_break_minute(self, all_calendars_with_answers):\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.is_break_minute)\n\n        for non_trading_min in ans.non_trading_minutes_only():\n            assert f(non_trading_min) is False\n\n        for trading_min in ans.trading_minutes_only():\n            assert f(trading_min) is False\n\n        for break_min in ans.break_minutes_only():\n            assert f(break_min) is True\n\n    def test_is_open_on_minute(self, all_calendars_with_answers):\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.is_open_on_minute)\n\n        # minimal test as is_open_on_minute delegates evaluation to is_trading_minute\n        # and is_break_minute, both of which are comprehensively tested.\n\n        for non_trading_min in itertools.islice(ans.non_trading_minutes_only(), 50):\n            assert f(non_trading_min) is False\n\n        for trading_min in itertools.islice(ans.trading_minutes_only(), 50):\n            assert f(trading_min) is True\n\n        for break_min in ans.break_minutes_only():\n            rtrn = f(break_min, ignore_breaks=True)\n            assert rtrn is True\n            rtrn = f(break_min)\n            assert rtrn is False\n\n    def test_is_open_at_time(self, all_calendars_with_answers, one_minute):\n        cal, ans = all_calendars_with_answers\n\n        one_min = one_minute\n        one_sec = pd.Timedelta(1, \"S\")\n\n        sides = (\"left\", \"both\", \"right\", \"neither\")\n\n        # verify raises expected errors\n        oob_time = ans.first_minute - one_sec\n        for side in sides:\n            with pytest.raises(errors.MinuteOutOfBounds):\n                cal.is_open_at_time(oob_time, side, ignore_breaks=True)\n\n        match = (\n            \"`timestamp` expected to receive type pd.Timestamp although got type\"\n            \" <class 'str'>.\"\n        )\n        with pytest.raises(TypeError, match=match):\n            cal.is_open_at_time(\"2022-06-21 14:22\", \"left\", ignore_breaks=True)\n\n        # verify expected returns\n        bools = (True, False)\n\n        def get_returns(\n            ts: pd.Timestamp,\n            ignore_breaks: bool,\n        ) -> list[bool]:\n            return [cal.is_open_at_time(ts, side, ignore_breaks) for side in sides]\n\n        gap_before = ans.sessions_with_gap_before\n        gap_after = ans.sessions_with_gap_after\n\n        for session in ans.sessions_sample:\n            ts = ans.opens[session]\n            expected = [True, True, False, False]\n            expected_no_gap = [True, True, True, False]\n            if ts > ans.first_minute:\n                for ignore in bools:\n                    expected_ = expected if session in gap_before else expected_no_gap\n                    assert get_returns(ts, ignore) == expected_\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts - one_sec, ts - one_min)\n                ):\n                    if session in gap_before:\n                        assert not any(get_returns(ts_, ignore))\n                    else:\n                        assert all(get_returns(ts_, ignore))\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts + one_sec, ts + one_min)\n                ):\n                    assert all(get_returns(ts_, ignore))\n\n            if ans.session_has_break(session):\n                ts = ans.break_ends[session]\n                assert get_returns(ts, ignore_breaks=False) == expected\n                assert all(get_returns(ts, ignore_breaks=True))\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts + one_sec, ts + one_min)\n                ):\n                    assert all(get_returns(ts_, ignore))\n\n                for ts_ in (ts - one_sec, ts - one_min):\n                    assert not any(get_returns(ts_, ignore_breaks=False))\n                    assert all(get_returns(ts_, ignore_breaks=True))\n\n            ts = ans.closes[session]\n            expected = [False, True, True, False]\n            expected_no_gap = [True, True, True, False]\n            if ts < ans.last_minute:\n                for ignore in bools:\n                    expected_ = expected if session in gap_after else expected_no_gap\n                    # check interprets tz-naive timestamp as UTC\n                    assert get_returns(ts.astimezone(None), ignore) == expected_\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts - one_sec, ts - one_min)\n                ):\n                    assert all(get_returns(ts_, ignore))\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts + one_sec, ts + one_min)\n                ):\n                    if session in gap_after:\n                        assert not any(get_returns(ts_, ignore))\n                    else:\n                        assert all(get_returns(ts_.astimezone(None), ignore))\n\n            if ans.session_has_break(session):\n                ts = ans.break_starts[session]\n                assert get_returns(ts, ignore_breaks=False) == expected\n                assert all(get_returns(ts, ignore_breaks=True))\n\n                for ignore, ts_ in itertools.product(\n                    bools, (ts - one_sec, ts - one_min)\n                ):\n                    assert all(get_returns(ts_, ignore))\n\n                for ts_ in (ts + one_sec, ts + one_min):\n                    assert not any(get_returns(ts_, ignore_breaks=False))\n                    assert all(get_returns(ts_, ignore_breaks=True))\n\n    def test_prev_next_open_close(self, default_calendar_with_answers):\n        \"\"\"Test methods that return previous/next open/close.\n\n        Tests methods:\n            previous_open\n            previous_close\n            next_open\n            next_close\n        \"\"\"\n        cal, ans = default_calendar_with_answers\n        generator = ans.prev_next_open_close_minutes()\n\n        for minute, (prev_open, prev_close, next_open, next_close) in generator:\n            if prev_open is None:\n                with pytest.raises(ValueError):\n                    cal.previous_open(minute, _parse=False)\n            else:\n                assert cal.previous_open(minute, _parse=False) == prev_open\n\n            if prev_close is None:\n                with pytest.raises(ValueError):\n                    cal.previous_close(minute, _parse=False)\n            else:\n                assert cal.previous_close(minute, _parse=False) == prev_close\n\n            if next_open is None:\n                with pytest.raises(ValueError):\n                    cal.next_open(minute, _parse=False)\n            else:\n                assert cal.next_open(minute, _parse=False) == next_open\n\n            if next_close is None:\n                with pytest.raises(ValueError):\n                    cal.next_close(minute, _parse=False)\n            else:\n                assert cal.next_close(minute, _parse=False) == next_close\n\n    def test_prev_next_minute(self, all_calendars_with_answers, one_minute):\n        \"\"\"Test methods that return previous/next minute.\n\n        Test focuses on and inside of edge cases.\n\n        Tests methods:\n            next_minute\n            previous_minute\n        \"\"\"\n        cal, ans = all_calendars_with_answers\n        f_next = no_parsing(cal.next_minute)\n        f_prev = no_parsing(cal.previous_minute)\n\n        # minutes of first session\n        first_min = ans.first_minutes[0]\n        first_min_plus_one = ans.first_minutes_plus_one[0]\n        first_min_less_one = ans.first_minutes_less_one[0]\n        last_min = ans.last_minutes[0]\n        last_min_plus_one = ans.last_minutes_plus_one[0]\n        last_min_less_one = ans.last_minutes_less_one[0]\n\n        match = \"Requested minute would fall before the calendar's first trading minute\"\n        with pytest.raises(errors.RequestedMinuteOutOfBounds, match=match):\n            f_prev(first_min)\n        # minutes earlier than first_minute assumed handled via parse_timestamp\n        assert f_next(first_min) == first_min_plus_one\n        assert f_next(first_min_plus_one) == first_min_plus_one + one_minute\n        assert f_prev(first_min_plus_one) == first_min\n        assert f_prev(last_min) == last_min_less_one\n        assert f_prev(last_min_less_one) == last_min_less_one - one_minute\n        assert f_next(last_min_less_one) == last_min\n        assert f_prev(last_min_plus_one) == last_min\n\n        prev_last_min = last_min\n        for (\n            first_min,\n            first_min_plus_one,\n            first_min_less_one,\n            last_min,\n            last_min_plus_one,\n            last_min_less_one,\n            gap_before,\n        ) in zip(\n            ans.first_minutes[1:],\n            ans.first_minutes_plus_one[1:],\n            ans.first_minutes_less_one[1:],\n            ans.last_minutes[1:],\n            ans.last_minutes_plus_one[1:],\n            ans.last_minutes_less_one[1:],\n            ~ans._mask_sessions_without_gap_before[1:],\n        ):\n            assert f_next(prev_last_min) == first_min\n            assert f_prev(first_min) == prev_last_min\n            assert f_next(first_min) == first_min_plus_one\n            assert f_prev(first_min_plus_one) == first_min\n            assert f_next(first_min_less_one) == first_min\n            assert f_prev(last_min) == last_min_less_one\n            assert f_next(last_min_less_one) == last_min\n            assert f_prev(last_min_plus_one) == last_min\n\n            if gap_before:\n                assert f_next(prev_last_min + one_minute) == first_min\n                assert f_prev(first_min_less_one) == prev_last_min\n            else:\n                assert f_next(prev_last_min + one_minute) == first_min_plus_one\n                assert f_next(prev_last_min + one_minute) == first_min_plus_one\n\n            prev_last_min = last_min\n\n        match = \"Requested minute would fall after the calendar's last trading minute\"\n        with pytest.raises(errors.RequestedMinuteOutOfBounds, match=match):\n            f_next(last_min)\n        # minutes later than last_minute assumed handled via parse_timestamp\n\n        if ans.has_a_session_with_break:\n            for (\n                last_am_min,\n                last_am_min_less_one,\n                last_am_min_plus_one,\n                first_pm_min,\n                first_pm_min_less_one,\n                first_pm_min_plus_one,\n            ) in zip(\n                ans.last_am_minutes,\n                ans.last_am_minutes_less_one,\n                ans.last_am_minutes_plus_one,\n                ans.first_pm_minutes,\n                ans.first_pm_minutes_less_one,\n                ans.first_pm_minutes_plus_one,\n            ):\n                if pd.isna(last_am_min):\n                    continue\n                assert f_next(last_am_min_less_one) == last_am_min\n                assert f_next(last_am_min) == first_pm_min\n                assert f_prev(last_am_min) == last_am_min_less_one\n                assert f_next(last_am_min_plus_one) == first_pm_min\n                assert f_prev(last_am_min_plus_one) == last_am_min\n\n                assert f_prev(first_pm_min_less_one) == last_am_min\n                assert f_next(first_pm_min_less_one) == first_pm_min\n                assert f_prev(first_pm_min) == last_am_min\n                assert f_next(first_pm_min) == first_pm_min_plus_one\n                assert f_prev(first_pm_min_plus_one) == first_pm_min\n\n    def test_minute_to_session(self, all_calendars_with_answers, all_directions):\n        direction = all_directions\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.minute_to_session)\n\n        for non_trading_mins, prev_session, next_session in ans.non_trading_minutes:\n            for non_trading_min in non_trading_mins:\n                if direction == \"none\":\n                    with pytest.raises(ValueError):\n                        f(non_trading_min, direction)\n                else:\n                    session = f(non_trading_min, direction)\n                    if direction == \"next\":\n                        assert session == next_session\n                    else:\n                        assert session == prev_session\n\n        for trading_minutes, session in ans.trading_minutes:\n            for trading_minute in trading_minutes:\n                rtrn = f(trading_minute, direction)\n                assert rtrn == session\n\n        if ans.has_a_session_with_break:\n            for break_minutes, session in ans.break_minutes[:15]:\n                for break_minute in break_minutes:\n                    rtrn = f(break_minute, direction)\n                    assert rtrn == session\n\n        oob_minute = ans.minute_too_early\n        if direction in [\"previous\", \"none\"]:\n            error_msg = (\n                f\"Received `minute` as '{oob_minute}' although this is earlier than\"\n                f\" the calendar's first trading minute ({ans.first_minute})\"\n            )\n            with pytest.raises(ValueError, match=re.escape(error_msg)):\n                f(oob_minute, direction)\n        else:\n            session = f(oob_minute, direction)\n            assert session == ans.first_session\n\n        oob_minute = ans.minute_too_late\n        if direction in [\"next\", \"none\"]:\n            error_msg = (\n                f\"Received `minute` as '{oob_minute}' although this is later\"\n                f\" than the calendar's last trading minute ({ans.last_minute})\"\n            )\n            with pytest.raises(ValueError, match=re.escape(error_msg)):\n                f(oob_minute, direction)\n        else:\n            session = f(oob_minute, direction)\n            assert session == ans.last_session\n\n    def test_minute_to_past_session(self, all_calendars_with_answers, one_minute):\n        \"\"\"\n        Only lightly tested given method is little more than a wrapper over\n        comprehensively tested methods.\n        \"\"\"\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minute_to_past_session)\n\n        for _, block_sessions in ans.session_block_generator():\n            num_sessions = max(len(block_sessions), 5)\n            session = block_sessions[-1]\n            try:\n                sessions = ans.get_prev_sessions(session, num_sessions)\n            except IndexError:\n                sessions = ans.get_prev_sessions(session, len(block_sessions))\n\n            num_sessions = len(sessions)\n            prev_session = sessions[-2]\n            first_minute = ans.first_minutes[session]\n            # trading_minutes\n            minutes = [first_minute, ans.last_minutes[session]]\n            if ans.session_has_break(session):\n                # break minutes\n                minutes.append(ans.last_am_minutes[session] + one_minute)\n                minutes.append(ans.first_pm_minutes[session] - one_minute)\n            if session in ans.sessions_with_gap_before:\n                # non break minutes\n                minutes.append(first_minute - one_minute)\n                minutes.append(ans.last_minutes[prev_session] + one_minute)\n\n            for i in range(1, num_sessions - 1):\n                rtrn = sessions[-(i + 1)]  # all minutes should resolve to this session.\n                for minute in minutes:\n                    assert rtrn == f(minute, i)\n\n        # verify raises errors.\n        for count in [0, -1]:\n            with pytest.raises(ValueError):\n                f(minute, count)\n\n    def test_minute_to_future_session(self, all_calendars_with_answers, one_minute):\n        \"\"\"\n        Only lightly tested given method is little more than a wrapper over\n        comprehensively tested methods.\n        \"\"\"\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minute_to_future_session)\n\n        for _, block_sessions in ans.session_block_generator():\n            num_sessions = max(len(block_sessions), 5)\n            session = block_sessions[0]\n            try:\n                sessions = ans.get_next_sessions(session, num_sessions)\n            except IndexError:\n                sessions = ans.get_next_sessions(session, len(block_sessions))\n\n            num_sessions = len(sessions)\n            next_session = sessions[1]\n            last_minute = ans.last_minutes[session]\n            # trading_minutes\n            minutes = [ans.first_minutes[session], last_minute]\n            if ans.session_has_break(session):\n                # break minutes\n                minutes.append(ans.last_am_minutes[session] + one_minute)\n                minutes.append(ans.first_pm_minutes[session] - one_minute)\n            if session in ans.sessions_with_gap_after:\n                # non break minutes\n                minutes.append(last_minute + one_minute)\n                minutes.append(ans.first_minutes[next_session] - one_minute)\n\n            for i in range(1, num_sessions - 1):\n                rtrn = sessions[i]  # all minutes should resolve to this session.\n                for minute in minutes:\n                    assert rtrn == f(minute, i)\n\n        # verify raises errors.\n        for count in [0, -1]:\n            with pytest.raises(ValueError):\n                f(minute, count)\n\n    def test_minute_to_trading_minute(self, all_calendars_with_answers, all_directions):\n        \"\"\"\n        Limited testing as tested method is simply a filter for\n        comprehensively tested methods.\n        \"\"\"\n        direction = all_directions\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.minute_to_trading_minute)\n\n        for minute in itertools.islice(ans.trading_minutes_only(), 6):\n            assert minute == f(minute, direction=direction)\n\n        for minutes, session in ans.break_minutes[:1]:\n            for minute in minutes:\n                if direction == \"previous\":\n                    f(minute, direction) == ans.last_am_minutes[session]\n                elif direction == \"next\":\n                    f(minute, direction) == ans.first_pm_minutes[session]\n                else:\n                    error_msg = (\n                        f\"`minute` '{minute}' is not a trading minute. Consider passing\"\n                        \" `direction` as 'next' or 'previous'.\"\n                    )\n                    with pytest.raises(ValueError, match=re.escape(error_msg)):\n                        f(minute, direction)\n\n        for minutes, prev_session, next_session in ans.non_trading_minutes[:1]:\n            for minute in minutes:\n                if direction == \"previous\":\n                    assert f(minute, direction) == ans.last_minutes[prev_session]\n                elif direction == \"next\":\n                    assert f(minute, direction) == ans.first_minutes[next_session]\n                else:\n                    error_msg = f\"`minute` '{minute}' is not a trading minute.\"\n                    with pytest.raises(ValueError, match=re.escape(error_msg)):\n                        f(minute, direction)\n\n    def test_minute_offset(self, all_calendars_with_answers, one_minute):\n        calendar, ans = all_calendars_with_answers\n        f = no_parsing(calendar.minute_offset)\n\n        for _, sessions in ans.session_block_generator():\n            for i, session in enumerate(sessions):\n\n                # intra session\n                first_minute = ans.first_minutes[session]\n                rtrn = f(first_minute + pd.Timedelta(20, \"T\"), 10)\n                assert rtrn == first_minute + pd.Timedelta(30, \"T\")\n\n                last_minute = ans.last_minutes[session]\n                rtrn = f(last_minute - pd.Timedelta(20, \"T\"), -10)\n                assert rtrn == last_minute - pd.Timedelta(30, \"T\")\n\n                # crossing break\n                if ans.session_has_break(session):\n                    last_am_minute = ans.last_am_minutes[session]\n                    first_pm_minute = ans.first_pm_minutes[session]\n\n                    rtrn = f(last_am_minute - one_minute, 3)\n                    assert rtrn == first_pm_minute + one_minute\n\n                    rtrn = f(first_pm_minute + one_minute, -3)\n                    assert rtrn == last_am_minute - one_minute\n\n                # crossing sessions\n                prev_session = False if i == 0 else sessions[i - 1]\n                next_session = False if i == len(sessions) - 1 else sessions[i + 1]\n                if prev_session:\n                    rtrn = f(first_minute + one_minute, -3)\n                    assert rtrn == ans.last_minutes[prev_session] - one_minute\n\n                if next_session:\n                    rtrn = f(last_minute - one_minute, 3)\n                    assert rtrn == ans.first_minutes[next_session] + one_minute\n\n        # Verify raising expected errors.\n\n        rtrn = f(ans.first_minute, 0)\n        assert rtrn == ans.first_minute\n        with pytest.raises(errors.RequestedMinuteOutOfBounds, match=\"before\"):\n            f(ans.first_minute, -1)\n\n        rtrn = f(ans.last_minute, 0)\n        assert rtrn == ans.last_minute\n        with pytest.raises(errors.RequestedMinuteOutOfBounds, match=\"after\"):\n            f(ans.last_minute, 1)\n\n    def test_minute_offset_by_sessions(self, all_calendars_with_answers):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minute_offset_by_sessions)\n        delta_int = 20\n        delta = pd.Timedelta(delta_int, \"T\")\n\n        # tests for rtrn with same time.\n\n        def assertions(\n            minute: pd.Timestamp,\n            target_session: pd.Timestamp,\n            rtrn: pd.Timestamp,\n        ):\n            assert (rtrn.hour == minute.hour) and (rtrn.minute == minute.minute)\n            assert rtrn >= ans.first_minutes[target_session]\n            assert rtrn <= ans.last_minutes[target_session]\n\n        sessions_unchanging_times_run = ans.sessions_unchanging_times_run\n\n        session = sessions_unchanging_times_run[0]\n        minutes = ans.get_session_edge_minutes(session, delta_int)\n        target_sessions = sessions_unchanging_times_run[1:6]\n        for i, target_session in enumerate(target_sessions):\n            for minute in minutes:\n                assertions(minute, target_session, f(minute, i + 1))\n\n        session = sessions_unchanging_times_run[-1]\n        minutes = ans.get_session_edge_minutes(session, delta_int)\n        target_sessions = sessions_unchanging_times_run[-6:-1]\n        for i, target_session in enumerate(reversed(target_sessions)):\n            for minute in minutes:\n                assertions(minute, target_session, f(minute, -(i + 1)))\n\n        sessions = ans.sessions_next_close_later[-5:]\n        for session in sessions:\n            target_session = ans.get_next_session(session)\n            minute_ = ans.last_minutes[session]\n            for minute in [minute_, minute_ - delta]:\n                assertions(minute, target_session, f(minute, 1))\n\n        target_sessions = ans.sessions_next_close_earlier[-5:]\n        for target_session in target_sessions:\n            session = ans.get_next_session(target_session)  # previous close later\n            minute_ = ans.last_minutes[session]\n            for minute in [minute_, minute_ - delta]:\n                assertions(minute, target_session, f(minute, -1))\n\n        sessions = ans.sessions_next_open_earlier[-5:]\n        for session in sessions:\n            target_session = ans.get_next_session(session)\n            minute_ = ans.first_minutes[session]\n            for minute in [minute_, minute_ + delta]:\n                assertions(minute, target_session, f(minute, 1))\n\n        target_sessions = ans.sessions_next_open_later[-5:]\n        for target_session in target_sessions:\n            session = ans.get_next_session(target_session)  # previous open earlier\n            minute_ = ans.first_minutes[session]\n            for minute in [minute_, minute_ + delta]:\n                assertions(minute, target_session, f(minute, -1))\n\n        if ans.has_a_session_with_break:\n\n            sessions = ans.sessions_next_break_start_later[-5:]\n            for session in sessions:\n                target_session = ans.get_next_session(session)\n                minute_ = ans.last_am_minutes[session]\n                for minute in [minute_, minute_ - delta]:\n                    assertions(minute, target_session, f(minute, 1))\n\n            target_sessions = ans.sessions_next_break_start_earlier[-5:]\n            for target_session in target_sessions:\n                session = ans.get_next_session(target_session)  # prev break start later\n                minute_ = ans.last_am_minutes[session]\n                for minute in [minute_, minute_ - delta]:\n                    assertions(minute, target_session, f(minute, -1))\n\n            sessions = ans.sessions_next_break_end_earlier[-5:]\n            for session in sessions:\n                target_session = ans.get_next_session(session)\n                minute_ = ans.first_pm_minutes[session]\n                for minute in [minute_, minute_ + delta]:\n                    assertions(minute, target_session, f(minute, 1))\n\n            target_sessions = ans.sessions_next_break_end_later[-5:]\n            for target_session in target_sessions:\n                session = ans.get_next_session(target_session)  # prev break end earlier\n                minute_ = ans.first_pm_minutes[session]\n                for minute in [minute_, minute_ + delta]:\n                    assertions(minute, target_session, f(minute, -1))\n\n        # tests for rtrn with different time.\n\n        sessions = ans.sessions_next_close_earlier[-5:]\n        if ans.sessions[-2] in sessions:  # guard against offset minute exceeding bound\n            sessions = sessions[sessions != ans.sessions[-2]]\n        for session in sessions:\n            target_session = ans.get_next_session(session)\n            minute = ans.last_minutes[session]\n            assert f(minute, 1) == ans.last_minutes[target_session]\n\n        target_sessions = ans.sessions_next_close_later[-5:]\n        for target_session in target_sessions:\n            session = ans.get_next_session(target_session)  # previous close earlier\n            minute = ans.last_minutes[session]\n            assert f(minute, -1) == ans.last_minutes[target_session]\n\n        sessions = ans.sessions_next_open_later[-5:]\n        for session in sessions:\n            target_session = ans.get_next_session(session)\n            minute = ans.first_minutes[session]\n            assert f(minute, 1) == ans.first_minutes[target_session]\n\n        target_sessions = ans.sessions_next_open_earlier[-5:]\n        if ans.sessions[1] in sessions:  # guard against offset minute exceeding bound\n            sessions = sessions[sessions != ans.sessions[1]]\n        for target_session in target_sessions:\n            session = ans.get_next_session(target_session)  # previous open later\n            minute = ans.first_minutes[session]\n            assert f(minute, -1) == ans.first_minutes[target_session]\n\n        # tests for trading minutes that would otherwise offset to a break minute.\n\n        for minute, _, target_session in ans.trading_minute_to_break_minute_next:\n            assert f(minute, 1) == ans.last_am_minutes[target_session]\n\n        for minute, _, target_session in ans.trading_minute_to_break_minute_prev:\n            assert f(minute, -1) == ans.last_am_minutes[target_session]\n\n        # Verify expected errors raised.\n\n        minutes = [ans.first_minutes[ans.last_session], ans.last_minute]\n        for minute in minutes:\n            for i in range(1, 3):\n                with pytest.raises(errors.RequestedMinuteOutOfBounds, match=\"after\"):\n                    f(minute, i)\n\n        minutes = [ans.first_minute, ans.last_minutes[ans.first_session]]\n        for minute in minutes:\n            for i in range(-2, 0):\n                with pytest.raises(errors.RequestedMinuteOutOfBounds, match=\"before\"):\n                    f(minute, i)\n\n    # Tests for methods that evaluate or interrogate a range of minutes.\n\n    def test_minutes_in_range(self, all_calendars_with_answers, one_minute):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minutes_in_range)\n\n        block_minutes = ans.session_block_minutes\n        for name, block in ans.session_block_generator():\n            ans_dti = block_minutes[name]\n            from_ = ans.first_minutes[block[0]]\n            to = ans.last_minutes[block[-1]]\n            cal_dti = f(from_, to)\n            tm.assert_index_equal(ans_dti, cal_dti)\n\n            # test consequence of getting range from one minute before/after the\n            # block's first/last trading minute.\n            if name in [\"first_three\", \"last_three\"]:\n                continue\n            cal_dti = f(from_ - one_minute, to + one_minute)\n            start_idx = 1 if block[0] in ans.sessions_without_gap_before else 0\n            end_idx = -1 if block[-1] in ans.sessions_without_gap_after else None\n            tm.assert_index_equal(ans_dti, cal_dti[start_idx:end_idx])\n\n        # intra-session\n        from_ = ans.first_minutes[ans.first_session] + pd.Timedelta(15, \"T\")\n        to = ans.first_minutes[ans.first_session] + pd.Timedelta(45, \"T\")\n        expected = pd.date_range(from_, to, freq=\"T\")\n        rtrn = f(from_, to)\n        tm.assert_index_equal(expected, rtrn)\n\n        # inter-session\n        if not ans.sessions_with_gap_after.empty:\n            session = ans.sessions_with_gap_after[0]\n            next_session = ans.get_next_session(session)\n            from_ = ans.last_minutes[session] + one_minute\n            to = ans.first_minutes[next_session] - one_minute\n            assert f(from_, to).empty\n\n    def test_minutes_window(self, all_calendars_with_answers):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minutes_window)\n\n        block_minutes = ans.session_block_minutes\n        for name, block in ans.session_block_generator():\n            start = ans.first_minutes[block[0]]\n            ans_dti = block_minutes[name]\n            count = len(ans_dti)\n            cal_dti = f(start, count)\n            tm.assert_index_equal(ans_dti, cal_dti)\n\n            start = ans.last_minutes[block[-1]]\n            cal_dti = f(start, -count)\n            tm.assert_index_equal(ans_dti, cal_dti)\n\n        # intra-session\n        from_ = ans.first_minutes[ans.first_session] + pd.Timedelta(15, \"T\")\n        count = 30\n        expected = pd.date_range(from_, periods=count, freq=\"T\")\n        rtrn = f(from_, count)\n        tm.assert_index_equal(expected, rtrn)\n\n        # inter-session\n        if not ans.sessions_with_gap_after.empty:\n            session = ans.sessions_with_gap_after[0]\n            next_session = ans.get_next_session(session)\n            from_ = ans.last_minutes[session] - pd.Timedelta(4, \"T\")\n            count = 10\n            expected_1 = pd.date_range(from_, periods=5, freq=\"T\")\n            from_2 = ans.first_minutes[next_session]\n            expected_2 = pd.date_range(from_2, periods=5, freq=\"T\")\n            expected = expected_1.union(expected_2)\n            rtrn = f(from_, count)\n            tm.assert_index_equal(expected, rtrn)\n\n        # verify raises ValueError when window extends beyond calendar's minute bounds\n        # at limit, window starts on first calendar minute\n        delta = pd.Timedelta(2, \"T\")\n        minute = ans.first_minute + delta\n        assert f(minute, count=-3)[0] == ans.first_minute\n        # window would start before first calendar minute\n        match = re.escape(\n            \"Minutes window cannot begin before the calendar's first minute\"\n            f\" ({ans.first_minute}). `count` cannot be lower than -3 for `minute`\"\n            f\" '{minute}'.\"\n        )\n        with pytest.raises(ValueError, match=match):\n            f(minute, count=-4)\n\n        # at limit, window ends on last calendar minute\n        minute = ans.last_minute - delta\n        assert f(minute, count=3)[-1] == ans.last_minute\n        # window would end after last calendar minute\n        match = re.escape(\n            \"Minutes window cannot end after the calendar's last minute\"\n            f\" ({ans.last_minute}). `count` cannot be higher than 3 for `minute`\"\n            f\" '{minute}'.\"\n        )\n        with pytest.raises(ValueError):\n            f(minute, count=4)\n\n        # verify raises ValueError if `count` passed as 0\n        with pytest.raises(ValueError, match=\"`count` cannot be 0.\"):\n            f(ans.first_minute, count=0)\n\n    def test_minutes_distance(self, all_calendars_with_answers, one_minute):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.minutes_distance)\n\n        for mins in ans.session_block_minutes.values():\n            if mins.empty:\n                continue\n            mins = mins[7:-7]\n            distance = len(mins)\n            assert f(mins[0], mins[-1]) == distance\n            assert f(mins[-1], mins[0]) == -distance\n\n        # test for same start / end\n        assert f(ans.trading_minute, ans.trading_minute) == 1\n\n        # tests where start and end are non-trading minutes\n        if ans.non_trading_minutes:\n            # test that range within which there are no minutes returns 0\n            assert f(*ans.non_trading_minutes[0][0]) == 0\n\n            # test range defined with start and end as non-trading minutes\n            sessions = ans.sessions_with_gap_before.intersection(\n                ans.sessions_with_gap_after\n            )\n            if not sessions.empty:\n                session = sessions[0]\n                distance = len(ans.get_sessions_minutes(session, 1))\n                start = ans.first_minutes[session] - one_minute\n                end = ans.last_minutes[session] + one_minute\n                assert f(start, end) == distance\n\n    def test_minutes_to_sessions(self, all_calendars_with_answers):\n        calendar, ans = all_calendars_with_answers\n        f = calendar.minutes_to_sessions\n\n        trading_minute = ans.trading_minute\n        for minute in ans.non_trading_minutes_only():\n            with pytest.raises(ValueError):\n                f(pd.DatetimeIndex([minute]))\n            with pytest.raises(ValueError):\n                f(pd.DatetimeIndex([trading_minute, minute]))\n\n        mins, sessions = [], []\n        for trading_minutes, session in ans.trading_minutes[:30]:\n            mins.extend(trading_minutes)\n            sessions.extend([session] * len(trading_minutes))\n\n        index = pd.DatetimeIndex(mins).sort_values()\n        sessions_labels = f(index)\n        tm.assert_index_equal(sessions_labels, pd.DatetimeIndex(sessions).sort_values())\n\n    # Tests for methods that evaluate or interrogate a range of sessions.\n\n    def test_sessions_in_range(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.sessions_in_range)\n\n        # test where start and end are sessions\n        start, end = ans.sessions[10], ans.sessions[-10]\n        tm.assert_index_equal(f(start, end), ans.sessions[10:-9])\n\n        # test session blocks\n        for _, block in ans.session_block_generator():\n            tm.assert_index_equal(f(block[0], block[-1]), block)\n\n        # tests where start and end are non-session dates\n        if len(ans.non_sessions) > 1:\n            # test that range within which there are no sessions returns empty\n            assert f(*ans.non_sessions_range).empty\n\n            # test range defined with start and end as non-sessions\n            (start, end), sessions = ans.sessions_range_defined_by_non_sessions\n            tm.assert_index_equal(f(start, end), sessions)\n\n    def test_sessions_has_break(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.sessions_has_break)\n\n        has_a_break = ans.has_a_session_with_break\n        assert f(ans.first_session, ans.last_session) == has_a_break\n\n        if ans.has_a_session_without_break:\n            assert not f(*ans.sessions_without_break_range)\n\n            if has_a_break:\n                # i.e. mixed, some sessions have a break, some don't\n                block = ans.session_blocks[\"with_break_to_without_break\"]\n                if not block.empty:\n                    # guard against starting with no breaks, then an introduction\n                    # of breaks to every session after a certain date\n                    # (i.e. there would be no with_break_to_without_break)\n                    assert f(block[0], block[-1])\n                block = ans.session_blocks[\"without_break_to_with_break\"]\n                if not block.empty:\n                    # ...guard against opposite case (e.g. XKRX)\n                    assert f(block[0], block[-1])\n        else:\n            # in which case all sessions must have a break. Make sure...\n            assert cal.break_starts.notna().all()\n\n    def test_sessions_window(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.sessions_window)\n\n        for _, block in ans.session_block_generator():\n            count = len(block)\n            tm.assert_index_equal(f(block[0], count), block)\n            tm.assert_index_equal(f(block[-1], -count), block)\n\n        # verify raises ValueError if window extends beyond calendar's session bounds.\n        # at limit, window starts on first calendar session\n        assert f(ans.sessions[2], count=-3)[0] == ans.first_session\n        # window would start before first calendar session\n        match = re.escape(\n            \"Sessions window cannot begin before the first calendar session\"\n            f\" ({ans.first_session}). `count` cannot be lower than -3 for `session`\"\n            f\" '{ans.sessions[2]}'.\"\n        )\n        with pytest.raises(ValueError, match=match):\n            f(ans.sessions[2], count=-4)\n\n        # at limit, window ends on last calendar session\n        assert f(ans.sessions[-3], count=3)[-1] == ans.last_session\n        # window would end after last calendar session\n        match = re.escape(\n            \"Sessions window cannot end after the last calendar session\"\n            f\" ({ans.last_session}). `count` cannot be higher than 3 for `session`\"\n            f\" '{ans.sessions[-3]}'.\"\n        )\n        with pytest.raises(ValueError):\n            f(ans.sessions[-3], count=4)\n\n        # verify raises ValueError if `count` passed as 0\n        with pytest.raises(ValueError, match=\"`count` cannot be 0.\"):\n            f(ans.sessions[0], count=0)\n\n    def test_sessions_distance(self, default_calendar_with_answers):\n        cal, ans = default_calendar_with_answers\n        f = no_parsing(cal.sessions_distance)\n\n        for _, block in ans.session_block_generator():\n            distance = len(block)\n            assert f(block[0], block[-1]) == distance\n            assert f(block[-1], block[0]) == -distance\n\n        # test for same start / end\n        assert f(ans.sessions[0], ans.sessions[0]) == 1\n\n        # tests where start and end are non-session dates\n        if len(ans.non_sessions) > 1:\n            # test that range within which there are no sessions returns 0\n            assert f(*ans.non_sessions_range) == 0\n\n            # test range defined with start and end as non_sessions\n            (start, end), sessions = ans.sessions_range_defined_by_non_sessions\n            assert f(start, end) == len(sessions)\n\n    def test_sessions_minutes(self, all_calendars_with_answers):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.sessions_minutes)\n\n        block_minutes = ans.session_block_minutes\n        for name, block in ans.session_block_generator():\n            ans_minutes = block_minutes[name]\n            cal_minutes = f(block[0], block[-1])\n            tm.assert_index_equal(ans_minutes, cal_minutes)\n\n        # tests where start and end are non-session dates\n        if len(ans.non_sessions) > 1:\n            # test that range within which there are no sessions returns empty\n            assert f(*ans.non_sessions_range).empty\n\n            # test range defined with start and end as non-sessions\n            (start, end), sessions = ans.sessions_range_defined_by_non_sessions\n            minutes = ans.get_sessions_minutes(sessions[0], sessions[-1])\n            tm.assert_index_equal(f(start, end), minutes)\n\n    def test_sessions_minutes_count(self, all_calendars_with_answers):\n        cal, ans = all_calendars_with_answers\n        f = no_parsing(cal.sessions_minutes_count)\n\n        block_minutes = ans.session_block_minutes\n        for name, block in ans.session_block_generator():\n            ans_minutes = len(block_minutes[name])\n            cal_minutes = f(block[0], block[-1])\n            assert cal_minutes == ans_minutes\n\n        # tests where start and end are non-session dates\n        if len(ans.non_sessions) > 1:\n            # test that range within which there are no sessions returns 0\n            assert f(*ans.non_sessions_range) == 0\n\n            # test range defined with start and end as non-sessions\n            (start, end), sessions = ans.sessions_range_defined_by_non_sessions\n            minutes = ans.get_sessions_minutes(sessions[0], sessions[-1])\n            assert f(start, end) == len(minutes)\n\n        # Additional belt-and-braces test to reconcile with cal.minutes\n        assert f(ans.first_session, ans.last_session) == len(cal.minutes)\n\n    def test_trading_index(self, calendars, answers):\n        \"\"\"Test trading index with options as default values.\n\n        Tests multitude of concrete cases covering product of all\n        session blocks and various periods.\n\n        Assumes default value (False) for each of `force_close`,\n        `force_break_close` and `curtail_overlaps`. See test class\n        `test_calendar_helpers.TestTradingIndex` for more comprehensive\n        testing (including fuzz tests and parsing tests).\n        \"\"\"\n        cal, ans = calendars[\"left\"], answers[\"left\"]\n\n        def unite(dtis: list[pd.DatetimeIndex]) -> pd.DatetimeIndex:\n            return dtis[0].append(dtis[1:])  # append to not sort or remove duplicates\n\n        for _, sessions in ans.session_block_generator():\n            for mins in [5, 17, 60, 123, 333, 1033]:\n                period = pd.Timedelta(mins, \"T\")\n                dtis = []\n                for session in sessions:\n                    indexes = ans.get_session_minutes(session)\n                    for i, index in enumerate(indexes):\n                        # Create closed 'both' trading index for each session/subsession\n                        if i == 0 and len(indexes) == 2:\n                            ends = ans.break_starts\n                        else:\n                            ends = ans.closes\n                        # index for a 'left' calendar, add end so evaluated as if 'both'\n                        index = index.append(pd.DatetimeIndex([ends[session]]))\n\n                        index = index[::mins]  # only want every period\n                        if not index[-1] == ends[session]:\n                            # if period doesn't coincide with end, add right side of\n                            # last interval which lies beyond end.\n                            last_indice = index[-1] + period\n                            index = index.append(pd.DatetimeIndex([last_indice]))\n                        dtis.append(index)\n\n                both_index = unite(dtis)\n                left_index = unite([dti[:-1] for dti in dtis])\n                right_index = unite([dti[1:] for dti in dtis])\n                neither_index = unite([dti[1:-1] for dti in dtis])\n\n                overlaps = (right_index[:-1] > left_index[1:]).any()\n                if overlaps:\n                    both_overlaps = overlaps\n                else:\n                    both_overlaps = False\n                    for dti, next_dti in zip(dtis, dtis[1:]):\n                        if dti[-1] == next_dti[0]:\n                            both_overlaps = True\n                            break\n\n                def get_index(closed: str, intervals: bool):\n                    start, end = sessions[0], sessions[-1]\n                    return cal.trading_index(\n                        start, end, period, intervals, closed, parse=False\n                    )\n\n                def tst_indices_index(\n                    expected: pd.DatetimeIndex, closed: str, overlaps: bool\n                ):\n                    if not overlaps:\n                        rtrn = get_index(closed, False)\n                        pd.testing.assert_index_equal(expected, rtrn)\n                    else:\n                        with pytest.raises(errors.IndicesOverlapError):\n                            get_index(closed, False)\n\n                tst_indices_index(both_index, \"both\", both_overlaps)\n                tst_indices_index(left_index, \"left\", False)\n                tst_indices_index(right_index, \"right\", overlaps)\n                tst_indices_index(neither_index, \"neither\", False)\n\n                def tst_intervals_index(closed: str, overlaps: bool):\n                    if not overlaps:\n                        rtrn = get_index(closed, True)\n                        expected = pd.IntervalIndex.from_arrays(\n                            left_index, right_index, closed\n                        )\n                        pd.testing.assert_index_equal(expected, rtrn)\n                    else:\n                        with pytest.raises(errors.IntervalsOverlapError):\n                            get_index(closed, True)\n\n                tst_intervals_index(\"left\", overlaps)\n                tst_intervals_index(\"right\", overlaps)\n\n    def test_deprecated(self, default_calendar_with_answers):\n        \"\"\"Test currently deprecated properties/methods raise FutureWarning.\"\"\"\n        cal, ans = default_calendar_with_answers\n\n        # deprecated properties / attributes\n        for name in []:\n            with pytest.warns(FutureWarning):\n                getattr(cal, name)\n\n        # deprecated class methods\n        for name in [\"bound_start\", \"bound_end\"]:\n            with pytest.warns(FutureWarning):\n                getattr(cal, name)()\n\n        # deprecated methods that take a single 'session' argument.\n        session = ans.sessions[-5]\n        for name in []:\n            with pytest.warns(FutureWarning):\n                getattr(cal, name)(session, _parse=False)\n\n        # deprecated methods that take start and end session parameters.\n        start = ans.sessions[-10]\n        end = session\n        for name in [\n            \"sessions_opens\",\n            \"sessions_closes\",\n        ]:\n            with pytest.warns(FutureWarning):\n                getattr(cal, name)(start, end, _parse=False)\n\n        # deprecated methods that take a single 'minute' argument.\n        minute = ans.trading_minutes[len(ans.trading_minutes) // 2][0][1]\n        for name in []:\n            with pytest.warns(FutureWarning):\n                getattr(cal, name)(minute, _parse=False)\n\n\nclass EuronextCalendarTestBase(ExchangeCalendarTestBase):\n    \"\"\"Common calendar-specific fixtures for Euronext exchanges.\"\"\"\n\n    # Subclass should override the following fixtures if close times differ\n    # from the default yielded.\n\n    @pytest.fixture\n    def early_closes_sample_time(self):\n        # Early close is 2:05 PM.\n        # Source: https://www.euronext.com/en/calendars-hours\n        yield pd.Timedelta(hours=14, minutes=5)\n\n    @pytest.fixture\n    def non_early_closes_sample_time(self):\n        yield pd.Timedelta(hours=17, minutes=30)\n\n    # Subclass can override the following fixtures to add to calendar-specific samples.\n\n    @pytest.fixture\n    def additional_regular_holidays_sample(self):\n        yield []\n\n    @pytest.fixture\n    def additional_non_holidays_sample(self):\n        yield []\n\n    # Subclass should NOT override any of the following fixtures.\n\n    @pytest.fixture\n    def max_session_hours(self):\n        yield 8.5\n\n    @pytest.fixture\n    def regular_holidays_sample(self, additional_regular_holidays_sample):\n        yield additional_regular_holidays_sample + [\n            # 2014\n            \"2014-01-01\",  # New Year's Day\n            \"2014-04-18\",  # Good Friday\n            \"2014-04-21\",  # Easter Monday\n            \"2014-05-01\",  # Labor Day\n            \"2014-12-25\",  # Christmas\n            \"2014-12-26\",  # Boxing Day\n        ]\n\n    @pytest.fixture\n    def non_holidays_sample(self, additional_non_holidays_sample):\n        yield additional_non_holidays_sample + [\n            # Holidays falling on a weekend that are not made up. Ensure\n            # surrounding sessions are not holidays...\n            # In 2010, Labor Day fell on a Saturday, so the market should be open...\n            \"2010-04-30\",  # ...on prior Friday...\n            \"2010-05-03\",  # ...and following Monday.\n            # Christmas fell on a Saturday and Boxing Day on a Sunday...\n            \"2010-12-24\",  # market should be open on both the prior Friday...\n            \"2010-12-27\",  # ...and following Monday.\n        ]\n\n    @pytest.fixture\n    def early_closes_sample(self):\n        # Christmas Eve, New Year's Eve, Christmas Eve, New Year's Eve\n        yield [\"2010-12-24\", \"2010-12-31\", \"2014-12-24\", \"2014-12-31\"]\n\n    @pytest.fixture\n    def non_early_closes_sample(self):\n        # In Dec 2011, Christmas Eve and NYE were both on a Saturday, so\n        # the preceding Fridays should be full days.\n        yield [\"2011-12-23\", \"2011-12-30\"]\n\n\n### tests/test_utils.py ###\n\nimport pandas as pd\n\n\ndef T(x):\n    return pd.Timestamp(x)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom exchange_calendars.exchange_calendar_xshg import XSHGExchangeCalendar\nfrom .test_exchange_calendar import ExchangeCalendarTestBase\nfrom .test_utils import T\n\n\nclass TestXSHGCalendar(ExchangeCalendarTestBase):\n    @pytest.fixture(scope=\"class\")\n    def calendar_cls(self):\n        yield XSHGExchangeCalendar\n\n    @pytest.fixture\n    def max_session_hours(self):\n        # Shanghai stock exchange is open from 9:30 am to 3pm\n        yield 5.5\n\n    @pytest.fixture\n    def start_bound(self):\n        yield T(\"1999-01-01\")\n\n    @pytest.fixture\n    def end_bound(self):\n        yield T(\"2025-12-31\")\n\n    @pytest.fixture\n    def regular_holidays_sample(self):\n        yield [\n            # 2017\n            \"2017-01-02\",\n            \"2017-01-27\",\n            \"2017-01-30\",\n            \"2017-01-31\",\n            \"2017-02-01\",\n            \"2017-02-02\",\n            \"2017-04-03\",\n            \"2017-04-04\",\n            \"2017-05-01\",\n            \"2017-05-29\",\n            \"2017-05-30\",\n            \"2017-10-02\",\n            \"2017-10-03\",\n            \"2017-10-04\",\n            \"2017-10-05\",\n            \"2017-10-06\",\n\n            # 2020\n            \"2020-01-31\"\n        ]\n"
  },
  {
    "prompt": "\n\n### MidiCompose/logic/rhythm/part.py ###\n\nfrom __future__ import annotations\n\nfrom copy import deepcopy\nfrom typing import Collection, Optional, List, Sequence\nimport random\n\nimport numpy as np\nfrom icecream import ic\n\nfrom MidiCompose.logic.rhythm.measure import Measure\nfrom MidiCompose.logic.rhythm.measure import Beat\n\nfrom MidiCompose.utilities import ctx_random_seed\n\n\nclass PartIterator:\n\n    def __init__(self, part):\n        self._Part = part\n        self._index = 0\n        self._len_Part = self._Part.n_measures\n\n    def __next__(self) -> Measure:\n        if self._index < self._len_Part:\n            result = self._Part.measures[self._index]\n            self._index += 1\n            return result\n        else:\n            raise StopIteration\n\n\nclass Part:\n    \"\"\"\n    Container for Measures\n    \"\"\"\n\n    def __init__(self, measures: Optional[Collection[Measure]] = None):\n        self.measures = measures\n\n    @property\n    def measures(self) -> List[Measure]:\n        return self._measures\n\n    @measures.setter\n    def measures(self, value):\n\n        if value is None:  # initialize empty part\n            self._measures = []\n        else:\n            self._measures = [measure for measure in value]\n\n    @property\n    def state(self):\n        measure_states = np.concatenate([m.state for m in self.measures])\n        state = np.empty(shape=(measure_states.size + 2,), dtype=np.int8)\n        state[0], state[-1] = -1, -1\n        state[1:-1] = measure_states\n        return state\n\n    @property\n    def n_note_on(self) -> int:\n        return sum([m.n_note_on for m in self.measures])\n\n    @property\n    def n_measures(self) -> int:\n        return len(self.measures)\n\n    @property\n    def n_beats(self) -> int:\n        return sum([m.n_beats for m in self.measures])\n\n    @property\n    def active_state(self):\n        pass\n\n    #### UTILITY METHODS ####\n    def append_measure(self, measure: Measure):\n\n        if not isinstance(measure,Measure):\n            e = \"`measure` must be a Measure instance.\"\n            raise TypeError(e)\n\n        self.measures.append(measure)\n        return self\n\n    def activate_random(self,\n                        density: float,\n                        random_seed: int = None,\n                        measure_idx: Sequence[int] = None) -> Part:\n\n        if measure_idx is None:\n            measure_idx = list()\n\n        _measures = []\n        with ctx_random_seed(seed=random_seed):\n            for i, measure in enumerate(self.measures):\n                if i in measure_idx:\n                    _measure = measure\n                else:\n                    _n_beats = measure.n_beats\n                    _sub_values = list(measure.subdivision_values)\n                    ic(_sub_values)\n\n                    choices = random.choices([1,0],\n                                             weights=[density,1-density],\n                                             k=sum(_sub_values))\n                    ic(choices)\n\n                    _beats = []\n                    idx = 0\n                    for sub_val in _sub_values:\n                        _beats.append(Beat(choices[idx:sub_val+1]))\n                        idx += sub_val\n                    _measure = Measure(_beats)\n                _measures.append(_measure)\n\n        return Part(_measures)\n\n\n\n\n\n\n\n\n    #### GENERATOR METHODS ####\n\n    def get_complement(self, measure_idx: Optional[Sequence[int]] = None):\n\n        if measure_idx is not None:\n            e = \"Implement measure indexing!\"\n            raise NotImplementedError(e)\n        _measures = self._measures\n        complement = Part([m.get_complement() for m in _measures])\n        return complement\n\n    #### MAGIC METHODS ####\n    def __iter__(self):\n        return PartIterator(self)\n\n    def __getitem__(self, item: int) -> Measure:\n        return self.measures[item]\n\n    def __len__(self):\n        return len(self.measures)\n\n    def __mul__(self, other: int):\n        return [deepcopy(self) for _ in range(other)]\n\n    def __repr__(self):\n\n        r = \"Part([\"\n        measure_strings = [str(m) for m in self.measures]\n        for m in measure_strings:\n            r += \"\\n\" + \" \" + m\n        r += f\"\\nn_beats: {self.n_beats}\"\n        r += \"\\n])\"\n        return r\n\n\n\n### MidiCompose/logic/rhythm/beat.py ###\n\nfrom copy import deepcopy\nfrom typing import Union, Iterable, Collection, Optional, List\nimport random\n\nimport numpy as np\n\nfrom MidiCompose.logic.rhythm.time_unit import TimeUnit\nfrom MidiCompose.utilities import temp_seed, ctx_random_seed\n\n\nclass BeatIterator:\n\n    def __init__(self, beat):\n        self._Beat = beat\n        self._index = 0\n\n        self._len_Beat = len(self._Beat)\n\n    def __next__(self):\n        if self._index < self._len_Beat:\n            result = self._Beat.time_units[self._index]\n            self._index += 1\n            return result\n        else:\n            raise StopIteration\n\n\nclass Beat:\n    \"\"\"\n    Container for TimeUnit objects.\n\n    Definitive attribute is `self.time_units`, which is a numpy array containing TimeUnit objects.\n\n    Argument `time_units` must either be a single integer representing the number of\n    subdivisions, or an iterable containing TimeUnit objects and/or \"TimeUnit-like\"\n    integers (ie. {0,1,2}). The latter is useful when passing stateful TimeUnit objects.\n    \"\"\"\n\n    def __init__(self,\n                 time_units: Union[int, Iterable[Union[int, TimeUnit]]] = 1,\n                 verbose: bool = False):\n        \"\"\"\n        :param verbose: determines format of output\n        \"\"\"\n\n        # self._parse_beat_arg(time_units)\n\n        self.time_units = time_units  # calls setter method\n\n        self.verbose = verbose\n\n    @property\n    def time_units(self) -> List[TimeUnit]:\n        return self._time_units\n\n    @time_units.setter\n    def time_units(self, value):\n\n        # if integer, `value` represents number of subdivisions\n        if isinstance(value, int):\n            self._time_units = [TimeUnit() for _ in range(value)]\n        else:\n            tu_like_type_set = {int, TimeUnit}\n            value_type_set = set([type(v) for v in value])\n\n            # else, collection of integers/TimeUnit objects\n            if value_type_set.issubset(tu_like_type_set):\n                _time_units = []\n                for v in value:\n                    if isinstance(v, TimeUnit):\n                        _time_units.append(v)\n                    else:\n                        _time_units.append(TimeUnit(v))\n                self._time_units = _time_units\n\n            else:\n                msg = f\"Invalid input\"\n                raise AttributeError(msg)\n\n    @property\n    def subdivision(self) -> int:\n        return len(self)\n\n    @property\n    def state(self) -> np.ndarray:\n        \"\"\"\n        1d numeric array representing the value of each TimeUnit in the Beat.\n        \"\"\"\n        state = np.empty(shape=(self.subdivision + 2,), dtype=np.int8)\n        state[:2] = [-3, self.subdivision]\n        state[2:] = [tu.state for tu in self.time_units]\n        return state\n\n    @property\n    def active_state(self) -> np.ndarray:\n        return self.state[2:]\n\n    @property\n    def n_note_on(self) -> int:\n        \"\"\"\n        The number of \"note_on\" events in the Beat.\n        \"\"\"\n        return np.where(self.active_state == 1)[0].size\n\n    @property\n    def is_active(self) -> bool:\n        \"\"\"\n        Returns True if any TimeUnit instances contain active time_units (1 or 2).\n        Otherwise, returns False.\n        \"\"\"\n        if self.n_note_on > 0:\n            return True\n        else:\n            return False\n\n    #### UTILITY FUNCTIONS ####\n\n    def set_state(self,\n                  state: Collection[int],\n                  override: bool = False):\n        \"\"\"\n        Set the `value` of the time_units instance to collection of either 0,1 or 2.\n\n        Automatically updates `time_units` attribute.\n\n        :param state: Collection of integers in {0,1,2}\n        :param override: If False, error will be raised if setting time_units to an already active\n        \"\"\"\n        valid_state_set = {0, 1, 2}\n        given_state_set = set(state)\n        if not given_state_set.issubset(valid_state_set):\n            msg = \"Parameter `value` takes a collection containing only integers 0,1 and 2.\"\n            raise AttributeError(msg)\n\n        # PICKUP HERE -- SEE FAILING TEST\n        self.time_units = state  # calls setter method\n\n        return self\n\n    def activate_random(self,\n                        density: float,\n                        random_seed: Optional[int] = None):\n        \"\"\"\n        :param density: float between 0 and 1 representing the density of activation.\n        :param random_seed: Provide a random random_seed for reproducibility.\n        \"\"\"\n        _beat = deepcopy(self)\n\n        if random_seed is not None:\n            with temp_seed(random_seed):\n                choices = np.random.choice(a=[0, 1],\n                                           size=_beat.subdivision,\n                                           p=[1 - density, density])\n\n                [tu.set_state(c) for tu, c in zip(_beat.time_units, choices)]\n        else:\n            choices = np.random.choice(a=[0, 1],\n                                       size=_beat.subdivision,\n                                       p=[1 - density, density])\n            [tu.set_state(c) for tu, c in zip(_beat.time_units, choices)]\n\n        return _beat\n\n    def sustain_all(self):\n        \"\"\"\n        Convert all \"note_off\" events to sustain events (ie change all 0s to 2).\n        \"\"\"\n        _beat = deepcopy(self)\n\n        idx_off = np.where(_beat.state[2:] == 0)[0]\n        for idx in idx_off:\n            _beat.time_units[idx].sustain()\n\n        return _beat\n\n    def shorten_all(self):\n        \"\"\"\n        Convert all \"sustain\" events to \"note_off\".\n        \"\"\"\n        idx_sustain = np.where(self.state[2:] == 2)[0]\n        for idx in idx_sustain:\n            self.time_units[idx].deactivate()\n\n    #### GENERATOR METHODS ####\n\n    def get_complement(self,\n                       adherence: float = 1.0,\n                       random_seed: Optional[int] = None):\n        \"\"\"\n        Returns new `Beat` instance which is complement of \"attack\".\n\n        ie. all \"sustain\" is stripped.\n\n        Params:\n        - adherence (str) : ...\n        \"\"\"\n\n        if adherence < 0 or adherence > 1:\n            msg = \"`Adherence` must be a float between 0 and 1\"\n            raise ValueError(msg)\n\n        _time_units = deepcopy(self._time_units)\n\n        with ctx_random_seed(random_seed):\n            _adherence = random.choices([0,1],\n                                        weights=[1-adherence,adherence],\n                                        k=len(_time_units))\n\n        _complement = []\n        for tu,adhere in zip(_time_units,_adherence):\n            if adhere == 1:\n                _tu = tu.toggle()\n            else:\n                _tu = tu\n            _complement.append(_tu)\n\n        complement = Beat(_complement)\n\n        return complement\n\n    #### MAGIC METHODS ####\n\n    def __iter__(self):\n        return BeatIterator(self)\n\n    def __getitem__(self, item: int) -> TimeUnit:\n        return self.time_units[item]\n\n    def __mul__(self, number: int):\n        copies = []\n        for _ in range(number):\n            copies.append(deepcopy(self))\n        return copies\n\n    def __len__(self):\n        return len(self.time_units)\n\n    def set_verbosity(self, verbose: bool):\n        self.verbose = verbose\n\n    def __repr__(self):\n        r = \"Beat(\"\n        time_units = [str(tu) for tu in self.time_units]\n        r += \",\".join(time_units) + \")\"\n        return r\n\n### MidiCompose/logic/rhythm/measure.py ###\n\nimport random\nfrom typing import Union, Collection, Optional, List, Sequence\nfrom copy import deepcopy\nfrom itertools import chain\n\nimport numpy as np\nfrom icecream import ic\n\nfrom MidiCompose.logic.rhythm.beat import Beat\nfrom MidiCompose.utilities import temp_seed,ctx_random_seed\n\n\nclass MeasureIterator:\n\n    def __init__(self, measure):\n        self._Measure = measure\n        self._index = 0\n        self._len_Measure = len(self._Measure)\n\n    def __next__(self) -> Beat:\n        if self._index < self._len_Measure:\n            result = self._Measure.beats[self._index]\n            self._index += 1\n            return result\n        else:\n            raise StopIteration\n\n\nclass Measure:\n\n    def __init__(self,\n                 beats: Optional[Union[Collection[Union[int, Beat, Collection[int]]]]] = None,\n                 verbose: bool = False):\n        \"\"\"\n        Three options for initialization:\n        1) Supply iterable of Beat object. This is useful if passing Beats with pre-defined time_units.\n        2) Supply a collection of collections of integers, where the number of items represents the number\n           of time_units, and the values of the integers represents the respective subdivision of each time_units.\n        3) Combination of the previous two.\n\n        Note that passing an integer will automatically instantiate an \"empty\" time_units. That is,\n        all TimeUnit objects will be set to 0 within that time_units.\n\n        :param beats: iterable containing Beat objects, bare integers, or a combination of the two.\n        :param verbose: if True, __repr__ gives more info.\n        \"\"\"\n\n        self.beats: Collection[Beat] = beats  # calls setter method\n        self.verbose: bool = verbose\n\n\n    #### PROPERTIES ####\n\n    @property\n    def beats(self) -> List[Beat]:\n        return self._beats\n\n    @beats.setter\n    def beats(self, value):\n\n        if value is None:  # initialize empty measure\n            self._beats = []\n        else:\n\n            value_type_set = set([type(b) for b in value])\n\n            beat_set = {Beat}\n            int_set = {int}\n            col_of_ints_set = {Collection}\n            mixed_set = {Beat, int}\n\n            # collection of collections of integers\n            coll_of_colls = all([issubclass(type(b), Collection) for b in value])\n            if coll_of_colls:\n                self._beats = [Beat(c) for c in value]\n\n            # contains only Beats -- no validation needed\n            elif value_type_set.issubset(beat_set):\n                self._beats = [v for v in value]\n\n            # contains only integers -- validated by Beat constructor\n            elif value_type_set.issubset(int_set):\n                self._beats = [Beat(a) for a in value]\n\n            # contains mixture Beat and int -- validated by Beat constructor\n            else:\n                _beats = []\n                for b in value:\n                    if type(b) == int:\n                        _beats.append(Beat(b))\n                    else:\n                        _beats.append(b)\n                self._beats = _beats\n\n    @property\n    def n_beats(self):\n        return len(self)\n\n    @property\n    def state(self):\n        \"\"\"\n        1-d numeric array containing figure of each time_units in Measure.\n        \"\"\"\n        beat_states = np.concatenate([b.state for b in self.beats])\n        state = np.empty(shape=(beat_states.size + 1,), dtype=np.int8)\n        state[0] = -2\n        state[1:] = beat_states\n        return state\n\n    @property\n    def active_state(self) -> np.ndarray:\n        \"\"\"\n        Same as `figure` array but without beat/measure flags.\n        \"\"\"\n        return np.concatenate([b.active_state for b in self.beats])\n\n    @property\n    def subdivision_values(self) -> np.ndarray:\n        \"\"\"\n        Returns a 1d array containing the subdivision of each `Beat` in the `Measure`.\n        \"\"\"\n        idx_sub_vals = np.where(self.state == -3)[0] + 1\n        sub_vals = self.state[idx_sub_vals]\n        return sub_vals\n\n    @property\n    def n_note_on(self) -> int:\n        \"\"\"\n        The number of \"note_on\" events in the Measure.\n        \"\"\"\n        return sum([b.n_note_on for b in self.beats])\n\n    @property\n    def is_active(self):\n        if self.n_note_on > 0:\n            return True\n        else:\n            return False\n\n    @property\n    def flattened(self) -> List[int]:\n        _flattened = list(chain(*self))\n        return _flattened\n\n    #### UTILITY FUNCTIONS ####\n\n    # TODO: implement override/reshape checks\n    def set_state(self,\n                  state: [Collection[Collection[int]]],\n                  override: bool = True,\n                  reshape: bool = False):\n        \"\"\"\n        Sets `figure` array as well as `beats` array.\n\n        :param override: If False, will raise exception if trying to override a stateful measure.\n        :param reshape: If False, will raise exception if `figure` argument would result in \"reshaping\" the measure (ie.\n        changing the number of beats, or number of subdivisions in a time_units.)\n        \"\"\"\n        self.beats = state\n\n    def activate_random(self, density: float,\n                        random_seed: Optional[int] = None,\n                        beat_idx: Sequence[int] = None):\n\n        beats = deepcopy(self.beats)\n\n        _beats = []\n        with ctx_random_seed(random_seed):\n            if beat_idx is None:\n                beat_idx = list()\n\n            for i,beat in enumerate(beats):\n                if i not in beat_idx:\n                    choices = random.choices(population=[1,0],\n                                             weights=[density,1-density],\n                                             k=len(beat))\n                    _beat = Beat(choices)\n                else:\n                    _beat = beat\n                _beats.append(_beat)\n\n        _measure = Measure(_beats)\n        return _measure\n\n    def sustain_all(self, beat_idx: Optional[Collection[int]] = None):\n        \"\"\"\n        Convert all \"item-off\" events to \"sustain\" events.\n        :param beat_idx: If given, only apply to the given beats.\n        \"\"\"\n        if beat_idx is not None:\n            if max(beat_idx) > len(self.beats):\n                msg = f\"`beat_idx` out of range.\"\n                raise IndexError(msg)\n            else:\n                for i in beat_idx:\n                    self.beats[i].sustain_all()\n        else:\n            for b in self.beats:\n                b.sustain_all()\n\n        return self\n\n    def shorten_all(self, beat_idx: Optional[Collection[int]] = None):\n        \"\"\"\n        Convert all \"sustain\" events to \"note_off\" events.\n        :param beat_idx: If given, only apply to the given beats.\n        \"\"\"\n\n        if beat_idx is not None:\n            if max(beat_idx) > len(self.beats):\n                msg = f\"`beat_idx` out of range.\"\n                raise IndexError(msg)\n            else:\n                for i in beat_idx:\n                    self.beats[i].shorten_all()\n        else:\n            for b in self.beats:\n                b.shorten_all()\n\n        return self\n\n    #### GENERATOR FUNCTIONS ####\n\n    def get_complement(self,\n                       adherence: float = 1.0,\n                       random_seed: Optional[int] = None,\n                       beat_idx:Optional[Sequence[int]] = None) -> Beat():\n\n        raise NotImplementedError()\n\n        if adherence > 1 or adherence < 0:\n            msg = \"`adherence` must be a float between 0 and 1.\"\n            raise ValueError(msg)\n\n        if beat_idx is not None:\n            e = \"Implement beat indexing!\"\n            raise NotImplementedError(e)\n\n    #### MAGIC METHODS ####\n\n    def __iter__(self):\n        return MeasureIterator(self)\n\n    def __getitem__(self, item: int) -> Beat:\n        return self.beats[item]\n\n    def __mul__(self,number: int) -> list:\n        return [deepcopy(self) for _ in range(number)]\n\n    def __len__(self):\n        return len(self.beats)\n\n    def __repr__(self):\n        r = \"Measure(\"\n        beat_strs = [str(b.active_state) for b in self.beats]\n        for i,b in enumerate(beat_strs):\n            if i < len(beat_strs) - 1:\n                r += b + \", \"\n            else:\n                r += b + \")\"\n        return r\n\n\n\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\r\n\r\nfrom MidiCompose.logic.rhythm.beat import Beat\r\nfrom MidiCompose.logic.rhythm.measure import Measure\r\nfrom MidiCompose.logic.rhythm.part import Part\r\n\r\n@pytest.fixture\r\ndef part_1():\r\n\r\n    m1 = Measure([Beat([1,2,1,2]),\r\n                  Beat([1,0,0,1])])\r\n    m2 = Measure([Beat([2,2,1,1]),\r\n                  Beat([2,2,2,2])])\r\n\r\n    part = Part([m1,m2])\r\n\r\n    return part\r\n\r\ndef test_empty_constructor():\r\n    p = Part()\r\n    assert p.n_measures == 1\r\n    assert p.n_beats == 1\r\n    assert p.n_note_on == 0\r\n\r\ndef test_n_note_on(part_1):\r\n\r\n    assert part_1.n_note_on == 6\r\n\r\n\r\ndef test_iterator(part_1):\r\n    for m in part_1:\r\n        assert type(m) == Measure\r\n\r\n\r\n\r\n"
  },
  {
    "prompt": "\n\n### my_blog/users/forms.py ###\n\nfrom django.contrib.auth import forms as admin_forms\nfrom django.contrib.auth import get_user_model\nfrom django.utils.translation import gettext_lazy as _\n\nUser = get_user_model()\n\n\nclass UserChangeForm(admin_forms.UserChangeForm):\n    class Meta(admin_forms.UserChangeForm.Meta):\n        model = User\n\n\nclass UserCreationForm(admin_forms.UserCreationForm):\n    class Meta(admin_forms.UserCreationForm.Meta):\n        model = User\n\n        error_messages = {\n            \"username\": {\"unique\": _(\"This username has already been taken.\")}\n        }\n\n\n### my_blog/users/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for My Blog.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom my_blog.users.forms import UserCreationForm\nfrom my_blog.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"
  },
  {
    "prompt": "\n\n### flare/dft_interface/vasp_util.py ###\n\nimport numpy as np\nimport os\nimport shutil\n\nfrom json import dump, load\nfrom subprocess import call\nfrom typing import List, Union\n\ntry:\n    from pymatgen.io.vasp.inputs import Poscar\n    from pymatgen.io.vasp.outputs import Vasprun\n    from pymatgen.io.vasp.sets import VaspInputSet\n    from pymatgen.core.periodic_table import Element\n\n    _pmg_present = True\nexcept:\n    _pmg_present = False\n\nfrom flare.struc import Structure\nfrom flare.utils.element_coder import NumpyEncoder\n\nname = \"VASP\"\n\n\ndef check_vasprun(vasprun, vasprun_kwargs: dict = {}):\n    \"\"\"\n    Helper utility to take a vasprun file name or Vasprun object\n    and return a vasprun object.\n    :param vasprun: Vasprun filename or object\n    \"\"\"\n\n    if type(vasprun) == str:\n        return Vasprun(vasprun, **vasprun_kwargs)\n    elif type(vasprun) == Vasprun:\n        return vasprun\n    else:\n        raise ValueError(\"Vasprun argument is not a string or Vasprun instance!\")\n\n\ndef parse_dft_input(input: str):\n    \"\"\"\n    Returns the positions, species, and cell of a POSCAR file.\n    Outputs are specced for OTF module.\n\n    :param input: POSCAR file input\n    :return:\n    \"\"\"\n\n    pmg_structure = Poscar.from_file(input).structure\n    flare_structure = Structure.from_pmg_structure(pmg_structure)\n\n    positions = flare_structure.positions\n    species = flare_structure.species_labels\n    cell = flare_structure.cell\n    # TODO Allow for custom masses in POSCAR\n\n    elements = set(species)\n\n    # conversion from amu to md units\n    mass_dict = {elt: Element(elt).atomic_mass * 0.000103642695727 for elt in elements}\n\n    return positions, species, cell, mass_dict\n\n\ndef run_dft(\n    calc_dir: str,\n    dft_loc: str,\n    structure: Structure = None,\n    en: bool = False,\n    vasp_cmd=\"{}\",\n):\n    \"\"\"\n    Run a VASP calculation.\n    :param calc_dir: Name of directory to perform calculation in\n    :param dft_loc: Name of VASP command (i.e. executable location)\n    :param structure: flare structure object\n    :param en: whether to return the final energy along with the forces\n    :param vasp_cmd: Command to run VASP (leave a formatter \"{}\" to insert dft_loc);\n        this can be used to specify mpirun, srun, etc.\n    Returns:\n        forces on each atom (and energy if en=True)\n    \"\"\"\n\n    currdir = os.getcwd()\n    if structure:\n        edit_dft_input_positions(\"POSCAR\", structure)\n    try:\n        if currdir != calc_dir:\n            os.chdir(calc_dir)\n        call(vasp_cmd.format(dft_loc).split())\n\n        if en:\n            parse_func = parse_dft_forces_and_energy\n        else:\n            parse_func = parse_dft_forces\n\n        try:\n            forces = parse_func(\"vasprun.xml\")\n        except FileNotFoundError:\n            os.chdir(currdir)\n            raise FileNotFoundError(\n                \"Could not load vasprun.xml.\"\n                \"The calculation may not have finished.\"\n                f\"Current directory is {os.getcwd()}\"\n            )\n\n        os.chdir(currdir)\n        return forces\n\n    except Exception as e:\n        os.chdir(currdir)\n        raise e\n\n\ndef run_dft_par(\n    dft_input: str,\n    structure: Structure,\n    dft_command: str = None,\n    n_cpus=1,\n    dft_out=\"vasprun.xml\",\n    parallel_prefix=\"mpi\",\n    mpi=None,\n    npool=None,\n    screen_out=\"vasp.out\",\n    **dft_kwargs,\n):\n    # TODO Incorporate Custodian.\n    edit_dft_input_positions(dft_input, structure)\n\n    if dft_command is None or not os.environ.get(\"VASP_COMMAND\"):\n        raise FileNotFoundError(\n            \"Warning: No VASP Command passed, or stored in \"\n            \"environment as VASP_COMMAND. \"\n        )\n\n    if n_cpus > 1:\n        # why is parallel prefix needed?\n        if (parallel_prefix == \"mpi\") and (mpi == \"mpi\"):\n            dft_command = f\"mpirun -np {n_cpus} {dft_command}\"\n        elif mpi == \"srun\":\n            dft_command = f\"srun -n {n_cpus} {dft_command}\"\n\n    else:\n        serial_prefix = dft_kwargs.get(\"serial_prefix\", \"\")\n        dft_command = f\"{serial_prefix} {dft_command}\"\n\n    with open(screen_out, \"w+\") as fout:\n        call(dft_command.split(), stdout=fout)\n\n    return parse_dft_forces(dft_out)\n\n\ndef dft_input_to_structure(poscar: str):\n    \"\"\"\n    Parse the DFT input in a directory.\n    :param vasp_input: directory of vasp input\n    \"\"\"\n    return Structure.from_pmg_structure(Poscar.from_file(poscar).structure)\n\n\ndef edit_dft_input_positions(output_name: str, structure: Structure):\n    \"\"\"\n    Writes a VASP POSCAR file from structure with the name poscar .\n    WARNING: Destructively replaces the file with the name specified by poscar\n    :param poscar: Name of file\n    :param structure: structure to write to file\n    \"\"\"\n    if os.path.isfile(output_name):\n        shutil.copyfile(output_name, output_name + \".bak\")\n    poscar = Poscar(structure.to_pmg_structure())\n    poscar.write_file(output_name)\n    return output_name\n\n\ndef parse_dft_forces(vasprun):\n    \"\"\"\n    Parses the DFT forces from the last ionic step of a VASP vasprun.xml file\n    :param vasprun: pymatgen Vasprun object or vasprun filename\n    \"\"\"\n    vasprun = check_vasprun(vasprun)\n    istep = vasprun.ionic_steps[-1]\n    return np.array(istep[\"forces\"])\n\n\ndef parse_dft_forces_and_energy(vasprun):\n    \"\"\"\n    Parses the DFT forces and energy from a VASP vasprun.xml file\n    :param vasprun: pymatgen Vasprun object or vasprun filename\n    \"\"\"\n    vasprun = check_vasprun(vasprun)\n    istep = vasprun.ionic_steps[-1]\n    return np.array(istep[\"forces\"]), istep[\"electronic_steps\"][-1][\"e_0_energy\"]\n\n\ndef md_trajectory_from_vasprun(vasprun, ionic_step_skips=1, vasprun_kwargs: dict = {}):\n    \"\"\"\n    Returns a list of flare Structure objects decorated with forces, stress,\n    and total energy from a MD trajectory performed in VASP.\n    :param vasprun: pymatgen Vasprun object or vasprun filename\n    :param ionic_step_skips: if True, only samples the configuration every\n        ionic_skip_steps steps.\n    \"\"\"\n    vasprun = check_vasprun(vasprun, vasprun_kwargs)\n\n    struc_lst = []\n    for step in vasprun.ionic_steps[::ionic_step_skips]:\n        structure = Structure.from_pmg_structure(step[\"structure\"])\n        structure.energy = step[\"electronic_steps\"][-1][\"e_0_energy\"]\n        # TODO should choose e_wo_entrp or e_fr_energy?\n        structure.forces = np.array(step.get(\"forces\"))\n        structure.stress = np.array(step.get(\"stress\"))\n        struc_lst.append(structure)\n\n    return struc_lst\n\n\n### flare/struc.py ###\n\n\"\"\"\nThe :class:`Structure` object is a collection of atoms in a periodic box.\nThe mandatory inputs are the cell vectors of the box and the chemical species\nand *Cartesian coordinates* of the atoms.\nThe atoms are automatically folded back into the primary cell, so the\ninput coordinates don't need to lie inside the box.\n\"\"\"\n\nfrom typing import List, Union, Any\nfrom json import dumps, loads\nfrom abc import abstractmethod\n\nimport pickle as pickle\nimport numpy as np\n\nfrom flare.utils.element_coder import element_to_Z, Z_to_element, NumpyEncoder\nfrom flare.utils.learner import get_max_cutoff\n\ntry:\n    # Used for to_pmg_structure method\n    import pymatgen.core.structure as pmgstruc\n    import pymatgen.io.vasp.inputs as pmgvaspio\n\n    _pmg_present = True\nexcept ImportError:\n    _pmg_present = False\n\n\nclass Structure:\n    \"\"\"\n    Contains information about a periodic structure of atoms, including the\n    periodic cell boundaries, atomic species, and coordinates.\n\n    *Note that input positions are assumed to be Cartesian.*\n\n    :param cell: 3x3 array whose rows are the Bravais lattice vectors of the\n        cell.\n    :type cell: np.ndarray\n    :param species: List of atomic species, which are represented either as\n        integers or chemical symbols.\n    :type species: List\n    :param positions: Nx3 array of atomic coordinates.\n    :type positions: np.ndarray\n    :param mass_dict: Dictionary of atomic masses used in MD simulations.\n    :type mass_dict: dict\n    :param prev_positions: Nx3 array of previous atomic coordinates used in\n        MD simulations.\n    :type prev_positions: np.ndarray\n    :param species_labels: List of chemical symbols. Used in the output file\n        of on-the-fly runs.\n    :type species_labels: List[str]\n    :param stds: Uncertainty associated with forces\n    :type stds: np.ndarray\n    \"\"\"\n\n    def __init__(\n        self,\n        cell: \"ndarray\",\n        species: Union[List[str], List[int]],\n        positions: \"ndarray\",\n        mass_dict: dict = None,\n        prev_positions: \"ndarray\" = None,\n        species_labels: List[str] = None,\n        forces=None,\n        stds=None,\n        energy: float = None,\n    ):\n\n        # Define cell (each row is a Bravais lattice vector).\n        self.cell = np.array(cell)\n\n        # Compute the max cutoff compatible with a 3x3x3 supercell of the\n        # structure.\n        self.max_cutoff = get_max_cutoff(self.cell)\n\n        # Set positions.\n        self.positions = np.array(positions)\n\n        # If species are strings, convert species to integers by atomic number\n        if species_labels is None:\n            self.species_labels = species\n        else:\n            self.species_labels = species_labels\n        self.coded_species = np.array([element_to_Z(spec) for spec in species])\n        self.nat = len(species)\n\n        # Default: atoms have no velocity\n        if prev_positions is None:\n            self.prev_positions = np.copy(self.positions)\n        else:\n            assert len(positions) == len(\n                prev_positions\n            ), \"Previous positions and positions are not same length\"\n            self.prev_positions = prev_positions\n\n        # Set forces, energies, and stresses and their uncertainties.\n        if forces is not None:\n            self.forces = np.array(forces)\n        else:\n            self.forces = np.zeros((len(positions), 3))\n\n        if stds is not None:\n            self.stds = np.array(stds)\n        else:\n            self.stds = np.zeros((len(positions), 3))\n\n        self.energy = energy\n\n        self.local_energies = None\n        self.local_energy_stds = None\n        self.partial_stresses = None\n        self.partial_stress_stds = None\n        self.stress = None\n        self.stress_stds = None\n\n        # Potential energy attribute needed to mirror ASE atoms object.\n        self.potential_energy = None\n\n        self.mass_dict = mass_dict\n\n        # Convert from elements to atomic numbers in mass dict\n        if mass_dict is not None:\n            keys = list(mass_dict.keys())\n            for elt in keys:\n                if isinstance(elt, str):\n                    mass_dict[element_to_Z(elt)] = mass_dict[elt]\n                    if elt.isnumeric():\n                        mass_dict[int(elt)] = mass_dict[elt]\n\n    @property\n    def positions(self):\n        return self._positions\n\n    @property\n    def wrapped_positions(self):\n        return self._wrapped_positions\n\n    @positions.setter\n    def positions(self, position_array):\n        self._positions = position_array\n        self._wrapped_positions = self.wrap_positions()\n\n    @property\n    def cell(self):\n        return self._cell\n\n    @property\n    def vec1(self):\n        return self._vec1\n\n    @property\n    def vec2(self):\n        return self._vec2\n\n    @property\n    def vec3(self):\n        return self._vec3\n\n    @property\n    def cell_transpose(self):\n        return self._cell_transpose\n\n    @property\n    def cell_transpose_inverse(self):\n        return self._cell_transpose_inverse\n\n    @property\n    def cell_dot(self):\n        return self._cell_dot\n\n    @property\n    def cell_dot_inverse(self):\n        return self._cell_dot_inverse\n\n    @cell.setter\n    def cell(self, cell_array):\n        \"\"\"Set the cell and related properties.\"\"\"\n        self._cell = cell_array\n        self._vec1 = cell_array[0, :]\n        self._vec2 = cell_array[1, :]\n        self._vec3 = cell_array[2, :]\n        self._cell_transpose = cell_array.transpose()\n        self._cell_transpose_inverse = np.linalg.inv(self._cell_transpose)\n        self._cell_dot = self.get_cell_dot(cell_array)\n        self._cell_dot_inverse = np.linalg.inv(self._cell_dot)\n\n    @staticmethod\n    def get_cell_dot(cell_array):\n        \"\"\"\n        Compute 3x3 array of dot products of cell vectors used to\n        fold atoms back to the unit cell.\n\n        :return: 3x3 array of cell vector dot products.\n        :rtype: np.ndarray\n        \"\"\"\n\n        cell_dot = np.zeros((3, 3))\n\n        for m in range(3):\n            for n in range(3):\n                cell_dot[m, n] = np.dot(cell_array[m], cell_array[n])\n\n        return cell_dot\n\n    @staticmethod\n    def raw_to_relative(\n        positions: \"ndarray\", cell_transpose: \"ndarray\", cell_dot_inverse: \"ndarray\"\n    ) -> \"ndarray\":\n        \"\"\"Convert Cartesian coordinates to relative (fractional) coordinates,\n        expressed in terms of the cell vectors set in self.cell.\n\n        :param positions: Cartesian coordinates.\n        :type positions: np.ndarray\n        :param cell_transpose: Transpose of the cell array.\n        :type cell_transpose: np.ndarray\n        :param cell_dot_inverse: Inverse of the array of dot products of\n            cell vectors.\n        :type cell_dot_inverse: np.ndarray\n        :return: Relative positions.\n        :rtype: np.ndarray\n        \"\"\"\n\n        relative_positions = np.matmul(\n            np.matmul(positions, cell_transpose), cell_dot_inverse\n        )\n\n        return relative_positions\n\n    @staticmethod\n    def relative_to_raw(\n        relative_positions: \"ndarray\",\n        cell_transpose_inverse: \"ndarray\",\n        cell_dot: \"ndarray\",\n    ) -> \"ndarray\":\n        \"\"\"Convert fractional coordinates to raw (Cartesian) coordinates.\n\n        :param relative_positions: fractional coordinates.\n        :type relative_positions: np.ndarray\n        :param cell_transpose_inverse: Transpose of the cell array.\n        :type cell_transpose_inverse: np.ndarray\n        :param cell_dot: Dot products of cell vectors\n        :type cell_dot: np.ndarray\n        :return: Cartesian positions.\n        :rtype: np.ndarray\n        \"\"\"\n\n        return np.matmul(\n            np.matmul(relative_positions, cell_dot), cell_transpose_inverse\n        )\n\n    def wrap_positions(self) -> \"ndarray\":\n        \"\"\"\n        Convenience function which folds atoms outside of the unit cell back\n        into the unit cell. in_place flag controls if the wrapped positions\n        are set in the class.\n\n        :return: Cartesian coordinates of positions all in unit cell\n        :rtype: np.ndarray\n        \"\"\"\n        rel_pos = self.raw_to_relative(\n            self.positions, self.cell_transpose, self.cell_dot_inverse\n        )\n\n        rel_wrap = rel_pos - np.floor(rel_pos)\n\n        pos_wrap = self.relative_to_raw(\n            rel_wrap, self.cell_transpose_inverse, self.cell_dot\n        )\n\n        return pos_wrap\n\n    def indices_of_specie(self, specie: Union[int, str]) -> List[int]:\n        \"\"\"\n        Return the indices of a given species within atoms of the structure.\n\n        :param specie: Element to target, can be string or integer\n        :return: The indices in the structure at which this element occurs\n        :rtype: List[str]\n        \"\"\"\n        return [i for i, spec in enumerate(self.coded_species) if spec == specie]\n\n    # TODO make more descriptive\n    def __str__(self) -> str:\n        \"\"\"\n        Simple descriptive string of structure.\n\n        :return: One-line descriptor of number of atoms and species present.\n        :rtype: str\n        \"\"\"\n\n        return \"Structure with {} atoms of types {}\".format(\n            self.nat, set(self.species_labels)\n        )\n\n    def __len__(self) -> int:\n        \"\"\"\n        Returns number of atoms in structure.\n\n        :return: number of atoms in structure.\n        :rtype: int\n        \"\"\"\n        return self.nat\n\n    def as_dict(self) -> dict:\n        \"\"\"\n        Returns structure as a dictionary; useful for serialization purposes.\n\n        :return: Dictionary version of current structure\n        :rtype: dict\n        \"\"\"\n        return dict(vars(self))\n\n    def as_str(self) -> str:\n        \"\"\"\n        Returns string dictionary serialization cast as string.\n\n        :return: output of as_dict method cast as string\n        :rtype: str\n        \"\"\"\n        return dumps(self.as_dict(), cls=NumpyEncoder)\n\n    @staticmethod\n    def from_dict(dictionary: dict) -> \"flare.struc.Structure\":\n        \"\"\"\n        Assembles a Structure object from a dictionary parameterizing one.\n\n        :param dictionary: dict describing structure parameters.\n        :return: FLARE structure assembled from dictionary\n        \"\"\"\n        struc = Structure(\n            cell=np.array(dictionary.get(\"_cell\", dictionary.get(\"cell\"))),\n            species=dictionary[\"coded_species\"],\n            positions=np.array(\n                dictionary.get(\"_positions\", dictionary.get(\"positions\"))\n            ),\n            mass_dict=dictionary.get(\"mass_dict\"),\n            prev_positions=dictionary.get(\"prev_positions\", None),\n            species_labels=dictionary.get(\"species_labels\"),\n            forces=np.array(dictionary.get(\"forces\")),\n            stds=np.array(dictionary.get(\"stds\")),\n            energy=dictionary.get(\"energy\", None),\n        )\n\n        struc.stress = dictionary.get(\"stress\", None)\n\n        return struc\n\n    @staticmethod\n    def from_ase_atoms(atoms: \"ase.Atoms\", cell=None) -> \"flare.struc.Structure\":\n        \"\"\"\n        From an ASE Atoms object, return a FLARE structure\n\n        :param atoms: ASE Atoms object\n        :type atoms: ASE Atoms object\n        :return: A FLARE structure from an ASE atoms object\n        \"\"\"\n\n        if cell is None:\n            cell = np.array(atoms.cell)\n\n        try:\n            forces = atoms.get_forces()\n        except:\n            forces = None\n\n        try:\n            stds = atoms.get_uncertainties()\n        except:\n            stds = None\n\n        try:\n            energy = atoms.get_potential_energy()\n        except:\n            energy = None\n\n        try:\n            stress = atoms.get_stress()  # TODO: what stress order should we use?\n        except:\n            stress = None\n\n        struc = Structure(\n            cell=cell,\n            positions=atoms.positions,\n            species=atoms.get_chemical_symbols(),\n            forces=forces,\n            stds=stds,\n            energy=energy,\n        )\n        struc.stress = stress\n        return struc\n\n    def to_ase_atoms(self) -> \"ase.Atoms\":\n        from ase import Atoms\n        from ase.calculators.singlepoint import SinglePointCalculator\n\n        atoms = Atoms(\n            self.species_labels, positions=self.positions, cell=self.cell, pbc=True\n        )\n\n        results = {}\n        properties = [\"forces\", \"energy\", \"stress\"]\n        for p in properties:\n            results[p] = getattr(self, p)\n        atoms.calc = SinglePointCalculator(atoms, **results)\n\n        return atoms\n\n    def to_pmg_structure(self):\n        \"\"\"\n        Returns FLARE structure as a pymatgen structure.\n\n        :return: Pymatgen structure corresponding to current FLARE structure\n        \"\"\"\n\n        if not _pmg_present:\n            raise ModuleNotFoundError(\n                \"Pymatgen is not present. Please install Pymatgen and try again\"\n            )\n\n        if self.forces is None:\n            forces_temp = np.zeros((len(self.positions), 3))\n            site_properties = {\"force:\": forces_temp, \"std\": self.stds}\n        else:\n            site_properties = {\"force:\": self.forces, \"std\": self.stds}\n\n        return pmgstruc.Structure(\n            lattice=self.cell,\n            species=self.species_labels,\n            coords=self.positions,\n            coords_are_cartesian=True,\n            site_properties=site_properties,\n        )\n\n    @staticmethod\n    def from_pmg_structure(structure: \"pymatgen Structure\") -> \"flare Structure\":\n        \"\"\"\n        Returns Pymatgen structure as FLARE structure.\n\n        :param structure: Pymatgen Structure\n        :type structure: Pymatgen Structure\n        :return: FLARE Structure\n        \"\"\"\n\n        cell = structure.lattice.matrix.copy()\n        species = [str(spec) for spec in structure.species]\n        positions = structure.cart_coords.copy()\n\n        new_struc = Structure(cell=cell, species=species, positions=positions)\n\n        site_props = structure.site_properties\n\n        if \"force\" in site_props.keys():\n            forces = site_props[\"force\"]\n            new_struc.forces = [np.array(force) for force in forces]\n\n        if \"std\" in site_props.keys():\n            stds = site_props[\"std\"]\n            new_struc.stds = [np.array(std) for std in stds]\n\n        return new_struc\n\n    def is_valid(self, tolerance: float = 0.5) -> bool:\n        \"\"\"\n        Plugin to pymatgen's is_valid method to gauge if a structure\n        has atoms packed too closely together, which is likely\n        to cause unphysically large forces / energies or present convergence\n        issues in DFT.\n        :return:\n        \"\"\"\n        pmg_structure = self.to_pmg_structure()\n        return pmg_structure.is_valid(tol=tolerance)\n\n    def to_xyz(\n        self,\n        extended_xyz: bool = True,\n        print_stds: bool = False,\n        print_forces: bool = False,\n        print_max_stds: bool = False,\n        print_energies: bool = False,\n        predict_energy=None,\n        dft_forces=None,\n        dft_energy=None,\n        target_atoms=None,\n        timestep=-1,\n        write_file: str = \"\",\n        append: bool = False,\n    ) -> str:\n        \"\"\"\n        Convenience function which turns a structure into an extended .xyz\n        file; useful for further input into visualization programs like VESTA\n        or Ovito. Can be saved to an output file via write_file.\n\n        :param print_stds: Print the stds associated with the structure.\n        :param print_forces:\n        :param extended_xyz:\n        :param print_max_stds:\n        :param write_file:\n        :return:\n        \"\"\"\n        species_list = [Z_to_element(x) for x in self.coded_species]\n        xyz_str = \"\"\n        xyz_str += f\"{len(self.coded_species)} \\n\"\n\n        # Add header line with info about lattice and properties if extended\n        #  xyz option is called.\n        if extended_xyz:\n            cell = self.cell\n\n            xyz_str += f'Lattice=\"{cell[0,0]} {cell[0,1]} {cell[0,2]}'\n            xyz_str += f\" {cell[1,0]} {cell[1,1]} {cell[1,2]}\"\n            xyz_str += f' {cell[2,0]} {cell[2,1]} {cell[2,2]}\"'\n            if timestep > 0:\n                xyz_str += f\" Timestep={timestep}\"\n            if predict_energy:\n                xyz_str += f\" PE={predict_energy}\"\n            if dft_energy is not None:\n                xyz_str += f\" DFT_PE={dft_energy}\"\n            if target_atoms is not None:\n                indices = \" \".join([str(t) for t in target_atoms])\n                xyz_str += f' target_atoms=\"{indices}\"'\n            xyz_str += f' Proprties=\"species:S:1:pos:R:3'\n\n            if print_stds:\n                xyz_str += \":stds:R:3\"\n                stds = self.stds\n            if print_forces:\n                xyz_str += \":forces:R:3\"\n                forces = self.forces\n            if print_max_stds:\n                xyz_str += \":max_std:R:1\"\n                stds = self.stds\n            if print_energies:\n                if self.local_energies is None:\n                    print_energies = False\n                else:\n                    xyz_str += \":local_energy:R:1\"\n                    local_energies = self.local_energies\n            if dft_forces is not None:\n                xyz_str += \":dft_forces:R:3\"\n            xyz_str += \"\\n\"\n        else:\n            xyz_str += \"\\n\"\n\n        for i, pos in enumerate(self.positions):\n            # Write positions\n            xyz_str += f\"{species_list[i]} {pos[0]} {pos[1]} {pos[2]}\"\n\n            # If extended XYZ: Add in extra information\n            if print_stds and extended_xyz:\n                xyz_str += f\" {stds[i,0]} {stds[i,1]} {stds[i,2]}\"\n            if print_forces and extended_xyz:\n                xyz_str += f\" {forces[i,0]} {forces[i,1]} {forces[i,2]}\"\n            if print_energies and extended_xyz:\n                xyz_str += f\" {local_energies[i]}\"\n            if print_max_stds and extended_xyz:\n                xyz_str += f\" {np.max(stds[i,:])} \"\n            if dft_forces is not None:\n                xyz_str += f\" {dft_forces[i, 0]} {dft_forces[i,1]} {dft_forces[i, 2]}\"\n            if i < (len(self.positions) - 1):\n                xyz_str += \"\\n\"\n\n        # Write to file, optionally\n        if write_file:\n            if append:\n                fmt = \"a\"\n            else:\n                fmt = \"w\"\n            with open(write_file, fmt) as f:\n                f.write(xyz_str)\n                f.write(\"\\n\")\n\n        return xyz_str\n\n    @staticmethod\n    def from_file(\n        file_name: str, format: str = \"\", as_trajectory: bool = False\n    ) -> Union[\"flare.struc.Structure\", List[\"flare.struc.Structure\"]]:\n        \"\"\"\n        Load a FLARE structure from a file or a series of FLARE structures\n        :param file_name:\n        :param format:\n        :return:\n        \"\"\"\n\n        # Ensure the file specified exists.\n        with open(file_name, \"r\") as _:\n            pass\n\n        if \"pickle\" in file_name or (\n            \"pickle\" in format.lower() or \"binary\" in format.lower()\n        ):\n            with open(file_name, \"rb\") as f:\n                return pickle.load(f)\n\n        if \"xyz\" in file_name or \"xyz\" in format.lower():\n            raise NotImplementedError\n\n        if \"json\" in format.lower() or \".json\" in file_name:\n            # Assumed format is one FLARE structure per line,\n            # or one line with many FLARE structures\n            with open(file_name, \"r\") as f:\n                thelines = f.readlines()\n\n                non_empty_lines = [loads(line) for line in thelines if len(line) > 2]\n\n            structures = [\n                Structure.from_dict(struc_dict) for struc_dict in non_empty_lines\n            ]\n\n            if len(structures) == 1:\n                return structures[0]\n            else:\n                return structures\n\n        is_poscar = (\n            \"POSCAR\" in file_name or \"CONTCAR\" in file_name or \"vasp\" in format.lower()\n        )\n        if is_poscar and _pmg_present:\n            pmg_structure = pmgvaspio.Poscar.from_file(file_name).structure\n            return Structure.from_pmg_structure(pmg_structure)\n        elif is_poscar and not _pmg_present:\n            raise ImportError(\"Pymatgen not imported; functionality requires pymatgen.\")\n\n    def __eq__(self, other):\n        \"\"\"\n        Very crude equality measure that will check to see if positions,\n        cell, and species are identical. Will not detect e.g. symmetry\n        equivalence, translation, if one structure is a supercell of another,\n        etc. Requires that species are in the same order.\n        :param other:\n        :return:\n        \"\"\"\n        if not isinstance(other, Structure):\n            return False\n\n        if len(other) != len(self):\n            return False\n        if not all(other.coded_species == self.coded_species):\n            return False\n        if not np.allclose(other.positions, self.positions):\n            return False\n        if not np.allclose(other.cell, self.cell):\n            return False\n\n        return True\n\n\nclass StructureSource(object):\n    def __init__(self):\n        pass\n\n    @abstractmethod\n    def get_next_structure(self) -> Structure:\n        raise NotImplementedError\n\n    def write_file(self):\n        raise NotImplementedError\n\n\nclass ForceSource(object):\n    def __init__(self):\n        pass\n\n    @abstractmethod\n    def get_next_force(self, *args, **kwargs) -> \"np.ndarray\":\n        raise NotImplementedError\n\n    def pre_force(self, *args, **kwargs):\n        raise NotImplementedError\n\n\nclass Trajectory(StructureSource, ForceSource):\n    def __init__(\n        self, frames: List[Structure] = None, iterate_strategy: Union[int, str] = 1\n    ):\n        if frames is None:\n            frames = []\n        self.frames = frames\n        self.cur_idx = 0\n        self.iterate_strategy = iterate_strategy\n        self.seen_before = []\n\n        if self.iterate_strategy == \"shuffle\":\n            self.frames = np.random.shuffle(frames)\n        if isinstance(iterate_strategy, int):\n            self.frames = frames[::iterate_strategy]\n\n    def get_next_structure(self) -> Union[Structure, None]:\n\n        if self.cur_idx == len(self):\n            self.cur_idx = 0\n            return None\n\n        cur_frame = self.frames[self.cur_idx]\n        self.cur_idx += 1\n        return cur_frame\n\n    @property\n    def cur_frame(self):\n        return self.frames[self.cur_idx]\n\n    @property\n    def cur_forces(self):\n        return self.frames[self.cur_idx].forces\n\n    def get_next_force(self, index: int = -1) -> \"np.ndarray\":\n        \"\"\"\n        Return the forces associated with a current structure,\n        and if an index is passed, that atom.\n        :param index:\n        :return:\n        \"\"\"\n        if index != 1:\n            return self.cur_frame.forces[index]\n        return self.cur_frame.forces\n\n    def __getitem__(self, item):\n        return self.frames[item]\n\n    def __len__(self):\n        return len(self.frames)\n\n    def __next__(self):\n        struc = self.get_next_structure()\n        if struc is None:\n            raise StopIteration()\n        return struc\n\n    def __iter__(self):\n        self.cur_idx = 0\n        return self\n\n    def append(self, frame: Structure):\n        self.frames.append(frame)\n\n\ndef get_unique_species(species: List[Any]) -> (List, List[int]):\n    \"\"\"\n    Returns a list of the unique species passed in, and a list of\n    integers indexing them.\n\n    :param species: Species to index uniquely\n    :return: List of the unique species, and integer indexes\n    \"\"\"\n    unique_species = []\n    coded_species = []\n    for spec in species:\n        if spec in unique_species:\n            coded_species.append(unique_species.index(spec))\n        else:\n            coded_species.append(len(unique_species))\n            unique_species.append(spec)\n    coded_species = np.array(coded_species)\n\n    return unique_species, coded_species\n\n\n### flare/utils/flare_io.py ###\n\nfrom flare.struc import Structure\nfrom typing import List\nfrom json import dump, load\nfrom flare.utils.element_coder import NumpyEncoder\n\n\ndef md_trajectory_to_file(filename: str, structures: List[Structure]):\n    \"\"\"\n    Take a list of structures and write them to a json file.\n    :param filename:\n    :param structures:\n    \"\"\"\n    with open(filename, \"w\") as f:\n        dump([s.as_dict() for s in structures], f, cls=NumpyEncoder)\n\n\ndef md_trajectory_from_file(filename: str):\n    \"\"\"\n    Read a list of structures from a json file, formatted as in md_trajectory_to_file.\n    :param filename:\n    \"\"\"\n    with open(filename, \"r\") as f:\n        structure_list = load(f)\n        structures = [Structure.from_dict(dictionary) for dictionary in structure_list]\n    return structures\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\npmgout = pytest.importorskip(\"pymatgen.io.vasp.outputs\")\nVasprun = pmgout.Vasprun\nimport os\nimport numpy as np\nfrom flare.struc import Structure, get_unique_species\nfrom flare.dft_interface.vasp_util import md_trajectory_from_vasprun\nfrom flare.utils.flare_io import md_trajectory_to_file, md_trajectory_from_file\n\npytestmark = pytest.mark.filterwarnings(\n    \"ignore::UserWarning\", \"ignore::pymatgen.io.vasp.outputs.UnconvergedVASPWarning\"\n)\n\n\ndef test_read_write_trajectory():\n    structures = md_trajectory_from_vasprun(\"test_files/test_vasprun.xml\")\n    fname = \"tst_traj.json\"\n    md_trajectory_to_file(fname, structures)\n    fstructures = md_trajectory_from_file(fname)\n    for s, f in zip(structures, fstructures):\n        assert np.isclose(s.forces, f.forces).all()\n        assert np.isclose(s.positions, f.positions).all()\n    os.system(\"rm tst_traj.json\")\n"
  },
  {
    "prompt": "\n\n### server/tests/integration/conftest.py ###\n\nimport json\nfrom pathlib import Path\nimport time\nfrom typing import Any, Dict, List\n\nfrom girder_client import GirderClient\nfrom girder_worker.utils import JobStatus\nimport pytest\n\nlocalDataRoot = Path('tests/integration/data')\n\n\"\"\"\nAlice and Bobby have different types of data (images and video)\nMost tests run operations on a single dataset for each user, so keeping\neach user constrained to a single data type will help ensure robustness\n\"\"\"\nusers = {\n    'alice': {\n        'login': 'alice',\n        'email': 'alice@locahost.lan',\n        'firstName': 'Alice',\n        'lastName': 'User',\n        'password': 'alicespassword',\n        'data': [\n            {\n                'name': 'video1_train_mp4',\n                'path': 'TestData/video1_train_mp4',\n                'fps': 30,  # Should get reduced.\n                'originalFps': 30_000 / 1001,\n                'type': 'video',\n                'trackCount': 102,\n                'pipeline': {\n                    \"name\": \"fish\",\n                    \"pipe\": \"tracker_fish.pipe\",\n                    \"type\": \"tracker\",\n                },\n            },\n            {\n                'name': 'video2_train_mp4',\n                'path': 'TestData/video2_train_mp4',\n                'fps': 5.8,\n                'originalFps': 30_000 / 1001,\n                'type': 'video',\n                'trackCount': 102,\n            },\n            {\n                'name': 'annotation_testTrain1_imagelist',\n                'path': 'TestData/testTrain1_imagelist',\n                'fps': 1,\n                'type': 'image-sequence',\n                'trackCount': 2,\n                'sharedWith': 'bobby',\n            },\n        ],\n    },\n    'bobby': {\n        'login': 'bobby',\n        'email': 'bobby@locahost.lan',\n        'firstName': 'Bob',\n        'lastName': 'User',\n        'password': 'bobspass',\n        'data': [\n            {\n                'name': 'testTrain1_imagelist',\n                'path': 'TestData/testTrain1_imagelist',\n                'fps': 1,\n                'type': 'image-sequence',\n                'trackCount': 2,\n                'pipeline': {\n                    \"name\": \"add segmentations watershed\",\n                    \"pipe\": \"utility_add_segmentations_watershed.pipe\",\n                    \"type\": \"utility\",\n                    'resultTracks': 28,\n                },\n            },\n            {\n                'name': 'testTrain2_imagelist',\n                'path': 'TestData/testTrain2_imagelist',\n                'fps': 6,\n                'type': 'image-sequence',\n                'trackCount': 1,\n                'pipeline': {\n                    \"name\": \"empty frame lbls 1fr\",\n                    \"pipe\": \"utility_empty_frame_lbls_1fr.pipe\",\n                    \"type\": \"utility\",\n                    'resultTracks': 14,\n                },\n            },\n            {\n                'name': 'multiConfidence_text',\n                'path': 'TestData/multiConfidence_test',\n                'fps': 22.1,\n                'type': 'image-sequence',\n                'trackCount': 4,\n                'pipeline': {\n                    \"name\": \"motion\",\n                    \"pipe\": \"detector_motion.pipe\",\n                    \"type\": \"detector\",\n                },\n            },\n        ],\n    },\n    'kwcoco': {\n        'login': 'kwcoco',\n        'email': 'kwcoco@locahost.lan',\n        'firstName': 'KW',\n        'lastName': 'COCO',\n        'password': 'kwcocopass',\n        'data': [\n            {\n                'name': 'scallops',\n                'path': 'kwcoco/scallops',\n                'fps': 1,\n                'type': 'image-sequence',\n                'trackCount': 197,\n            },\n            {\n                'name': 'kwpolys',\n                'path': 'kwcoco/polygons',\n                'fps': 1,\n                'type': 'image-sequence',\n                'trackCount': 14,\n            },\n            {\n                'name': 'kwvideo',\n                'path': 'kwcoco/video',\n                'fps': 29.969,\n                'originalFps': 29969 / 1000,\n                'type': 'video',\n                'trackCount': 6,\n            },\n        ],\n    },\n    'testCharacters': {\n        'login': 'testCharacters',\n        'email': 'testCharacters@locahost.lan',\n        'firstName': 't\ud83e\udd22\u00f8\u4e09\u597d\u0414\u0638',\n        'lastName': 't\ud83e\udd22\u00f8\u4e09\u597d\u0414\u0638',\n        'password': 'testCharactersPassword',\n        'data': [\n            {\n                'name': 't\ud83e\udd22\u00f8\u4e09\u597d\u0414\u0638',\n                'path': 'TestData/testTrain1_imagelist',\n                'fps': 1,\n                'type': 'image-sequence',\n                'trackCount': 2,\n                'pipeline': {\n                    \"name\": \"add segmentations watershed\",\n                    \"pipe\": \"utility_add_segmentations_watershed.pipe\",\n                    \"type\": \"utility\",\n                    'resultTracks': 28,\n                },\n            }\n        ],\n    },\n}\n\nzipUser = {\n    'login': 'zipUser',\n    'email': 'zipUser@locahost.lan',\n    'firstName': 'zip',\n    'lastName': 'User',\n    'password': 'zipUserPass',\n    'data': [\n        {\n            'name': 'testImageZip',\n            'path': 'zipTestFiles/testImageZip.zip',\n            'fps': 1,\n            'type': 'image-sequence',\n            'trackCount': 197,\n            'job_status': JobStatus.SUCCESS,\n        },\n        {\n            'name': 'testVideoZip',\n            'path': 'zipTestFiles/testVideoZip.zip',\n            'fps': 29.97002997002997,\n            'originalFps': 30000 / 1001,\n            'type': 'video',\n            'job_status': JobStatus.SUCCESS,\n        },\n        {\n            'name': 'SingleDatasetImport',\n            'path': 'zipTestFiles/SingleDatasetImport.zip',\n            'fps': 29.97002997002997,\n            'originalFps': 30000 / 1001,\n            'type': 'video',\n            'job_status': JobStatus.SUCCESS,\n        },\n        {\n            'name': 'flatMultiImport',\n            'path': 'zipTestFiles/flatMultiImport.zip',\n            'fps': -1,\n            'type': 'zip',\n            'subDatasets': [\n                {\n                    'name': 'testVideoZip',\n                    'type': 'video',\n                    'fps': 29.97002997002997,\n                },\n                {\n                    'name': 'testImageZip',\n                    'type': 'image-sequence',\n                    'fps': 1,\n                },\n            ],\n            'job_status': JobStatus.SUCCESS,\n        },\n        {\n            'name': 'MultiDatasetImport',\n            'path': 'zipTestFiles/MultiDatasetImport.zip',\n            'fps': -1,\n            'type': 'zip',\n            'subDatasets': [\n                {\n                    'name': 'video1_train_mp4',\n                    'type': 'video',\n                    'fps': 29.97002997002997,\n                },\n                {\n                    'name': 'testtrain1_imagelist',\n                    'type': 'image-sequence',\n                    'fps': 1,\n                },\n            ],\n            'job_status': JobStatus.SUCCESS,\n        },\n        {\n            'name': 'badFormatZip',\n            'path': 'zipTestFiles/badFormatZip.zip',\n            'fps': 1,\n            'type': 'image-sequence',\n            'job_status': JobStatus.ERROR,\n        },\n        {\n            'name': 'nestedZip',\n            'path': 'zipTestFiles/nestedZip.zip',\n            'fps': 1,\n            'type': 'image-sequence',\n            'job_status': JobStatus.ERROR,\n        },\n        {\n            'name': 'zipBomb',\n            'path': 'zipTestFiles/zipBomb.zip',\n            'fps': 1,\n            'type': 'image-sequence',\n            'job_status': JobStatus.ERROR,\n        },\n    ],\n}\n\n\ndef getClient(name: str) -> GirderClient:\n    gc = GirderClient(apiUrl='http://localhost:8010/api/v1')\n    gc.authenticate(username=name, password=users[name]['password'])\n    return gc\n\n\ndef getTestFolder(client: GirderClient):\n    me = client.get('user/me')\n    privateFolder = client.loadOrCreateFolder(\"Integration\", me['_id'], 'user')\n    return privateFolder\n\n\n@pytest.fixture(scope=\"module\")\ndef admin_client() -> GirderClient:\n    gc = GirderClient(apiUrl='http://localhost:8010/api/v1')\n    gc.authenticate(username='admin', password='letmein')\n    return gc\n\n\ndef wait_for_jobs(client: GirderClient, max_wait_timeout=30, expected_status=JobStatus.SUCCESS):\n    \"\"\"Wait for all worker jobs to complete\"\"\"\n    start_time = time.time()\n    incompleteJobs = []\n    while True and (time.time() - start_time < max_wait_timeout):\n        incompleteJobs = client.get(\n            'job',\n            parameters={\n                # https://github.com/girder/girder/blob/master/plugins/jobs/girder_jobs/constants.py\n                # https://github.com/girder/girder_worker/blob/master/girder_worker/girder_plugin/status.py\n                'statuses': json.dumps([0, 1, 2, 820, 821, 822, 823, 824]),\n            },\n        )\n        if len(incompleteJobs) == 0:\n            break\n        time.sleep(1)\n    if len(incompleteJobs) > 0:\n        raise Exception(\"Jobs were still running after timeout\")\n    # Verify that all jobs succeeded\n    time.sleep(1)\n    lastJob = client.get(\n        'job',\n        parameters={\n            'limit': 1,\n        },\n    )\n    if len(lastJob) > 0 and lastJob[0]['status'] != expected_status:\n        raise Exception(f\"Some jobs did not meet their expected status: {expected_status}\")\n\n\ndef match_user_server_data(user: Dict[str, Any], dataset) -> List[dict]:\n    return [item for item in user['data'] if item['name'] == dataset['name']]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import json\n\nfrom girder.constants import AccessType\nfrom girder_client import HttpError\nimport pytest\n\nfrom .conftest import getClient, getTestFolder, localDataRoot, users, wait_for_jobs\n\n\n@pytest.mark.integration\n@pytest.mark.parametrize(\"user\", users.values())\n@pytest.mark.run(order=3)\ndef test_reset_integration_env(user: dict):\n    client = getClient(user['login'])\n    privateFolder = getTestFolder(client)\n    client.delete(f\"folder/{privateFolder['_id']}\")\n\n\n@pytest.mark.integration\n@pytest.mark.parametrize(\"user\", users.values())\n@pytest.mark.run(order=4)\ndef test_upload_user_data(user: dict):\n    client = getClient(user['login'])\n    createdDatasets = []\n    for dataset in user['data']:\n        dsPath = localDataRoot / str(dataset['path'])\n        privateFolder = getTestFolder(client)\n        newDatasetFolder = client.createFolder(\n            privateFolder['_id'],\n            dataset['name'],\n            metadata={\n                'fps': dataset['fps'],\n                'type': dataset['type'],\n            },\n        )\n        createdDatasets.append(newDatasetFolder)\n        # Validate the fileset\n        filenames = [file.name for file in dsPath.iterdir()]\n        valid = client.post('dive_dataset/validate_files', json=filenames)\n        assert valid['ok'], 'File validation failed'\n        for file in dsPath.iterdir():\n            if file.is_file():\n                client.uploadFileToFolder(newDatasetFolder['_id'], str(file))\n        client.post(f'dive_rpc/postprocess/{newDatasetFolder[\"_id\"]}')\n        if dataset.get('sharedWith', False):\n            me = client.get('user/me')\n            otherClient = getClient(dataset['sharedWith'])\n            otherUser = otherClient.get('user/me')\n            with pytest.raises(HttpError):\n                otherClient.get(f'dive_dataset/{newDatasetFolder[\"_id\"]}')\n            client.put(\n                f'folder/{newDatasetFolder[\"_id\"]}/access',\n                data={\n                    'public': False,\n                    'recurse': False,\n                    'progress': False,\n                    'access': json.dumps(\n                        {\n                            'users': [\n                                {'id': me['_id'], 'level': AccessType.ADMIN, 'flags': []},\n                                {'id': otherUser['_id'], 'level': AccessType.READ, 'flags': []},\n                            ],\n                            'groups': [],\n                        }\n                    ),\n                },\n            )\n            assert (\n                otherClient.get(\n                    f'dive_dataset/{newDatasetFolder[\"_id\"]}', jsonResp=False\n                ).status_code\n                == 200\n            )\n\n    wait_for_jobs(client)\n    # Confirm that the new dataset looks like it should.\n    for created, expected in zip(createdDatasets, user['data']):\n        created = client.get(f'dive_dataset/{created[\"_id\"]}')\n        if expected['type'] == 'video':\n            assert created['fps'] == expected['originalFps'] or created['fps'] == expected['fps']\n            assert created['annotate']\n            assert created['originalFps'] == expected['originalFps']\n"
  },
  {
    "prompt": "\n\n### icepyx/core/visualization.py ###\n\n\"\"\"\nInteractive visualization of spatial extent and ICESat-2 elevations\n\"\"\"\nimport concurrent.futures\nimport datetime\nimport re\n\nimport backoff\nimport dask.array as da\nimport dask.dataframe as dd\nimport datashader as ds\nimport holoviews as hv\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom holoviews.operation.datashader import rasterize\nfrom tqdm import tqdm\n\nimport icepyx as ipx\nimport icepyx.core.is2ref as is2ref\nimport icepyx.core.granules as granules\n\nhv.extension(\"bokeh\")\n\n\ndef files_in_latest_n_cycles(files, cycles, n=1) -> list:\n    \"\"\"\n    Get list of file names from latest n ICESat-2 cycles\n\n    Parameters\n    ----------\n    files : list\n        A list of file names.\n    cycles: list\n        A list of available ICESat-2 cycles\n    n: int, default 1\n        Number of latest ICESat-2 cycles to pick\n\n    Returns\n    -------\n    viz_file_list : list\n        A list of file names from latest n ICESat-2 cycles\n    \"\"\"\n    if n == 1:\n        latest_cycle = max(cycles)\n        viz_file_list = [\n            f for f in files if int(f.rsplit(\"_\")[-3][4:6]) == latest_cycle\n        ]\n        return viz_file_list\n\n    elif n > 1:\n        if len(cycles) >= n:\n            viz_cycle_list = [max(cycles) - i for i in np.arange(n)]\n        else:\n            viz_cycle_list = cycles\n        viz_file_list = [\n            f for f in files if int(f.rsplit(\"_\")[-3][4:6]) in viz_cycle_list\n        ]\n        return viz_file_list\n\n    else:\n        raise Exception(\"Wrong n value\")\n\n\ndef gran_paras(filename) -> list:\n    \"\"\"\n    Returns a list of granule information for file name string.\n\n    Parameters\n    ----------\n    filename: String\n        ICESat-2 file name\n\n    Returns\n    -------\n    gran_paras_list : list\n        A list of parameters including RGT, cycle, and datetime of ICESat-2 data granule\n    \"\"\"\n\n    trk, cycl, date_str = granules.gran_IDs(\n        [{\"producer_granule_id\": filename}],\n        ids=False,\n        cycles=True,\n        tracks=True,\n        dates=True,\n    )[:]\n    gran_paras_list = [int(cycl[0]), int(trk[0]), date_str[0]]\n\n    return gran_paras_list\n\n\ndef user_check(message):\n    \"\"\"\n    Check if user wants to proceed visualization when the API request number exceeds 200\n\n    Parameters\n    ----------\n    message : string\n        Message to indicate users the options\n    \"\"\"\n    check = input(message)\n    if str(check) == \"yes\" or str(check) == \"no\":\n        return str(check)\n    else:\n        user_check(\"Wrong input, please enter yes or no\")\n\n\nclass Visualize:\n    \"\"\"\n    Object class to quickly visualize elevation data for select ICESat-2 products\n    (ATL06, ATL07, ATL08, ATL10, ATL12, ATL13) based on the query parameters\n    defined by the icepyx Query object. Provides interactive maps that show product\n    elevation on a satellite basemap.\n\n    Parameters\n    ----------\n    query_obj : ipx.Query object, default None\n        icepy Query class object.\n    product : string\n        ICESat-2 product ID; equivalent to the Query object dataset\n    spatial_extent: list or string, default None\n        as in the ipx.Query object\n    date_range : list of 'YYYY-MM-DD' strings, default None\n        as in the ipx.Query object\n    cycle : string, default all available orbital cycles, default None\n        as in the ipx.Query object\n    track : string, default all available reference ground tracks (RGTs), default None\n        as in the ipx.Query object\n\n    See Also\n    --------\n    ipx.Query\n    \"\"\"\n\n    def __init__(\n        self,\n        query_obj=None,\n        product=None,\n        spatial_extent=None,\n        date_range=None,\n        cycles=None,\n        tracks=None,\n    ):\n\n        if query_obj:\n            pass\n        else:\n            query_obj = ipx.Query(\n                dataset=product,\n                spatial_extent=spatial_extent,\n                date_range=date_range,\n                cycles=cycles,\n                tracks=tracks,\n            )\n\n        self.product = is2ref._validate_OA_product(query_obj.dataset)\n\n        if query_obj.extent_type == \"bounding_box\":\n            self.bbox = query_obj._spat_extent\n\n        else:\n            mrc_bound = query_obj._spat_extent.minimum_rotated_rectangle\n            # generate bounding box\n            lonmin = min(mrc_bound.exterior.coords.xy[0])\n            lonmax = max(mrc_bound.exterior.coords.xy[0])\n            latmin = min(mrc_bound.exterior.coords.xy[1])\n            latmax = max(mrc_bound.exterior.coords.xy[1])\n\n            self.bbox = [lonmin, latmin, lonmax, latmax]\n\n        self.date_range = (\n            [query_obj._start.strftime(\"%Y-%m-%d\"), query_obj._end.strftime(\"%Y-%m-%d\")]\n            if hasattr(query_obj, \"_start\")\n            else None\n        )\n        self.cycles = query_obj._cycles if hasattr(query_obj, \"_cycles\") else None\n        self.tracks = query_obj._tracks if hasattr(query_obj, \"_tracks\") else None\n\n    def grid_bbox(self, binsize=5) -> list:\n        \"\"\"\n        Split bounding box into 5 x 5 grids when latitude/longitude range\n        exceeds the default OpenAltimetry 5*5 degree spatial limits\n\n        Returns\n        -------\n        bbox_list : list\n            A list of bounding boxes with a maximum size of 5*5 degree\n        \"\"\"\n        lonmin, latmin, lonmax, latmax = self.bbox\n        split_flag = ((lonmax - lonmin) > 5) or ((latmax - latmin) > 5)\n\n        if split_flag:\n            # split bounding box into a list of 5*5 bbox\n            lonx = np.arange(lonmin, lonmax + binsize, binsize)\n            laty = np.arange(latmin, latmax + binsize, binsize)\n            lonxv, latyv = np.meshgrid(lonx, laty)\n\n            ydim, xdim = lonxv.shape\n\n            bbox_list = []\n            for i in np.arange(0, ydim - 1):\n                for j in np.arange(0, xdim - 1):\n                    # iterate grid for bounding box\n                    bbox_ij = [\n                        lonxv[i, j],\n                        latyv[i, j],\n                        lonxv[i + 1, j + 1],\n                        latyv[i + 1, j + 1],\n                    ]\n\n                    if bbox_ij[2] > lonmax:\n                        bbox_ij[2] = lonmax\n\n                    if bbox_ij[3] > latmax:\n                        bbox_ij[3] = latmax\n\n                    bbox_list.append(bbox_ij)\n\n            return bbox_list\n\n        else:\n            return [self.bbox]\n\n    def query_icesat2_filelist(self) -> tuple:\n        \"\"\"\n        Query list of ICESat-2 files for each bounding box\n\n        Returns\n        -------\n        filelist_tuple : tuple\n            A tuple of non-empty lists of bounding boxes and corresponding ICESat-2 file lists\n        \"\"\"\n        # a list of 5*5 bounding boxes\n        bbox_list = self.grid_bbox()\n\n        is2_bbox_list = []\n        is2_file_list = []\n\n        for bbox_i in bbox_list:\n\n            region = ipx.Query(\n                self.product,\n                bbox_i,\n                self.date_range,\n                cycles=self.cycles,\n                tracks=self.tracks,\n            )\n            icesat2_files = region.avail_granules(ids=True)[0]\n\n            if not icesat2_files:\n                continue\n            else:\n                all_cycles = list(set(region.avail_granules(cycles=True)[0]))\n                icesat2_files_latest_cycle = files_in_latest_n_cycles(\n                    icesat2_files, [int(c) for c in all_cycles]\n                )\n                is2_bbox_list.append(bbox_i)\n                is2_file_list.append(icesat2_files_latest_cycle)\n\n        is2_file_tuple = zip(is2_bbox_list, is2_file_list)\n\n        return is2_file_tuple\n\n    def generate_OA_parameters(self) -> list:\n        \"\"\"\n        Get metadata from file lists in each 5*5 bounding box.\n\n        Returns\n        -------\n        paras_list : list\n            A list of parameters for OpenAltimetry API query, including the\n            reference ground track (RGT), cycle number, datetime, bounding box,\n            and product name.\n        \"\"\"\n        # list of parameters for API query\n        paras_list = []\n\n        # tuple of non-empty bbox and ICESat-2 datafiles\n        filelist_tuple = self.query_icesat2_filelist()\n\n        for bbox_i, filelist in filelist_tuple:\n            for fname in filelist:\n                rgt, cycle, f_date = gran_paras(fname)\n                paras = [rgt, f_date, cycle, bbox_i, self.product]\n                paras_list.append(paras)\n\n        return paras_list\n\n    @backoff.on_exception(\n        backoff.expo,\n        (\n            requests.exceptions.Timeout,\n            requests.exceptions.ConnectionError,\n            requests.exceptions.ChunkedEncodingError,\n        ),\n        max_tries=5,\n    )\n    def make_request(self, base_url, payload):\n        \"\"\"\n        Make HTTP request\n\n        Parameters\n        ----------\n        base_url : string\n            OpenAltimetry URL\n\n        See Also\n        --------\n        request_OA_data\n        \"\"\"\n        return requests.get(base_url, params=payload)\n\n    def request_OA_data(self, paras) -> da.array:\n        \"\"\"\n        Request data from OpenAltimetry based on API:\n        https://openaltimetry.org/data/swagger-ui/#/\n\n        Parameters\n        ----------\n        paras : list\n            A single parameter list for an OpenAltimetry API data request.\n\n        Returns\n        -------\n        OA_darr : da.array\n            A dask array containing the ICESat-2 elevation data.\n        \"\"\"\n\n        base_url = \"https://openaltimetry.org/data/api/icesat2/level3a\"\n        trackId, Date, cycle, bbox, product = paras\n\n        # Generate API\n        payload = {\n            \"product\": product.lower(),\n            \"endDate\": Date,\n            \"minx\": str(bbox[0]),\n            \"miny\": str(bbox[1]),\n            \"maxx\": str(bbox[2]),\n            \"maxy\": str(bbox[3]),\n            \"trackId\": trackId,\n            \"outputFormat\": \"json\",\n        }  # default return all six beams\n\n        # request OpenAltimetry\n        r = self.make_request(base_url, payload)\n\n        # get elevation data\n        elevation_data = r.json()\n\n        df = pd.json_normalize(data=elevation_data, record_path=[\"data\"])\n\n        # get data we need (with the correct date)\n        try:\n\n            df_series = df.query(expr=\"date == @Date\").iloc[0]\n            beam_data = df_series.beams\n\n        except (NameError, KeyError, IndexError) as error:\n            beam_data = None\n\n        if not beam_data:\n            return\n\n        data_name = \"lat_lon_elev_canopy\" if product == \"ATL08\" else \"lat_lon_elev\"\n\n        sample_rate = 50 if product == \"ATL06\" else 20\n\n        # iterate six beams\n        beam_elev = [\n            beam_data[i][data_name][::sample_rate]\n            for i in range(6)\n            if beam_data[i][data_name]\n        ]\n\n        if not beam_elev:\n            return\n\n        # elevation for all available beams\n        OA_array = np.vstack(beam_elev)\n\n        if OA_array.shape[0] > 0:\n            OA_array = np.c_[\n                OA_array,\n                np.full(np.size(OA_array, 0), trackId),\n                np.full(np.size(OA_array, 0), cycle),\n            ]\n            OA_darr = da.from_array(OA_array, chunks=1000)\n\n            return OA_darr\n\n    def parallel_request_OA(self) -> da.array:\n        \"\"\"\n        Requests elevation data from OpenAltimetry API in parallel.\n        Currently supports OA_Products ['ATL06','ATL07','ATL08','ATL10','ATL12','ATL13']\n\n        For ATL03 Photon Data, OA only supports single date request\n        according to: https://openaltimetry.org/data/swagger-ui/#/Public/getATL08DataByDate,\n        with geospatial limitation of 1 degree lat/lon. Visualization of ATL03 data\n        is not implemented within this module at this time.\n\n        Returns\n        -------\n        OA_data_da : dask.Array\n            A dask array containing the ICESat-2 data.\n        \"\"\"\n        print(\"Generating urls\")\n\n        # generate parameter lists for OA requesting\n        OA_para_list = self.generate_OA_parameters()\n\n        url_number = len(OA_para_list)\n\n        if url_number > 200:\n            answer = user_check(\n                \"Too many API requests, this may take a long time, do you still want to continue: \"\n                \"please enter yes/no\\n\"\n            )\n\n            if answer == \"yes\":\n                pass\n            else:\n                return\n\n        print(\"Sending request to OpenAltimetry, please wait...\")\n\n        # Parallel processing\n        requested_OA_data = []\n\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=len(OA_para_list)\n        ) as executor:\n            parallel_OA_data = {\n                executor.submit(self.request_OA_data, para): para\n                for para in OA_para_list\n            }\n\n            for future in tqdm(\n                iterable=concurrent.futures.as_completed(parallel_OA_data),\n                total=len(parallel_OA_data),\n            ):\n                r = future.result()\n                if r is not None:\n                    requested_OA_data.append(r)\n\n        if not requested_OA_data:\n            return\n        else:\n            OA_data_da = da.concatenate(requested_OA_data, axis=0)\n            return OA_data_da\n\n    def viz_elevation(self) -> (hv.DynamicMap, hv.Layout):\n        \"\"\"\n        Visualize elevation requested from OpenAltimetry API using datashader based on cycles\n        https://holoviz.org/tutorial/Large_Data.html\n\n        Returns\n        -------\n        map_cycle, map_rgt + lineplot_rgt : Holoviews objects\n            Holoviews data visualization elements\n        \"\"\"\n\n        OA_da = self.parallel_request_OA()\n\n        if OA_da is None:\n            print(\"No data\")\n            return (None,) * 2\n\n        else:\n\n            cols = (\n                [\"lat\", \"lon\", \"elevation\", \"canopy\", \"rgt\", \"cycle\"]\n                if self.product == \"ATL08\"\n                else [\"lat\", \"lon\", \"elevation\", \"rgt\", \"cycle\"]\n            )\n            ddf = dd.io.from_dask_array(OA_da, columns=cols).astype(\n                {\n                    \"lat\": \"float\",\n                    \"lon\": \"float\",\n                    \"elevation\": \"float\",\n                    \"rgt\": \"int\",\n                    \"cycle\": \"int\",\n                }\n            )\n\n            print(\"Plot elevation, please wait...\")\n\n            x, y = ds.utils.lnglat_to_meters(ddf.lon, ddf.lat)\n            ddf_new = ddf.assign(x=x, y=y).persist()\n            dset = hv.Dataset(ddf_new)\n\n            raster_cycle = dset.to(\n                hv.Points, [\"x\", \"y\"], [\"elevation\"], groupby=[\"cycle\"], dynamic=True,\n            )\n            raster_rgt = dset.to(\n                hv.Points, [\"x\", \"y\"], [\"elevation\"], groupby=[\"rgt\"], dynamic=True\n            )\n            curve_rgt = dset.to(\n                hv.Scatter, [\"lat\"], [\"elevation\"], groupby=[\"rgt\"], dynamic=True\n            )\n\n            tiles = hv.element.tiles.EsriImagery().opts(\n                xaxis=None, yaxis=None, width=450, height=450\n            )\n            map_cycle = tiles * rasterize(\n                raster_cycle, aggregator=ds.mean(\"elevation\")\n            ).opts(colorbar=True, tools=[\"hover\"])\n            map_rgt = tiles * rasterize(\n                raster_rgt, aggregator=ds.mean(\"elevation\")\n            ).opts(colorbar=True, tools=[\"hover\"])\n            lineplot_rgt = rasterize(curve_rgt, aggregator=ds.mean(\"elevation\")).opts(\n                width=450, height=450, cmap=[\"blue\"]\n            )\n\n            return map_cycle, map_rgt + lineplot_rgt\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom icepyx.core.visualization import Visualize\nimport icepyx.core.visualization as vis\n\n\n@pytest.mark.parametrize(\n    \"n, exp\",\n    [\n        (\n            1,\n            [\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n        (\n            2,\n            [\n                \"ATL06_20200612151119_11920712_004_01.h5\",\n                \"ATL06_20200616021517_12450710_004_01.h5\",\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n        (\n            3,\n            [\n                \"ATL06_20200612151119_11920712_004_01.h5\",\n                \"ATL06_20200616021517_12450710_004_01.h5\",\n                \"ATL06_20200702014158_01020810_004_01.h5\",\n                \"ATL06_20200703011618_01170810_004_01.h5\",\n            ],\n        ),\n    ],\n)\ndef test_files_in_latest_cycles(n, exp):\n    files = [\n        \"ATL06_20190710071617_01860412_004_01.h5\",\n        \"ATL06_20190713182016_02390410_004_01.h5\",\n        \"ATL06_20200612151119_11920712_004_01.h5\",\n        \"ATL06_20200616021517_12450710_004_01.h5\",\n        \"ATL06_20200702014158_01020810_004_01.h5\",\n        \"ATL06_20200703011618_01170810_004_01.h5\",\n    ]\n    cycles = [8, 7, 4]\n    obs = vis.files_in_latest_n_cycles(files, cycles=cycles, n=n)\n    assert obs == exp\n\n\n@pytest.mark.parametrize(\n    \"filename, expect\",\n    [\n        ('ATL06_20190525202604_08790310_004_01.h5', [879, 3, '2019-05-25']),\n        ('ATL06_20190614194425_11840310_004_01.h5', [1184, 3, '2019-06-14']),\n        ('ATL07-02_20190624063616_13290301_004_01.h5', [1329, 3, '2019-06-24']),\n        ('ATL07-02_20190602190916_10010301_004_01.h5', [1001, 3, '2019-06-02']),\n        ('ATL10-02_20190611072656_11310301_004_01.h5', [1131, 3, '2019-06-11']),\n        ('ATL10-02_20190731045538_05060401_004_01.h5', [506, 4, '2019-07-31']),\n        ('ATL12_20190615023544_11890301_004_01.h5', [1189, 3, '2019-06-15']),\n        ('ATL12_20190721170332_03610401_004_01.h5', [361, 4, '2019-07-21']),\n    ],\n)\ndef test_gran_paras(filename, expect):\n\n    para_list = vis.gran_paras(filename)\n\n    assert para_list == expect\n\n\n@pytest.mark.parametrize(\n    \"product, date_range, bbox, expect\",\n    [\n        (\"ATL06\", [\"2019-6-15\", \"2019-7-1\"], [-64.5, -66, -63.5, -65], 3240),\n        (\"ATL07\", [\"2019-7-1\", \"2019-8-1\"], [-65, -66, -64.5, -65], 7160),\n        (\"ATL08\", [\"2019-6-15\", \"2019-7-1\"], [-18, 63, -17, 64], 852),\n        (\"ATL10\", [\"2019-8-1\", \"2019-9-1\"], [-64, -67, -60, -60], 7375),\n        (\"ATL12\", [\"2019-7-1\", \"2019-10-1\"], [-65.5, -65.5, -64.5, -65], 95),\n        (\"ATL13\", [\"2019-6-1\", \"2019-12-1\"], [-75, -51, -74, -50], 20),\n    ],\n)\ndef test_visualization_date_range(product, date_range, bbox, expect):\n\n    region_viz = Visualize(product=product, spatial_extent=bbox, date_range=date_range)\n    data_size = region_viz.parallel_request_OA().size\n\n    assert data_size == expect\n\n\n@pytest.mark.parametrize(\n    \"product, bbox, cycles, tracks, expect\",\n    [\n        (\"ATL06\", [-64.5, -66, -63.5, -65], [\"03\"], [\"1306\"], 3240),\n        (\"ATL07\", [-65, -66, -64.5, -65], [\"04\"], [\"0186\"], 7130),\n        (\"ATL08\", [-18, 63, -17, 64], [\"03\"], [\"1320\"], 852),\n        (\"ATL10\", [-64, -67, -60, -60], [\"04\"], [\"0681\"], 6015),\n        (\"ATL12\", [-65.5, -65.5, -64.5, -65], [\"05\"], [\"0041\"], 95),\n        (\"ATL13\", [-75, -51, -74, -50], [\"05\"], [\"0293\"], 20),\n    ],\n)\ndef test_visualization_orbits(product, bbox, cycles, tracks, expect):\n\n    region_viz = Visualize(\n        product=product, spatial_extent=bbox, cycles=cycles, tracks=tracks\n    )\n    data_size = region_viz.parallel_request_OA().size\n\n    assert data_size == expect\n"
  },
  {
    "prompt": "\n\n### migri/backends/postgresql.py ###\n\nimport re\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Optional\n\nimport asyncpg\n\nfrom migri.elements import Query\nfrom migri.interfaces import ConnectionBackend, TransactionBackend\n\n\n@dataclass\nclass PostgreSQLConnection(ConnectionBackend):\n    _dialect = \"postgresql\"\n    connection: Optional[asyncpg.Connection] = None\n\n    @staticmethod\n    def _compile(query: Query) -> dict:\n        q = query.statement\n        v = []\n\n        if query.placeholders:\n            keys = list(query.values.keys())\n            v = [query.values[k] for k in keys]\n\n            for p in set(query.placeholders):\n                # Find index of key and add 1\n                replacement = f\"${keys.index(p.replace('$', '')) + 1}\"\n\n                # Substitute\n                q = re.sub(f\"\\\\{p}\", replacement, q)\n\n        return {\"query\": q, \"values\": v}\n\n    async def connect(self):\n        if not self.db:\n            if self.connection is not None:\n                self.db = self.connection\n            else:\n                self.db = await asyncpg.connect(\n                    host=self.db_host,\n                    port=self.db_port,\n                    user=self.db_user,\n                    password=self.db_pass,\n                    database=self.db_name,\n                )\n\n    async def disconnect(self):\n        if self.connection is None:\n            # don't close the connection if we didn't create it\n            await self.db.close()\n\n    async def execute(self, query: Query):\n        q = self._compile(query)\n        await self.db.execute(q[\"query\"], *q[\"values\"])\n\n    async def fetch(self, query: Query) -> Dict[str, Any]:\n        q = self._compile(query)\n        res = await self.db.fetchrow(q[\"query\"], *q[\"values\"])\n        return dict(res)\n\n    async def fetch_all(self, query: Query) -> List[Dict[str, Any]]:\n        q = self._compile(query)\n        res = await self.db.fetch(q[\"query\"], *q[\"values\"])\n\n        return [dict(r) for r in res]\n\n    def transaction(self) -> TransactionBackend:\n        return PostgreSQLTransaction(self)\n\n\nclass PostgreSQLTransaction(TransactionBackend):\n    def __init__(self, connection: ConnectionBackend):\n        super().__init__(connection)\n        self._committed = False\n        self._transaction = None\n\n    async def start(self):\n        self._transaction = self._connection.database.transaction()\n        await self._transaction.start()\n\n    async def commit(self):\n        await self._transaction.commit()\n        self._committed = True\n\n    async def rollback(self):\n        if not self._committed:\n            await self._transaction.rollback()\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom migri.backends.postgresql import PostgreSQLConnection\nfrom test import QUERIES\n\n\n@pytest.mark.parametrize(\n    \"query_element,expected_query,expected_values\",\n    [\n        (QUERIES[0], \"INSERT INTO mytable (a) VALUES ($1), ($2)\", [150, 300]),\n        (QUERIES[1], \"UPDATE tbl SET info=$2 WHERE id=$1\", [39, \"ok\"]),\n        (QUERIES[2], \"SELECT * FROM school\", []),\n        (\n            QUERIES[3],\n            \"SELECT * FROM val WHERE (value < $1 AND status = $3) \"\n            \"OR (value > $2 AND status = $3)\",\n            [20, 100, \"ok\"],\n        ),\n    ],\n)\ndef test_compile(query_element, expected_query, expected_values):\n    backend = PostgreSQLConnection(\"postgres\")\n    assert backend._compile(query_element) == {\n        \"query\": expected_query,\n        \"values\": expected_values,\n    }\n"
  },
  {
    "prompt": "\n\n### pytest_selenium_enhancer/pytest_selenium_enhancer.py ###\n\n# pylint: disable=function-redefined\n# pylint: disable=import-outside-toplevel\n# pylint: disable=no-member\n# pylint: disable=too-many-statements\n# pylint: disable=unused-variable\n\nimport base64\nfrom io import BytesIO\nimport cv2\nimport numpy\nfrom PIL import Image\nfrom selenium.common.exceptions import WebDriverException\n\n\ndef add_custom_commands():\n    from selenium.webdriver.remote.webdriver import WebDriver\n    from selenium.webdriver.remote.webelement import WebElement\n\n    @add_method(WebDriver)\n    def get_full_page_screenshot_as_base64(self, elements_to_hide=None, ios_offset=0):\n        \"\"\"Gets full page screenshot of current page by automatically scroll the full width and height of the page\n                NOTE:\n                    - Does not work for infinite scrolling pages\n\n            Returns:\n            PIL.Image.Image: returns the image as Image object\n\n        \"\"\"\n        stitched_image = __take_full_page_screenshot(self, elements_to_hide, ios_offset)\n        return cv2.cvtColor(numpy.array(stitched_image), cv2.COLOR_RGB2BGR)\n\n    @add_method(WebDriver)\n    def get_full_page_screenshot_as_png(self, image_path, elements_to_hide=None, ios_offset=0):\n        \"\"\"Gets full page screenshot of current page by automatically scroll the full width and height of the page\n                NOTE:\n                    - Does not work for infinite scrolling pages\n\n            Returns:\n            PIL.Image.Image: returns the image as Image object\n\n        \"\"\"\n        stitched_image = __take_full_page_screenshot(self, elements_to_hide, ios_offset)\n        from os import makedirs\n        makedirs(image_path[:image_path.rfind('/')], exist_ok=True)\n        stitched_image.save(image_path)\n        return cv2.imread(image_path)\n\n    @add_method(WebDriver)\n    def shadow_find_element(self, css_selector):\n        \"\"\"Returns an element by given CSS selector\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        return self.execute_script('return document.shadowRoot.querySelector(arguments[0])', css_selector)\n\n    @add_method(WebDriver)\n    def shadow_cascade_find_element(self, *args):\n        \"\"\"Returns an element by given list of CSS selectors\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        script = 'return document'\n        for arg in args:\n            script += '.querySelector(\"%s\").shadowRoot' % arg\n        script = script[:-11] + ';'\n        return self.execute_script(script)\n\n    @add_method(WebDriver)\n    def shadow_find_elements(self, css_selector):\n        \"\"\"Returns a list of elements by given of CSS selector\n\n            Returns:\n            list<WebElement>: returns the element as WebElement\n        \"\"\"\n        return self.execute_script('return document.shadowRoot.querySelectorAll(arguments[0])', css_selector)\n\n    @add_method(WebElement)\n    def shadow_find_element(self, css_selector):\n        \"\"\"Returns an element by given CSS selector\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        return self.parent.execute_script('return arguments[0].shadowRoot.querySelector(arguments[1])', self,\n                                          css_selector)\n\n    @add_method(WebElement)\n    def shadow_cascade_find_element(self, *args):\n        \"\"\"Returns an element by given list of CSS selectors\n\n            Returns:\n            WebElement: returns the element as WebElement\n        \"\"\"\n        script = 'return arguments[0].shadowRoot'\n        for arg in args:\n            script += '.querySelector(\"%s\").shadowRoot' % arg\n        script = script[:-11] + ';'\n        return self.parent.execute_script(script, self)\n\n    @add_method(WebElement)\n    def shadow_find_elements(self, css_selector):\n        \"\"\"Returns a list of elements by given of CSS selector\n\n            Returns:\n            list<WebElement>: returns the element as WebElement\n        \"\"\"\n        return self.parent.execute_script('return arguments[0].shadowRoot.querySelectorAll(arguments[1])', self,\n                                          css_selector)\n\n    def __take_full_page_screenshot(selenium, elements_to_hide, ios_offset=0):\n        if elements_to_hide is None:\n            elements_to_hide = {\"start\": [], \"all\": [], \"end\": []}\n        device_pixel_ratio = selenium.execute_script('return ratio = window.devicePixelRatio || 1;')\n        total_width = round(\n            selenium.execute_script(\"return document.body.scrollWidth * arguments[0];\", device_pixel_ratio))\n        total_height = round(\n            selenium.execute_script(\"return document.body.scrollHeight * arguments[0];\", device_pixel_ratio))\n        viewport_width = round(\n            selenium.execute_script(\"return document.body.parentNode.clientWidth * arguments[0];\", device_pixel_ratio))\n        viewport_height = round(\n            selenium.execute_script(\"return document.body.parentNode.clientHeight * arguments[0];\", device_pixel_ratio))\n\n        rectangles = []\n        i = 0\n        while i < total_height:\n            ii = 0\n            top_height = i + viewport_height\n            if top_height > total_height:\n                top_height = total_height\n            while ii < total_width:\n                top_width = ii + viewport_width\n                if top_width > total_width:\n                    top_width = total_width\n                rectangles.append((ii, i, top_width, top_height))\n                ii = ii + viewport_width\n            i = i + viewport_height - ios_offset\n        stitched_image = Image.new('RGB', (total_width, total_height))\n        previous = None\n        i = 1\n\n        __hide_elements(selenium, elements_to_hide['all'])\n        for rectangle in rectangles:\n            if i == 1 != rectangles.__len__():\n                __hide_elements(selenium, elements_to_hide['end'])\n            if rectangle[1] != 0:\n                __hide_elements(selenium, elements_to_hide['start'])\n            if i == rectangles.__len__():\n                __show_elements(selenium, elements_to_hide['end'])\n            if previous is not None:\n                selenium.execute_script(\"window.scrollTo({0}, {1})\".format(round(rectangle[0] / device_pixel_ratio),\n                                                                           round(rectangle[1] / device_pixel_ratio)))\n                import time\n                time.sleep(3)\n            offset = (rectangle[0], rectangle[1])\n\n            image_base_64 = selenium.get_screenshot_as_base64()\n            screenshot = Image.open(BytesIO(base64.b64decode(image_base_64)))\n            screenshot = screenshot.crop((0, ios_offset, screenshot.size[0], screenshot.size[1]))\n            if viewport_width < total_width < rectangle[0] + viewport_width \\\n                    and viewport_height < total_height < rectangle[1] + viewport_height:\n                offset = (total_width - viewport_width, total_height - viewport_height)\n            elif viewport_width < total_width < rectangle[0] + viewport_width:\n                offset = (total_width - viewport_width, rectangle[1])\n            elif viewport_height < total_height < rectangle[1] + viewport_height:\n                offset = (rectangle[0], total_height - viewport_height)\n            # screenshot.save('/Users/spopescu/PersonalDev/pytest-selenium-enhancer/tests/screenshots/actual/a.png')\n            # stitched_image.save('/Users/spopescu/PersonalDev/pytest-selenium-enhancer/tests/screenshots/actual/b.png')\n            stitched_image.paste(screenshot, offset)\n            del screenshot\n            previous = rectangle\n            i += 1\n\n        return stitched_image\n\n    def __show_elements(selenium, elements):\n        \"\"\"\n        Usage:\n            Hide elements from web page\n        Args:\n            selenium(str) : WebDriver / Appium instance\n            elements (list) : The element on web page to be hide\n        Returns:\n            N/A\n        Raises:\n            N/A\n        \"\"\"\n        if elements is not None:\n            try:\n                for element in elements:\n                    selenium.execute_script(\"arguments[0].setAttribute('style', 'opacity:1;');\", element)\n            except WebDriverException as error:\n                print('Error : ', str(error))\n\n    def __hide_elements(selenium, elements):\n        \"\"\"\n        Usage:\n            Hide elements from web page\n        Args:\n            selenium(str) : WebDriver / Appium instance\n            elements (list) : The element on web page to be hide\n        Returns:\n            N/A\n        Raises:\n            N/A\n        \"\"\"\n        if elements is not None:\n            try:\n                for element in elements:\n                    selenium.execute_script(\"arguments[0].setAttribute('style', 'opacity:0;');\", element)\n            except WebDriverException as error:\n                print('Error : ', str(error))\n\n\ndef add_method(cls):\n    def decorator(func):\n        from functools import wraps\n\n        @wraps(func)\n        def wrapper(self, *args, **kwargs):\n            return func(self, *args, **kwargs)\n\n        setattr(cls, func.__name__, wrapper)\n        # Note we are not binding func, but wrapper which accepts self but does exactly the same as func\n        return func  # returning func means func can still be used normally\n\n    return decorator\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"Pytest plugin entry point. Used for any fixtures needed.\"\"\"\nimport pytest\nfrom .pytest_selenium_enhancer import add_custom_commands\n\n\n@pytest.fixture(scope='session')\ndef selenium_patcher():\n    \"\"\"Add custom .\"\"\"\n    add_custom_commands()\n"
  },
  {
    "prompt": "\n\n### tests/integration/utils.py ###\n\n\"\"\"Integration test utils.\"\"\"\n\nfrom solana.rpc.types import RPCResponse\n\nAIRDROP_AMOUNT = 10_000_000_000\n\n\ndef assert_valid_response(resp: RPCResponse):\n    \"\"\"Assert valid RPCResponse.\"\"\"\n    assert resp[\"jsonrpc\"] == \"2.0\"\n    assert resp[\"id\"]\n    assert resp[\"result\"]\n\n\ndef compare_responses_without_ids(left: RPCResponse, right: RPCResponse) -> None:\n    \"\"\"Compare RPC responses but ignore IDs.\"\"\"\n    assert {key: val for key, val in left.items() if key != \"id\"} == {\n        key: val for key, val in right.items() if key != \"id\"\n    }\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"Tests for the HTTP API Client.\"\"\"\nimport pytest\n\nimport solana.system_program as sp\nfrom solana.rpc.api import DataSliceOpt, Client\nfrom solana.keypair import Keypair\nfrom solana.rpc.core import RPCException\nfrom solana.rpc.types import RPCError\nfrom solana.transaction import Transaction\nfrom solana.rpc.commitment import Finalized\nfrom spl.token.constants import WRAPPED_SOL_MINT\n\nfrom .utils import AIRDROP_AMOUNT, assert_valid_response\n\n\n@pytest.mark.integration\ndef test_request_air_drop(stubbed_sender: Keypair, test_http_client: Client):\n    \"\"\"Test air drop to stubbed_sender.\"\"\"\n    resp = test_http_client.request_airdrop(stubbed_sender.public_key, AIRDROP_AMOUNT)\n    assert_valid_response(resp)\n    test_http_client.confirm_transaction(resp[\"result\"])\n    balance = test_http_client.get_balance(stubbed_sender.public_key)\n    assert balance[\"result\"][\"value\"] == AIRDROP_AMOUNT\n\n\n@pytest.mark.integration\ndef test_request_air_drop_prefetched_blockhash(stubbed_sender_prefetched_blockhash, test_http_client):\n    \"\"\"Test air drop to stubbed_sender.\"\"\"\n    resp = test_http_client.request_airdrop(stubbed_sender_prefetched_blockhash.public_key, AIRDROP_AMOUNT)\n    assert_valid_response(resp)\n    test_http_client.confirm_transaction(resp[\"result\"])\n    balance = test_http_client.get_balance(stubbed_sender_prefetched_blockhash.public_key)\n    assert balance[\"result\"][\"value\"] == AIRDROP_AMOUNT\n\n\n@pytest.mark.integration\ndef test_request_air_drop_cached_blockhash(stubbed_sender_cached_blockhash, test_http_client):\n    \"\"\"Test air drop to stubbed_sender.\"\"\"\n    resp = test_http_client.request_airdrop(stubbed_sender_cached_blockhash.public_key, AIRDROP_AMOUNT)\n    assert_valid_response(resp)\n    test_http_client.confirm_transaction(resp[\"result\"])\n    assert_valid_response(resp)\n    balance = test_http_client.get_balance(stubbed_sender_cached_blockhash.public_key)\n    assert balance[\"result\"][\"value\"] == AIRDROP_AMOUNT\n\n\n@pytest.mark.integration\ndef test_send_invalid_transaction(test_http_client):\n    \"\"\"Test sending an invalid transaction to localnet.\"\"\"\n    # Create transfer tx to transfer lamports from stubbed sender to stubbed_receiver\n    with pytest.raises(RPCException) as exc_info:\n        test_http_client.send_raw_transaction(b\"foo\")\n    assert exc_info.value.args[0].keys() == RPCError.__annotations__.keys()  # pylint: disable=no-member\n\n\n@pytest.mark.integration\ndef test_send_transaction_and_get_balance(stubbed_sender, stubbed_receiver, test_http_client):\n    \"\"\"Test sending a transaction to localnet.\"\"\"\n    # Create transfer tx to transfer lamports from stubbed sender to stubbed_receiver\n    transfer_tx = Transaction().add(\n        sp.transfer(sp.TransferParams(from_pubkey=stubbed_sender.public_key, to_pubkey=stubbed_receiver, lamports=1000))\n    )\n    resp = test_http_client.send_transaction(transfer_tx, stubbed_sender)\n    assert_valid_response(resp)\n    # Confirm transaction\n    test_http_client.confirm_transaction(resp[\"result\"])\n    # Check balances\n    resp = test_http_client.get_balance(stubbed_sender.public_key)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 9999994000\n    resp = test_http_client.get_balance(stubbed_receiver)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 954\n\n\n@pytest.mark.integration\ndef test_send_transaction_prefetched_blockhash(\n    stubbed_sender_prefetched_blockhash, stubbed_receiver_prefetched_blockhash, test_http_client\n):\n    \"\"\"Test sending a transaction to localnet.\"\"\"\n    # Create transfer tx to transfer lamports from stubbed sender to stubbed_receiver\n    transfer_tx = Transaction().add(\n        sp.transfer(\n            sp.TransferParams(\n                from_pubkey=stubbed_sender_prefetched_blockhash.public_key,\n                to_pubkey=stubbed_receiver_prefetched_blockhash,\n                lamports=1000,\n            )\n        )\n    )\n    recent_blockhash = test_http_client.parse_recent_blockhash(test_http_client.get_recent_blockhash(Finalized))\n    resp = test_http_client.send_transaction(\n        transfer_tx, stubbed_sender_prefetched_blockhash, recent_blockhash=recent_blockhash\n    )\n    assert_valid_response(resp)\n    # Confirm transaction\n    test_http_client.confirm_transaction(resp[\"result\"])\n    # Check balances\n    resp = test_http_client.get_balance(stubbed_sender_prefetched_blockhash.public_key)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 9999994000\n    resp = test_http_client.get_balance(stubbed_receiver_prefetched_blockhash)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 954\n\n\n@pytest.mark.integration\ndef test_send_transaction_cached_blockhash(\n    stubbed_sender_cached_blockhash, stubbed_receiver_cached_blockhash, test_http_client_cached_blockhash\n):\n    \"\"\"Test sending a transaction to localnet.\"\"\"\n    # Create transfer tx to transfer lamports from stubbed sender to stubbed_receiver\n    transfer_tx = Transaction().add(\n        sp.transfer(\n            sp.TransferParams(\n                from_pubkey=stubbed_sender_cached_blockhash.public_key,\n                to_pubkey=stubbed_receiver_cached_blockhash,\n                lamports=1000,\n            )\n        )\n    )\n    assert len(test_http_client_cached_blockhash.blockhash_cache.unused_blockhashes) == 0\n    assert len(test_http_client_cached_blockhash.blockhash_cache.used_blockhashes) == 0\n    resp = test_http_client_cached_blockhash.send_transaction(transfer_tx, stubbed_sender_cached_blockhash)\n    # we could have got a new blockhash or not depending on network latency and luck\n    assert len(test_http_client_cached_blockhash.blockhash_cache.unused_blockhashes) in (0, 1)\n    assert len(test_http_client_cached_blockhash.blockhash_cache.used_blockhashes) == 1\n    assert_valid_response(resp)\n    # Confirm transaction\n    test_http_client_cached_blockhash.confirm_transaction(resp[\"result\"])\n    # Check balances\n    resp = test_http_client_cached_blockhash.get_balance(stubbed_sender_cached_blockhash.public_key)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 9999994000\n\n    # Second transaction\n    transfer_tx = Transaction().add(\n        sp.transfer(\n            sp.TransferParams(\n                from_pubkey=stubbed_sender_cached_blockhash.public_key,\n                to_pubkey=stubbed_receiver_cached_blockhash,\n                lamports=2000,\n            )\n        )\n    )\n    resp = test_http_client_cached_blockhash.get_balance(stubbed_receiver_cached_blockhash)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 954\n    resp = test_http_client_cached_blockhash.send_transaction(transfer_tx, stubbed_sender_cached_blockhash)\n    # we could have got a new blockhash or not depending on network latency and luck\n    assert len(test_http_client_cached_blockhash.blockhash_cache.unused_blockhashes) in (0, 1)\n    assert len(test_http_client_cached_blockhash.blockhash_cache.used_blockhashes) in (1, 2)\n    assert_valid_response(resp)\n    # Confirm transaction\n    test_http_client_cached_blockhash.confirm_transaction(resp[\"result\"])\n    # Check balances\n    resp = test_http_client_cached_blockhash.get_balance(stubbed_sender_cached_blockhash.public_key)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 9999987000\n    assert len(test_http_client_cached_blockhash.blockhash_cache.unused_blockhashes) == 1\n    assert len(test_http_client_cached_blockhash.blockhash_cache.used_blockhashes) == 1\n\n\n@pytest.mark.integration\ndef test_send_raw_transaction_and_get_balance(stubbed_sender, stubbed_receiver, test_http_client):\n    \"\"\"Test sending a raw transaction to localnet.\"\"\"\n    # Get a recent blockhash\n    resp = test_http_client.get_recent_blockhash(Finalized)\n    assert_valid_response(resp)\n    recent_blockhash = resp[\"result\"][\"value\"][\"blockhash\"]\n    # Create transfer tx transfer lamports from stubbed sender to stubbed_receiver\n    transfer_tx = Transaction(recent_blockhash=recent_blockhash).add(\n        sp.transfer(sp.TransferParams(from_pubkey=stubbed_sender.public_key, to_pubkey=stubbed_receiver, lamports=1000))\n    )\n    # Sign transaction\n    transfer_tx.sign(stubbed_sender)\n    # Send raw transaction\n    resp = test_http_client.send_raw_transaction(transfer_tx.serialize())\n    assert_valid_response(resp)\n    # Confirm transaction\n    test_http_client.confirm_transaction(resp[\"result\"])\n    # Check balances\n    resp = test_http_client.get_balance(stubbed_sender.public_key)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 9999988000\n    resp = test_http_client.get_balance(stubbed_receiver)\n    assert_valid_response(resp)\n    assert resp[\"result\"][\"value\"] == 1954\n\n\n@pytest.mark.integration\ndef test_confirm_bad_signature(test_http_client: Client) -> None:\n    \"\"\"Test that RPCException is raised when trying to confirm an invalid signature.\"\"\"\n    with pytest.raises(RPCException) as exc_info:\n        test_http_client.confirm_transaction(\"foo\")\n    err_object = exc_info.value.args[0]\n    assert err_object == {\"code\": -32602, \"message\": \"Invalid param: WrongSize\"}\n\n\n@pytest.mark.integration\ndef test_get_block_commitment(test_http_client):\n    \"\"\"Test get block commitment.\"\"\"\n    resp = test_http_client.get_block_commitment(5)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_block_time(test_http_client):\n    \"\"\"Test get block time.\"\"\"\n    resp = test_http_client.get_block_time(5)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_cluster_nodes(test_http_client):\n    \"\"\"Test get cluster nodes.\"\"\"\n    resp = test_http_client.get_cluster_nodes()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_confirmed_block(test_http_client):\n    \"\"\"Test get confirmed block.\"\"\"\n    resp = test_http_client.get_confirmed_block(1)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_confirmed_block_with_encoding(test_http_client):\n    \"\"\"Test get confrimed block with encoding.\"\"\"\n    resp = test_http_client.get_confirmed_block(1, encoding=\"base64\")\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_block(test_http_client):\n    \"\"\"Test get block.\"\"\"\n    resp = test_http_client.get_block(1)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_block_with_encoding(test_http_client):\n    \"\"\"Test get block with encoding.\"\"\"\n    resp = test_http_client.get_block(1, encoding=\"base64\")\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_block_height(test_http_client):\n    \"\"\"Test get height.\"\"\"\n    resp = test_http_client.get_block_height()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_confirmed_blocks(test_http_client):\n    \"\"\"Test get confirmed blocks.\"\"\"\n    resp = test_http_client.get_confirmed_blocks(5, 10)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_blocks(test_http_client):\n    \"\"\"Test get blocks.\"\"\"\n    resp = test_http_client.get_blocks(5, 10)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_confirmed_signature_for_address2(test_http_client):\n    \"\"\"Test get confirmed signature for address2.\"\"\"\n    resp = test_http_client.get_confirmed_signature_for_address2(\"Vote111111111111111111111111111111111111111\", limit=1)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_signatures_for_address(test_http_client):\n    \"\"\"Test get signatures for addresses.\"\"\"\n    resp = test_http_client.get_signatures_for_address(\"Vote111111111111111111111111111111111111111\", limit=1)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_epoch_info(test_http_client):\n    \"\"\"Test get epoch info.\"\"\"\n    resp = test_http_client.get_epoch_info()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_epoch_schedule(test_http_client):\n    \"\"\"Test get epoch schedule.\"\"\"\n    resp = test_http_client.get_epoch_schedule()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_fee_calculator_for_blockhash(test_http_client):\n    \"\"\"Test get fee calculator for blockhash.\"\"\"\n    resp = test_http_client.get_recent_blockhash(Finalized)\n    assert_valid_response(resp)\n    resp = test_http_client.get_fee_calculator_for_blockhash(resp[\"result\"][\"value\"][\"blockhash\"])\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_slot(test_http_client):\n    \"\"\"Test get slot.\"\"\"\n    resp = test_http_client.get_slot()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_fees(test_http_client):\n    \"\"\"Test get fees.\"\"\"\n    resp = test_http_client.get_fees()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_first_available_block(test_http_client):\n    \"\"\"Test get first available block.\"\"\"\n    resp = test_http_client.get_first_available_block()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_genesis_hash(test_http_client):\n    \"\"\"Test get genesis hash.\"\"\"\n    resp = test_http_client.get_genesis_hash()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_identity(test_http_client):\n    \"\"\"Test get identity.\"\"\"\n    resp = test_http_client.get_genesis_hash()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_inflation_governor(test_http_client):\n    \"\"\"Test get inflation governor.\"\"\"\n    resp = test_http_client.get_inflation_governor()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_inflation_rate(test_http_client):\n    \"\"\"Test get inflation rate.\"\"\"\n    resp = test_http_client.get_inflation_rate()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_largest_accounts(test_http_client):\n    \"\"\"Test get largest accounts.\"\"\"\n    resp = test_http_client.get_largest_accounts()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_leader_schedule(test_http_client):\n    \"\"\"Test get leader schedule.\"\"\"\n    resp = test_http_client.get_leader_schedule()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_minimum_balance_for_rent_exemption(test_http_client):\n    \"\"\"Test get minimum balance for rent exemption.\"\"\"\n    resp = test_http_client.get_minimum_balance_for_rent_exemption(50)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_slot_leader(test_http_client):\n    \"\"\"Test get slot leader.\"\"\"\n    resp = test_http_client.get_slot_leader()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_supply(test_http_client):\n    \"\"\"Test get slot leader.\"\"\"\n    resp = test_http_client.get_supply()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_transaction_count(test_http_client):\n    \"\"\"Test get transactinon count.\"\"\"\n    resp = test_http_client.get_transaction_count()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_version(test_http_client):\n    \"\"\"Test get version.\"\"\"\n    resp = test_http_client.get_version()\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_account_info(stubbed_sender, test_http_client):\n    \"\"\"Test get_account_info.\"\"\"\n    resp = test_http_client.get_account_info(stubbed_sender.public_key)\n    assert_valid_response(resp)\n    resp = test_http_client.get_account_info(stubbed_sender.public_key, encoding=\"jsonParsed\")\n    assert_valid_response(resp)\n    resp = test_http_client.get_account_info(stubbed_sender.public_key, data_slice=DataSliceOpt(1, 1))\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_multiple_accounts(stubbed_sender, test_http_client):\n    \"\"\"Test get_multiple_accounts.\"\"\"\n    pubkeys = [stubbed_sender.public_key] * 2\n    resp = test_http_client.get_multiple_accounts(pubkeys)\n    assert_valid_response(resp)\n    resp = test_http_client.get_multiple_accounts(pubkeys, encoding=\"jsonParsed\")\n    assert_valid_response(resp)\n    resp = test_http_client.get_multiple_accounts(pubkeys, data_slice=DataSliceOpt(1, 1))\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_token_largest_accounts(test_http_client):\n    \"\"\"Test get token largest accounts.\"\"\"\n    resp = test_http_client.get_token_largest_accounts(WRAPPED_SOL_MINT)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_token_supply(test_http_client):\n    \"\"\"Test get token supply.\"\"\"\n    resp = test_http_client.get_token_supply(WRAPPED_SOL_MINT)\n    assert_valid_response(resp)\n\n\n@pytest.mark.integration\ndef test_get_vote_accounts(test_http_client):\n    \"\"\"Test get vote accounts.\"\"\"\n    resp = test_http_client.get_vote_accounts()\n    assert_valid_response(resp)\n"
  },
  {
    "prompt": "\n\n### tickit/devices/eiger/eiger_status.py ###\n\nfrom dataclasses import dataclass, field, fields\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, List\n\n\nclass State(Enum):\n    \"\"\"Possible states of the Eiger detector.\"\"\"\n\n    NA = \"na\"\n    READY = \"ready\"\n    INITIALIZE = \"initialize\"\n    CONFIGURE = \"configure\"\n    ACQUIRE = \"acquire\"\n    IDLE = \"idle\"\n    TEST = \"test\"\n    ERROR = \"error\"\n\n\n@dataclass\nclass EigerStatus:\n    \"\"\"Stores the status parameters of the Eiger detector.\"\"\"\n\n    state: State = field(default=State.NA)\n    errors: List[str] = field(default_factory=list)\n    th0_temp: float = field(default=24.5)\n    th0_humidity: float = field(default=0.2)\n    time: datetime = field(default=datetime.now())\n    dcu_buffer_free: float = field(default=0.5)\n\n    def __getitem__(self, key: str) -> Any:  # noqa: D105\n        f = {}\n        for field_ in fields(self):\n            f[field_.name] = vars(self)[field_.name]\n        return f[key]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nfrom tickit.devices.eiger.eiger_status import EigerStatus\n\n# # # # # EigerStatus Tests # # # # #\n\n\n@pytest.fixture\ndef eiger_status() -> EigerStatus:\n    return EigerStatus()\n\n\ndef test_eiger_status_constructor():\n    EigerStatus()\n\n\ndef test_eiger_status_getitem(eiger_status):\n    assert 24.5 == eiger_status[\"th0_temp\"]\n"
  },
  {
    "prompt": "\n\n### sinergym/utils/rewards.py ###\n\n\"\"\"Implementation of different types of rewards.\"\"\"\n\nfrom datetime import datetime\nfrom math import exp\nfrom typing import Dict, List, Tuple\n\nfrom ..utils.common import get_season_comfort_range\n\n\nclass LinearReward():\n\n    def __init__(self,\n                 energy_weight: float = 0.5,\n                 lambda_energy: float = 1e-4,\n                 lambda_temperature: float = 1.0\n                 ):\n        \"\"\"Simple reward considering absolute difference to temperature comfort.\n\n        .. math::\n            R = - W * lambda_E * power - (1 - W) * lambda_T * (max(T - T_{low}, 0) + max(T_{up} - T, 0))\n\n        Args:\n            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n        \"\"\"\n\n        # Variables\n        self.W_energy = energy_weight\n        self.lambda_energy = lambda_energy\n        self.lambda_temp = lambda_temperature\n\n    def calculate(self,\n                  power: float,\n                  temperatures: List[float],\n                  month: int,\n                  day: int) \\\n            -> Tuple[float, Dict[str, float]]:\n        \"\"\"Reward calculus.\n\n        Args:\n            power (float): Power consumption.\n            temperatures (List[float]): Indoor temperatures (one per zone).\n            month (int): Current month.\n            day (int): Current day.\n\n        Returns:\n            Tuple[float, Dict[str, float]]: Reward value.\n        \"\"\"\n        # Energy term\n        reward_energy = - self.lambda_energy * power\n\n        # Comfort term\n        range_T = get_season_comfort_range(month, day)\n        delta_T = 0.0\n        for temperature in temperatures:\n            delta_T += 0.0 if temperature >= range_T[0] and temperature <= range_T[1] else min(\n                abs(range_T[0] - temperature), abs(temperature - range_T[1]))\n        reward_comfort = - self.lambda_temp * delta_T\n\n        # Weighted sum of both terms\n        reward = self.W_energy * reward_energy + \\\n            (1.0 - self.W_energy) * reward_comfort\n        terms = {'reward_energy': reward_energy,\n                 'reward_comfort': reward_comfort}\n\n        return reward, terms\n\n\nclass ExpReward():\n\n    def __init__(self,\n                 energy_weight: float = 0.5,\n                 lambda_energy: float = 1e-4,\n                 lambda_temperature: float = 1.0\n                 ):\n        \"\"\"Reward considering exponential absolute difference to temperature comfort.\n\n        .. math::\n            R = - W * lambda_E * power - (1 - W) * lambda_T * exp( (max(T - T_{low}, 0) + max(T_{up} - T, 0)) )\n\n        Args:\n            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n        \"\"\"\n\n        # Variables\n        self.W_energy = energy_weight\n        self.lambda_energy = lambda_energy\n        self.lambda_temp = lambda_temperature\n\n    def calculate(self, power: float, temperatures: List[float],\n                  month: int, day: int) -> Tuple[float, Dict[str, float]]:\n        \"\"\"Reward calculus.\n\n        Args:\n            power (float): Power consumption.\n            temperatures (List[float]): Indoor temperatures (one per zone).\n            month (int): Current month.\n            day (int): Current day.\n\n        Returns:\n            Tuple[float, Dict[str, float]]: Reward value.\n        \"\"\"\n        # Energy term\n        reward_energy = - self.lambda_energy * power\n\n        # Comfort term\n        range_T = get_season_comfort_range(month, day)\n        delta_T = 0.0\n        for temperature in temperatures:\n            delta_T += 0.0 if temperature >= range_T[0] and temperature <= range_T[1] else exp(\n                min(abs(range_T[0] - temperature), abs(temperature - range_T[1])))\n        reward_comfort = - self.lambda_temp * delta_T\n\n        # Weighted sum of both terms\n        reward = self.W_energy * reward_energy + \\\n            (1.0 - self.W_energy) * reward_comfort\n        terms = {'reward_energy': reward_energy,\n                 'reward_comfort': reward_comfort}\n\n        return reward, terms\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\n\nimport sinergym.utils.rewards as R\n\n\n@pytest.mark.parametrize(\n    'power,temperatures,month,day,reward,reward_energy,reward_comfort',\n    [\n        # Input 1\n        (\n            186.5929171535975,\n            [22.16742570092868],\n            3,\n            31,\n            -0.009329645857679876,\n            -0.018659291715359752,\n            -0.0\n        ),\n        # Input 2\n        (\n            688.0477550424935,\n            [26.7881162590194],\n            3,\n            30,\n            -1.6784605172618248,\n            -0.06880477550424935,\n            -3.2881162590194\n        ),\n        # Input 3\n        (\n            23168.30752221127,\n            [20.37505026953311],\n            2,\n            25,\n            -1.1584153761105636,\n            -2.316830752221127,\n            -0.0\n        ),\n    ]\n)\ndef test_calculate(\n        simple_reward,\n        power,\n        temperatures,\n        month,\n        day,\n        reward,\n        reward_energy,\n        reward_comfort):\n    result = simple_reward.calculate(power, temperatures, month, day)\n    assert result[0] == reward\n    assert result[1]['reward_energy'] == reward_energy\n    assert result[1]['reward_comfort'] == reward_comfort\n"
  },
  {
    "prompt": "\n\n### bokeh/_testing/util/api.py ###\n\n#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n''' Provide utility classes and functions useful for testing Bokeh itself.\n\n'''\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nimport logging\nlog = logging.getLogger(__name__)\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Standard library imports\nimport importlib\n\n# External imports\nimport pytest\n\n# Bokeh imports\n\n#-----------------------------------------------------------------------------\n# Globals and constants\n#-----------------------------------------------------------------------------\n\n__all__ = (\n    'verify_all',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\ndef verify_all(module, ALL):\n    '''\n\n    '''\n    class Test___all__(object):\n        def test___all__(self):\n            if isinstance(module, str):\n                mod = importlib.import_module(module)\n            else:\n                mod = module\n            assert hasattr(mod, \"__all__\")\n            assert mod.__all__ == ALL, \"for module %s, expected: %r, actual: %r\" % (mod.__name__, set(ALL)-set(mod.__all__), set(mod.__all__)-set(ALL))\n\n        @pytest.mark.parametrize('name', ALL)\n        @pytest.mark.unit\n        def test_contents(self, name):\n            if isinstance(module, str):\n                mod = importlib.import_module(module)\n            else:\n                mod = module\n            assert hasattr(mod, name)\n    return Test___all__\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "#-----------------------------------------------------------------------------\n# Copyright (c) 2012 - 2019, Anaconda, Inc., and Bokeh Contributors.\n# All rights reserved.\n#\n# The full license is in the file LICENSE.txt, distributed with this software.\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Boilerplate\n#-----------------------------------------------------------------------------\nimport pytest ; pytest\n\n#-----------------------------------------------------------------------------\n# Imports\n#-----------------------------------------------------------------------------\n\n# Standard library imports\n\n# External imports\n\n# Bokeh imports\nfrom bokeh._testing.util.api import verify_all\n\n# Module under test\n#import bokeh.sampledata.glucose as bsg\n\n#-----------------------------------------------------------------------------\n# Setup\n#-----------------------------------------------------------------------------\n\nALL = (\n    'data',\n)\n\n#-----------------------------------------------------------------------------\n# General API\n#-----------------------------------------------------------------------------\n\nTest___all__ = pytest.mark.sampledata(verify_all(\"bokeh.sampledata.glucose\", ALL))\n\n@pytest.mark.sampledata\ndef test_data(pd):\n    import bokeh.sampledata.glucose as bsg\n    assert isinstance(bsg.data, pd.DataFrame)\n\n    # don't check detail for external data\n\n#-----------------------------------------------------------------------------\n# Dev API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Private API\n#-----------------------------------------------------------------------------\n\n#-----------------------------------------------------------------------------\n# Code\n#-----------------------------------------------------------------------------\n"
  },
  {
    "prompt": "\n\n### qualle/label_calibration/simple.py ###\n\n#  Copyright 2021 ZBW  \u2013 Leibniz Information Centre for Economics\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\nfrom typing import List\n\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.utils.validation import check_is_fitted\n\nfrom stwfsapy.text_features import mk_text_features\n\n\nclass LabelCalibrator(BaseEstimator, RegressorMixin):\n\n    def __init__(self, regressor=ExtraTreesRegressor()):\n        self.regressor = regressor\n\n    def fit(self, X: List[str], y):\n        features = mk_text_features()\n        self.pipeline_ = Pipeline(\n            [(\"features\", features), (\"regressor\", self.regressor)]\n        )\n        self.pipeline_.fit(X, y)\n        return self\n\n    def predict(self, X: List[str]):\n        check_is_fitted(self)\n        return self.pipeline_.predict(X)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "#  Copyright 2021 ZBW  \u2013 Leibniz Information Centre for Economics\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n\nimport numpy as np\nimport pytest\nfrom sklearn.exceptions import NotFittedError\nfrom stwfsapy.text_features import mk_text_features\n\nfrom qualle.label_calibration.simple import LabelCalibrator\nfrom tests.common import DummyRegressor\n\n\n@pytest.fixture\ndef calibrator():\n    return LabelCalibrator(DummyRegressor())\n\n\ndef test_lc_predict(calibrator, X):\n    calibrator.fit(X, [3, 5])\n    assert np.array_equal(calibrator.predict(X), [0, 1])\n\n\ndef test_lc_predict_without_fit_raises_exc(calibrator, X):\n    with pytest.raises(NotFittedError):\n        calibrator.predict(X)\n\n\ndef test_lc_fit_fits_regressor_with_txt_features(calibrator, X, mocker):\n    y = [3, 5]\n    txt_features = mk_text_features().fit(X)\n    X_transformed = txt_features.transform(X)\n\n    spy = mocker.spy(calibrator.regressor, 'fit')\n    calibrator.fit(X, y)\n    spy.assert_called_once()\n    assert (spy.call_args[0][0].toarray() == X_transformed.toarray()).all()\n    assert spy.call_args[0][1] == y\n"
  },
  {
    "prompt": "\n\n### cem/backend.py ###\n\n#######################################################\n# Author: Qixin Hu\n# Email:  hqx11@hust.edu.cn\n# Version: 1.0\n#######################################################\n# The backends contain Numpy and CuPy(optional).\n# Default one is Numpy, you can choose:\n#   1. numpy\n#   2. cupy (GPU if it's available)\n# we use int64 and float64 as our data type.\n#######################################################\n# Usage: In the fdtd main program, call:\n#\n#     from .backend import backend as bd\n#\n# Then replace np/cp with bd, e.g:\n# 1. a = np.array([1,2,3]) ---> a = bd.array([1,2,3])\n# 2. np.sin(a)             ---> bd.sin(a)\n# 3. np.exp(a)             ---> bd.exp(a)\n#\n# You can change different backend by call:\n# bd.set_backend('cupy') or bd.set_backend('numpy')\n#######################################################\n\n# Basic(default) numpy backend\nimport numpy\n\n# Optional cupy backend\ntry:\n    import cupy\n    CUPY_AVAILABLE = True\nexcept ImportError:\n    CUPY_AVAILABLE = False\n\n# You can add other backend here (e.g: Pytorch, TensorFlow, Mars...)\n\n\nclass Backend:\n    \"\"\" Basic backend class \"\"\"\n\n    def __repr__(self):\n        return self.__class__.__name__\n\n\n    def set_backend(self, name: str):\n        \"\"\"\n        Set backend to FDTD simulation program.\n        Two backends: 'cupy' and 'numpy'\n        \"\"\"\n\n        # check if cupy is installed.\n        if name == 'cupy' and not CUPY_AVAILABLE:\n            raise RuntimeError(\n                \"\"\"\n                CuPy backend is not available. Have you installed cupy?\n                Please check https://docs.cupy.dev/en/stable/install.html \n                to see how to install cupy on your device.\n                \"\"\"\n            )\n\n        if name == 'numpy':\n            self.__class__ = NumpyBackend\n        elif name == 'cupy':\n            self.__class__ = CuPyBackend\n        else:\n            raise RuntimeError(r'unknown backend \"{}\"'.format(name))\n        #\n\n# numpy backend\nclass NumpyBackend(Backend):\n    \"\"\"\n    Numpy backend class,\n    here we use np.ndarray as our bd.ndarray\n    \"\"\"\n\n    # Types\n    int = numpy.int64\n    float = numpy.float64\n\n    # Math calculation\n    # you can add more if needed\n    exp = staticmethod(numpy.exp)\n    sin = staticmethod(numpy.sin)\n    cos = staticmethod(numpy.cos)\n    sqrt = staticmethod(numpy.sqrt)\n\n    # Create array\n    # you can add more if needed\n    array = staticmethod(numpy.array)\n    ones = staticmethod(numpy.ones)\n    zeros = staticmethod(numpy.zeros)\n    arange = staticmethod(numpy.arange)\n\n    @staticmethod\n    def is_array(arr):\n        \"\"\" check if arr is a numpy ndarray.\"\"\"\n        return isinstance(arr, numpy.ndarray)\n\n    def numpy(self, arr):\n        \"\"\" if the arr is numpy.ndarray, return it. Or raise TypeError\"\"\"\n        if self.is_array(arr):\n            return arr\n        else:\n            raise TypeError(\"The input should be a numpy.ndarray.\")\n\n\nif CUPY_AVAILABLE:\n    class CuPyBackend(Backend):\n        \"\"\"\n        CuPy backend class, GPU accelerate.\n        \"\"\"\n\n        # Types\n        int = cupy.int64\n        float = cupy.float64\n\n        # Math calculation\n        # you can add more if needed\n        exp = staticmethod(cupy.exp)\n        sin = staticmethod(cupy.sin)\n        cos = staticmethod(cupy.cos)\n        sqrt = staticmethod(cupy.sqrt)\n\n        # Create array\n        array = staticmethod(cupy.array)\n        ones = staticmethod(cupy.ones)\n        zeros = staticmethod(cupy.zeros)\n        arange = staticmethod(cupy.arange)\n\n        @staticmethod\n        def is_array(arr):\n            \"\"\" check if arr is a cupy ndarray.\"\"\"\n            return isinstance(arr, cupy.ndarray)\n\n        def numpy(self, arr):\n            \"\"\"\n            Convert cupy.ndarray into numpy.ndarray.\n            The data will transfer between CPU and the GPU,\n            which is costly in terms of performance. So I\n            recommend call this function after all computation.\n            \"\"\"\n            if self.is_array(arr):\n                return cupy.asnumpy(arr)\n            else:\n                raise TypeError(\"The input should be a cupy.ndarray.\")\n\n# Default Backend: numpy\n# All the data types and operations is based on the backend.\n# User should choose backend at the very beginning.\n# By calling bd.set_backend('cupy') to set cupy as backend.\nbackend = NumpyBackend()\n\n# Test Unit\nif __name__ == '__main__':\n\n    import matplotlib.pyplot as plt\n\n    bd = backend\n    print(bd)\n    # a = bd.ones((10, 10)\n    # plt.imshow()\n    # plt.show()\n    bd.set_backend('abc')\n    print(bd)\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\nimport numpy as np\nimport random\n\nfrom cem.backend import backend, NumpyBackend\n\ntry:\n    from cem.backend import CuPyBackend\n    import cupy as cp\n    skip_cupy_test = False\nexcept ImportError:\n    skip_cupy_test = True\n\n\ndef test_numpy_backend():\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, NumpyBackend)\n    assert isinstance(zeros, np.ndarray)\n    assert isinstance(ones, np.ndarray)\n    assert backend.int == np.int64\n    assert backend.float == np.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).any() == np.sin(ones).any()\n    assert backend.cos(ones).any() == np.cos(ones).any()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_cupy_backend():\n    backend.set_backend('cupy')\n    X = random.randint(0, 10) * 10\n    Y = random.randint(0, 10) * 10\n\n    zeros = backend.zeros((X, Y))\n    ones = backend.ones((X, Y))\n\n    assert isinstance(backend, CuPyBackend)\n    assert isinstance(zeros, cp.ndarray)\n    assert isinstance(ones, cp.ndarray)\n    assert backend.int == cp.int64\n    assert backend.float == cp.float64\n    assert zeros.shape == (X, Y)\n    assert ones.shape == (X, Y)\n    assert backend.sin(ones).all() == cp.sin(ones).all()\n    assert backend.cos(ones).all() == cp.cos(ones).all()\n\n\n@pytest.mark.skipif(skip_cupy_test, reason='CuPy is not installed.')\ndef test_set_backend():\n    backend.set_backend('numpy')\n    assert isinstance(backend, NumpyBackend)\n    backend.set_backend('cupy')\n    assert isinstance(backend, CuPyBackend)\n"
  },
  {
    "prompt": "\n\n### bigchaindb/core.py ###\n\nimport random\nfrom time import time\n\nfrom bigchaindb import exceptions as core_exceptions\nfrom bigchaindb.common import crypto, exceptions\nfrom bigchaindb.common.utils import gen_timestamp, serialize\n\nimport bigchaindb\n\nfrom bigchaindb import backend, config_utils, fastquery\nfrom bigchaindb.consensus import BaseConsensusRules\nfrom bigchaindb.models import Block, Transaction\n\n\nclass Bigchain(object):\n    \"\"\"Bigchain API\n\n    Create, read, sign, write transactions to the database\n    \"\"\"\n\n    BLOCK_INVALID = 'invalid'\n    \"\"\"return if a block has been voted invalid\"\"\"\n\n    BLOCK_VALID = TX_VALID = 'valid'\n    \"\"\"return if a block is valid, or tx is in valid block\"\"\"\n\n    BLOCK_UNDECIDED = TX_UNDECIDED = 'undecided'\n    \"\"\"return if block is undecided, or tx is in undecided block\"\"\"\n\n    TX_IN_BACKLOG = 'backlog'\n    \"\"\"return if transaction is in backlog\"\"\"\n\n    def __init__(self, public_key=None, private_key=None, keyring=[], connection=None, backlog_reassign_delay=None):\n        \"\"\"Initialize the Bigchain instance\n\n        A Bigchain instance has several configuration parameters (e.g. host).\n        If a parameter value is passed as an argument to the Bigchain\n        __init__ method, then that is the value it will have.\n        Otherwise, the parameter value will come from an environment variable.\n        If that environment variable isn't set, then the value\n        will come from the local configuration file. And if that variable\n        isn't in the local configuration file, then the parameter will have\n        its default value (defined in bigchaindb.__init__).\n\n        Args:\n            public_key (str): the base58 encoded public key for the ED25519 curve.\n            private_key (str): the base58 encoded private key for the ED25519 curve.\n            keyring (list[str]): list of base58 encoded public keys of the federation nodes.\n            connection (:class:`~bigchaindb.backend.connection.Connection`):\n                A connection to the database.\n        \"\"\"\n\n        config_utils.autoconfigure()\n\n        self.me = public_key or bigchaindb.config['keypair']['public']\n        self.me_private = private_key or bigchaindb.config['keypair']['private']\n        self.nodes_except_me = keyring or bigchaindb.config['keyring']\n\n        if backlog_reassign_delay is None:\n            backlog_reassign_delay = bigchaindb.config['backlog_reassign_delay']\n        self.backlog_reassign_delay = backlog_reassign_delay\n\n        consensusPlugin = bigchaindb.config.get('consensus_plugin')\n\n        if consensusPlugin:\n            self.consensus = config_utils.load_consensus_plugin(consensusPlugin)\n        else:\n            self.consensus = BaseConsensusRules\n\n        self.connection = connection if connection else backend.connect(**bigchaindb.config['database'])\n        # if not self.me:\n        #    raise exceptions.KeypairNotFoundException()\n\n    federation = property(lambda self: set(self.nodes_except_me + [self.me]))\n    \"\"\" Set of federation member public keys \"\"\"\n\n    def write_transaction(self, signed_transaction):\n        \"\"\"Write the transaction to bigchain.\n\n        When first writing a transaction to the bigchain the transaction will be kept in a backlog until\n        it has been validated by the nodes of the federation.\n\n        Args:\n            signed_transaction (Transaction): transaction with the `signature` included.\n\n        Returns:\n            dict: database response\n        \"\"\"\n        signed_transaction = signed_transaction.to_dict()\n\n        # we will assign this transaction to `one` node. This way we make sure that there are no duplicate\n        # transactions on the bigchain\n        if self.nodes_except_me:\n            assignee = random.choice(self.nodes_except_me)\n        else:\n            # I am the only node\n            assignee = self.me\n\n        signed_transaction.update({'assignee': assignee})\n        signed_transaction.update({'assignment_timestamp': time()})\n\n        # write to the backlog\n        return backend.query.write_transaction(self.connection, signed_transaction)\n\n    def reassign_transaction(self, transaction):\n        \"\"\"Assign a transaction to a new node\n\n        Args:\n            transaction (dict): assigned transaction\n\n        Returns:\n            dict: database response or None if no reassignment is possible\n        \"\"\"\n\n        other_nodes = tuple(\n            self.federation.difference([transaction['assignee']])\n        )\n        new_assignee = random.choice(other_nodes) if other_nodes else self.me\n\n        return backend.query.update_transaction(\n                self.connection, transaction['id'],\n                {'assignee': new_assignee, 'assignment_timestamp': time()})\n\n    def delete_transaction(self, *transaction_id):\n        \"\"\"Delete a transaction from the backlog.\n\n        Args:\n            *transaction_id (str): the transaction(s) to delete\n\n        Returns:\n            The database response.\n        \"\"\"\n\n        return backend.query.delete_transaction(self.connection, *transaction_id)\n\n    def get_stale_transactions(self):\n        \"\"\"Get a cursor of stale transactions.\n\n        Transactions are considered stale if they have been assigned a node, but are still in the\n        backlog after some amount of time specified in the configuration\n        \"\"\"\n\n        return backend.query.get_stale_transactions(self.connection, self.backlog_reassign_delay)\n\n    def validate_transaction(self, transaction):\n        \"\"\"Validate a transaction.\n\n        Args:\n            transaction (Transaction): transaction to validate.\n\n        Returns:\n            The transaction if the transaction is valid else it raises an\n            exception describing the reason why the transaction is invalid.\n        \"\"\"\n\n        return self.consensus.validate_transaction(self, transaction)\n\n    def is_new_transaction(self, txid, exclude_block_id=None):\n        \"\"\"Return True if the transaction does not exist in any\n        VALID or UNDECIDED block. Return False otherwise.\n\n        Args:\n            txid (str): Transaction ID\n            exclude_block_id (str): Exclude block from search\n        \"\"\"\n        block_statuses = self.get_blocks_status_containing_tx(txid)\n        block_statuses.pop(exclude_block_id, None)\n        for status in block_statuses.values():\n            if status != self.BLOCK_INVALID:\n                return False\n        return True\n\n    def get_block(self, block_id, include_status=False):\n        \"\"\"Get the block with the specified `block_id` (and optionally its status)\n\n        Returns the block corresponding to `block_id` or None if no match is\n        found.\n\n        Args:\n            block_id (str): transaction id of the transaction to get\n            include_status (bool): also return the status of the block\n                       the return value is then a tuple: (block, status)\n        \"\"\"\n        # get block from database\n        block_dict = backend.query.get_block(self.connection, block_id)\n        # get the asset ids from the block\n        if block_dict:\n            asset_ids = Block.get_asset_ids(block_dict)\n            txn_ids = Block.get_txn_ids(block_dict)\n            # get the assets from the database\n            assets = self.get_assets(asset_ids)\n            # get the metadata from the database\n            metadata = self.get_metadata(txn_ids)\n            # add the assets to the block transactions\n            block_dict = Block.couple_assets(block_dict, assets)\n            # add the metadata to the block transactions\n            block_dict = Block.couple_metadata(block_dict, metadata)\n\n        status = None\n        if include_status:\n            if block_dict:\n                status = self.block_election_status(block_dict)\n            return block_dict, status\n        else:\n            return block_dict\n\n    def get_transaction(self, txid, include_status=False):\n        \"\"\"Get the transaction with the specified `txid` (and optionally its status)\n\n        This query begins by looking in the bigchain table for all blocks containing\n        a transaction with the specified `txid`. If one of those blocks is valid, it\n        returns the matching transaction from that block. Else if some of those\n        blocks are undecided, it returns a matching transaction from one of them. If\n        the transaction was found in invalid blocks only, or in no blocks, then this\n        query looks for a matching transaction in the backlog table, and if it finds\n        one there, it returns that.\n\n        Args:\n            txid (str): transaction id of the transaction to get\n            include_status (bool): also return the status of the transaction\n                                   the return value is then a tuple: (tx, status)\n\n        Returns:\n            A :class:`~.models.Transaction` instance if the transaction\n            was found in a valid block, an undecided block, or the backlog table,\n            otherwise ``None``.\n            If :attr:`include_status` is ``True``, also returns the\n            transaction's status if the transaction was found.\n        \"\"\"\n\n        response, tx_status = None, None\n\n        blocks_validity_status = self.get_blocks_status_containing_tx(txid)\n        check_backlog = True\n\n        if blocks_validity_status:\n            # Disregard invalid blocks, and return if there are no valid or undecided blocks\n            blocks_validity_status = {\n                _id: status for _id, status in blocks_validity_status.items()\n                if status != Bigchain.BLOCK_INVALID\n            }\n            if blocks_validity_status:\n\n                # The transaction _was_ found in an undecided or valid block,\n                # so there's no need to look in the backlog table\n                check_backlog = False\n\n                tx_status = self.TX_UNDECIDED\n                # If the transaction is in a valid or any undecided block, return it. Does not check\n                # if transactions in undecided blocks are consistent, but selects the valid block\n                # before undecided ones\n                for target_block_id in blocks_validity_status:\n                    if blocks_validity_status[target_block_id] == Bigchain.BLOCK_VALID:\n                        tx_status = self.TX_VALID\n                        break\n\n                # Query the transaction in the target block and return\n                response = backend.query.get_transaction_from_block(self.connection, txid, target_block_id)\n\n        if check_backlog:\n            response = backend.query.get_transaction_from_backlog(self.connection, txid)\n\n            if response:\n                tx_status = self.TX_IN_BACKLOG\n\n        if response:\n            if tx_status == self.TX_IN_BACKLOG:\n                response = Transaction.from_dict(response)\n            else:\n                # If we are reading from the bigchain collection the asset is\n                # not in the transaction so we need to fetch the asset and\n                # reconstruct the transaction.\n                response = Transaction.from_db(self, response)\n\n        if include_status:\n            return response, tx_status\n        else:\n            return response\n\n    def get_status(self, txid):\n        \"\"\"Retrieve the status of a transaction with `txid` from bigchain.\n\n        Args:\n            txid (str): transaction id of the transaction to query\n\n        Returns:\n            (string): transaction status ('valid', 'undecided',\n            or 'backlog'). If no transaction with that `txid` was found it\n            returns `None`\n        \"\"\"\n        _, status = self.get_transaction(txid, include_status=True)\n        return status\n\n    def get_blocks_status_containing_tx(self, txid):\n        \"\"\"Retrieve block ids and statuses related to a transaction\n\n        Transactions may occur in multiple blocks, but no more than one valid block.\n\n        Args:\n            txid (str): transaction id of the transaction to query\n\n        Returns:\n            A dict of blocks containing the transaction,\n            e.g. {block_id_1: 'valid', block_id_2: 'invalid' ...}, or None\n        \"\"\"\n\n        # First, get information on all blocks which contain this transaction\n        blocks = backend.query.get_blocks_status_from_transaction(self.connection, txid)\n        if blocks:\n            # Determine the election status of each block\n            blocks_validity_status = {\n                block['id']: self.block_election_status(block)\n                for block in blocks\n            }\n\n            # NOTE: If there are multiple valid blocks with this transaction,\n            # something has gone wrong\n            if list(blocks_validity_status.values()).count(Bigchain.BLOCK_VALID) > 1:\n                block_ids = str([\n                    block for block in blocks_validity_status\n                    if blocks_validity_status[block] == Bigchain.BLOCK_VALID\n                ])\n                raise core_exceptions.CriticalDoubleInclusion(\n                    'Transaction {tx} is present in '\n                    'multiple valid blocks: {block_ids}'\n                    .format(tx=txid, block_ids=block_ids))\n\n            return blocks_validity_status\n\n        else:\n            return None\n\n    def get_asset_by_id(self, asset_id):\n        \"\"\"Returns the asset associated with an asset_id.\n\n            Args:\n                asset_id (str): The asset id.\n\n            Returns:\n                dict if the asset exists else None.\n        \"\"\"\n        cursor = backend.query.get_asset_by_id(self.connection, asset_id)\n        cursor = list(cursor)\n        if cursor:\n            return cursor[0]['asset']\n\n    def get_spent(self, txid, output):\n        \"\"\"Check if a `txid` was already used as an input.\n\n        A transaction can be used as an input for another transaction. Bigchain\n        needs to make sure that a given `(txid, output)` is only used once.\n\n        This method will check if the `(txid, output)` has already been\n        spent in a transaction that is in either the `VALID`, `UNDECIDED` or\n        `BACKLOG` state.\n\n        Args:\n            txid (str): The id of the transaction\n            output (num): the index of the output in the respective transaction\n\n        Returns:\n            The transaction (Transaction) that used the `(txid, output)` as an\n            input else `None`\n\n        Raises:\n            CriticalDoubleSpend: If the given `(txid, output)` was spent in\n            more than one valid transaction.\n        \"\"\"\n        # checks if an input was already spent\n        # checks if the bigchain has any transaction with input {'txid': ...,\n        # 'output': ...}\n        transactions = list(backend.query.get_spent(self.connection, txid,\n                                                    output))\n\n        # a transaction_id should have been spent at most one time\n        # determine if these valid transactions appear in more than one valid\n        # block\n        num_valid_transactions = 0\n        non_invalid_transactions = []\n        for transaction in transactions:\n            # ignore transactions in invalid blocks\n            # FIXME: Isn't there a faster solution than doing I/O again?\n            txn, status = self.get_transaction(transaction['id'],\n                                               include_status=True)\n            if status == self.TX_VALID:\n                num_valid_transactions += 1\n            # `txid` can only have been spent in at most on valid block.\n            if num_valid_transactions > 1:\n                raise core_exceptions.CriticalDoubleSpend(\n                    '`{}` was spent more than once. There is a problem'\n                    ' with the chain'.format(txid))\n            # if its not and invalid transaction\n            if status is not None:\n                transaction.update({'metadata': txn.metadata})\n                non_invalid_transactions.append(transaction)\n\n        if non_invalid_transactions:\n            return Transaction.from_dict(non_invalid_transactions[0])\n\n        # Either no transaction was returned spending the `(txid, output)` as\n        # input or the returned transactions are not valid.\n\n    def get_owned_ids(self, owner):\n        \"\"\"Retrieve a list of ``txid`` s that can be used as inputs.\n\n        Args:\n            owner (str): base58 encoded public key.\n\n        Returns:\n            :obj:`list` of TransactionLink: list of ``txid`` s and ``output`` s\n            pointing to another transaction's condition\n        \"\"\"\n        return self.get_outputs_filtered(owner, spent=False)\n\n    @property\n    def fastquery(self):\n        return fastquery.FastQuery(self.connection, self.me)\n\n    def get_outputs_filtered(self, owner, spent=None):\n        \"\"\"Get a list of output links filtered on some criteria\n\n        Args:\n            owner (str): base58 encoded public_key.\n            spent (bool): If ``True`` return only the spent outputs. If\n                          ``False`` return only unspent outputs. If spent is\n                          not specified (``None``) return all outputs.\n\n        Returns:\n            :obj:`list` of TransactionLink: list of ``txid`` s and ``output`` s\n            pointing to another transaction's condition\n        \"\"\"\n        outputs = self.fastquery.get_outputs_by_public_key(owner)\n        if spent is None:\n            return outputs\n        elif spent is True:\n            return self.fastquery.filter_unspent_outputs(outputs)\n        elif spent is False:\n            return self.fastquery.filter_spent_outputs(outputs)\n\n    def get_transactions_filtered(self, asset_id, operation=None):\n        \"\"\"Get a list of transactions filtered on some criteria\n        \"\"\"\n        txids = backend.query.get_txids_filtered(self.connection, asset_id,\n                                                 operation)\n        for txid in txids:\n            tx, status = self.get_transaction(txid, True)\n            if status == self.TX_VALID:\n                yield tx\n\n    def create_block(self, validated_transactions):\n        \"\"\"Creates a block given a list of `validated_transactions`.\n\n        Note that this method does not validate the transactions. Transactions\n        should be validated before calling create_block.\n\n        Args:\n            validated_transactions (list(Transaction)): list of validated\n                                                        transactions.\n\n        Returns:\n            Block: created block.\n        \"\"\"\n        # Prevent the creation of empty blocks\n        if not validated_transactions:\n            raise exceptions.OperationError('Empty block creation is not '\n                                            'allowed')\n\n        voters = list(self.federation)\n        block = Block(validated_transactions, self.me, gen_timestamp(), voters)\n        block = block.sign(self.me_private)\n\n        return block\n\n    # TODO: check that the votings structure is correctly constructed\n    def validate_block(self, block):\n        \"\"\"Validate a block.\n\n        Args:\n            block (Block): block to validate.\n\n        Returns:\n            The block if the block is valid else it raises and exception\n            describing the reason why the block is invalid.\n        \"\"\"\n        return self.consensus.validate_block(self, block)\n\n    def has_previous_vote(self, block_id):\n        \"\"\"Check for previous votes from this node\n\n        Args:\n            block_id (str): the id of the block to check\n\n        Returns:\n            bool: :const:`True` if this block already has a\n            valid vote from this node, :const:`False` otherwise.\n\n        \"\"\"\n        votes = list(backend.query.get_votes_by_block_id_and_voter(self.connection, block_id, self.me))\n        el, _ = self.consensus.voting.partition_eligible_votes(votes, [self.me])\n        return bool(el)\n\n    def write_block(self, block):\n        \"\"\"Write a block to bigchain.\n\n        Args:\n            block (Block): block to write to bigchain.\n        \"\"\"\n\n        # Decouple assets from block\n        assets, block_dict = block.decouple_assets()\n        metadatas, block_dict = block.decouple_metadata(block_dict)\n\n        # write the assets\n        if assets:\n            self.write_assets(assets)\n\n        if metadatas:\n            self.write_metadata(metadatas)\n\n        # write the block\n        return backend.query.write_block(self.connection, block_dict)\n\n    def prepare_genesis_block(self):\n        \"\"\"Prepare a genesis block.\"\"\"\n\n        metadata = {'message': 'Hello World from the BigchainDB'}\n        transaction = Transaction.create([self.me], [([self.me], 1)],\n                                         metadata=metadata)\n\n        # NOTE: The transaction model doesn't expose an API to generate a\n        #       GENESIS transaction, as this is literally the only usage.\n        transaction.operation = 'GENESIS'\n        transaction = transaction.sign([self.me_private])\n\n        # create the block\n        return self.create_block([transaction])\n\n    def create_genesis_block(self):\n        \"\"\"Create the genesis block\n\n        Block created when bigchain is first initialized. This method is not atomic, there might be concurrency\n        problems if multiple instances try to write the genesis block when the BigchainDB Federation is started,\n        but it's a highly unlikely scenario.\n        \"\"\"\n\n        # 1. create one transaction\n        # 2. create the block with one transaction\n        # 3. write the block to the bigchain\n\n        blocks_count = backend.query.count_blocks(self.connection)\n\n        if blocks_count:\n            raise exceptions.GenesisBlockAlreadyExistsError('Cannot create the Genesis block')\n\n        block = self.prepare_genesis_block()\n        self.write_block(block)\n\n        return block\n\n    def vote(self, block_id, previous_block_id, decision, invalid_reason=None):\n        \"\"\"Create a signed vote for a block given the\n        :attr:`previous_block_id` and the :attr:`decision` (valid/invalid).\n\n        Args:\n            block_id (str): The id of the block to vote on.\n            previous_block_id (str): The id of the previous block.\n            decision (bool): Whether the block is valid or invalid.\n            invalid_reason (Optional[str]): Reason the block is invalid\n        \"\"\"\n\n        if block_id == previous_block_id:\n            raise exceptions.CyclicBlockchainError()\n\n        vote = {\n            'voting_for_block': block_id,\n            'previous_block': previous_block_id,\n            'is_block_valid': decision,\n            'invalid_reason': invalid_reason,\n            'timestamp': gen_timestamp()\n        }\n\n        vote_data = serialize(vote)\n        signature = crypto.PrivateKey(self.me_private).sign(vote_data.encode())\n\n        vote_signed = {\n            'node_pubkey': self.me,\n            'signature': signature.decode(),\n            'vote': vote\n        }\n\n        return vote_signed\n\n    def write_vote(self, vote):\n        \"\"\"Write the vote to the database.\"\"\"\n        return backend.query.write_vote(self.connection, vote)\n\n    def get_last_voted_block(self):\n        \"\"\"Returns the last block that this node voted on.\"\"\"\n\n        last_block_id = backend.query.get_last_voted_block_id(self.connection,\n                                                              self.me)\n        return Block.from_dict(self.get_block(last_block_id))\n\n    def block_election(self, block):\n        if type(block) != dict:\n            block = block.to_dict()\n        votes = list(backend.query.get_votes_by_block_id(self.connection,\n                                                         block['id']))\n        return self.consensus.voting.block_election(block, votes,\n                                                    self.federation)\n\n    def block_election_status(self, block):\n        \"\"\"Tally the votes on a block, and return the status:\n           valid, invalid, or undecided.\n        \"\"\"\n        return self.block_election(block)['status']\n\n    def get_assets(self, asset_ids):\n        \"\"\"Return a list of assets that match the asset_ids\n\n        Args:\n            asset_ids (:obj:`list` of :obj:`str`): A list of asset_ids to\n                retrieve from the database.\n\n        Returns:\n            list: The list of assets returned from the database.\n        \"\"\"\n        return backend.query.get_assets(self.connection, asset_ids)\n\n    def get_metadata(self, txn_ids):\n        \"\"\"Return a list of metadata that match the transaction ids (txn_ids)\n\n        Args:\n            txn_ids (:obj:`list` of :obj:`str`): A list of txn_ids to\n                retrieve from the database.\n\n        Returns:\n            list: The list of metadata returned from the database.\n        \"\"\"\n        return backend.query.get_metadata(self.connection, txn_ids)\n\n    def write_assets(self, assets):\n        \"\"\"Writes a list of assets into the database.\n\n        Args:\n            assets (:obj:`list` of :obj:`dict`): A list of assets to write to\n                the database.\n        \"\"\"\n        return backend.query.write_assets(self.connection, assets)\n\n    def write_metadata(self, metadata):\n        \"\"\"Writes a list of metadata into the database.\n\n        Args:\n            metadata (:obj:`list` of :obj:`dict`): A list of metadata to write to\n                the database.\n        \"\"\"\n        return backend.query.write_metadata(self.connection, metadata)\n\n    def text_search(self, search, *, limit=0, table='assets'):\n        \"\"\"Return an iterator of assets that match the text search\n\n        Args:\n            search (str): Text search string to query the text index\n            limit (int, optional): Limit the number of returned documents.\n\n        Returns:\n            iter: An iterator of assets that match the text search.\n        \"\"\"\n        objects = backend.query.text_search(self.connection, search, limit=limit,\n                                            table=table)\n\n        # TODO: This is not efficient. There may be a more efficient way to\n        #       query by storing block ids with the assets and using fastquery.\n        #       See https://github.com/bigchaindb/bigchaindb/issues/1496\n        for obj in objects:\n            tx, status = self.get_transaction(obj['id'], True)\n            if status == self.TX_VALID:\n                yield obj\n\n\n### bigchaindb/exceptions.py ###\n\nclass BigchainDBError(Exception):\n    \"\"\"Base class for BigchainDB exceptions.\"\"\"\n\n\nclass CriticalDoubleSpend(BigchainDBError):\n    \"\"\"Data integrity error that requires attention\"\"\"\n\n\nclass CriticalDoubleInclusion(BigchainDBError):\n    \"\"\"Data integrity error that requires attention\"\"\"\n\n\nclass CriticalDuplicateVote(BigchainDBError):\n    \"\"\"Data integrity error that requires attention\"\"\"\n\n\n### bigchaindb/voting.py ###\n\nimport collections\n\nfrom bigchaindb.common.schema import SchemaValidationError, validate_vote_schema\nfrom bigchaindb.exceptions import CriticalDuplicateVote\nfrom bigchaindb.common.utils import serialize\nfrom bigchaindb.common.crypto import PublicKey\n\n\nVALID = 'valid'\nINVALID = 'invalid'\nUNDECIDED = 'undecided'\n\n\nclass Voting:\n    \"\"\"Everything to do with verifying and counting votes for block election.\n\n    All functions in this class should be referentially transparent, that is,\n    they always give the same output for a given input. This makes it easier\n    to test. This also means no logging!\n\n    Assumptions regarding data:\n        * Vote is a dictionary, but no assumptions are made on it's properties.\n        * Everything else is assumed to be structurally correct, otherwise errors\n        may be thrown.\n    \"\"\"\n\n    @classmethod\n    def block_election(cls, block, votes, keyring):\n        \"\"\"Calculate the election status of a block.\"\"\"\n        eligible_voters = set(block['block']['voters']) & set(keyring)\n        n_voters = len(eligible_voters)\n        eligible_votes, ineligible_votes = \\\n            cls.partition_eligible_votes(votes, eligible_voters)\n        by_voter = cls.dedupe_by_voter(eligible_votes)\n        results = cls.count_votes(by_voter)\n        results['block_id'] = block['id']\n        results['status'] = cls.decide_votes(n_voters, **results['counts'])\n        results['ineligible'] = ineligible_votes\n        return results\n\n    @classmethod\n    def partition_eligible_votes(cls, votes, eligible_voters):\n        \"\"\"Filter votes from unknown nodes or nodes that are not listed on\n        block. This is the primary Sybill protection.\n        \"\"\"\n        eligible, ineligible = ([], [])\n\n        for vote in votes:\n            voter_eligible = vote.get('node_pubkey') in eligible_voters\n            if voter_eligible:\n                try:\n                    if cls.verify_vote_signature(vote):\n                        eligible.append(vote)\n                        continue\n                except ValueError:\n                    pass\n            ineligible.append(vote)\n        return eligible, ineligible\n\n    @classmethod\n    def dedupe_by_voter(cls, eligible_votes):\n        \"\"\"Throw a critical error if there is a duplicate vote\n        \"\"\"\n        by_voter = {}\n        for vote in eligible_votes:\n            pubkey = vote['node_pubkey']\n            if pubkey in by_voter:\n                raise CriticalDuplicateVote(pubkey)\n            by_voter[pubkey] = vote\n        return by_voter\n\n    @classmethod\n    def count_votes(cls, by_voter):\n        \"\"\"Given a list of eligible votes, (votes from known nodes that are listed\n        as voters), produce the number that say valid and the number that say\n        invalid. Votes must agree on previous block, otherwise they become invalid.\n        \"\"\"\n        prev_blocks = collections.Counter()\n        malformed = []\n\n        for vote in by_voter.values():\n            if not cls.verify_vote_schema(vote):\n                malformed.append(vote)\n                continue\n\n            if vote['vote']['is_block_valid'] is True:\n                prev_blocks[vote['vote']['previous_block']] += 1\n\n        n_valid = 0\n        prev_block = None\n        # Valid votes must agree on previous block\n        if prev_blocks:\n            prev_block, n_valid = prev_blocks.most_common()[0]\n            del prev_blocks[prev_block]\n\n        return {\n            'counts': {\n                'n_valid': n_valid,\n                'n_invalid': len(by_voter) - n_valid,\n            },\n            'malformed': malformed,\n            'previous_block': prev_block,\n            'other_previous_block': dict(prev_blocks),\n        }\n\n    @classmethod\n    def decide_votes(cls, n_voters, n_valid, n_invalid):\n        \"\"\"Decide on votes.\n\n        To return VALID there must be a clear majority that say VALID\n        and also agree on the previous block.\n\n        A tie on an even number of votes counts as INVALID.\n        \"\"\"\n        if n_invalid * 2 >= n_voters:\n            return INVALID\n        if n_valid * 2 > n_voters:\n            return VALID\n        return UNDECIDED\n\n    @classmethod\n    def verify_vote_signature(cls, vote):\n        \"\"\"Verify the signature of a vote\n        \"\"\"\n        signature = vote.get('signature')\n        pk_base58 = vote.get('node_pubkey')\n\n        if not (type(signature) == str and type(pk_base58) == str):\n            raise ValueError('Malformed vote: %s' % vote)\n\n        public_key = PublicKey(pk_base58)\n        body = serialize(vote['vote']).encode()\n        return public_key.verify(body, signature)\n\n    @classmethod\n    def verify_vote_schema(cls, vote):\n        # I'm not sure this is the correct approach. Maybe we should allow\n        # duck typing w/r/t votes.\n        try:\n            validate_vote_schema(vote)\n            return True\n        except SchemaValidationError as e:\n            return False\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\nfrom unittest.mock import patch\nfrom collections import Counter\n\nfrom bigchaindb.core import Bigchain\nfrom bigchaindb.exceptions import CriticalDuplicateVote\nfrom bigchaindb.voting import Voting, INVALID, VALID, UNDECIDED\n\n\n################################################################################\n# Tests for checking vote eligibility\n\n\ndef test_partition_eligible_votes():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            if vote['node_pubkey'] == 'invalid sig':\n                return False\n            if vote['node_pubkey'] == 'value error':\n                raise ValueError()\n            return True\n\n    voters = ['valid', 'invalid sig', 'value error', 'not in set']\n    votes = [{'node_pubkey': k} for k in voters]\n\n    el, inel = TestVoting.partition_eligible_votes(votes, voters[:-1])\n    assert el == [votes[0]]\n    assert inel == votes[1:]\n\n\n################################################################################\n# Test vote counting\n\n\ndef test_count_votes():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return vote['node_pubkey'] != 'malformed'\n\n    voters = (['says invalid', 'malformed'] +\n              ['kosher' + str(i) for i in range(10)])\n\n    votes = [Bigchain(v).vote('block', 'a', True) for v in voters]\n    votes[0]['vote']['is_block_valid'] = False\n    # Incorrect previous block subtracts from n_valid and adds to n_invalid\n    votes[-1]['vote']['previous_block'] = 'z'\n\n    by_voter = dict(enumerate(votes))\n\n    assert TestVoting.count_votes(by_voter) == {\n        'counts': {\n            'n_valid': 9,    # 9 kosher votes\n            'n_invalid': 3,  # 1 invalid, 1 malformed, 1 rogue prev block\n        },\n        'malformed': [votes[1]],\n        'previous_block': 'a',\n        'other_previous_block': {'z': 1},\n    }\n\n\ndef test_must_agree_prev_block():\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return True\n\n    voters = 'abcd'\n    votes = [Bigchain(v).vote('block', 'a', True) for v in voters]\n    votes[0]['vote']['previous_block'] = 'b'\n    votes[1]['vote']['previous_block'] = 'c'\n    by_voter = dict(enumerate(votes))\n    assert TestVoting.count_votes(by_voter) == {\n        'counts': {\n            'n_valid': 2,\n            'n_invalid': 2,\n        },\n        'previous_block': 'a',\n        'other_previous_block': {'b': 1, 'c': 1},\n        'malformed': [],\n    }\n\n\n################################################################################\n# Tests for vote decision making\n\n\nDECISION_TESTS = [\n    {'n_voters': 1, 'n_valid': 1, 'n_invalid': 1},\n    {'n_voters': 2, 'n_valid': 2, 'n_invalid': 1},\n    {'n_voters': 3, 'n_valid': 2, 'n_invalid': 2},\n    {'n_voters': 4, 'n_valid': 3, 'n_invalid': 2},\n    {'n_voters': 5, 'n_valid': 3, 'n_invalid': 3},\n    {'n_voters': 6, 'n_valid': 4, 'n_invalid': 3},\n    {'n_voters': 7, 'n_valid': 4, 'n_invalid': 4},\n    {'n_voters': 8, 'n_valid': 5, 'n_invalid': 4}\n]\n\n\n@pytest.mark.parametrize('kwargs', DECISION_TESTS)\ndef test_decide_votes_valid(kwargs):\n    kwargs = kwargs.copy()\n    kwargs['n_invalid'] = 0\n    assert Voting.decide_votes(**kwargs) == VALID\n    kwargs['n_valid'] -= 1\n    assert Voting.decide_votes(**kwargs) == UNDECIDED\n\n\n@pytest.mark.parametrize('kwargs', DECISION_TESTS)\ndef test_decide_votes_invalid(kwargs):\n    kwargs = kwargs.copy()\n    kwargs['n_valid'] = 0\n    assert Voting.decide_votes(**kwargs) == INVALID\n    kwargs['n_invalid'] -= 1\n    assert Voting.decide_votes(**kwargs) == UNDECIDED\n\n\n################################################################################\n# Actions - test state transitions\n\n\n@pytest.mark.parametrize('n_voters', range(8))\ndef test_vote_actions(n_voters):\n    \"\"\"* Legal transitions are UNDECIDED -> [VALID|INVALID] only\n    * Block is never left UNDECIDED after voting\n    * Accomodates rogues on previous block / invalid schema\n    \"\"\"\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return type(vote['vote']['is_block_valid']) == bool\n\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            return True\n\n    keyring = 'abcdefghijklmnopqrstuvwxyz'[:n_voters]\n    block = {'id': 'block', 'block': {'voters': keyring}}\n    state = UNDECIDED\n    todo = [(state, [], [])]\n\n    def branch(p, r):\n        todo.append((state, votes, votes + [{\n            'node_pubkey': keyring[len(votes)],\n            'vote': {'previous_block': p, 'is_block_valid': r}\n        }]))\n\n    while todo:\n        prev_state, prev_votes, votes = todo.pop(0)\n        results = Counter(v['vote']['is_block_valid'] for v in votes)\n        prev_blocks = Counter(v['vote']['previous_block'] for v in votes)\n        majority = n_voters // 2 + 1\n        honest = (len(votes) == majority and len(prev_blocks) == 1 and\n                  not results['lol'] and len(results) == 1)\n        closed = len(votes) == n_voters\n\n        # Test legal transition\n        if votes:\n            state = TestVoting.block_election(block, votes, keyring)['status']\n            assert prev_state in [state, UNDECIDED]\n\n        # Test that decision has been reached\n        if honest or closed:\n            assert state != UNDECIDED or n_voters == 0\n\n        if closed:\n            continue\n\n        # Can accomodate more votes, add them to the todo list.\n        # This vote is the good case\n        branch('A', True)\n        # This vote disagrees on previous block\n        branch('B', True)\n        # This vote says the block is invalid\n        branch('A', False)\n        # This vote is invalid\n        branch('A', 'lol')\n\n\n################################################################################\n# Tests for vote signature\n\n\ndef test_verify_vote_signature_passes(b):\n    vote = b.vote('block', 'a', True)\n    assert Voting.verify_vote_signature(vote)\n    vote['signature'] = ''\n    assert not Voting.verify_vote_signature(vote)\n\n\n################################################################################\n# Tests for vote schema\n\n\ndef test_verify_vote_schema(b):\n    vote = b.vote('b' * 64, 'a' * 64, True)\n    assert Voting.verify_vote_schema(vote)\n    vote = b.vote('b' * 64, 'a', True)\n    assert not Voting.verify_vote_schema(vote)\n    vote = b.vote('b', 'a' * 64, True)\n    assert not Voting.verify_vote_schema(vote)\n\n\n################################################################################\n# block_election tests\n\n\ndef test_block_election(b):\n\n    class TestVoting(Voting):\n        @classmethod\n        def verify_vote_signature(cls, vote):\n            return True\n\n        @classmethod\n        def verify_vote_schema(cls, vote):\n            return True\n\n    keyring = 'abc'\n    block = {'id': 'xyz', 'block': {'voters': 'ab'}}\n    votes = [{\n        'node_pubkey': c,\n        'vote': {'is_block_valid': True, 'previous_block': 'a'}\n    } for c in 'abc']\n\n    assert TestVoting.block_election(block, votes, keyring) == {\n        'status': VALID,\n        'block_id': 'xyz',\n        'counts': {'n_valid': 2, 'n_invalid': 0},\n        'ineligible': [votes[-1]],\n        'malformed': [],\n        'previous_block': 'a',\n        'other_previous_block': {},\n    }\n\n\n@patch('bigchaindb.voting.Voting.verify_vote_signature', return_value=True)\ndef test_duplicate_vote_throws_critical_error(b):\n    keyring = 'abc'\n    block = {'id': 'xyz', 'block': {'voters': 'ab'}}\n    votes = [{\n        'node_pubkey': c,\n        'vote': {'is_block_valid': True, 'previous_block': 'a'}\n    } for c in 'aabc']\n    with pytest.raises(CriticalDuplicateVote):\n        Voting.block_election(block, votes, keyring)\n"
  },
  {
    "prompt": "\n\n### greenery/fsm.py ###\n\n# -*- coding: utf-8 -*-\n\n'''\n\tFinite state machine library.\n'''\n\nclass anything_else_cls:\n\t'''\n\t\tThis is a surrogate symbol which you can use in your finite state machines\n\t\tto represent \"any symbol not in the official alphabet\". For example, if your\n\t\tstate machine's alphabet is {\"a\", \"b\", \"c\", \"d\", fsm.anything_else}, then\n\t\tyou can pass \"e\" in as a symbol and it will be converted to\n\t\tfsm.anything_else, then follow the appropriate transition.\n\t'''\n\tdef __str__(self):\n\t\treturn \"anything_else\"\n\tdef __repr__(self):\n\t\treturn \"anything_else\"\n\n# We use a class instance because that gives us control over how the special\n# value gets serialised. Otherwise this would just be `object()`.\nanything_else = anything_else_cls()\n\ndef key(symbol):\n\t'''Ensure `fsm.anything_else` always sorts last'''\n\treturn (symbol is anything_else, symbol)\n\nclass OblivionError(Exception):\n\t'''\n\t\tThis exception is thrown while `crawl()`ing an FSM if we transition to the\n\t\toblivion state. For example while crawling two FSMs in parallel we may\n\t\ttransition to the oblivion state of both FSMs at once. This warrants an\n\t\tout-of-bound signal which will reduce the complexity of the new FSM's map.\n\t'''\n\tpass\n\nclass fsm:\n\t'''\n\t\tA Finite State Machine or FSM has an alphabet and a set of states. At any\n\t\tgiven moment, the FSM is in one state. When passed a symbol from the\n\t\talphabet, the FSM jumps to another state (or possibly the same state).\n\t\tA map (Python dictionary) indicates where to jump.\n\t\tOne state is nominated as a starting state. Zero or more states are\n\t\tnominated as final states. If, after consuming a string of symbols,\n\t\tthe FSM is in a final state, then it is said to \"accept\" the string.\n\t\tThis class also has some pretty powerful methods which allow FSMs to\n\t\tbe concatenated, alternated between, multiplied, looped (Kleene star\n\t\tclosure), intersected, and simplified.\n\t\tThe majority of these methods are available using operator overloads.\n\t'''\n\tdef __setattr__(self, name, value):\n\t\t'''Immutability prevents some potential problems.'''\n\t\traise Exception(\"This object is immutable.\")\n\n\tdef __init__(self, alphabet, states, initial, finals, map):\n\t\t'''\n\t\t\t`alphabet` is an iterable of symbols the FSM can be fed.\n\t\t\t`states` is the set of states for the FSM\n\t\t\t`initial` is the initial state\n\t\t\t`finals` is the set of accepting states\n\t\t\t`map` may be sparse (i.e. it may omit transitions). In the case of omitted\n\t\t\ttransitions, a non-final \"oblivion\" state is simulated.\n\t\t'''\n\n\t\t# Validation. Thanks to immutability, this only needs to be carried out once.\n\t\tif not initial in states:\n\t\t\traise Exception(\"Initial state \" + repr(initial) + \" must be one of \" + repr(states))\n\t\tif not finals.issubset(states):\n\t\t\traise Exception(\"Final states \" + repr(finals) + \" must be a subset of \" + repr(states))\n\t\tfor state in map.keys():\n\t\t\tfor symbol in map[state]:\n\t\t\t\tif not map[state][symbol] in states:\n\t\t\t\t\traise Exception(\"Transition for state \" + repr(state) + \" and symbol \" + repr(symbol) + \" leads to \" + repr(map[state][symbol]) + \", which is not a state\")\n\n\t\t# Initialise the hard way due to immutability.\n\t\tself.__dict__[\"alphabet\"] = set(alphabet)\n\t\tself.__dict__[\"states\"  ] = set(states)\n\t\tself.__dict__[\"initial\" ] = initial\n\t\tself.__dict__[\"finals\"  ] = set(finals)\n\t\tself.__dict__[\"map\"     ] = map\n\n\tdef accepts(self, input):\n\t\t'''\n\t\t\tTest whether the present FSM accepts the supplied string (iterable of\n\t\t\tsymbols). Equivalently, consider `self` as a possibly-infinite set of\n\t\t\tstrings and test whether `string` is a member of it.\n\t\t\tThis is actually mainly used for unit testing purposes.\n\t\t\tIf `fsm.anything_else` is in your alphabet, then any symbol not in your\n\t\t\talphabet will be converted to `fsm.anything_else`.\n\t\t'''\n\t\tstate = self.initial\n\t\tfor symbol in input:\n\t\t\tif anything_else in self.alphabet and not symbol in self.alphabet:\n\t\t\t\tsymbol = anything_else\n\n\t\t\t# Missing transition = transition to dead state\n\t\t\tif not (state in self.map and symbol in self.map[state]):\n\t\t\t\treturn False\n\n\t\t\tstate = self.map[state][symbol]\n\t\treturn state in self.finals\n\n\tdef __contains__(self, string):\n\t\t'''\n\t\t\tThis lets you use the syntax `\"a\" in fsm1` to see whether the string \"a\"\n\t\t\tis in the set of strings accepted by `fsm1`.\n\t\t'''\n\t\treturn self.accepts(string)\n\n\tdef reduce(self):\n\t\t'''\n\t\t\tA result by Brzozowski (1963) shows that a minimal finite state machine\n\t\t\tequivalent to the original can be obtained by reversing the original\n\t\t\ttwice.\n\t\t'''\n\t\treturn reversed(reversed(self))\n\n\tdef __repr__(self):\n\t\tstring = \"fsm(\"\n\t\tstring += \"alphabet = \" + repr(self.alphabet)\n\t\tstring += \", states = \" + repr(self.states)\n\t\tstring += \", initial = \" + repr(self.initial)\n\t\tstring += \", finals = \" + repr(self.finals)\n\t\tstring += \", map = \" + repr(self.map)\n\t\tstring += \")\"\n\t\treturn string\n\n\tdef __str__(self):\n\t\trows = []\n\n\t\t# top row\n\t\trow = [\"\", \"name\", \"final?\"]\n\t\trow.extend(str(symbol) for symbol in sorted(self.alphabet, key=key))\n\t\trows.append(row)\n\n\t\t# other rows\n\t\tfor state in self.states:\n\t\t\trow = []\n\t\t\tif state == self.initial:\n\t\t\t\trow.append(\"*\")\n\t\t\telse:\n\t\t\t\trow.append(\"\")\n\t\t\trow.append(str(state))\n\t\t\tif state in self.finals:\n\t\t\t\trow.append(\"True\")\n\t\t\telse:\n\t\t\t\trow.append(\"False\")\n\t\t\tfor symbol in sorted(self.alphabet, key=key):\n\t\t\t\tif state in self.map and symbol in self.map[state]:\n\t\t\t\t\trow.append(str(self.map[state][symbol]))\n\t\t\t\telse:\n\t\t\t\t\trow.append(\"\")\n\t\t\trows.append(row)\n\n\t\t# column widths\n\t\tcolwidths = []\n\t\tfor x in range(len(rows[0])):\n\t\t\tcolwidths.append(max(len(str(rows[y][x])) for y in range(len(rows))) + 1)\n\n\t\t# apply padding\n\t\tfor y in range(len(rows)):\n\t\t\tfor x in range(len(rows[y])):\n\t\t\t\trows[y][x] = rows[y][x].ljust(colwidths[x])\n\n\t\t# horizontal line\n\t\trows.insert(1, [\"-\" * colwidth for colwidth in colwidths])\n\n\t\treturn \"\".join(\"\".join(row) + \"\\n\" for row in rows)\n\n\tdef concatenate(*fsms):\n\t\t'''\n\t\t\tConcatenate arbitrarily many finite state machines together.\n\t\t'''\n\t\talphabet = set().union(*[fsm.alphabet for fsm in fsms])\n\n\t\tdef connect_all(i, substate):\n\t\t\t'''\n\t\t\t\tTake a state in the numbered FSM and return a set containing it, plus\n\t\t\t\t(if it's final) the first state from the next FSM, plus (if that's\n\t\t\t\tfinal) the first state from the next but one FSM, plus...\n\t\t\t'''\n\t\t\tresult = {(i, substate)}\n\t\t\twhile i < len(fsms) - 1 and substate in fsms[i].finals:\n\t\t\t\ti += 1\n\t\t\t\tsubstate = fsms[i].initial\n\t\t\t\tresult.add((i, substate))\n\t\t\treturn result\n\n\t\t# Use a superset containing states from all FSMs at once.\n\t\t# We start at the start of the first FSM. If this state is final in the\n\t\t# first FSM, then we are also at the start of the second FSM. And so on.\n\t\tinitial = set()\n\t\tif len(fsms) > 0:\n\t\t\tinitial.update(connect_all(0, fsms[0].initial))\n\t\tinitial = frozenset(initial)\n\n\t\tdef final(state):\n\t\t\t'''If you're in a final state of the final FSM, it's final'''\n\t\t\tfor (i, substate) in state:\n\t\t\t\tif i == len(fsms) - 1 and substate in fsms[i].finals:\n\t\t\t\t\treturn True\n\t\t\treturn False\n\n\t\tdef follow(current, symbol):\n\t\t\t'''\n\t\t\t\tFollow the collection of states through all FSMs at once, jumping to the\n\t\t\t\tnext FSM if we reach the end of the current one\n\t\t\t\tTODO: improve all follow() implementations to allow for dead metastates?\n\t\t\t'''\n\t\t\tnext = set()\n\t\t\tfor (i, substate) in current:\n\t\t\t\tfsm = fsms[i]\n\t\t\t\tif substate in fsm.map:\n\t\t\t\t\tif symbol in fsm.map[substate]:\n\t\t\t\t\t\tnext.update(connect_all(i, fsm.map[substate][symbol]))\n\t\t\t\t\telif  anything_else in fsm.map[substate] and symbol not in fsm.alphabet:\n\t\t\t\t\t\tnext.update(connect_all(i,fsm.map[substate][anything_else]))\n\t\t\tif len(next) == 0:\n\t\t\t\traise OblivionError\n\t\t\treturn frozenset(next)\n\n\t\treturn crawl(alphabet, initial, final, follow).reduce()\n\n\tdef __add__(self, other):\n\t\t'''\n\t\t\tConcatenate two finite state machines together.\n\t\t\tFor example, if self accepts \"0*\" and other accepts \"1+(0|1)\",\n\t\t\twill return a finite state machine accepting \"0*1+(0|1)\".\n\t\t\tAccomplished by effectively following non-deterministically.\n\t\t\tCall using \"fsm3 = fsm1 + fsm2\"\n\t\t'''\n\t\treturn self.concatenate(other)\n\n\tdef star(self):\n\t\t'''\n\t\t\tIf the present FSM accepts X, returns an FSM accepting X* (i.e. 0 or\n\t\t\tmore Xes). This is NOT as simple as naively connecting the final states\n\t\t\tback to the initial state: see (b*ab)* for example.\n\t\t'''\n\t\talphabet = self.alphabet\n\n\t\tinitial = {self.initial}\n\n\t\tdef follow(state, symbol):\n\t\t\tnext = set()\n\t\t\tfor substate in state:\n\t\t\t\tif substate in self.map and symbol in self.map[substate]:\n\t\t\t\t\tnext.add(self.map[substate][symbol])\n\n\t\t\t\t# If one of our substates is final, then we can also consider\n\t\t\t\t# transitions from the initial state of the original FSM.\n\t\t\t\tif substate in self.finals \\\n\t\t\t\tand self.initial in self.map \\\n\t\t\t\tand symbol in self.map[self.initial]:\n\t\t\t\t\tnext.add(self.map[self.initial][symbol])\n\n\t\t\tif len(next) == 0:\n\t\t\t\traise OblivionError\n\n\t\t\treturn frozenset(next)\n\n\t\tdef final(state):\n\t\t\treturn any(substate in self.finals for substate in state)\n\n\t\treturn crawl(alphabet, initial, final, follow) | epsilon(alphabet)\n\n\tdef times(self, multiplier):\n\t\t'''\n\t\t\tGiven an FSM and a multiplier, return the multiplied FSM.\n\t\t'''\n\t\tif multiplier < 0:\n\t\t\traise Exception(\"Can't multiply an FSM by \" + repr(multiplier))\n\n\t\talphabet = self.alphabet\n\n\t\t# metastate is a set of iterations+states\n\t\tinitial = {(self.initial, 0)}\n\n\t\tdef final(state):\n\t\t\t'''If the initial state is final then multiplying doesn't alter that'''\n\t\t\tfor (substate, iteration) in state:\n\t\t\t\tif substate == self.initial \\\n\t\t\t\tand (self.initial in self.finals or iteration == multiplier):\n\t\t\t\t\treturn True\n\t\t\treturn False\n\n\t\tdef follow(current, symbol):\n\t\t\tnext = []\n\t\t\tfor (substate, iteration) in current:\n\t\t\t\tif iteration < multiplier \\\n\t\t\t\tand substate in self.map \\\n\t\t\t\tand symbol in self.map[substate]:\n\t\t\t\t\tnext.append((self.map[substate][symbol], iteration))\n\t\t\t\t\t# final of self? merge with initial on next iteration\n\t\t\t\t\tif self.map[substate][symbol] in self.finals:\n\t\t\t\t\t\tnext.append((self.initial, iteration + 1))\n\t\t\tif len(next) == 0:\n\t\t\t\traise OblivionError\n\t\t\treturn frozenset(next)\n\n\t\treturn crawl(alphabet, initial, final, follow).reduce()\n\n\tdef __mul__(self, multiplier):\n\t\t'''\n\t\t\tGiven an FSM and a multiplier, return the multiplied FSM.\n\t\t'''\n\t\treturn self.times(multiplier)\n\n\tdef union(*fsms):\n\t\t'''\n\t\t\tTreat `fsms` as a collection of arbitrary FSMs and return the union FSM.\n\t\t\tCan be used as `fsm1.union(fsm2, ...)` or `fsm.union(fsm1, ...)`. `fsms`\n\t\t\tmay be empty.\n\t\t'''\n\t\treturn parallel(fsms, any)\n\n\tdef __or__(self, other):\n\t\t'''\n\t\t\tAlternation.\n\t\t\tReturn a finite state machine which accepts any sequence of symbols\n\t\t\tthat is accepted by either self or other. Note that the set of strings\n\t\t\trecognised by the two FSMs undergoes a set union.\n\t\t\tCall using \"fsm3 = fsm1 | fsm2\"\n\t\t'''\n\t\treturn self.union(other)\n\n\tdef intersection(*fsms):\n\t\t'''\n\t\t\tIntersection.\n\t\t\tTake FSMs and AND them together. That is, return an FSM which\n\t\t\taccepts any sequence of symbols that is accepted by both of the original\n\t\t\tFSMs. Note that the set of strings recognised by the two FSMs undergoes\n\t\t\ta set intersection operation.\n\t\t\tCall using \"fsm3 = fsm1 & fsm2\"\n\t\t'''\n\t\treturn parallel(fsms, all)\n\n\tdef __and__(self, other):\n\t\t'''\n\t\t\tTreat the FSMs as sets of strings and return the intersection of those\n\t\t\tsets in the form of a new FSM. `fsm1.intersection(fsm2, ...)` or\n\t\t\t`fsm.intersection(fsm1, ...)` are acceptable.\n\t\t'''\n\t\treturn self.intersection(other)\n\n\tdef symmetric_difference(*fsms):\n\t\t'''\n\t\t\tTreat `fsms` as a collection of sets of strings and compute the symmetric\n\t\t\tdifference of them all. The python set method only allows two sets to be\n\t\t\toperated on at once, but we go the extra mile since it's not too hard.\n\t\t'''\n\t\treturn parallel(fsms, lambda accepts: (accepts.count(True) % 2) == 1)\n\n\tdef __xor__(self, other):\n\t\t'''\n\t\t\tSymmetric difference. Returns an FSM which recognises only the strings\n\t\t\trecognised by `self` or `other` but not both.\n\t\t'''\n\t\treturn self.symmetric_difference(other)\n\n\tdef everythingbut(self):\n\t\t'''\n\t\t\tReturn a finite state machine which will accept any string NOT\n\t\t\taccepted by self, and will not accept any string accepted by self.\n\t\t\tThis is more complicated if there are missing transitions, because the\n\t\t\tmissing \"dead\" state must now be reified.\n\t\t'''\n\t\talphabet = self.alphabet\n\n\t\tinitial = {0 : self.initial}\n\n\t\tdef follow(current, symbol):\n\t\t\tnext = {}\n\t\t\tif 0 in current and current[0] in self.map and symbol in self.map[current[0]]:\n\t\t\t\tnext[0] = self.map[current[0]][symbol]\n\t\t\treturn next\n\n\t\t# state is final unless the original was\n\t\tdef final(state):\n\t\t\treturn not (0 in state and state[0] in self.finals)\n\n\t\treturn crawl(alphabet, initial, final, follow).reduce()\n\n\tdef reversed(self):\n\t\t'''\n\t\t\tReturn a new FSM such that for every string that self accepts (e.g.\n\t\t\t\"beer\", the new FSM accepts the reversed string (\"reeb\").\n\t\t'''\n\t\talphabet = self.alphabet\n\n\t\t# Start from a composite \"state-set\" consisting of all final states.\n\t\t# If there are no final states, this set is empty and we'll find that\n\t\t# no other states get generated.\n\t\tinitial = frozenset(self.finals)\n\n\t\t# Find every possible way to reach the current state-set\n\t\t# using this symbol.\n\t\tdef follow(current, symbol):\n\t\t\tnext = frozenset([\n\t\t\t\tprev\n\t\t\t\tfor prev in self.map\n\t\t\t\tfor state in current\n\t\t\t\tif symbol in self.map[prev] and self.map[prev][symbol] == state\n\t\t\t])\n\t\t\tif len(next) == 0:\n\t\t\t\traise OblivionError\n\t\t\treturn next\n\n\t\t# A state-set is final if the initial state is in it.\n\t\tdef final(state):\n\t\t\treturn self.initial in state\n\n\t\t# Man, crawl() is the best!\n\t\treturn crawl(alphabet, initial, final, follow)\n\t\t# Do not reduce() the result, since reduce() calls us in turn\n\n\tdef __reversed__(self):\n\t\t'''\n\t\t\tReturn a new FSM such that for every string that self accepts (e.g.\n\t\t\t\"beer\", the new FSM accepts the reversed string (\"reeb\").\n\t\t'''\n\t\treturn self.reversed()\n\n\tdef islive(self, state):\n\t\t'''A state is \"live\" if a final state can be reached from it.'''\n\t\treachable = [state]\n\t\ti = 0\n\t\twhile i < len(reachable):\n\t\t\tcurrent = reachable[i]\n\t\t\tif current in self.finals:\n\t\t\t\treturn True\n\t\t\tif current in self.map:\n\t\t\t\tfor symbol in self.map[current]:\n\t\t\t\t\tnext = self.map[current][symbol]\n\t\t\t\t\tif next not in reachable:\n\t\t\t\t\t\treachable.append(next)\n\t\t\ti += 1\n\t\treturn False\n\n\tdef empty(self):\n\t\t'''\n\t\t\tAn FSM is empty if it recognises no strings. An FSM may be arbitrarily\n\t\t\tcomplicated and have arbitrarily many final states while still recognising\n\t\t\tno strings because those final states may all be inaccessible from the\n\t\t\tinitial state. Equally, an FSM may be non-empty despite having an empty\n\t\t\talphabet if the initial state is final.\n\t\t'''\n\t\treturn not self.islive(self.initial)\n\n\tdef strings(self):\n\t\t'''\n\t\t\tGenerate strings (lists of symbols) that this FSM accepts. Since there may\n\t\t\tbe infinitely many of these we use a generator instead of constructing a\n\t\t\tstatic list. Strings will be sorted in order of length and then lexically.\n\t\t\tThis procedure uses arbitrary amounts of memory but is very fast. There\n\t\t\tmay be more efficient ways to do this, that I haven't investigated yet.\n\t\t\tYou can use this in list comprehensions.\n\t\t'''\n\n\t\t# Many FSMs have \"dead states\". Once you reach a dead state, you can no\n\t\t# longer reach a final state. Since many strings may end up here, it's\n\t\t# advantageous to constrain our search to live states only.\n\t\tlivestates = set(state for state in self.states if self.islive(state))\n\n\t\t# We store a list of tuples. Each tuple consists of an input string and the\n\t\t# state that this input string leads to. This means we don't have to run the\n\t\t# state machine from the very beginning every time we want to check a new\n\t\t# string.\n\t\tstrings = []\n\n\t\t# Initial entry (or possibly not, in which case this is a short one)\n\t\tcstate = self.initial\n\t\tcstring = []\n\t\tif cstate in livestates:\n\t\t\tif cstate in self.finals:\n\t\t\t\tyield cstring\n\t\t\tstrings.append((cstring, cstate))\n\n\t\t# Fixed point calculation\n\t\ti = 0\n\t\twhile i < len(strings):\n\t\t\t(cstring, cstate) = strings[i]\n\t\t\tif cstate in self.map:\n\t\t\t\tfor symbol in sorted(self.map[cstate], key=key):\n\t\t\t\t\tnstate = self.map[cstate][symbol]\n\t\t\t\t\tnstring = cstring + [symbol]\n\t\t\t\t\tif nstate in livestates:\n\t\t\t\t\t\tif nstate in self.finals:\n\t\t\t\t\t\t\tyield nstring\n\t\t\t\t\t\tstrings.append((nstring, nstate))\n\t\t\ti += 1\n\n\tdef __iter__(self):\n\t\t'''\n\t\t\tThis allows you to do `for string in fsm1` as a list comprehension!\n\t\t'''\n\t\treturn self.strings()\n\n\tdef equivalent(self, other):\n\t\t'''\n\t\t\tTwo FSMs are considered equivalent if they recognise the same strings.\n\t\t\tOr, to put it another way, if their symmetric difference recognises no\n\t\t\tstrings.\n\t\t'''\n\t\treturn (self ^ other).empty()\n\n\tdef __eq__(self, other):\n\t\t'''\n\t\t\tYou can use `fsm1 == fsm2` to determine whether two FSMs recognise the\n\t\t\tsame strings.\n\t\t'''\n\t\treturn self.equivalent(other)\n\n\tdef different(self, other):\n\t\t'''\n\t\t\tTwo FSMs are considered different if they have a non-empty symmetric\n\t\t\tdifference.\n\t\t'''\n\t\treturn not (self ^ other).empty()\n\n\tdef __ne__(self, other):\n\t\t'''\n\t\t\tUse `fsm1 != fsm2` to determine whether two FSMs recognise different\n\t\t\tstrings.\n\t\t'''\n\t\treturn self.different(other)\n\n\tdef difference(*fsms):\n\t\t'''\n\t\t\tDifference. Returns an FSM which recognises only the strings\n\t\t\trecognised by the first FSM in the list, but none of the others.\n\t\t'''\n\t\treturn parallel(fsms, lambda accepts: accepts[0] and not any(accepts[1:]))\n\n\tdef __sub__(self, other):\n\t\treturn self.difference(other)\n\n\tdef cardinality(self):\n\t\t'''\n\t\t\tConsider the FSM as a set of strings and return the cardinality of that\n\t\t\tset, or raise an OverflowError if there are infinitely many\n\t\t'''\n\t\tnum_strings = {}\n\t\tdef get_num_strings(state):\n\t\t\t# Many FSMs have at least one oblivion state\n\t\t\tif self.islive(state):\n\t\t\t\tif state in num_strings:\n\t\t\t\t\tif num_strings[state] is None: # \"computing...\"\n\t\t\t\t\t\t# Recursion! There are infinitely many strings recognised\n\t\t\t\t\t\traise OverflowError(state)\n\t\t\t\t\treturn num_strings[state]\n\t\t\t\tnum_strings[state] = None # i.e. \"computing...\"\n\n\t\t\t\tn = 0\n\t\t\t\tif state in self.finals:\n\t\t\t\t\tn += 1\n\t\t\t\tif state in self.map:\n\t\t\t\t\tfor symbol in self.map[state]:\n\t\t\t\t\t\tn += get_num_strings(self.map[state][symbol])\n\t\t\t\tnum_strings[state] = n\n\n\t\t\telse:\n\t\t\t\t# Dead state\n\t\t\t\tnum_strings[state] = 0\n\n\t\t\treturn num_strings[state]\n\n\t\treturn get_num_strings(self.initial)\n\n\tdef __len__(self):\n\t\t'''\n\t\t\tConsider the FSM as a set of strings and return the cardinality of that\n\t\t\tset, or raise an OverflowError if there are infinitely many\n\t\t'''\n\t\treturn self.cardinality()\n\n\tdef isdisjoint(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if they are disjoint\n\t\t'''\n\t\treturn (self & other).empty()\n\n\tdef issubset(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a subset\n\t\t\tof `other`... `self` recognises no strings which `other` doesn't.\n\t\t'''\n\t\treturn (self - other).empty()\n\n\tdef __le__(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a subset\n\t\t\tof `other`... `self` recognises no strings which `other` doesn't.\n\t\t'''\n\t\treturn self.issubset(other)\n\n\tdef ispropersubset(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a proper\n\t\t\tsubset of `other`.\n\t\t'''\n\t\treturn self <= other and self != other\n\n\tdef __lt__(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a strict\n\t\t\tsubset of `other`.\n\t\t'''\n\t\treturn self.ispropersubset(other)\n\n\tdef issuperset(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a\n\t\t\tsuperset of `other`.\n\t\t'''\n\t\treturn (other - self).empty()\n\n\tdef __ge__(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a\n\t\t\tsuperset of `other`.\n\t\t'''\n\t\treturn self.issuperset(other)\n\n\tdef ispropersuperset(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a proper\n\t\t\tsuperset of `other`.\n\t\t'''\n\t\treturn self >= other and self != other\n\n\tdef __gt__(self, other):\n\t\t'''\n\t\t\tTreat `self` and `other` as sets of strings and see if `self` is a\n\t\t\tstrict superset of `other`.\n\t\t'''\n\t\treturn self.ispropersuperset(other)\n\n\tdef copy(self):\n\t\t'''\n\t\t\tFor completeness only, since `set.copy()` also exists. FSM objects are\n\t\t\timmutable, so I can see only very odd reasons to need this.\n\t\t'''\n\t\treturn fsm(\n\t\t\talphabet = self.alphabet,\n\t\t\tstates   = self.states,\n\t\t\tinitial  = self.initial,\n\t\t\tfinals   = self.finals,\n\t\t\tmap      = self.map,\n\t\t)\n\n\tdef derive(self, input):\n\t\t'''\n\t\t\tCompute the Brzozowski derivative of this FSM with respect to the input\n\t\t\tstring of symbols. <https://en.wikipedia.org/wiki/Brzozowski_derivative>\n\t\t\tIf any of the symbols are not members of the alphabet, that's a KeyError.\n\t\t\tIf you fall into oblivion, then the derivative is an FSM accepting no\n\t\t\tstrings.\n\t\t'''\n\t\ttry:\n\t\t\t# Consume the input string.\n\t\t\tstate = self.initial\n\t\t\tfor symbol in input:\n\t\t\t\tif not symbol in self.alphabet:\n\t\t\t\t\tif not anything_else in self.alphabet:\n\t\t\t\t\t\traise KeyError(symbol)\n\t\t\t\t\tsymbol = anything_else\n\n\t\t\t\t# Missing transition = transition to dead state\n\t\t\t\tif not (state in self.map and symbol in self.map[state]):\n\t\t\t\t\traise OblivionError\n\n\t\t\t\tstate = self.map[state][symbol]\n\n\t\t\t# OK so now we have consumed that string, use the new location as the\n\t\t\t# starting point.\n\t\t\treturn fsm(\n\t\t\t\talphabet = self.alphabet,\n\t\t\t\tstates   = self.states,\n\t\t\t\tinitial  = state,\n\t\t\t\tfinals   = self.finals,\n\t\t\t\tmap      = self.map,\n\t\t\t)\n\n\t\texcept OblivionError:\n\t\t\t# Fell out of the FSM. The derivative of this FSM is the empty FSM.\n\t\t\treturn null(self.alphabet)\n\ndef null(alphabet):\n\t'''\n\t\tAn FSM accepting nothing (not even the empty string). This is\n\t\tdemonstrates that this is possible, and is also extremely useful\n\t\tin some situations\n\t'''\n\treturn fsm(\n\t\talphabet = alphabet,\n\t\tstates   = {0},\n\t\tinitial  = 0,\n\t\tfinals   = set(),\n\t\tmap      = {\n\t\t\t0: dict([(symbol, 0) for symbol in alphabet]),\n\t\t},\n\t)\n\ndef epsilon(alphabet):\n\t'''\n\t\tReturn an FSM matching an empty string, \"\", only.\n\t\tThis is very useful in many situations\n\t'''\n\treturn fsm(\n\t\talphabet = alphabet,\n\t\tstates   = {0},\n\t\tinitial  = 0,\n\t\tfinals   = {0},\n\t\tmap      = {},\n\t)\n\ndef parallel(fsms, test):\n\t'''\n\t\tCrawl several FSMs in parallel, mapping the states of a larger meta-FSM.\n\t\tTo determine whether a state in the larger FSM is final, pass all of the\n\t\tfinality statuses (e.g. [True, False, False] to `test`.\n\t'''\n\talphabet = set().union(*[fsm.alphabet for fsm in fsms])\n\n\tinitial = dict([(i, fsm.initial) for (i, fsm) in enumerate(fsms)])\n\n\t# dedicated function accepts a \"superset\" and returns the next \"superset\"\n\t# obtained by following this transition in the new FSM\n\tdef follow(current, symbol):\n\t\tnext = {}\n\t\tfor i in range(len(fsms)):\n\t\t\tif symbol not in fsms[i].alphabet and anything_else in fsms[i].alphabet:\n\t\t\t\tactual_symbol = anything_else\n\t\t\telse:\n\t\t\t\tactual_symbol = symbol\n\t\t\tif i in current \\\n\t\t\tand current[i] in fsms[i].map \\\n\t\t\tand actual_symbol in fsms[i].map[current[i]]:\n\t\t\t\tnext[i] = fsms[i].map[current[i]][actual_symbol]\n\t\tif len(next.keys()) == 0:\n\t\t\traise OblivionError\n\t\treturn next\n\n\t# Determine the \"is final?\" condition of each substate, then pass it to the\n\t# test to determine finality of the overall FSM.\n\tdef final(state):\n\t\taccepts = [i in state and state[i] in fsm.finals for (i, fsm) in enumerate(fsms)]\n\t\treturn test(accepts)\n\n\treturn crawl(alphabet, initial, final, follow).reduce()\n\ndef crawl(alphabet, initial, final, follow):\n\t'''\n\t\tGiven the above conditions and instructions, crawl a new unknown FSM,\n\t\tmapping its states, final states and transitions. Return the new FSM.\n\t\tThis is a pretty powerful procedure which could potentially go on\n\t\tforever if you supply an evil version of follow().\n\t'''\n\n\tstates = [initial]\n\tfinals = set()\n\tmap = {}\n\n\t# iterate over a growing list\n\ti = 0\n\twhile i < len(states):\n\t\tstate = states[i]\n\n\t\t# add to finals\n\t\tif final(state):\n\t\t\tfinals.add(i)\n\n\t\t# compute map for this state\n\t\tmap[i] = {}\n\t\tfor symbol in sorted(alphabet, key=key):\n\t\t\ttry:\n\t\t\t\tnext = follow(state, symbol)\n\n\t\t\t\ttry:\n\t\t\t\t\tj = states.index(next)\n\t\t\t\texcept ValueError:\n\t\t\t\t\tj = len(states)\n\t\t\t\t\tstates.append(next)\n\n\t\t\texcept OblivionError:\n\t\t\t\t# Reached an oblivion state. Don't list it.\n\t\t\t\tcontinue\n\n\t\t\tmap[i][symbol] = j\n\n\t\ti += 1\n\n\treturn fsm(\n\t\talphabet = alphabet,\n\t\tstates   = range(len(states)),\n\t\tinitial  = 0,\n\t\tfinals   = finals,\n\t\tmap      = map,\n\t)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# -*- coding: utf-8 -*-\n\nif __name__ == \"__main__\":\n\traise Exception(\"Test files can't be run directly. Use `python -m pytest greenery`\")\n\nimport pytest\nfrom greenery.fsm import fsm, null, epsilon, anything_else\n\ndef test_addbug():\n\t# Odd bug with fsm.__add__(), exposed by \"[bc]*c\"\n\tint5A = fsm(\n\t\talphabet = {\"a\", \"b\", \"c\", anything_else},\n\t\tstates   = {0, 1},\n\t\tinitial  = 1,\n\t\tfinals   = {1},\n\t\tmap      = {\n\t\t\t0: {anything_else: 0, \"a\": 0, \"b\": 0, \"c\": 0},\n\t\t\t1: {anything_else: 0, \"a\": 0, \"b\": 1, \"c\": 1},\n\t\t}\n\t)\n\tassert int5A.accepts(\"\")\n\n\tint5B = fsm(\n\t\talphabet = {\"a\", \"b\", \"c\", anything_else},\n\t\tstates   = {0, 1, 2},\n\t\tinitial  = 1,\n\t\tfinals   = {0},\n\t\tmap      = {\n\t\t\t0: {anything_else: 2, \"a\": 2, \"b\": 2, \"c\": 2},\n\t\t\t1: {anything_else: 2, \"a\": 2, \"b\": 2, \"c\": 0},\n\t\t\t2: {anything_else: 2, \"a\": 2, \"b\": 2, \"c\": 2},\n\t\t}\n\t)\n\tassert int5B.accepts(\"c\")\n\n\tint5C = int5A + int5B\n\tassert int5C.accepts(\"c\")\n\t# assert int5C.initial == 0\n\ndef test_builtins():\n\tassert not null(\"a\").accepts(\"a\")\n\tassert epsilon(\"a\").accepts(\"\")\n\tassert not epsilon(\"a\").accepts(\"a\")\n\n@pytest.fixture\ndef a():\n\ta = fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates   = {0, 1, \"ob\"},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap      = {\n\t\t\t0    : {\"a\" : 1   , \"b\" : \"ob\"},\n\t\t\t1    : {\"a\" : \"ob\", \"b\" : \"ob\"},\n\t\t\t\"ob\" : {\"a\" : \"ob\", \"b\" : \"ob\"},\n\t\t},\n\t)\n\treturn a\n\ndef test_a(a):\n\tassert not a.accepts(\"\")\n\tassert a.accepts(\"a\")\n\tassert not a.accepts(\"b\")\n\n@pytest.fixture\ndef b():\n\tb = fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates   = {0, 1, \"ob\"},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap      = {\n\t\t\t0    : {\"a\" : \"ob\", \"b\" : 1   },\n\t\t\t1    : {\"a\" : \"ob\", \"b\" : \"ob\"},\n\t\t\t\"ob\" : {\"a\" : \"ob\", \"b\" : \"ob\"},\n\t\t},\n\t)\n\treturn b\n\ndef test_b(b):\n\tassert not b.accepts(\"\")\n\tassert not b.accepts(\"a\")\n\tassert b.accepts(\"b\")\n\ndef test_concatenation_aa(a):\n\tconcAA = a + a\n\tassert not concAA.accepts(\"\")\n\tassert not concAA.accepts(\"a\")\n\tassert concAA.accepts(\"aa\")\n\tassert not concAA.accepts(\"aaa\")\n\n\tconcAA = epsilon({\"a\", \"b\"}) + a + a\n\tassert not concAA.accepts(\"\")\n\tassert not concAA.accepts(\"a\")\n\tassert concAA.accepts(\"aa\")\n\tassert not concAA.accepts(\"aaa\")\n\ndef test_concatenation_ab(a, b):\n\tconcAB = a + b\n\tassert not concAB.accepts(\"\")\n\tassert not concAB.accepts(\"a\")\n\tassert not concAB.accepts(\"b\")\n\tassert not concAB.accepts(\"aa\")\n\tassert concAB.accepts(\"ab\")\n\tassert not concAB.accepts(\"ba\")\n\tassert not concAB.accepts(\"bb\")\n\ndef test_alternation_a(a):\n\taltA = a | null({\"a\", \"b\"})\n\tassert not altA.accepts(\"\")\n\tassert altA.accepts(\"a\")\n\ndef test_alternation_ab(a, b):\n\taltAB = a | b\n\tassert not altAB.accepts(\"\")\n\tassert altAB.accepts(\"a\")\n\tassert altAB.accepts(\"b\")\n\tassert not altAB.accepts(\"aa\")\n\tassert not altAB.accepts(\"ab\")\n\tassert not altAB.accepts(\"ba\")\n\tassert not altAB.accepts(\"bb\")\n\ndef test_star(a):\n\tstarA = a.star()\n\tassert starA.accepts(\"\")\n\tassert starA.accepts(\"a\")\n\tassert not starA.accepts(\"b\")\n\tassert starA.accepts(\"aaaaaaaaa\")\n\ndef test_multiply_0(a):\n\tzeroA = a * 0\n\tassert zeroA.accepts(\"\")\n\tassert not zeroA.accepts(\"a\")\n\ndef test_multiply_1(a):\n\toneA = a * 1\n\tassert not oneA.accepts(\"\")\n\tassert oneA.accepts(\"a\")\n\tassert not oneA.accepts(\"aa\")\n\ndef test_multiply_2(a):\n\ttwoA = a * 2\n\tassert not twoA.accepts(\"\")\n\tassert not twoA.accepts(\"a\")\n\tassert twoA.accepts(\"aa\")\n\tassert not twoA.accepts(\"aaa\")\n\ndef test_multiply_7(a):\n\tsevenA = a * 7\n\tassert not sevenA.accepts(\"aaaaaa\")\n\tassert sevenA.accepts(\"aaaaaaa\")\n\tassert not sevenA.accepts(\"aaaaaaaa\")\n\ndef test_optional_mul(a, b):\n\tunit = a + b\n\t# accepts \"ab\"\n\n\toptional = (epsilon(a.alphabet) | unit)\n\t# accepts \"(ab)?\n\tassert optional.accepts([])\n\tassert not optional.accepts([\"a\"])\n\tassert not optional.accepts([\"b\"])\n\tassert optional.accepts([\"a\", \"b\"])\n\tassert not optional.accepts([\"a\", \"a\"])\n\n\toptional = optional * 2\n\t# accepts \"(ab)?(ab)?\"\n\tassert optional.accepts([])\n\tassert not optional.accepts([\"a\"])\n\tassert not optional.accepts([\"b\"])\n\tassert not optional.accepts([\"a\", \"a\"])\n\tassert optional.accepts([\"a\", \"b\"])\n\tassert not optional.accepts([\"b\", \"a\"])\n\tassert not optional.accepts([\"b\", \"b\"])\n\tassert not optional.accepts([\"a\", \"a\", \"a\"])\n\tassert optional.accepts([\"a\", \"b\", \"a\", \"b\"])\n\ndef test_intersection_ab(a, b):\n\tintAB = a & b\n\tassert not intAB.accepts(\"\")\n\tassert not intAB.accepts(\"a\")\n\tassert not intAB.accepts(\"b\")\n\ndef test_negation(a):\n\teverythingbutA = a.everythingbut()\n\tassert everythingbutA.accepts(\"\")\n\tassert not everythingbutA.accepts(\"a\")\n\tassert everythingbutA.accepts(\"b\")\n\tassert everythingbutA.accepts(\"aa\")\n\tassert everythingbutA.accepts(\"ab\")\n\ndef test_crawl_reduction():\n\t# this is \"0*1\" in heavy disguise. crawl should resolve this duplication\n\t# Notice how states 2 and 3 behave identically. When resolved together,\n\t# states 1 and 2&3 also behave identically, so they, too should be resolved\n\t# (this is impossible to spot before 2 and 3 have been combined).\n\t# Finally, the oblivion state should be omitted.\n\tmerged = fsm(\n\t\talphabet = {\"0\", \"1\"},\n\t\tstates   = {1, 2, 3, 4, \"oblivion\"},\n\t\tinitial  = 1,\n\t\tfinals   = {4},\n\t\tmap      = {\n\t\t\t1          : {\"0\" : 2         , \"1\" : 4         },\n\t\t\t2          : {\"0\" : 3         , \"1\" : 4         },\n\t\t\t3          : {\"0\" : 3         , \"1\" : 4         },\n\t\t\t4          : {\"0\" : \"oblivion\", \"1\" : \"oblivion\"},\n\t\t\t\"oblivion\" : {\"0\" : \"oblivion\", \"1\" : \"oblivion\"},\n\t\t}\n\t).reduce()\n\tassert len(merged.states) == 2\n\ndef test_bug_28():\n\t# This is (ab*)* and it caused some defects.\n\tabstar = fsm(\n\t\talphabet = {'a', 'b'},\n\t\tstates   = {0, 1},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap = {\n\t\t\t0: {'a': 1},\n\t\t\t1: {'b': 1}\n\t\t}\n\t)\n\tassert abstar.accepts(\"a\")\n\tassert not abstar.accepts(\"b\")\n\tassert abstar.accepts(\"ab\")\n\tassert abstar.accepts(\"abb\")\n\tabstarstar = abstar.star()\n\tassert abstarstar.accepts(\"a\")\n\tassert not abstarstar.accepts(\"b\")\n\tassert abstarstar.accepts(\"ab\")\n\tassert not abstar.star().accepts(\"bb\")\n\ndef test_star_advanced():\n\t# This is (a*ba)*. Naively connecting the final states to the initial state\n\t# gives the incorrect result here.\n\tstarred = fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates   = {0, 1, 2, \"oblivion\"},\n\t\tinitial  = 0,\n\t\tfinals   = {2},\n\t\tmap      = {\n\t\t\t0          : {\"a\" : 0         , \"b\" : 1         },\n\t\t\t1          : {\"a\" : 2         , \"b\" : \"oblivion\"},\n\t\t\t2          : {\"a\" : \"oblivion\", \"b\" : \"oblivion\"},\n\t\t\t\"oblivion\" : {\"a\" : \"oblivion\", \"b\" : \"oblivion\"},\n\t\t}\n\t).star()\n\tassert starred.alphabet == frozenset([\"a\", \"b\"])\n\tassert starred.accepts(\"\")\n\tassert not starred.accepts(\"a\")\n\tassert not starred.accepts(\"b\")\n\tassert not starred.accepts(\"aa\")\n\tassert starred.accepts(\"ba\")\n\tassert starred.accepts(\"aba\")\n\tassert starred.accepts(\"aaba\")\n\tassert not starred.accepts(\"aabb\")\n\tassert starred.accepts(\"abababa\")\n\ndef test_reduce():\n\t# FSM accepts no strings but has 3 states, needs only 1\n\tasdf = fsm(\n\t\talphabet = {None},\n\t\tstates   = {0, 1, 2},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap = {\n\t\t\t0 : {None : 2},\n\t\t\t1 : {None : 2},\n\t\t\t2 : {None : 2},\n\t\t},\n\t)\n\tasdf = asdf.reduce()\n\tassert len(asdf.states) == 1\n\ndef test_reverse_abc():\n\tabc = fsm(\n\t\talphabet = {\"a\", \"b\", \"c\"},\n\t\tstates   = {0, 1, 2, 3, None},\n\t\tinitial  = 0,\n\t\tfinals   = {3},\n\t\tmap = {\n\t\t\t0    : {\"a\" : 1   , \"b\" : None, \"c\" : None},\n\t\t\t1    : {\"a\" : None, \"b\" : 2   , \"c\" : None},\n\t\t\t2    : {\"a\" : None, \"b\" : None, \"c\" : 3   },\n\t\t\t3    : {\"a\" : None, \"b\" : None, \"c\" : None},\n\t\t\tNone : {\"a\" : None, \"b\" : None, \"c\" : None},\n\t\t},\n\t)\n\tcba = reversed(abc)\n\tassert cba.accepts(\"cba\")\n\ndef test_reverse_brzozowski():\n\t# This is (a|b)*a(a|b)\n\tbrzozowski = fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates = {\"A\", \"B\", \"C\", \"D\", \"E\"},\n\t\tinitial = \"A\",\n\t\tfinals = {\"C\", \"E\"},\n\t\tmap = {\n\t\t\t\"A\" : {\"a\" : \"B\", \"b\" : \"D\"},\n\t\t\t\"B\" : {\"a\" : \"C\", \"b\" : \"E\"},\n\t\t\t\"C\" : {\"a\" : \"C\", \"b\" : \"E\"},\n\t\t\t\"D\" : {\"a\" : \"B\", \"b\" : \"D\"},\n\t\t\t\"E\" : {\"a\" : \"B\", \"b\" : \"D\"},\n\t\t},\n\t)\n\tassert brzozowski.accepts(\"aa\")\n\tassert brzozowski.accepts(\"ab\")\n\tassert brzozowski.accepts(\"aab\")\n\tassert brzozowski.accepts(\"bab\")\n\tassert brzozowski.accepts(\"abbbbbbbab\")\n\tassert not brzozowski.accepts(\"\")\n\tassert not brzozowski.accepts(\"a\")\n\tassert not brzozowski.accepts(\"b\")\n\tassert not brzozowski.accepts(\"ba\")\n\tassert not brzozowski.accepts(\"bb\")\n\tassert not brzozowski.accepts(\"bbbbbbbbbbbb\")\n\n\t# So this is (a|b)a(a|b)*\n\tb2 = reversed(brzozowski)\n\tassert b2.accepts(\"aa\")\n\tassert b2.accepts(\"ba\")\n\tassert b2.accepts(\"baa\")\n\tassert b2.accepts(\"bab\")\n\tassert b2.accepts(\"babbbbbbba\")\n\tassert not b2.accepts(\"\")\n\tassert not b2.accepts(\"a\")\n\tassert not b2.accepts(\"b\")\n\tassert not b2.accepts(\"ab\")\n\tassert not b2.accepts(\"bb\")\n\tassert not b2.accepts(\"bbbbbbbbbbbb\")\n\n\t# Test string generator functionality.\n\tgen = b2.strings()\n\tassert next(gen) == [\"a\", \"a\"]\n\tassert next(gen) == [\"b\", \"a\"]\n\tassert next(gen) == [\"a\", \"a\", \"a\"]\n\tassert next(gen) == [\"a\", \"a\", \"b\"]\n\tassert next(gen) == [\"b\", \"a\", \"a\"]\n\tassert next(gen) == [\"b\", \"a\", \"b\"]\n\tassert next(gen) == [\"a\", \"a\", \"a\", \"a\"]\n\ndef test_reverse_epsilon():\n\t# epsilon reversed is epsilon\n\tassert reversed(epsilon(\"a\")).accepts(\"\")\n\ndef test_binary_3():\n\t# Binary numbers divisible by 3.\n\t# Disallows the empty string\n\t# Allows \"0\" on its own, but not leading zeroes.\n\tdiv3 = fsm(\n\t\talphabet = {\"0\", \"1\"},\n\t\tstates = {\"initial\", \"zero\", 0, 1, 2, None},\n\t\tinitial = \"initial\",\n\t\tfinals = {\"zero\", 0},\n\t\tmap = {\n\t\t\t\"initial\" : {\"0\" : \"zero\", \"1\" : 1   },\n\t\t\t\"zero\"    : {\"0\" : None  , \"1\" : None},\n\t\t\t0         : {\"0\" : 0     , \"1\" : 1   },\n\t\t\t1         : {\"0\" : 2     , \"1\" : 0   },\n\t\t\t2         : {\"0\" : 1     , \"1\" : 2   },\n\t\t\tNone      : {\"0\" : None  , \"1\" : None},\n\t\t},\n\t)\n\tassert not div3.accepts(\"\")\n\tassert div3.accepts(\"0\")\n\tassert not div3.accepts(\"1\")\n\tassert not div3.accepts(\"00\")\n\tassert not div3.accepts(\"01\")\n\tassert not div3.accepts(\"10\")\n\tassert div3.accepts(\"11\")\n\tassert not div3.accepts(\"000\")\n\tassert not div3.accepts(\"001\")\n\tassert not div3.accepts(\"010\")\n\tassert not div3.accepts(\"011\")\n\tassert not div3.accepts(\"100\")\n\tassert not div3.accepts(\"101\")\n\tassert div3.accepts(\"110\")\n\tassert not div3.accepts(\"111\")\n\tassert not div3.accepts(\"0000\")\n\tassert not div3.accepts(\"0001\")\n\tassert not div3.accepts(\"0010\")\n\tassert not div3.accepts(\"0011\")\n\tassert not div3.accepts(\"0100\")\n\tassert not div3.accepts(\"0101\")\n\tassert not div3.accepts(\"0110\")\n\tassert not div3.accepts(\"0111\")\n\tassert not div3.accepts(\"1000\")\n\tassert div3.accepts(\"1001\")\n\ndef test_invalid_fsms():\n\t# initial state 1 is not a state\n\ttry:\n\t\tfsm(\n\t\t\talphabet = {},\n\t\t\tstates = {},\n\t\t\tinitial = 1,\n\t\t\tfinals = set(),\n\t\t\tmap = {}\n\t\t)\n\t\tassert False\n\texcept AssertionError:\n\t\tassert False\n\texcept Exception:\n\t\tpass\n\n\t# final state 2 not a state\n\ttry:\n\t\tfsm(\n\t\t\talphabet = {},\n\t\t\tstates = {1},\n\t\t\tinitial = 1,\n\t\t\tfinals = {2},\n\t\t\tmap = {}\n\t\t)\n\t\tassert False\n\texcept AssertionError:\n\t\tassert False\n\texcept Exception:\n\t\tpass\n\n\t# invalid transition for state 1, symbol \"a\"\n\ttry:\n\t\tfsm(\n\t\t\talphabet = {\"a\"},\n\t\t\tstates = {1},\n\t\t\tinitial = 1,\n\t\t\tfinals = set(),\n\t\t\tmap = {\n\t\t\t\t1 : {\"a\" : 2}\n\t\t\t}\n\t\t)\n\t\tassert False\n\texcept AssertionError:\n\t\tassert False\n\texcept Exception:\n\t\tpass\n\ndef test_bad_multiplier(a):\n\ttry:\n\t\tx = a * -1\n\t\tassert False\n\texcept AssertionError:\n\t\tassert False\n\texcept Exception:\n\t\tpass\n\ndef test_anything_else_acceptance():\n\ta = fsm(\n\t\talphabet = {\"a\", \"b\", \"c\", anything_else},\n\t\tstates = {1},\n\t\tinitial = 1,\n\t\tfinals = {1},\n\t\tmap = {\n\t\t\t1 : {\"a\" : 1, \"b\" : 1, \"c\" : 1, anything_else : 1}\n\t\t},\n\t)\n\tassert a.accepts(\"d\")\n\ndef test_difference(a, b):\n\taorb = fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates = {0, 1, None},\n\t\tinitial = 0,\n\t\tfinals = {1},\n\t\tmap = { \n\t\t\t0    : {\"a\" : 1   , \"b\" : 1   },\n\t\t\t1    : {\"a\" : None, \"b\" : None},\n\t\t\tNone : {\"a\" : None, \"b\" : None},\n\t\t},\n\t)\n\n\tassert list((a ^ a).strings()) == []\n\tassert list((b ^ b).strings()) == []\n\tassert list((a ^ b).strings()) == [[\"a\"], [\"b\"]]\n\tassert list((aorb ^ a).strings()) == [[\"b\"]]\n\ndef test_empty(a, b):\n\tassert not a.empty()\n\tassert not b.empty()\n\n\tassert fsm(\n\t\talphabet = {},\n\t\tstates = {0, 1},\n\t\tinitial = 0,\n\t\tfinals = {1},\n\t\tmap = {0:{}, 1:{}},\n\t).empty()\n\n\tassert not fsm(\n\t\talphabet = {},\n\t\tstates = {0},\n\t\tinitial = 0,\n\t\tfinals = {0},\n\t\tmap = {0:{}},\n\t).empty()\n\n\tassert fsm(\n\t\talphabet = {\"a\", \"b\"},\n\t\tstates = {0, 1, None, 2},\n\t\tinitial = 0,\n\t\tfinals = {2},\n\t\tmap = { \n\t\t\t0    : {\"a\" : 1   , \"b\" : 1   },\n\t\t\t1    : {\"a\" : None, \"b\" : None},\n\t\t\tNone : {\"a\" : None, \"b\" : None},\n\t\t\t2    : {\"a\" : None, \"b\" : None},\n\t\t},\n\t).empty()\n\ndef test_equivalent(a, b):\n\tassert (a | b).equivalent(b | a)\n\ndef test_dead_default():\n\t'''\n\t\tYou may now omit a transition, or even an entire state, from the map. This\n\t\taffects every usage of `fsm.map`.\n\t'''\n\tblockquote = fsm(\n\t\talphabet = {\"/\", \"*\", anything_else},\n\t\tstates = {0, 1, 2, 3, 4, 5},\n\t\tinitial = 0,\n\t\tfinals = {4},\n\t\tmap = {\n\t\t\t\t0 : {\"/\" : 1},\n\t\t\t\t1 : {\"*\" : 2},\n\t\t\t\t2 : {\"/\" : 2, anything_else : 2, \"*\" : 3},\n\t\t\t\t3 : {\"/\" : 4, anything_else : 2, \"*\" : 3},\n\t\t}\n\t)\n\tassert blockquote.accepts([\"/\", \"*\", \"whatever\", \"*\", \"/\"])\n\tassert not blockquote.accepts([\"*\", \"*\", \"whatever\", \"*\", \"/\"])\n\tstr(blockquote) # test stringification\n\tblockquote | blockquote\n\tblockquote & blockquote\n\tblockquote ^ blockquote\n\treversed(blockquote)\n\tassert not blockquote.everythingbut().accepts([\"/\", \"*\", \"whatever\", \"*\", \"/\"])\n\tassert blockquote.everythingbut().accepts([\"*\"]) # deliberately seek oblivion\n\tassert blockquote.islive(3)\n\tassert blockquote.islive(4)\n\tassert not blockquote.islive(5)\n\tgen = blockquote.strings()\n\tassert next(gen) == [\"/\", \"*\", \"*\", \"/\"]\n\ndef test_alphabet_unions():\n\t# Thanks to sparse maps it should now be possible to compute the union of FSMs\n\t# with disagreeing alphabets!\n\ta = fsm(\n\t\talphabet = {\"a\"},\n\t\tstates   = {0, 1},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap      = {\n\t\t\t0    : {\"a\" : 1},\n\t\t},\n\t)\n\n\tb = fsm(\n\t\talphabet = {\"b\"},\n\t\tstates   = {0, 1},\n\t\tinitial  = 0,\n\t\tfinals   = {1},\n\t\tmap      = {\n\t\t\t0    : {\"b\" : 1},\n\t\t},\n\t)\n\n\tassert (a | b).accepts([\"a\"])\n\tassert (a | b).accepts([\"b\"])\n\tassert (a & b).empty()\n\tassert (a + b).accepts([\"a\", \"b\"])\n\tassert (a ^ b).accepts([\"a\"])\n\tassert (a ^ b).accepts([\"b\"])\n\ndef test_repr():\n\tassert repr(anything_else) == \"anything_else\"\n\tassert str(anything_else) == \"anything_else\"\n\ndef test_new_set_methods(a, b):\n\t# A whole bunch of new methods were added to the FSM module to enable FSMs to\n\t# function exactly as if they were sets of strings (symbol lists), see:\n\t# https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset\n\t# But do they work?\n\tassert len(a) == 1\n\tassert len((a | b) * 4) == 16\n\ttry:\n\t\tlen(a.star())\n\t\tassert False\n\texcept OverflowError:\n\t\tpass\n\n\t# \"in\"\n\tassert \"a\" in a\n\tassert not \"a\" in b\n\tassert \"a\" not in b\n\n\t# List comprehension!\n\tfour = (a | b) * 2\n\tfor string in four:\n\t\tassert string == [\"a\", \"a\"]\n\t\tbreak\n\tassert [s for s in four] == [[\"a\", \"a\"], [\"a\", \"b\"], [\"b\", \"a\"], [\"b\", \"b\"]]\n\n\t# set.union() imitation\n\tassert fsm.union(a, b) == a.union(b)\n\tassert len(fsm.union()) == 0\n\tassert fsm.intersection(a, b) == a.intersection(b)\n\n\t# This takes a little explaining. In general, `a & b & c` is equivalent to\n\t# `EVERYTHING & a & b & c` where `EVERYTHING` is an FSM accepting every\n\t# possible string. Similarly `a` is equivalent to `EVERYTHING & a`, and the\n\t# intersection of no sets at all is... `EVERYTHING`.\n\t# However, since we compute the union of alphabets, and there are no\n\t# alphabets, the union is the empty set. So the only string which `EVERYTHING`\n\t# actually recognises is the empty string, [] (or \"\" if you prefer).\n\tint_none = fsm.intersection()\n\tassert len(int_none) == 1\n\tassert [] in int_none\n\n\tassert (a | b).difference(a) == fsm.difference((a | b), a) == (a | b) - a == b\n\tassert (a | b).difference(a, b) == fsm.difference((a | b), a, b) == (a | b) - a - b == null(\"ab\")\n\tassert a.symmetric_difference(b) == fsm.symmetric_difference(a, b) == a ^ b\n\tassert a.isdisjoint(b)\n\tassert a <= (a | b)\n\tassert a < (a | b)\n\tassert a != (a | b)\n\tassert (a | b) > a\n\tassert (a | b) >= a\n\n\tassert list(a.concatenate(a, a).strings()) == [[\"a\", \"a\", \"a\"]]\n\tassert list(a.concatenate().strings()) == [[\"a\"]]\n\tassert list(fsm.concatenate(b, a, b).strings()) == [[\"b\", \"a\", \"b\"]]\n\tassert list(fsm.concatenate().strings()) == []\n\tassert not a.copy() is a\n\ndef test_oblivion_crawl(a):\n\t# When crawling a new FSM, we should avoid generating an oblivion state.\n\t# `abc` has no oblivion state... all the results should not as well!\n\tabc = fsm(\n\t\talphabet = {\"a\", \"b\", \"c\"},\n\t\tstates = {0, 1, 2, 3},\n\t\tinitial = 0,\n\t\tfinals = {3},\n\t\tmap = {\n\t\t\t0 : {\"a\" : 1},\n\t\t\t1 : {\"b\" : 2},\n\t\t\t2 : {\"c\" : 3},\n\t\t}\n\t)\n\tassert len((abc + abc).states) == 7\n\tassert len(abc.star().states) == 3\n\tassert len((abc * 3).states) == 10\n\tassert len(reversed(abc).states) == 4\n\tassert len((abc | abc).states) == 4\n\tassert len((abc & abc).states) == 4\n\tassert len((abc ^ abc).states) == 1\n\tassert len((abc - abc).states) == 1\n\ndef test_concatenate_bug(a):\n\t# This exposes a defect in fsm.concatenate.\n\tassert fsm.concatenate(a, epsilon({\"a\"}), a).accepts(\"aa\")\n\tassert fsm.concatenate(a, epsilon({\"a\"}), epsilon({\"a\"}), a).accepts(\"aa\")\n\ndef test_derive(a, b):\n\t# Just some basic tests because this is mainly a regex thing.\n\tassert a.derive(\"a\") == epsilon({\"a\", \"b\"})\n\tassert a.derive(\"b\") == null({\"a\", \"b\"})\n\ttry:\n\t\ta.derive(\"c\")\n\t\tassert False\n\texcept KeyError:\n\t\tassert True\n\tassert (a * 3).derive(\"a\") == a * 2\n\tassert (a.star() - epsilon({\"a\", \"b\"})).derive(\"a\") == a.star()\n\ndef test_bug_36():\n\tetc1 = fsm(\n\t\talphabet = {anything_else},\n\t\tstates = {0},\n\t\tinitial = 0,\n\t\tfinals = {0},\n\t\tmap = {\n\t\t\t0: {\n\t\t\t\tanything_else: 0\n\t\t\t}\n\t\t}\n\t)\n\tetc2 = fsm(\n\t\talphabet = {'s', anything_else},\n\t\tstates = {0, 1},\n\t\tinitial = 0,\n\t\tfinals = {1},\n\t\tmap = {\n\t\t\t0: {\n\t\t\t\t's': 1\n\t\t\t},\n\t\t\t1: {\n\t\t\t\t's': 1,\n\t\t\t\tanything_else: 1\n\t\t\t}\n\t\t}\n\t)\n\tboth = etc1 & etc2\n\tassert etc1.accepts([\"s\"])\n\tassert etc2.accepts([\"s\"])\n\tassert both.alphabet == {anything_else, \"s\"}\n\tassert both.accepts([\"s\"])\n\ndef test_add_anything_else():\n\tfsm1=fsm( # [^a]\n\t\talphabet={\"a\",anything_else},\n\t\tstates={0,1},\n\t\tinitial=0,\n\t\tfinals={1},\n\t\tmap={0:{anything_else:1}}\n\t)\n\tfsm2=fsm( # [^b]\n\t\talphabet={\"b\",anything_else},\n\t\tstates={0,1},\n\t\tinitial=0,\n\t\tfinals={1},\n\t\tmap={0:{anything_else:1}}\n\t)\n\tassert (fsm1+fsm2).accepts(\"ba\")\n"
  },
  {
    "prompt": "\n\n### deepchem/utils/molecule_graph.py ###\n\nfrom typing import Optional, Sequence\nimport numpy as np\n\n\nclass MoleculeGraphData:\n  \"\"\"MoleculeGraphData class\n\n  This data class is almost same as `torch_geometric.data.Data \n  <https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data>`_.\n\n  Attributes\n  ----------\n  node_features : np.ndarray\n    Node feature matrix with shape [num_nodes, num_node_features]\n  edge_index : np.ndarray, dtype int\n    Graph connectivity in COO format with shape [2, num_edges]\n  targets : np.ndarray\n    Graph or node targets with arbitrary shape\n  edge_features : np.ndarray, optional (default None)\n    Edge feature matrix with shape [num_edges, num_edge_features]\n  graph_features : np.ndarray, optional (default None)\n    Graph feature vector with shape [num_graph_features,]\n  num_nodes : int\n    The number of nodes in the graph\n  num_node_features : int\n    The number of features per node in the graph\n  num_edges : int\n    The number of edges in the graph\n  num_edges_features : int, , optional (default None)\n    The number of features per edge in the graph\n  \"\"\"\n\n  def __init__(\n      self,\n      node_features: np.ndarray,\n      edge_index: np.ndarray,\n      targets: np.ndarray,\n      edge_features: Optional[np.ndarray] = None,\n      graph_features: Optional[np.ndarray] = None,\n  ):\n    \"\"\"\n    Parameters\n    ----------\n    node_features : np.ndarray\n      Node feature matrix with shape [num_nodes, num_node_features]\n    edge_index : np.ndarray, dtype int\n      Graph connectivity in COO format with shape [2, num_edges]\n    targets : np.ndarray\n      Graph or node targets with arbitrary shape\n    edge_features : np.ndarray, optional (default None)\n      Edge feature matrix with shape [num_edges, num_edge_features]\n    graph_features : np.ndarray, optional (default None)\n      Graph feature vector with shape [num_graph_features,]\n    \"\"\"\n    # validate params\n    if isinstance(node_features, np.ndarray) is False:\n      raise ValueError('node_features must be np.ndarray.')\n    if isinstance(edge_index, np.ndarray) is False:\n      raise ValueError('edge_index must be np.ndarray.')\n    elif edge_index.dtype != np.int:\n      raise ValueError('edge_index.dtype must be np.int')\n    elif edge_index.shape[0] != 2:\n      raise ValueError('The shape of edge_index is [2, num_edges].')\n    if isinstance(targets, np.ndarray) is False:\n      raise ValueError('y must be np.ndarray.')\n    if edge_features is not None:\n      if isinstance(edge_features, np.ndarray) is False:\n        raise ValueError('edge_features must be np.ndarray or None.')\n      elif edge_index.shape[1] != edge_features.shape[0]:\n        raise ValueError('The first dimension of edge_features must be the \\\n                    same as the second dimension of edge_index.')\n    if graph_features is not None and isinstance(graph_features,\n                                                 np.ndarray) is False:\n      raise ValueError('graph_features must be np.ndarray or None.')\n\n    self.node_features = node_features\n    self.edge_index = edge_index\n    self.edge_features = edge_features\n    self.graph_features = graph_features\n    self.targets = targets\n    self.num_nodes, self.num_node_features = self.node_features.shape\n    self.num_edges = edge_index.shape[1]\n    if self.node_features is not None:\n      self.num_edge_features = self.edge_features.shape[1]\n\n  def to_pyg_data(self):\n    \"\"\"Convert to PyTorch Geometric Data instance\n\n    Returns\n    -------\n    torch_geometric.data.Data\n      Molecule graph data for PyTorch Geometric\n    \"\"\"\n    try:\n      import torch\n      from torch_geometric.data import Data\n    except ModuleNotFoundError:\n      raise ValueError(\"This class requires PyTorch Geometric to be installed.\")\n\n    return Data(\n      x=torch.from_numpy(self.node_features),\n      edge_index=torch.from_numpy(self.edge_index),\n      edge_attr=None if self.edge_features is None \\\n        else torch.from_numpy(self.edge_features),\n      y=torch.from_numpy(self.targets),\n    )\n\n\nclass BatchMoleculeGraphData(MoleculeGraphData):\n  \"\"\"Batch MoleculeGraphData class\n  \n  Attributes\n  ----------\n  graph_index : np.ndarray, dtype int\n    This vector indicates which graph the node belongs with shape [num_nodes,]\n  \"\"\"\n\n  def __init__(self, molecule_graphs: Sequence[MoleculeGraphData]):\n    \"\"\"\n    Parameters\n    ----------\n    molecule_graphs : Sequence[MoleculeGraphData]\n      List of MoleculeGraphData\n    \"\"\"\n    # stack features and targets\n    batch_node_features = np.vstack(\n        [graph.node_features for graph in molecule_graphs])\n    batch_targets = np.vstack([graph.targets for graph in molecule_graphs])\n\n    # before stacking edge_features or graph_features,\n    # we should check whether these are None or not\n    if molecule_graphs[0].edge_features is not None:\n      batch_edge_features = np.vstack(\n          [graph.edge_features for graph in molecule_graphs])\n    else:\n      batch_edge_features = None\n\n    if molecule_graphs[0].graph_features is not None:\n      batch_graph_features = np.vstack(\n          [graph.graph_features for graph in molecule_graphs])\n    else:\n      batch_graph_features = None\n\n    # create new edge index\n    num_nodes_list = [graph.num_nodes for graph in molecule_graphs]\n    batch_edge_index = np.hstack(\n      [graph.edge_index + prev_num_node for prev_num_node, graph \\\n        in zip([0] + num_nodes_list[:-1], molecule_graphs)]\n    ).astype(int)\n\n    # graph_index indicates which nodes belong to which graph\n    graph_index = []\n    for i, num_nodes in enumerate(num_nodes_list):\n      graph_index.extend([i] * num_nodes)\n    self.graph_index = np.array(graph_index, dtype=int)\n\n    super().__init__(\n        node_features=batch_node_features,\n        edge_index=batch_edge_index,\n        targets=batch_targets,\n        edge_features=batch_edge_features,\n        graph_features=batch_graph_features,\n    )\n\n    @staticmethod  # type: ignore\n    def to_pyg_data(molecule_graphs: Sequence[MoleculeGraphData]):\n      \"\"\"Convert to PyTorch Geometric Batch instance\n\n      Parameters\n      ----------\n      molecule_graphs : Sequence[MoleculeGraphData]\n        List of MoleculeGraphData\n\n      Returns\n      -------\n      torch_geometric.data.Batch\n        Batch data of molecule graph for PyTorch Geometric\n      \"\"\"\n      try:\n        from torch_geometric.data import Batch\n      except ModuleNotFoundError:\n        raise ValueError(\n            \"This class requires PyTorch Geometric to be installed.\")\n\n      data_list = [mol_graph.to_pyg_data() for mol_graph in molecule_graphs]\n      return Batch.from_data_list(data_list=data_list)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import unittest\nimport pytest\nimport numpy as np\nfrom deepchem.utils.molecule_graph import MoleculeGraphData, BatchMoleculeGraphData\n\n\nclass TestMoleculeGraph(unittest.TestCase):\n\n  def test_molecule_graph_data(self):\n    num_nodes, num_node_features = 4, 32\n    num_edges, num_edge_features = 6, 32\n    node_features = np.random.random_sample((num_nodes, num_node_features))\n    edge_features = np.random.random_sample((num_edges, num_edge_features))\n    targets = np.random.random_sample(5)\n    edge_index = np.array([\n        [0, 1, 2, 2, 3, 4],\n        [1, 2, 0, 3, 4, 0],\n    ])\n    graph_features = None\n\n    mol_graph = MoleculeGraphData(\n        node_features=node_features,\n        edge_index=edge_index,\n        targets=targets,\n        edge_features=edge_features,\n        graph_features=graph_features)\n\n    assert mol_graph.num_nodes == num_nodes\n    assert mol_graph.num_node_features == num_node_features\n    assert mol_graph.num_edges == num_edges\n    assert mol_graph.num_edge_features == num_edge_features\n    assert mol_graph.targets.shape == (5,)\n\n  def test_invalid_molecule_graph_data(self):\n    with pytest.raises(ValueError):\n      invalid_node_features_type = list(np.random.random_sample((5, 5)))\n      edge_index = np.array([\n          [0, 1, 2, 2, 3, 4],\n          [1, 2, 0, 3, 4, 0],\n      ])\n      targets = np.random.random_sample(5)\n      mol_graph = MoleculeGraphData(\n          node_features=invalid_node_features_type,\n          edge_index=edge_index,\n          targets=targets,\n      )\n\n    with pytest.raises(ValueError):\n      node_features = np.random.random_sample((5, 5))\n      invalid_edge_index_shape = np.array([\n          [0, 1, 2, 2, 3, 4],\n          [1, 2, 0, 3, 4, 0],\n          [2, 2, 1, 4, 0, 3],\n      ])\n      targets = np.random.random_sample(5)\n      mol_graph = MoleculeGraphData(\n          node_features=node_features,\n          edge_index=invalid_edge_index_shape,\n          targets=targets,\n      )\n\n    with pytest.raises(TypeError):\n      node_features = np.random.random_sample((5, 5))\n      mol_graph = MoleculeGraphData(node_features=node_features)\n\n  def test_batch_molecule_graph_data(self):\n    num_nodes_list, num_edge_list = [3, 4, 5], [2, 4, 5]\n    num_node_features, num_edge_features = 32, 32\n    edge_index_list = [\n        np.array([[0, 1], [1, 2]]),\n        np.array([[0, 1, 2, 3], [1, 2, 0, 2]]),\n        np.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]])\n    ]\n    targets = np.random.random_sample(5)\n\n    molecule_graphs = [\n        MoleculeGraphData(\n            node_features=np.random.random_sample((num_nodes_list[i],\n                                                   num_node_features)),\n            edge_index=edge_index_list[i],\n            targets=targets,\n            edge_features=np.random.random_sample((num_edge_list[i],\n                                                   num_edge_features)),\n            graph_features=None) for i in range(len(num_edge_list))\n    ]\n    batch = BatchMoleculeGraphData(molecule_graphs)\n\n    assert batch.num_nodes == sum(num_nodes_list)\n    assert batch.num_node_features == num_node_features\n    assert batch.num_edges == sum(num_edge_list)\n    assert batch.num_edge_features == num_edge_features\n    assert batch.targets.shape == (3, 5)\n    assert batch.graph_index.shape == (sum(num_nodes_list),)\n"
  },
  {
    "prompt": "\n\n### tests/test_data.py ###\n\n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport elasticsearch_dsl as es\n\n\nclass DataDocType(es.DocType):\n    \"\"\"Elasticsearch test model\"\"\"\n    first_name = es.Keyword()\n    last_name = es.Keyword()\n    city = es.Text()\n    skills = es.Keyword()\n    birthday = es.Date()\n    is_active = es.Boolean()\n    score = es.Integer()\n    description = es.Text()\n\n    class Meta:\n        index = 'test'\n\n\ndef create_test_index():\n    \"\"\"Initialize test index\"\"\"\n    DataDocType.init()\n\n\nDATA = [\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '1',\n        '_source': {\n            'first_name': 'Zofia',\n            'last_name': 'Marie',\n            'city': 'Warsaw',\n            'skills': ['python', 'sql', 'js'],\n            'birthday': '1985-03-17T12:20:09',\n            'is_active': True,\n            'score': 100,\n            'description': \"\"\"\n                He had made one careless blunder though, because he had skimped\n                a bit on his preparatory research.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '2',\n        '_source': {\n            'first_name': 'Callisto',\n            'last_name': 'Alexandra',\n            'city': 'San Jose',\n            'skills': ['java', 'c#', 'sql'],\n            'birthday': '1990-02-07T15:22:09',\n            'is_active': True,\n            'score': 200,\n            'description': \"\"\"\n                The information he had gathered had led him to choose the name\n                Ford Prefect as being nicely inconspicuous.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '3',\n        '_source': {\n            'first_name': 'Samantha',\n            'last_name': 'Arundhati',\n            'city': 'Manila',\n            'skills': ['html', 'js', 'css'],\n            'birthday': '1987-05-27T16:08:02',\n            'is_active': False,\n            'score': 100,\n            'description': \"\"\"\n                He struck most of the friends he had made on Earth as an\n                eccentric, but a harmless one \u2013 an unruly boozer with some\n                oddish habits.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '4',\n        '_source': {\n            'first_name': 'Crocetta',\n            'last_name': 'Florette',\n            'city': 'Rome',\n            'skills': ['python', 'go', 'sql', 'django'],\n            'birthday': '1991-04-07T16:38:29',\n            'is_active': True,\n            'score': 450,\n            'description': \"\"\"\n                Thereafter, staggering semi-paralytic down the night streets he\n                would of ten ask passing policemen if they knew the way to\n                Betelgeuse.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '5',\n        '_source': {\n            'first_name': 'Akhmad',\n            'last_name': 'Farouk',\n            'city': 'Ottawa',\n            'skills': ['python', 'flask', 'django'],\n            'birthday': '1992-01-21T12:18:09',\n            'is_active': True,\n            'score': 10,\n            'description': \"\"\"\n                Ford Prefect was desperate that any flying saucer at all would\n                arrive soon because fifteen years was a long time to get\n                stranded anywhere, particularly somewhere as mindboggingly dull\n                as the Earth.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '6',\n        '_source': {\n            'first_name': 'Rohan',\n            'last_name': 'Dand',\n            'city': 'Ottawa',\n            'skills': ['ruby', 'ror', 'sql'],\n            'birthday': '1991-09-07T11:20:29',\n            'is_active': False,\n            'score': 1000,\n            'description': \"\"\"\n                Ford wished that a flying saucer would arrive soon because he\n                knew how to flag flying saucers down and get lifts from them.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '7',\n        '_source': {\n            'first_name': 'Odell',\n            'last_name': 'Leonidas',\n            'city': 'Rome',\n            'skills': ['angular', 'react', 'css'],\n            'birthday': '1993-09-20T16:20:08',\n            'is_active': True,\n            'score': 500,\n            'description': \"\"\"\n                He knew how to see the Marvels of the Universe for less than\n                thirty Altairan dollars a day.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '8',\n        '_source': {\n            'first_name': 'Markus',\n            'last_name': 'Emmeline',\n            'city': 'Ottawa',\n            'skills': ['php', 'html'],\n            'birthday': '1991-04-26T16:48:03',\n            'is_active': False,\n            'score': 600,\n            'description': \"\"\"\n                In fact, Ford Prefect was a roving researcher for that wholly\n                remarkable book The Hitchhiker\u2019s Guide to the Galaxy.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '9',\n        '_source': {\n            'first_name': 'Gabriel',\n            'last_name': 'Sara',\n            'city': 'Baku',\n            'skills': ['js', 'css', 'html', 'sql'],\n            'birthday': '1988-08-27T16:18:29',\n            'is_active': True,\n            'score': 100,\n            'description': \"\"\"\n                Human beings are great adaptors, and by lunchtime life in the\n                environs of Arthur\u2019s house had settled into a steady routine.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '10',\n        '_source': {\n            'first_name': 'Merilyn',\n            'last_name': 'Barrie',\n            'city': 'Rabat',\n            'skills': ['python', 'sql'],\n            'birthday': '1992-03-11T11:28:09',\n            'is_active': False,\n            'score': 600,\n            'description': \"\"\"\n                Arthur looked up and squinting into the sun was startled to see\n                Ford Prefect standing above him.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '11',\n        '_source': {\n            'first_name': 'Sunil',\n            'last_name': 'Allan',\n            'city': 'Lima',\n            'skills': ['java', 'android'],\n            'birthday': '1991-05-20T17:28:32',\n            'is_active': True,\n            'score': 900,\n            'description': \"\"\"\n                Then suddenly he squatted down beside Arthur.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '12',\n        '_source': {\n            'first_name': 'Navin',\n            'last_name': 'Mladen',\n            'city': 'Doha',\n            'skills': ['swift', 'c'],\n            'birthday': '1990-04-23T16:48:09',\n            'is_active': True,\n            'score': 10,\n            'description': \"\"\"\n                Ford stared at Arthur, and Arthur was astonished to find that\n                his will was beginning to weaken.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '13',\n        '_source': {\n            'first_name': 'Helga',\n            'last_name': 'Terell',\n            'city': 'Oslo',\n            'skills': ['c++', 'c#'],\n            'birthday': '1989-01-20T06:18:02',\n            'is_active': True,\n            'score': 200,\n            'description': \"\"\"\n                Two contestants would sit either side of a table, with a glass\n                in front of each of them.\n            \"\"\"\n        },\n    },\n    {\n        '_index': 'test',\n        '_type': 'doc',\n        '_id': '14',\n        '_source': {\n            'first_name': 'Lynsey',\n            'last_name': 'Brynja',\n            'city': 'Oslo',\n            'skills': ['c++', 'java'],\n            'birthday': '1984-07-21T12:18:29',\n            'is_active': True,\n            'score': 100,\n            'description': \"\"\"\n                The game was not unlike the Earth game called Indian Wrestling,\n                and was played like this.\n            \"\"\"\n        },\n    },\n]\n\n\n### tests/utils.py ###\n\n# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nfrom .test_data import DATA\n\n\ndef get_search_ids(search):\n    \"\"\"Execute search and return list of items ids\n\n    Args:\n        search (elasticsearch_dsl.Search): search instance\n    Returns:\n        [int]: list of items ids\n    \"\"\"\n    return [int(item.meta.id) for item in search[:len(DATA)].execute()]\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# -*- coding: utf-8 -*-\nfrom __future__ import unicode_literals\n\nimport pytest\nfrom rest_framework.test import APIRequestFactory\nfrom elasticsearch_dsl import Q\n\nfrom rest_framework_elasticsearch.es_filters import (\n    ESFieldFilter, ElasticOrderingFilter, ElasticFieldsFilter,\n    ElasticFieldsRangeFilter, ElasticSearchFilter)\nfrom rest_framework_elasticsearch.es_views import ElasticAPIView\nfrom .test_data import DataDocType, DATA\nfrom .utils import get_search_ids\n\n\nrf = APIRequestFactory()\n\n\n@pytest.mark.parametrize('dataset, expected', [\n    (\n        ('label', 'name', 'description'),\n        ('label', 'name', 'description')\n    ),\n    (\n        ('label', None, 'description'),\n        ('label', 'label', 'description')\n    ),\n    (\n        ('label', None, None),\n        ('label', 'label', None)\n    )\n])\ndef test_es_field_filters(dataset, expected):\n    ffilter = ESFieldFilter(dataset[0],\n                            name=dataset[1],\n                            description=dataset[2])\n    assert expected == (ffilter.label, ffilter.name, ffilter.description)\n\n\nclass TestElasticOrderingFilter:\n\n    def setup_method(self):\n        self.backend = ElasticOrderingFilter()\n\n    def create_view(self, es_ordering_fields):\n        \"\"\"Create and return test view class instance\n\n        Args:\n            es_ordering_fields (tuple): ordering fields\n        Returns:\n            ElasticAPIView: test view instance\n        \"\"\"\n        view = ElasticAPIView()\n        view.es_ordering_fields = es_ordering_fields\n        return view\n\n    @pytest.mark.parametrize('es_ordering_fields, expected', [\n        (\n            (\"first_name\", (\"is_active\", \"active\")),\n            (\"first_name\", (\"is_active\", \"active\")),\n        ),\n        (\n            \"first_name\",\n            (\"first_name\",)\n        )\n    ])\n    def test_get_es_ordering_fields(self, es_ordering_fields, expected):\n        view = self.create_view(es_ordering_fields)\n        result = self.backend.get_es_ordering_fields(view)\n        assert expected == result\n\n    @pytest.mark.parametrize('es_ordering_fields, expected', [\n        (\n            (\"is_active\", \"active\"),\n            (\"is_active\", \"active\")\n        ),\n        (\n            \"first_name\",\n            (\"first_name\", \"first_name\")\n        )\n    ])\n    def test_validation(self, es_ordering_fields, expected):\n        result = ElasticOrderingFilter.validation(es_ordering_fields)\n        assert expected == result\n\n    def test_get_valid_fields_with_es_ordering_fields(self):\n        es_ordering_fields = (\n            \"first_name\",\n            \"last_name\",\n            (\"is_active\", \"active\")\n        )\n        view = self.create_view(es_ordering_fields)\n        expected = [\n            (\"first_name\", \"first_name\"),\n            (\"last_name\", \"last_name\"),\n            (\"is_active\", \"active\")\n        ]\n        result = self.backend.get_valid_fields([], view)\n        assert result == expected\n\n    def test_get_valid_fields_without_es_ordering_fields(self):\n        view = self.create_view(None)\n        valid_fields = []\n        self.backend.get_default_valid_fields = lambda q, v: valid_fields\n        result = self.backend.get_valid_fields([], view)\n        assert result == valid_fields\n\n    @pytest.mark.parametrize('fields, expected', [\n        (\n            ['first_name', 'last_name', '-active'],\n            ['first_name', '-is_active']\n        ),\n        (\n            ['+first_name', 'last_name', '#active'],\n            ['+first_name']\n        ),\n        (\n            ['+first_name', '-active'],\n            ['+first_name', '-is_active']\n        )\n    ])\n    def test_remove_invalid_fields(self, fields, expected):\n        es_ordering_fields = (\n            \"first_name\",\n            (\"is_active\", \"active\")\n        )\n        view = self.create_view(es_ordering_fields)\n        request = rf.get('/test/')\n        result = self.backend.remove_invalid_fields([], fields, view, request)\n        assert result == expected\n\n    def test_filter_search(self, search):\n\n        def get_expected():\n            \"\"\"Return expected data items sorted by id\"\"\"\n            items = [\n                (\n                    item['_id'],\n                    item['_source']['first_name'],\n                    item['_source']['is_active']\n                )\n                for item in DATA\n            ]\n            items = sorted(items, key=lambda tup: (tup[1], not tup[2]))\n            return items\n\n        es_ordering_fields = (\n            (\"first_name\", \"first_name\"),\n            (\"is_active\", \"-active\")\n        )\n        view = self.create_view(es_ordering_fields)\n\n        request = rf.get('/test/')\n        request.query_params = {'ordering': 'first_name,active'}\n\n        search = self.backend.filter_search(request, search, view)\n        result = [\n            (item.meta.id, item.first_name, item.is_active)\n            for item in search[:len(DATA)].execute()\n        ]\n        assert result == get_expected()\n\n\nclass TestElasticFieldsFilter:\n\n    def setup_method(self):\n        self.backend = ElasticFieldsFilter()\n\n    def create_view(self, es_filter_fields):\n        \"\"\"Create and return test view class instance\n\n        Args:\n            es_filter_fields ([ESFieldFilter]): filtering fields\n        Returns:\n            ElasticAPIView: test view instance\n        \"\"\"\n        view = ElasticAPIView()\n        view.es_model = DataDocType\n        view.es_filter_fields = es_filter_fields\n        return view\n\n    def test_get_es_filter_fields(self):\n        es_filter_fields = (\n            ESFieldFilter('skills'),\n            ESFieldFilter('active', 'is_active')\n        )\n        view = self.create_view(es_filter_fields)\n        result = self.backend.get_es_filter_fields(view)\n        assert result == es_filter_fields\n\n    @pytest.mark.parametrize('es_filter_fields, query_params, expected', [\n        (\n            [ESFieldFilter('active', 'is_active')],\n            {'active': 'False'},\n            [3, 6, 8, 10]\n        ),\n        (\n            [\n                ESFieldFilter('birthday')\n            ],\n            {'birthday': '1985-03-17T12:20:09'},\n            [1]\n        ),\n        (\n            [ESFieldFilter('skills')],\n            {'skills': 'python'},\n            [1, 4, 5, 10]\n        ),\n        (\n            [ESFieldFilter('skills')],\n            {'skills': 'python,ruby'},\n            [1, 4, 5, 6, 10]\n        ),\n        (\n            [ESFieldFilter('active', 'is_active')],\n            {'active': 'False', 'skills': 'python'},\n            [3, 6, 8, 10]\n        ),\n        (\n            [ESFieldFilter('active', 'is_active')],\n            {'active': 'False', 'skills': 'python'},\n            [3, 6, 8, 10]\n        ),\n        (\n            [ESFieldFilter('score')],\n            {'score': '200'},\n            [2, 13]\n        ),\n    ])\n    def test_filter_search(self, search, es_filter_fields,\n                           query_params, expected):\n        view = self.create_view(es_filter_fields)\n        request = rf.get('/test/')\n        request.query_params = query_params\n        search = self.backend.filter_search(request, search, view)\n        result = get_search_ids(search)\n        assert sorted(result) == sorted(expected)\n\n\nclass TestElasticFieldsRangeFilter:\n\n    def setup_method(self):\n        self.backend = ElasticFieldsRangeFilter()\n\n    def create_view(self, es_range_filter_fields):\n        \"\"\"Create and return test view class instance\n\n        Args:\n            es_range_filter_fields ([ESFieldFilter]): filtering range fields\n        Returns:\n            ElasticAPIView: test view instance\n        \"\"\"\n        view = ElasticAPIView()\n        view.es_model = DataDocType\n        view.es_range_filter_fields = es_range_filter_fields\n        return view\n\n    def test_get_es_filter_fields(self):\n        es_range_filter_fields = (\n            ESFieldFilter('skills'),\n            ESFieldFilter('active', 'is_active')\n        )\n        view = self.create_view(es_range_filter_fields)\n        result = self.backend.get_es_range_filter_fields(view)\n        assert result == es_range_filter_fields\n\n    @pytest.mark.parametrize('es_filter_fields, query_params, expected', [\n        (\n            [ESFieldFilter('score')],\n            {'from_score': '500'},\n            [6, 7, 8, 10, 11]\n        ),\n        (\n            [ESFieldFilter('score')],\n            {'to_score': '100'},\n            [1, 3, 5, 9, 12, 14]\n        ),\n        (\n            [ESFieldFilter('score')],\n            {'from_score': '500', 'to_score': '600'},\n            [7, 8, 10]\n        ),\n        (\n            [ESFieldFilter('score')], {}, [int(item['_id']) for item in DATA]\n        ),\n    ])\n    def test_filter_search(self, search, es_filter_fields,\n                           query_params, expected):\n        view = self.create_view(es_filter_fields)\n        request = rf.get('/test/')\n        request.query_params = query_params\n        search = self.backend.filter_search(request, search, view)\n        result = get_search_ids(search)\n        assert sorted(result) == sorted(expected)\n\n\nclass TestElasticSearchFilter:\n\n    def setup_method(self):\n        self.backend = ElasticSearchFilter()\n\n    def create_view(self, es_search_fields):\n        \"\"\"Create and return test view class instance\n\n        Args:\n            es_search_fields ([ESFieldFilter]): search fields\n        Returns:\n            ElasticAPIView: test view instance\n        \"\"\"\n        view = ElasticAPIView()\n        view.es_model = DataDocType\n        view.es_search_fields = es_search_fields\n        return view\n\n    @pytest.mark.parametrize('search_param, query_params, expected', [\n        (\n            None, {'search': 'test'}, 'test'\n        ),\n        (\n            'search', {'search': 'test'}, 'test'\n        ),\n        (\n            'q', {'q': 'test'}, 'test'\n        ),\n        (\n            'search', {'q': 'test'}, ''\n        ),\n    ])\n    def test_get_search_query(self, search_param, query_params, expected):\n        request = rf.get('/test/')\n        request.query_params = query_params\n        if search_param:\n            self.backend.search_param = search_param\n        result = self.backend.get_search_query(request)\n        assert result == expected\n\n    def test_get_es_query(self):\n\n        class TestElasticSearchFilter(ElasticSearchFilter):\n            def get_es_query(self, s_query, s_fields, **kwargs):\n                return Q(\"match\", query=s_query, field=s_fields)\n\n        s_query = \"test\"\n        s_fields = \"first_name\"\n        backend = TestElasticSearchFilter()\n        result = backend.get_es_query(s_query, s_fields)\n        expected = Q(\"match\", query=s_query, field=s_fields)\n        assert result == expected\n\n    @pytest.mark.parametrize('es_search_fields, query_params, expected', [\n        (\n            ('first_name',),\n            {'search': 'Zofia'},\n            [1]\n        ),\n        (\n            ('first_name', 'last_name', 'city'),\n            {'search': 'Zofia'},\n            [1]\n        ),\n        (\n            ('first_name', 'last_name', 'city'),\n            {'search': 'Zofia Rome'},\n            [4, 7]\n        ),\n        (\n            ('description'),\n            {'search': 'information'},\n            [2]\n        ),\n        (\n            ('description'),\n            {'search': 'Ford Prefect'},\n            [2, 8, 10, 5, 6, 12]\n        ),\n        (\n            ('description'),\n            {'search': 'Earth'},\n            [5, 3, 14]\n        ),\n        (\n            ('description'),\n            {'search': 'The Hitchhiker\u2019s Guide'},\n            [8]\n        ),\n    ])\n    def test_filter_search(self, search, es_search_fields,\n                           query_params, expected):\n        view = self.create_view(es_search_fields)\n        request = rf.get('/test/')\n        request.query_params = query_params\n        search = self.backend.filter_search(request, search, view)\n        result = get_search_ids(search)\n        assert result == expected\n"
  },
  {
    "prompt": "\n\n### tests/components/mobile_app/const.py ###\n\n\"\"\"Constants for mobile_app tests.\"\"\"\nCALL_SERVICE = {\n    \"type\": \"call_service\",\n    \"data\": {\"domain\": \"test\", \"service\": \"mobile_app\", \"service_data\": {\"foo\": \"bar\"}},\n}\n\nFIRE_EVENT = {\n    \"type\": \"fire_event\",\n    \"data\": {\"event_type\": \"test_event\", \"event_data\": {\"hello\": \"yo world\"}},\n}\n\nREGISTER = {\n    \"app_data\": {\"foo\": \"bar\"},\n    \"app_id\": \"io.homeassistant.mobile_app_test\",\n    \"app_name\": \"Mobile App Tests\",\n    \"app_version\": \"1.0.0\",\n    \"device_name\": \"Test 1\",\n    \"manufacturer\": \"mobile_app\",\n    \"model\": \"Test\",\n    \"os_name\": \"Linux\",\n    \"os_version\": \"1.0\",\n    \"supports_encryption\": True,\n}\n\nREGISTER_CLEARTEXT = {\n    \"app_data\": {\"foo\": \"bar\"},\n    \"app_id\": \"io.homeassistant.mobile_app_test\",\n    \"app_name\": \"Mobile App Tests\",\n    \"app_version\": \"1.0.0\",\n    \"device_name\": \"Test 1\",\n    \"manufacturer\": \"mobile_app\",\n    \"model\": \"Test\",\n    \"device_id\": \"mock-device-id\",\n    \"os_name\": \"Linux\",\n    \"os_version\": \"1.0\",\n    \"supports_encryption\": False,\n}\n\nRENDER_TEMPLATE = {\n    \"type\": \"render_template\",\n    \"data\": {\"one\": {\"template\": \"Hello world\"}},\n}\n\nUPDATE = {\n    \"app_data\": {\"foo\": \"bar\"},\n    \"app_version\": \"2.0.0\",\n    \"device_name\": \"Test 1\",\n    \"manufacturer\": \"mobile_app\",\n    \"model\": \"Test\",\n    \"os_version\": \"1.0\",\n}\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"Webhook tests for mobile_app.\"\"\"\nimport logging\n\nimport pytest\n\nfrom homeassistant.components.camera import SUPPORT_STREAM as CAMERA_SUPPORT_STREAM\nfrom homeassistant.components.mobile_app.const import CONF_SECRET\nfrom homeassistant.components.zone import DOMAIN as ZONE_DOMAIN\nfrom homeassistant.const import CONF_WEBHOOK_ID\nfrom homeassistant.core import callback\nfrom homeassistant.exceptions import HomeAssistantError\nfrom homeassistant.setup import async_setup_component\n\nfrom .const import CALL_SERVICE, FIRE_EVENT, REGISTER_CLEARTEXT, RENDER_TEMPLATE, UPDATE\n\nfrom tests.async_mock import patch\nfrom tests.common import async_mock_service\n\n_LOGGER = logging.getLogger(__name__)\n\n\ndef encrypt_payload(secret_key, payload):\n    \"\"\"Return a encrypted payload given a key and dictionary of data.\"\"\"\n    try:\n        from nacl.secret import SecretBox\n        from nacl.encoding import Base64Encoder\n    except (ImportError, OSError):\n        pytest.skip(\"libnacl/libsodium is not installed\")\n        return\n\n    import json\n\n    keylen = SecretBox.KEY_SIZE\n    prepped_key = secret_key.encode(\"utf-8\")\n    prepped_key = prepped_key[:keylen]\n    prepped_key = prepped_key.ljust(keylen, b\"\\0\")\n\n    payload = json.dumps(payload).encode(\"utf-8\")\n\n    return (\n        SecretBox(prepped_key).encrypt(payload, encoder=Base64Encoder).decode(\"utf-8\")\n    )\n\n\ndef decrypt_payload(secret_key, encrypted_data):\n    \"\"\"Return a decrypted payload given a key and a string of encrypted data.\"\"\"\n    try:\n        from nacl.secret import SecretBox\n        from nacl.encoding import Base64Encoder\n    except (ImportError, OSError):\n        pytest.skip(\"libnacl/libsodium is not installed\")\n        return\n\n    import json\n\n    keylen = SecretBox.KEY_SIZE\n    prepped_key = secret_key.encode(\"utf-8\")\n    prepped_key = prepped_key[:keylen]\n    prepped_key = prepped_key.ljust(keylen, b\"\\0\")\n\n    decrypted_data = SecretBox(prepped_key).decrypt(\n        encrypted_data, encoder=Base64Encoder\n    )\n    decrypted_data = decrypted_data.decode(\"utf-8\")\n\n    return json.loads(decrypted_data)\n\n\nasync def test_webhook_handle_render_template(create_registrations, webhook_client):\n    \"\"\"Test that we render templates properly.\"\"\"\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]),\n        json=RENDER_TEMPLATE,\n    )\n\n    assert resp.status == 200\n\n    json = await resp.json()\n    assert json == {\"one\": \"Hello world\"}\n\n\nasync def test_webhook_handle_call_services(hass, create_registrations, webhook_client):\n    \"\"\"Test that we call services properly.\"\"\"\n    calls = async_mock_service(hass, \"test\", \"mobile_app\")\n\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]),\n        json=CALL_SERVICE,\n    )\n\n    assert resp.status == 200\n\n    assert len(calls) == 1\n\n\nasync def test_webhook_handle_fire_event(hass, create_registrations, webhook_client):\n    \"\"\"Test that we can fire events.\"\"\"\n    events = []\n\n    @callback\n    def store_event(event):\n        \"\"\"Helepr to store events.\"\"\"\n        events.append(event)\n\n    hass.bus.async_listen(\"test_event\", store_event)\n\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]), json=FIRE_EVENT\n    )\n\n    assert resp.status == 200\n    json = await resp.json()\n    assert json == {}\n\n    assert len(events) == 1\n    assert events[0].data[\"hello\"] == \"yo world\"\n\n\nasync def test_webhook_update_registration(webhook_client, authed_api_client):\n    \"\"\"Test that a we can update an existing registration via webhook.\"\"\"\n    register_resp = await authed_api_client.post(\n        \"/api/mobile_app/registrations\", json=REGISTER_CLEARTEXT\n    )\n\n    assert register_resp.status == 201\n    register_json = await register_resp.json()\n\n    webhook_id = register_json[CONF_WEBHOOK_ID]\n\n    update_container = {\"type\": \"update_registration\", \"data\": UPDATE}\n\n    update_resp = await webhook_client.post(\n        f\"/api/webhook/{webhook_id}\", json=update_container\n    )\n\n    assert update_resp.status == 200\n    update_json = await update_resp.json()\n    assert update_json[\"app_version\"] == \"2.0.0\"\n    assert CONF_WEBHOOK_ID not in update_json\n    assert CONF_SECRET not in update_json\n\n\nasync def test_webhook_handle_get_zones(hass, create_registrations, webhook_client):\n    \"\"\"Test that we can get zones properly.\"\"\"\n    await async_setup_component(\n        hass, ZONE_DOMAIN, {ZONE_DOMAIN: {}},\n    )\n\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]),\n        json={\"type\": \"get_zones\"},\n    )\n\n    assert resp.status == 200\n\n    json = await resp.json()\n    assert len(json) == 1\n    zones = sorted(json, key=lambda entry: entry[\"entity_id\"])\n    assert zones[0][\"entity_id\"] == \"zone.home\"\n\n\nasync def test_webhook_handle_get_config(hass, create_registrations, webhook_client):\n    \"\"\"Test that we can get config properly.\"\"\"\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]),\n        json={\"type\": \"get_config\"},\n    )\n\n    assert resp.status == 200\n\n    json = await resp.json()\n    if \"components\" in json:\n        json[\"components\"] = set(json[\"components\"])\n    if \"whitelist_external_dirs\" in json:\n        json[\"whitelist_external_dirs\"] = set(json[\"whitelist_external_dirs\"])\n\n    hass_config = hass.config.as_dict()\n\n    expected_dict = {\n        \"latitude\": hass_config[\"latitude\"],\n        \"longitude\": hass_config[\"longitude\"],\n        \"elevation\": hass_config[\"elevation\"],\n        \"unit_system\": hass_config[\"unit_system\"],\n        \"location_name\": hass_config[\"location_name\"],\n        \"time_zone\": hass_config[\"time_zone\"],\n        \"components\": hass_config[\"components\"],\n        \"version\": hass_config[\"version\"],\n        \"theme_color\": \"#03A9F4\",  # Default frontend theme color\n    }\n\n    assert expected_dict == json\n\n\nasync def test_webhook_returns_error_incorrect_json(\n    webhook_client, create_registrations, caplog\n):\n    \"\"\"Test that an error is returned when JSON is invalid.\"\"\"\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]), data=\"not json\"\n    )\n\n    assert resp.status == 400\n    json = await resp.json()\n    assert json == {}\n    assert \"invalid JSON\" in caplog.text\n\n\nasync def test_webhook_handle_decryption(webhook_client, create_registrations):\n    \"\"\"Test that we can encrypt/decrypt properly.\"\"\"\n    key = create_registrations[0][\"secret\"]\n    data = encrypt_payload(key, RENDER_TEMPLATE[\"data\"])\n\n    container = {\"type\": \"render_template\", \"encrypted\": True, \"encrypted_data\": data}\n\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[0][\"webhook_id\"]), json=container\n    )\n\n    assert resp.status == 200\n\n    webhook_json = await resp.json()\n    assert \"encrypted_data\" in webhook_json\n\n    decrypted_data = decrypt_payload(key, webhook_json[\"encrypted_data\"])\n\n    assert decrypted_data == {\"one\": \"Hello world\"}\n\n\nasync def test_webhook_requires_encryption(webhook_client, create_registrations):\n    \"\"\"Test that encrypted registrations only accept encrypted data.\"\"\"\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[0][\"webhook_id\"]),\n        json=RENDER_TEMPLATE,\n    )\n\n    assert resp.status == 400\n\n    webhook_json = await resp.json()\n    assert \"error\" in webhook_json\n    assert webhook_json[\"success\"] is False\n    assert webhook_json[\"error\"][\"code\"] == \"encryption_required\"\n\n\nasync def test_webhook_update_location(hass, webhook_client, create_registrations):\n    \"\"\"Test that location can be updated.\"\"\"\n    resp = await webhook_client.post(\n        \"/api/webhook/{}\".format(create_registrations[1][\"webhook_id\"]),\n        json={\n            \"type\": \"update_location\",\n            \"data\": {\"gps\": [1, 2], \"gps_accuracy\": 10, \"altitude\": -10},\n        },\n    )\n\n    assert resp.status == 200\n\n    state = hass.states.get(\"device_tracker.test_1_2\")\n    assert state is not None\n    assert state.attributes[\"latitude\"] == 1.0\n    assert state.attributes[\"longitude\"] == 2.0\n    assert state.attributes[\"gps_accuracy\"] == 10\n    assert state.attributes[\"altitude\"] == -10\n\n\nasync def test_webhook_enable_encryption(hass, webhook_client, create_registrations):\n    \"\"\"Test that encryption can be added to a reg initially created without.\"\"\"\n    webhook_id = create_registrations[1][\"webhook_id\"]\n\n    enable_enc_resp = await webhook_client.post(\n        f\"/api/webhook/{webhook_id}\", json={\"type\": \"enable_encryption\"},\n    )\n\n    assert enable_enc_resp.status == 200\n\n    enable_enc_json = await enable_enc_resp.json()\n    assert len(enable_enc_json) == 1\n    assert CONF_SECRET in enable_enc_json\n\n    key = enable_enc_json[\"secret\"]\n\n    enc_required_resp = await webhook_client.post(\n        f\"/api/webhook/{webhook_id}\", json=RENDER_TEMPLATE,\n    )\n\n    assert enc_required_resp.status == 400\n\n    enc_required_json = await enc_required_resp.json()\n    assert \"error\" in enc_required_json\n    assert enc_required_json[\"success\"] is False\n    assert enc_required_json[\"error\"][\"code\"] == \"encryption_required\"\n\n    enc_data = encrypt_payload(key, RENDER_TEMPLATE[\"data\"])\n\n    container = {\n        \"type\": \"render_template\",\n        \"encrypted\": True,\n        \"encrypted_data\": enc_data,\n    }\n\n    enc_resp = await webhook_client.post(f\"/api/webhook/{webhook_id}\", json=container)\n\n    assert enc_resp.status == 200\n\n    enc_json = await enc_resp.json()\n    assert \"encrypted_data\" in enc_json\n\n    decrypted_data = decrypt_payload(key, enc_json[\"encrypted_data\"])\n\n    assert decrypted_data == {\"one\": \"Hello world\"}\n\n\nasync def test_webhook_camera_stream_non_existent(\n    hass, create_registrations, webhook_client\n):\n    \"\"\"Test fetching camera stream URLs for a non-existent camera.\"\"\"\n    webhook_id = create_registrations[1][\"webhook_id\"]\n\n    resp = await webhook_client.post(\n        f\"/api/webhook/{webhook_id}\",\n        json={\n            \"type\": \"stream_camera\",\n            \"data\": {\"camera_entity_id\": \"camera.doesnt_exist\"},\n        },\n    )\n\n    assert resp.status == 400\n    webhook_json = await resp.json()\n    assert webhook_json[\"success\"] is False\n\n\nasync def test_webhook_camera_stream_non_hls(\n    hass, create_registrations, webhook_client\n):\n    \"\"\"Test fetching camera stream URLs for a non-HLS/stream-supporting camera.\"\"\"\n    hass.states.async_set(\"camera.non_stream_camera\", \"idle\", {\"supported_features\": 0})\n\n    webhook_id = create_registrations[1][\"webhook_id\"]\n\n    resp = await webhook_client.post(\n        f\"/api/webhook/{webhook_id}\",\n        json={\n            \"type\": \"stream_camera\",\n            \"data\": {\"camera_entity_id\": \"camera.non_stream_camera\"},\n        },\n    )\n\n    assert resp.status == 200\n    webhook_json = await resp.json()\n    assert webhook_json[\"hls_path\"] is None\n    assert (\n        webhook_json[\"mjpeg_path\"]\n        == \"/api/camera_proxy_stream/camera.non_stream_camera\"\n    )\n\n\nasync def test_webhook_camera_stream_stream_available(\n    hass, create_registrations, webhook_client\n):\n    \"\"\"Test fetching camera stream URLs for an HLS/stream-supporting camera.\"\"\"\n    hass.states.async_set(\n        \"camera.stream_camera\", \"idle\", {\"supported_features\": CAMERA_SUPPORT_STREAM}\n    )\n\n    webhook_id = create_registrations[1][\"webhook_id\"]\n\n    with patch(\n        \"homeassistant.components.camera.async_request_stream\",\n        return_value=\"/api/streams/some_hls_stream\",\n    ):\n        resp = await webhook_client.post(\n            f\"/api/webhook/{webhook_id}\",\n            json={\n                \"type\": \"stream_camera\",\n                \"data\": {\"camera_entity_id\": \"camera.stream_camera\"},\n            },\n        )\n\n    assert resp.status == 200\n    webhook_json = await resp.json()\n    assert webhook_json[\"hls_path\"] == \"/api/streams/some_hls_stream\"\n    assert webhook_json[\"mjpeg_path\"] == \"/api/camera_proxy_stream/camera.stream_camera\"\n\n\nasync def test_webhook_camera_stream_stream_available_but_errors(\n    hass, create_registrations, webhook_client\n):\n    \"\"\"Test fetching camera stream URLs for an HLS/stream-supporting camera but that streaming errors.\"\"\"\n    hass.states.async_set(\n        \"camera.stream_camera\", \"idle\", {\"supported_features\": CAMERA_SUPPORT_STREAM}\n    )\n\n    webhook_id = create_registrations[1][\"webhook_id\"]\n\n    with patch(\n        \"homeassistant.components.camera.async_request_stream\",\n        side_effect=HomeAssistantError(),\n    ):\n        resp = await webhook_client.post(\n            f\"/api/webhook/{webhook_id}\",\n            json={\n                \"type\": \"stream_camera\",\n                \"data\": {\"camera_entity_id\": \"camera.stream_camera\"},\n            },\n        )\n\n    assert resp.status == 200\n    webhook_json = await resp.json()\n    assert webhook_json[\"hls_path\"] is None\n    assert webhook_json[\"mjpeg_path\"] == \"/api/camera_proxy_stream/camera.stream_camera\"\n"
  },
  {
    "prompt": "\n\n### pymemcache/test/utils.py ###\n\n\"\"\"\nUseful testing utilities.\n\nThis module is considered public API.\n\n\"\"\"\n\nimport time\n\nimport six\n\nfrom pymemcache.exceptions import MemcacheIllegalInputError\nfrom pymemcache.serde import LegacyWrappingSerde\n\n\nclass MockMemcacheClient(object):\n    \"\"\"\n    A (partial) in-memory mock for Clients.\n\n    \"\"\"\n\n    def __init__(self,\n                 server=None,\n                 serde=None,\n                 serializer=None,\n                 deserializer=None,\n                 connect_timeout=None,\n                 timeout=None,\n                 no_delay=False,\n                 ignore_exc=False,\n                 default_noreply=True,\n                 allow_unicode_keys=False,\n                 encoding='ascii'):\n\n        self._contents = {}\n\n        self.serde = serde or LegacyWrappingSerde(serializer, deserializer)\n        self.allow_unicode_keys = allow_unicode_keys\n\n        # Unused, but present for interface compatibility\n        self.server = server\n        self.connect_timeout = connect_timeout\n        self.timeout = timeout\n        self.no_delay = no_delay\n        self.ignore_exc = ignore_exc\n        self.encoding = encoding\n\n    def clear(self):\n        \"\"\"Method used to clear/reset mock cache\"\"\"\n        self._contents.clear()\n\n    def get(self, key, default=None):\n        if not self.allow_unicode_keys:\n            if isinstance(key, six.string_types):\n                try:\n                    if isinstance(key, bytes):\n                        key = key.decode().encode('ascii')\n                    else:\n                        key = key.encode('ascii')\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n\n        if key not in self._contents:\n            return default\n\n        expire, value, flags = self._contents[key]\n        if expire and expire < time.time():\n            del self._contents[key]\n            return default\n\n        return self.serde.deserialize(key, value, flags)\n\n    def get_many(self, keys):\n        out = {}\n        for key in keys:\n            value = self.get(key)\n            if value is not None:\n                out[key] = value\n        return out\n\n    get_multi = get_many\n\n    def set(self, key, value, expire=0, noreply=True, flags=0):\n        if not self.allow_unicode_keys:\n            if isinstance(key, six.string_types):\n                try:\n                    if isinstance(key, bytes):\n                        key = key.decode().encode()\n                    else:\n                        key = key.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n        if (isinstance(value, six.string_types) and\n                not isinstance(value, six.binary_type)):\n            try:\n                value = value.encode(self.encoding)\n            except (UnicodeEncodeError, UnicodeDecodeError):\n                raise MemcacheIllegalInputError\n\n        value, flags = self.serde.serialize(key, value)\n\n        if expire:\n            expire += time.time()\n\n        self._contents[key] = expire, value, flags\n        return True\n\n    def set_many(self, values, expire=None, noreply=True):\n        for key, value in six.iteritems(values):\n            self.set(key, value, expire, noreply)\n        return []\n\n    set_multi = set_many\n\n    def incr(self, key, value, noreply=False):\n        current = self.get(key)\n        present = current is not None\n        if present:\n            self.set(key, current + value, noreply=noreply)\n        return None if noreply or not present else current + value\n\n    def decr(self, key, value, noreply=False):\n        current = self.get(key)\n        if current is None:\n            return\n\n        self.set(key, current - value, noreply=noreply)\n        return current - value\n\n    def add(self, key, value, expire=None, noreply=True):\n        current = self.get(key)\n        present = current is not None\n        if not present:\n            self.set(key, value, expire, noreply)\n        return not present\n\n    def delete(self, key, noreply=True):\n        current = self._contents.pop(key, None)\n        present = current is not None\n        return noreply or present\n\n    def delete_many(self, keys, noreply=True):\n        for key in keys:\n            self.delete(key, noreply)\n        return True\n\n    def prepend(self, key, value, expire=0, noreply=None, flags=None):\n        current = self.get(key)\n        if current is not None:\n            if (isinstance(value, six.string_types) and\n                    not isinstance(value, six.binary_type)):\n                try:\n                    value = value.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n            self.set(key, value + current)\n        return True\n\n    def append(self, key, value, expire=0, noreply=None, flags=None):\n        current = self.get(key)\n        if current is not None:\n            if (isinstance(value, six.string_types) and\n                    not isinstance(value, six.binary_type)):\n                try:\n                    value = value.encode(self.encoding)\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise MemcacheIllegalInputError\n            self.set(key, current + value)\n        return True\n\n    delete_multi = delete_many\n\n    def stats(self):\n        # I make no claim that these values make any sense, but the format\n        # of the output is the same as for pymemcache.client.Client.stats()\n        return {\n            \"version\": \"MockMemcacheClient\",\n            \"rusage_user\": 1.0,\n            \"rusage_system\": 1.0,\n            \"hash_is_expanding\": False,\n            \"slab_reassign_running\": False,\n            \"inter\": \"in-memory\",\n            \"evictions\": False,\n            \"growth_factor\": 1.0,\n            \"stat_key_prefix\": \"\",\n            \"umask\": 0o644,\n            \"detail_enabled\": False,\n            \"cas_enabled\": False,\n            \"auth_enabled_sasl\": False,\n            \"maxconns_fast\": False,\n            \"slab_reassign\": False,\n            \"slab_automove\": False,\n        }\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import six\nimport pytest\n\nfrom pymemcache.test.utils import MockMemcacheClient\n\n\n@pytest.mark.unit()\ndef test_get_set():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(b\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_unicide_key():\n    client = MockMemcacheClient()\n    assert client.get(u\"hello\") is None\n\n    client.set(b\"hello\", 12)\n    assert client.get(u\"hello\") == 12\n\n\n@pytest.mark.unit()\ndef test_get_set_non_ascii_value():\n    client = MockMemcacheClient()\n    assert client.get(b\"hello\") is None\n\n    # This is the value of msgpack.packb('non_ascii')\n    non_ascii_str = b'\\xa9non_ascii'\n    client.set(b\"hello\", non_ascii_str)\n    assert client.get(b\"hello\") == non_ascii_str\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many():\n    client = MockMemcacheClient()\n    client.set(b\"h\", 1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": 1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(dict(h=1, e=2, z=3)))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_get_many_set_many_non_ascii_values():\n    client = MockMemcacheClient()\n\n    # These are the values of calling msgpack.packb() on '1', '2', and '3'\n    non_ascii_1 = b'\\xa11'\n    non_ascii_2 = b'\\xa12'\n    non_ascii_3 = b'\\xa13'\n    client.set(b\"h\", non_ascii_1)\n\n    result = client.get_many([b\"h\", b\"e\", b\"l\", b\"o\"])\n    assert result == {b\"h\": non_ascii_1}\n\n    # Convert keys into bytes\n    d = dict((k.encode('ascii'), v)\n             for k, v in six.iteritems(\n                dict(h=non_ascii_1, e=non_ascii_2, z=non_ascii_3)\n             ))\n    client.set_many(d)\n    assert client.get_many([b\"h\", b\"e\", b\"z\", b\"o\"]) == d\n\n\n@pytest.mark.unit()\ndef test_add():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.add(b\"k\", 25)\n    assert client.get(b\"k\") == 2\n\n\n@pytest.mark.unit()\ndef test_delete():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n    assert client.get(b\"k\") == 2\n\n    client.delete(b\"k\")\n    assert client.get(b\"k\") is None\n\n\n@pytest.mark.unit()\ndef test_incr_decr():\n    client = MockMemcacheClient()\n\n    client.add(b\"k\", 2)\n\n    client.incr(b\"k\", 4)\n    assert client.get(b\"k\") == 6\n\n    client.decr(b\"k\", 2)\n    assert client.get(b\"k\") == 4\n\n\n@pytest.mark.unit()\ndef test_prepand_append():\n    client = MockMemcacheClient()\n\n    client.set(b\"k\", '1')\n    client.append(b\"k\", 'a')\n    client.prepend(b\"k\", 'p')\n    assert client.get(b\"k\") == b'p1a'\n"
  },
  {
    "prompt": "\n\n### argcomb.py ###\n\n\"\"\"ArgComb checks that the combination of arguments supplied for a\nfunction is valid. Take the following function::\n\n    def subseq(seq, start, length=None, end=None): ...\n\nThis returns a subsequence of ``seq`` starting at ``start``. The\nend can be specified by supplying either ``length`` or ``end``. The\n:func:`@argcomb<argcomb>` decorator checks that exactly one of these is supplied::\n\n    from argcomb import argcomb, Xor\n\n    @argcomb(Xor(\"length\", \"end\"))\n    def subseq(seq, start, length=None, end=None): ...\n\"\"\"\n\nfrom __future__ import annotations\n\nimport abc\nimport contextlib\nimport enum\nimport functools\nimport warnings\nfrom typing import Any, Callable, Dict, NoReturn, Optional, Tuple, Union\n\n__all__ = [\n    \"argcomb\",\n    \"Or\",\n    \"And\",\n    \"Xor\",\n    \"Not\",\n    \"Else\",\n    \"InvalidArgumentCombination\",\n    \"Condition\",\n    \"ArgumentSpec\",\n]\n\n\nclass InvalidArgumentCombination(ValueError):\n    \"\"\"Raised when the caller passes an invalid argument\n    combination. \"\"\"\n\n\nclass ConditionType(enum.Enum):\n    \"\"\"Enumeration of types of condition. \"\"\"\n\n    NOT = 0\n    AND = 1\n    OR = 2\n    XOR = 3\n\n\nclass DerivedCondition(abc.ABC):\n    \"\"\"A condition that is derived from one or more other\n    conditions. \"\"\"\n\n    type_: ConditionType\n\n    def __init__(self, *args: Condition):\n        \"\"\"Construct a condition.\n\n        :param args: list of conditions nested under this condition\n        \"\"\"\n\n        self.args = args\n        with contextlib.suppress(NotImplementedError):\n            self._validate()\n\n    def _validate(self) -> None:\n        \"\"\"Perform post initialisation validation if required. \"\"\"\n\n        raise NotImplementedError\n\n    def __repr__(self) -> str:\n        return (\n            self.type_.name.capitalize()\n            + \"(\"\n            + \", \".join(repr(a) for a in self.args)\n            + \")\"\n        )\n\n\nclass Or(DerivedCondition):\n    \"\"\"Logical OR condition.\n\n    An :class:`Or` condition will evaluate to ``True`` if any of\n    its child conditions evaluates to ``True``.\n\n    :param args: conditions from which this new condition should be\n        constructed.\n    \"\"\"\n\n    type_ = ConditionType.OR\n\n\nclass And(DerivedCondition):\n    \"\"\"Logical AND condition.\n\n    An :class:`And` condition will evaluate to ``True`` only if all\n    its child conditions evaluate to ``True``.\n\n    :param args: conditions from which this new condition should be\n        constructed.\n    \"\"\"\n\n    type_ = ConditionType.AND\n\n\nclass Xor(DerivedCondition):\n    \"\"\"Logical XOR condition.\n\n    An :class:`Xor` condition will evaluate to ``True`` only if exactly\n    1 of its child conditions evaluates to ``True``.\n\n    :param args: conditions from which this new condition should be\n        constructed.\n    \"\"\"\n\n    type_ = ConditionType.XOR\n\n\nclass Not(DerivedCondition):\n    \"\"\"Logical NOT condition.\n\n    An :class:`Not` condition will evaluate to ``True`` only if its child\n    condition evaluates to ``False``.\n\n    :param arg: the child condition that this new condition is based on\n    \"\"\"\n\n    type_ = ConditionType.NOT\n\n    def _validate(self) -> None:\n        \"\"\"Ensure that only one argument was passed. \"\"\"\n\n        if len(self.args) != 1:\n            raise TypeError(\n                f\"Not() takes 1 positional argument but {len(self.args)} were given\"\n            )\n\n\n#: Type definition for conditions. A condition can take one of two\n#: forms:\n#:\n#: #. A string containing the name of a variable. In this case, the\n#:    condition evaluates to ``True`` if the variable named in the\n#:    string is passed by the caller, or ``False`` otherwise.\n#: #. An instance of :class:`Or`, :class:`And`, :class:`Xor`,\n#:    or :class:`Not`. Such conditions are called \"derived\n#:    conditions\", as they are derived from other conditions.\n#:\n#: Since derived conditions can be constructed from other derived\n#: conditions, arbitrarily complex conditions can be created, for\n#: example::\n#:\n#:     my_condition = Or(And(\"a\", \"b\"), Not(Xor(\"a\", \"c\", \"d\")))\nCondition = Union[str, DerivedCondition]\n\n#: Type definition for argument specification.\n#:\n#: Argument specifications determine what validation is done in\n#: respect of the caller supplying a certain argument.\n#:\n#: An argument specification can either be a :data:`Condition` or a\n#: dictionary mapping values to :data:`Condition`\\ s.\n#:\n#: If an argument specification is a :data:`Condition` then\n#: validation of that argument will succeed if the condition is\n#: valid. If the argument specification is a dictionary mapping\n#: values to :data:`Condition`\\ s then the :data:`Condition` will be\n#: chosen based on the value of the argument being validated.\n#:\n#: If an argument specification is a dictionary, a special key\n#: :data:`Else` is available to serve as a catch-all for values\n#: not otherwise handled. If no :data:`Else` key is present and the\n#: value of the argument is also not present, no validation will take\n#: place. For example::\n#:\n#:     @argcomb(a={1: \"b\", 2: \"c\"})\n#:     def f(a, b, c): ...\n#:\n#: In this case, ``f(a=1, b=2)`` is valid but ``f(a=2, b=2)`` is not.\n#: ``f(a=3)`` is valid. ::\n#:\n#:     @argcomb(a={1: \"b\", Else: \"c\"})\n#:     def f(a, b, c): ...\n#:\n#: Now ``f(a=3)`` is not valid, but ``f(a=3, c=2)`` is\n#: valid.\nArgumentSpec = Union[Dict[Any, Condition], Condition]\n\n#: Special value to indicate validation behaviour when a value-specific\n#: condition is not available. See :data:`ArgumentSpec` for more\n#: details.\nElse = object()\n\n\nclass argcomb:\n    \"\"\"Check that the combination of arguments passed to a function by\n    the caller is valid.\n\n    The first argument is a condition which, if supplied, is\n    always evaluated. For example::\n\n        @argcomb(Or(\"a\", \"b\"))\n        def f(a=None, b=None): ...\n\n    The :data:`Condition` ``Or(\"a\", \"b\")`` stipulates that the caller\n    must pass at least one of ``a`` or ``b`` as an argument to ``f``\n    when calling it, otherwise an :exc:`InvalidArgumentCombination`\n    exception will be raised.\n\n    Subsequent arguments determine further validation that should be\n    carried out *if* an additional argument is specified. This\n    validation can optionally vary depending on the value that the\n    caller passes for this argument. ::\n\n        @argcomb(Or(\"a\", \"b\"), a=\"c\")\n        def g(a=None, b=None, c=None): ...\n\n        @argcomb(Or(\"a\", \"b\"), a={1: \"b\", 2: \"c\", Else: Or(\"b\", \"c\"))\n        def h(a=None, b=None, c=None): ...\n\n    For ``g``, at least one of ``a`` or ``b`` must be passed, and if\n    ``a`` is passed then ``c`` must be passed too.\n\n    For ``h``, at least one of ``a`` or ``b`` must be passed. If ``a``\n    is passed then further validation will take place depending on the\n    value of ``a``. If ``a==1`` then ``b`` must also be passed. If\n    ``a==2`` then ``c`` must also be passed. If ``a`` takes any value\n    except ``1`` or ``2`` then at least one of ``b`` or ``c`` must be\n    passed.\n\n    :param default: a :class:`Condition` that must always evaluate to\n        ``True`` in order for the call to be considered valid.\n    :param kwargs: for each keyword argument, the name is assumed to be\n        the name of a variable that the caller may supply, and the\n        value determines any validation actions that should take place\n        if that variable is passed by the caller to the decorated\n        function.\n    \"\"\"\n\n    _spec: Dict[str, ArgumentSpec]\n    _default: Optional[Condition]\n\n    def __init__(self, default: Optional[Condition] = None, /, **kwargs: ArgumentSpec):\n        \"\"\"Specify the conditions.\n\n        :param kwargs: the conditions to validate the arguments against\n\n        There are two forms that a condition can take. If the mere fact\n        that an argument is supplied means a condition should be\n        validated, the condition can be given directly. For example:\n            @argcomb(a=Or(\"b\", \"c\"))\n        This says that if argument `a is supplied then at least one of\n        `b` or `c` must also be supplied. Alternatively different\n        conditions can be given depending on the value that an argument\n        takes:\n            @argcomb(a={1: \"b\", 2: \"c\"})\n        This says if `a` is `1` then `b` must be supplied, and if `a`\n        is `2` then `c` must be supplied. In this case, `Else` may be\n        used as a catch-all for other cases:\n            @argcomb(a={1: \"b\", 2: \"c\", Else: Or(\"b\", \"c\")})\n        \"\"\"\n\n        self._spec = kwargs\n        self._default = default\n\n    def __call__(self, func: Callable) -> Callable:\n        \"\"\"Create the decorated function.\n\n        :param func: the original function\n        :return: the decorated function\n        \"\"\"\n\n        @functools.wraps(func)\n        def ret(*args: Any, **kwargs: Any) -> Any:\n            # Although functions and methods both have ``__defaults__` and\n            # ``__kwdefaults__`` members, not all callables necessarily have\n            # them\n            try:\n                pos_arg_defaults = func.__defaults__  # type: ignore\n            except AttributeError:\n                pos_arg_defaults = None\n            try:\n                kw_arg_defaults = func.__kwdefaults__  # type: ignore\n            except AttributeError:\n                kw_arg_defaults = None\n            arg_dict = self._get_arg_dict(\n                pos_arg_values=args,\n                kw_args=kwargs,\n                all_arg_names=func.__code__.co_varnames,\n                pos_arg_defaults=pos_arg_defaults,\n                kw_arg_defaults=kw_arg_defaults,\n                kw_only_arg_count=func.__code__.co_kwonlyargcount,\n            )\n            self._check_all(arg_dict)\n            return func(*args, **kwargs)\n\n        return ret\n\n    @staticmethod\n    def _get_arg_dict(\n        *,\n        pos_arg_values: Tuple,\n        kw_args: Dict[str, Any],\n        all_arg_names: Tuple[str, ...],\n        pos_arg_defaults: Optional[Tuple],\n        kw_arg_defaults: Optional[Dict[str, Any]],\n        kw_only_arg_count: int,\n    ) -> Dict[str, Any]:\n        \"\"\"Get a dictionary of user supplied arguments and their values.\n\n        If the user supplies an argument with its default value, it is\n        treated as if the user did not pass it at all.\n\n        For keyword arguments this is a slightly more simple since both\n        the values and the defaults are supplied in a dictionary\n        mapping argument names to values, but for positional arguments\n        we need to do some work to match up the argument names, values\n        and default values.\n        \"\"\"\n\n        defaults: Dict[str, Any] = {}\n        if pos_arg_defaults:\n            if kw_only_arg_count:\n                pos_arg_names = all_arg_names[:-kw_only_arg_count]\n            else:\n                pos_arg_names = all_arg_names\n            defaults.update(zip(reversed(pos_arg_names), reversed(pos_arg_defaults)))\n        if kw_arg_defaults:\n            defaults.update(kw_arg_defaults)\n\n        arg_dict = {\n            arg_name: arg_value\n            for arg_name, arg_value in zip(all_arg_names, pos_arg_values)\n            if arg_name not in defaults or defaults[arg_name] != arg_value\n        }\n        for arg_name in kw_args:\n            if arg_name in arg_dict:\n                # For a function such as:\n                #     f(a, /, **kwargs): ...\n                # the call ``f(1, a=1)`` is valid, but from\n                # ``argcomb``'s point of view there are now two\n                # arguments both called ``a``. This is not supported\n                # and ``argcomb`` should not be used where there are\n                # both positional only arguments and ``**kwargs``. We\n                # emit a warning when this situation is detected.\n                warnings.warn(\n                    f\"Argument {arg_name} was supplied as both a\"\n                    \"positional only argument and a keyword argument. This is\"\n                    \"not supported by ArgComb.\"\n                )\n        arg_dict.update(\n            {\n                arg_name: arg_value\n                for arg_name, arg_value in kw_args.items()\n                if arg_name not in defaults or defaults[arg_name] != arg_value\n            }\n        )\n        return arg_dict\n\n    def _check_all(self, arg_dict: Dict[str, Any]) -> None:\n        \"\"\"Execute all checks as specified in ``self._spec``.\n\n        Also check that ``self._default`` holds.\n\n        :param arg_dict: dictionary of argument names and values\n        \"\"\"\n\n        if self._default and not self._validate(arg_dict, self._default):\n            raise InvalidArgumentCombination(\n                f\"Condition `{self._default}` does not hold\"\n            )\n\n        for arg_name, arg_spec in self._spec.items():\n            self._check(arg_dict, arg_name, arg_spec)\n\n    def _check(\n        self,\n        arg_dict: Dict[str, Any],\n        arg_name: str,\n        arg_spec: Union[Dict[Any, Condition], Condition],\n    ) -> None:\n        \"\"\"Check an argument.\n\n        If the check fails then an `InvalidArgumentCombination`\n        exception is raised.\n\n        :param arg_dict: dictionary of arguments and values\n        :param arg_name: name of the argument being checked\n        :param arg_spec: specification for this argument\n        \"\"\"\n\n        if arg_name not in arg_dict:\n            # This argument wasn't supplied\n            return\n        if not isinstance(arg_spec, dict):\n            if not self._validate(arg_dict, arg_spec):\n                self._raise_error(arg_name, arg_spec)\n            return\n        for arg_val, condition in arg_spec.items():\n            if arg_val != arg_dict[arg_name] or arg_name is Else:\n                continue\n            if not self._validate(arg_dict, condition):\n                self._raise_error(arg_name, condition)\n        if Else in arg_spec:\n            if not self._validate(arg_dict, arg_spec[Else]):\n                self._raise_error(arg_name, arg_spec[Else])\n\n    @staticmethod\n    def _raise_error(arg_name: str, condition: Condition) -> NoReturn:\n        \"\"\"Raise an exception when validation fails.\n\n        :param arg_name: name of the argument that did not validate\n        :param condition: failing condition\n        \"\"\"\n\n        raise InvalidArgumentCombination(\n            f\"Argument `{arg_name}` is not valid: condition `{condition}` does not hold\"\n        )\n\n    def _validate(self, arg_dict: Dict[str, Any], condition: Condition) -> bool:\n        \"\"\"Validate a single condition.\n\n        :param arg_dict: dictionary of arguments and values\n        :param condition: the condition to evaluate\n        :return: `True` if the condition is satisfied or `False` otherwise\n        \"\"\"\n\n        if isinstance(condition, str):\n            return condition in arg_dict\n\n        if isinstance(condition, Not):\n            return not self._validate(arg_dict, condition.args[0])\n\n        if isinstance(condition, Or):\n            for arg in condition.args:\n                if self._validate(arg_dict, arg):\n                    return True\n            return False\n\n        if isinstance(condition, Xor):\n            found_true = False\n            for arg in condition.args:\n                if self._validate(arg_dict, arg):\n                    if found_true:\n                        return False\n                    found_true = True\n            return found_true\n\n        if isinstance(condition, And):\n            for arg in condition.args:\n                if not self._validate(arg_dict, arg):\n                    return False\n            return True\n\n        raise TypeError(f\"Condition type {type(condition)} is not supported\")\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"Tests for ArgComb. \"\"\"\n\n# pylint: disable=unused-argument, unused-variable\n\nfrom typing import Any, Callable\n\nimport pytest\n\nfrom argcomb import And, Else, InvalidArgumentCombination, Not, Or, Xor, argcomb\n\n\ndef test_default() -> None:\n    \"\"\"Test the ``default`` parameter of :function:``argcomb.__init__``.\n\n    This test also serves to check the basic functionality of\n    ``argcomb`` for different types of signature: normal arguments,\n    keyword only arguments, positional only arguments, or any\n    combination of the above.\n    \"\"\"\n\n    def test_func(\n        func: Callable[..., None], kw_only_count: int, pos_only_count: int\n    ) -> None:\n        \"\"\"Test a given function ``f``. \"\"\"\n\n        with pytest.raises(InvalidArgumentCombination):\n            func()\n        if pos_only_count == 0:\n            func(a=1)\n            func(a=1, b=1)\n            func(a=1, b=None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(a=None, b=1)\n        if kw_only_count < 2:\n            func(1)\n\n        if kw_only_count < 2 and pos_only_count < 2:\n            func(1, b=1)\n            func(1, b=None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(None, b=1)\n\n        if kw_only_count == 0:\n            func(1, 1)\n            func(1, None)\n            with pytest.raises(InvalidArgumentCombination):\n                func(None, 1)\n\n        if pos_only_count < 2:\n            with pytest.raises(InvalidArgumentCombination):\n                func(b=1)\n\n    @argcomb(\"a\")\n    def f(a: Any = None, b: Any = None) -> None:\n        ...\n\n    test_func(f, kw_only_count=0, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def g(a: Any = None, *, b: Any = None) -> None:\n        ...\n\n    test_func(g, kw_only_count=1, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def h(*, a: Any = None, b: Any = None) -> None:\n        ...\n\n    test_func(h, kw_only_count=2, pos_only_count=0)\n\n    @argcomb(\"a\")\n    def i(a: Any = None, /, b: Any = None) -> None:\n        ...\n\n    test_func(i, kw_only_count=0, pos_only_count=1)\n\n    @argcomb(\"a\")\n    def j(a: Any = None, b: Any = None, /) -> None:\n        ...\n\n    test_func(j, kw_only_count=0, pos_only_count=2)\n\n    @argcomb(\"a\")\n    def k(a: Any = None, /, *, b: Any = None) -> None:\n        ...\n\n    test_func(k, kw_only_count=1, pos_only_count=1)\n\n\ndef test_argument_specs() -> None:\n    \"\"\"Test providing specifications for arguments. \"\"\"\n\n    @argcomb(a=\"b\", c=\"d\")\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # 9 valid combinations\n    f()\n    f(d=1)\n    f(c=1, d=1)\n    f(b=1)\n    f(b=1, d=1)\n    f(b=1, c=1, d=1)\n    f(a=1, b=1)\n    f(a=1, b=1, d=1)\n    f(a=1, b=1, c=1, d=1)\n\n    # 7 invalid combinations\n    with pytest.raises(InvalidArgumentCombination):\n        f(c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, d=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1, d=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1, c=1)\n\n\ndef test_value_dependent_specs() -> None:\n    \"\"\"Test specifications which depend on argument value. \"\"\"\n\n    @argcomb(a={1: \"b\", 2: \"c\", 3: \"d\"})\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # valid\n    f()\n    f(a=1, b=4)\n    f(a=2, c=5)\n    f(a=3, d=6)\n    f(a=1, b=4, c=5)\n    f(a=1, b=4, c=5, d=6)\n    f(a=1, b=4, d=6)\n    f(a=2, c=5, d=6)\n    f(a=4)\n    f(b=4, c=5)\n    f(d=6)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=5)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=5, d=6)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, b=3)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, d=4)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=3, b=3, c=4)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=3)\n\n\ndef test_and() -> None:\n    \"\"\"Test ``And`` condition. \"\"\"\n\n    @argcomb(And(\"a\", \"b\"))\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    # \u00a0valid\n    f(a=1, b=2)\n    f(a=1, b=2, c=3)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=None)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=None, b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_or() -> None:\n    \"\"\"Test ``Or`` condition. \"\"\"\n\n    @argcomb(Or(\"a\", \"b\"))\n    def f(a: Any = None, b: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1)\n    f(b=2)\n    f(a=1, b=2)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_not() -> None:\n    \"\"\"Test ``Not`` condition. \"\"\"\n\n    @argcomb(Not(\"a\"))\n    def f(a: Any = None) -> None:\n        ...\n\n    # valid\n    f()\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n\n\ndef test_xor() -> None:\n    \"\"\"Test ``Xor`` condition. \"\"\"\n\n    @argcomb(Xor(\"a\", \"b\", \"c\"))\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1)\n    f(b=1)\n    f(c=1)\n\n    # \u00a0invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_else() -> None:\n    \"\"\"Test ``Else`` in value dependent specifications. \"\"\"\n\n    @argcomb(a={1: \"b\", Else: \"c\"})\n    def f(a: Any = None, b: Any = None, c: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=2, c=1)\n\n    # \u00a0invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=2, b=1)\n\n\ndef test_nested_condition() -> None:\n    \"\"\"Test a nested condition. \"\"\"\n\n    @argcomb(Or(And(\"a\", \"b\"), And(\"c\", \"d\")))\n    def f(a: Any = None, b: Any = None, c: Any = None, d: Any = None) -> None:\n        ...\n\n    # valid\n    f(a=1, b=1)\n    f(c=1, d=1)\n    f(a=1, b=1, c=1, d=1)\n\n    # invalid\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f()\n\n\ndef test_argument_named_default() -> None:\n    \"\"\"Test when an argument is named ``default``.\n\n    This collides with a positional only argument named ``default`` in\n    the ``argcomb`` signature, but as this is positional only this\n    should not matter.\n    \"\"\"\n\n    @argcomb(default=\"a\")\n    def f(default: Any = None, a: Any = None) -> None:\n        ...\n\n    f(a=1)\n    f(default=1, a=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(default=1)\n\n\ndef test_arguments_same_name() -> None:\n    \"\"\"Test that a warning is emitted when a function with two\n    identically named arguments. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(a: Any = None, /, b: Any = None, **kwargs: Any) -> None:\n        ...\n\n    with pytest.warns(UserWarning):\n        f(1, 2, a=3)  # pylint: disable=E1124\n\n\ndef test_default_arguments() -> None:\n    \"\"\"Test that default arguments are correctly recognised when they\n    are not ``None``. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(a: int = 1, b: int = 2) -> None:\n        ...\n\n    # valid since ``a`` is the default value\n    f(a=1)\n\n    with pytest.raises(InvalidArgumentCombination):\n        # invalid since ``b`` is the default value\n        f(a=2, b=2)\n\n\ndef test_kwargs() -> None:\n    \"\"\"Test functionality when signature uses ``**kwargs``. \"\"\"\n\n    @argcomb(a=\"b\")\n    def f(**kwargs: Any) -> None:\n        ...\n\n    f(a=1, b=1)\n    f(b=1, c=1)\n    with pytest.raises(InvalidArgumentCombination):\n        f(a=1)\n"
  },
  {
    "prompt": "\n\n### infsocsol/helpers.py ###\n\n# Copyright 2019 Alastair Pharo\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport matlab.engine\nimport numpy\nimport oct2py\nimport os\n\n# Adds the root of the project to the *lab path\ndef setroot(engine, root=None):\n    engine.addpath(os.path.join(*[p for p in [os.path.dirname(os.path.dirname(__file__)), root] if p]))\n\n# This enables engine-agnostic callbacks in the test code\nclass OctaveWithMatlabInterface:\n    def __init__(self, engine):\n        self.engine = engine\n\n    def __getattr__(self, name):\n        keymap = {\n            'nargout': 'nout'\n        }\n\n        def _feval(*args, **kwargs):\n            _kwargs = { keymap[k]: v for k, v in kwargs.items() if keymap[k] }\n            return self.engine.feval(name, *args, **_kwargs)\n\n        return _feval\n\ndef octave_engine(root=None):\n    engine = oct2py.Oct2Py()\n    setroot(engine, root)\n    return OctaveWithMatlabInterface(engine)\n\ndef matlab_engine(root=None):\n    engine = matlab.engine.start_matlab()\n    setroot(engine, root)\n    return engine\n\ndef matrix(engine, obj):\n    if engine.__class__ == OctaveWithMatlabInterface:\n        return numpy.array(obj)\n    else:\n        return matlab.double(obj)\n\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright 2019 Alastair Pharo\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nimport numpy\nimport os\nimport scipy\nfrom numpy.testing import assert_allclose\nfrom infsocsol.helpers import matrix\n\n@pytest.fixture(scope=\"module\", params=[\n    # engine    states time_step start         steps  steady steady_accuracy optim_accuracy\n    ( 'matlab', 10,    1,        (100.0, 0.5), 100,   True,  0.01,           0.009 ),\n    ( 'matlab', 20,    0.5,      (600.0, 0.6), 200,   True,  0.01,           0.015 ),\n    ( 'matlab', 40,    0.25,     (60.0, 0.1),  300,   True,  0.01,           0.018 ),\n    ( 'matlab', 10,    1,        (600.0, 1.0), 200,   False, 0.001,          None  ),\n    ( 'octave', 10,    1,        (100.0, 0.5), 100,   True,  0.001,          0.009 ),\n    ( 'octave', 20,    0.5,      (600.0, 0.6), 200,   True,  0.001,          0.015 )\n])\ndef fisheries_scenario(request):\n    return request.param\n\ndef test_fisheries_det_basic(engines, fisheries_scenario):\n    _engine, states, time_step, _start, steps, steady, steady_accuracy, optim_accuracy = fisheries_scenario\n    engine = engines[_engine]\n    start = matrix(engine, _start)\n    engine.cd(os.path.join(os.path.dirname(__file__), \"fisheries_det_basic\"))\n\n    engine.solve(float(states), float(time_step), nargout=0)\n    final = numpy.array(engine.sim_final(start, steps))\n    # This is determined by setting s\\dot = 0, which solves to 1 = x/L + q/r e\n    steady_one = numpy.dot(final, [1/600, 5/4])\n\n    if steady:\n        assert_allclose(steady_one, 1, atol=steady_accuracy)\n\n        # This is the most profitable steady state -- x = L/2 + c/2pq\n        profit_max_steady = numpy.array([[302.5, 0.39667]])\n        assert_allclose(final, profit_max_steady, rtol=optim_accuracy)\n    else:\n        assert steady_one > 1 + steady_accuracy\n"
  },
  {
    "prompt": "\n\n### web/tests/factories.py ###\n\nimport factory\nfrom django.db import models\nfrom directory.models import CoopType, Coop, ContactMethod, Person\nfrom address.models import AddressField, Address\nfrom phonenumber_field.modelfields import PhoneNumberField\nfrom address.models import State, Country, Locality\nfrom faker import Faker\n\nmyFactory = Faker()\n\nclass CountryFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Country Factory\n    \"\"\"\n    class Meta:\n        model = Country\n\n    name = myFactory.name() \n    code = \"NN\"\n\n\nclass StateFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define State Factory\n    \"\"\"\n    class Meta:\n        model = State \n\n    name = \"Narnia\"\n    code = \"NN\"\n    country = factory.SubFactory(CountryFactory) \n\n\nclass LocalityFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Locality Factory\n    \"\"\"\n    class Meta:\n        model = Locality \n\n    name = \"Narnia\"\n    postal_code = \"60605\"\n    state = factory.SubFactory(StateFactory) \n\n\nclass AddressFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Address Factory\n    \"\"\"\n\n    class Meta:\n        model = 'address.Address'\n\n    street_number = \"123\"\n    route = \"Rd\"\n    raw = \"123 Fake Rd\" \n    formatted = \"123 Fake Rd.\" \n    latitude = 87.1234\n    longitude = -100.12342\n    locality = factory.SubFactory(LocalityFactory)\n\n\nclass PhoneContactMethodFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Contact Method Factory for a phone number \n    \"\"\"\n    class Meta:\n        model = ContactMethod\n\n    type = ContactMethod.ContactTypes.EMAIL\n    phone = \"8005551234\"\n\n\nclass EmailContactMethodFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Contact Method Factory for emails \n    \"\"\"\n    class Meta:\n        model = ContactMethod\n\n    type = ContactMethod.ContactTypes.EMAIL\n    email = \"test@example.com\"\n\n\nclass CoopTypeFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Coop Type Factory\n    \"\"\"\n    class Meta:\n        model = CoopType\n\n    name = \"test name\"\n\n\nclass CoopFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Coop Factory\n    \"\"\"\n    class Meta:\n        model = Coop\n\n    name = \"test model\"\n    enabled = True\n    phone = factory.SubFactory(PhoneContactMethodFactory)\n    email = factory.SubFactory(EmailContactMethodFactory) \n    web_site = \"http://www.hello.com\"\n\n    @factory.post_generation\n    def addresses(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted:\n            # A list of types were passed in, use them\n            for address in extracted:\n                self.addresses.add(address)\n        else:\n            address = AddressFactory()\n            self.addresses.add( address )\n\n    @factory.post_generation\n    def types(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted is not None:\n        #if extracted:\n            # A list of types were passed in, use them\n            #for _ in range(extracted):\n            for type in extracted:\n                self.types.add(CoopTypeFactory())\n        #else:\n        #    print(\"Creating type ...\\n\")\n        #    type = CoopTypeFactory()\n        #    self.types.add( type )\n\n\nclass PersonFactory(factory.DjangoModelFactory):\n    \"\"\"\n        Define Person Factory\n    \"\"\"\n    class Meta:\n        model = Person\n\n    first_name = \"first name\"\n    last_name = \"last name\"\n\n    @factory.post_generation\n    def contact_methods(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted:\n            # A list of contact methods were passed in, use them\n            for contact_method in extracted:\n                self.contact_methods.add(contact_method)\n        else:\n            contact_method = EmailContactMethodFactory()\n            self.contact_methods.add( contact_method )\n\n    @factory.post_generation\n    def coops(self, create, extracted, **kwargs):\n        if not create:\n            # Simple build, do nothing.\n            return\n\n        if extracted is not None:\n        #if extracted:\n            print(\"calling this branch ...\")\n            # A list of coops were passed in, use them\n            for _ in range(extracted):\n            #for coop in extracted:\n                self.coops.add(coop)\n        else:\n            coop = CoopFactory()\n            self.coops.add( coop )\n\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import pytest\nfrom django.test import TestCase\nfrom .factories import CoopTypeFactory, CoopFactory, AddressFactory, PhoneContactMethodFactory \nfrom directory.models import Coop, CoopType\n\n\nclass ModelTests(TestCase):\n    @classmethod\n    def setUpTestData(cls):\n        print(\"setUpTestData: Run once to set up non-modified data for all class methods.\")\n        #management.call_command('loaddata', 'test_data.yaml', verbosity=0)\n        pass\n\n    @pytest.mark.django_db\n    def test_phone_create(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"7739441467\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone\n        assert phone.id is not None\n\n    @pytest.mark.django_db\n    def test_phone_create_invalid_num(self):\n        \"\"\" Test phone contact method \"\"\"    # create phone instance\n        phone_num = \"abcdefsfdsf\"\n        phone = PhoneContactMethodFactory.create(phone=phone_num) \n        assert phone_num == phone.phone  \n        assert phone.id is not None\n        print(\"\\n\\n\\n\\n-------------id is \", id) \n\n    @pytest.mark.django_db\n    def test_coop_type_create(self):\n        \"\"\" Test coop type model \"\"\"    # create customer model instance\n        coop_type = CoopTypeFactory(name=\"Test Coop Type Name\")\n        assert coop_type.name == \"Test Coop Type Name\"\n\n    @pytest.mark.django_db\n    def test_address_create(self):\n        \"\"\" Test address model \"\"\"    # create customer model instance\n        address = AddressFactory()\n        assert address is not None\n\n    @pytest.mark.django_db\n    def test_coop_create(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop = Coop.objects.create(name='test')\n        coop.addresses.set(coop_from_factory.addresses.all()) \n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_existing_type(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        coop_from_factory = CoopFactory()\n        self.assertIsNotNone(coop_from_factory)\n\n        coop_types = coop_from_factory.types\n        coop = CoopFactory.create(types=[coop_types.all().first()], addresses=coop_from_factory.addresses.all())\n        self.assertIsNotNone(coop)\n\n    @pytest.mark.django_db\n    def test_coop_create_with_no_types(self):\n        \"\"\" Test customer model \"\"\"    # create customer model instance\n        print(\"\\n\\n\\n\\n**********-------- starting test ....\\n\")\n        coop = CoopFactory.build(types=[])\n        print(\"phone:\",coop.phone.phone)\n        print(\"email:\",coop.email.email)\n        coop.full_clean()\n        self.assertIsNotNone(coop)\n        self.assertIsNone( coop.id )\n\n    def test_search_coops_wo_coords(self):\n        \"\"\"\n        Look for coops with addresses without latitude/longitude coords\n        \"\"\"\n        address = AddressFactory(latitude=None, longitude=None)\n        coop_from_factory = CoopFactory(addresses=[address])\n        # Verify coop appears when we search for those without a lat/lon\n        coops = Coop.objects.find_wo_coords()\n        results = list(coops)\n        assert len(results) > 0, \"Failed to find any matching results.\"\n        assert coop_from_factory in list(coops), \"Failed to find coop.\"\n \n\n"
  },
  {
    "prompt": "\n\n### djcutter/users/models.py ###\n\nfrom django.contrib.auth.models import AbstractUser\nfrom django.db.models import CharField\nfrom django.urls import reverse\nfrom django.utils.translation import gettext_lazy as _\n\n\nclass User(AbstractUser):\n    \"\"\"Default user for djcutter.\"\"\"\n\n    #: First and last name do not cover name patterns around the globe\n    name = CharField(_(\"Name of User\"), blank=True, max_length=255)\n    first_name = None  # type: ignore\n    last_name = None  # type: ignore\n\n    def get_absolute_url(self):\n        \"\"\"Get url for user's detail view.\n\n        Returns:\n            str: URL for user detail.\n\n        \"\"\"\n        return reverse(\"users:detail\", kwargs={\"username\": self.username})\n\n\n### djcutter/users/forms.py ###\n\nfrom django.contrib.auth import forms as admin_forms\nfrom django.contrib.auth import get_user_model\nfrom django.utils.translation import gettext_lazy as _\n\nUser = get_user_model()\n\n\nclass UserChangeForm(admin_forms.UserChangeForm):\n    class Meta(admin_forms.UserChangeForm.Meta):\n        model = User\n\n\nclass UserCreationForm(admin_forms.UserCreationForm):\n    class Meta(admin_forms.UserCreationForm.Meta):\n        model = User\n\n        error_messages = {\n            \"username\": {\"unique\": _(\"This username has already been taken.\")}\n        }\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "\"\"\"\nModule for all Form Tests.\n\"\"\"\nimport pytest\nfrom django.utils.translation import gettext_lazy as _\n\nfrom djcutter.users.forms import UserCreationForm\nfrom djcutter.users.models import User\n\npytestmark = pytest.mark.django_db\n\n\nclass TestUserCreationForm:\n    \"\"\"\n    Test class for all tests related to the UserCreationForm\n    \"\"\"\n\n    def test_username_validation_error_msg(self, user: User):\n        \"\"\"\n        Tests UserCreation Form's unique validator functions correctly by testing:\n            1) A new user with an existing username cannot be added.\n            2) Only 1 error is raised by the UserCreation Form\n            3) The desired error message is raised\n        \"\"\"\n\n        # The user already exists,\n        # hence cannot be created.\n        form = UserCreationForm(\n            {\n                \"username\": user.username,\n                \"password1\": user.password,\n                \"password2\": user.password,\n            }\n        )\n\n        assert not form.is_valid()\n        assert len(form.errors) == 1\n        assert \"username\" in form.errors\n        assert form.errors[\"username\"][0] == _(\"This username has already been taken.\")\n"
  },
  {
    "prompt": "\n\n### tests/splunkutils.py ###\n\n# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https://opensource.org/licenses/BSD-2-Clause\nfrom time import sleep\n\n\ndef splunk_single(service, search):\n    kwargs_normalsearch = {\"exec_mode\": \"normal\"}\n    tried = 0\n    while True:\n        job = service.jobs.create(search, **kwargs_normalsearch)\n\n        # A normal search returns the job's SID right away, so we need to poll for completion\n        while True:\n            while not job.is_ready():\n                pass\n            stats = {\n                \"isDone\": job[\"isDone\"],\n                \"doneProgress\": float(job[\"doneProgress\"]) * 100,\n                \"scanCount\": int(job[\"scanCount\"]),\n                \"eventCount\": int(job[\"eventCount\"]),\n                \"resultCount\": int(job[\"resultCount\"]),\n            }\n\n            if stats[\"isDone\"] == \"1\":\n                break\n            else:\n                sleep(2)\n\n        # Get the results and display them\n        resultCount = stats[\"resultCount\"]\n        eventCount = stats[\"eventCount\"]\n        if resultCount > 0 or tried > 5:\n            break\n        else:\n            tried += 1\n            sleep(5)\n    return resultCount, eventCount\n\n\n### tests/sendmessage.py ###\n\n# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https://opensource.org/licenses/BSD-2-Clause\n\nimport socket\nfrom time import sleep\nimport os\n\n\ndef sendsingle(message, host, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    server_address = (host, port)\n\n    tried = 0\n    while True:\n        try:\n            sock.connect(server_address)\n            break\n        except socket:\n            tried += 1\n            if tried > 90:\n                raise\n            sleep(1)\n    sock.sendall(str.encode(message))\n    sock.close()\n\n\n### tests/timeutils.py ###\n\nimport re\nimport datetime\n\n# Helper functions\n# Insert a character at given location in string (e.g space between ms and TZ offset 2020-02-12 12:46:39.323 -08:00)\ndef insert_char(string, char, integer):\n    return string[0:integer] + char + string[integer:]\n\n\ndef removeZero(tz):\n    return re.sub(r\"\\b0+(\\d)(?=:)\", r\"\\1\", tz)\n\n\ndef time_operations(dt):\n    # Generate an ISO 8601 (RFC 5424) compliant timestamp with local timezone offset (2020-02-12T12:46:39.323-08:00)\n    # See https://stackoverflow.com/questions/2150739/iso-time-iso-8601-in-python\n    iso = dt.astimezone().isoformat(sep=\"T\", timespec=\"microseconds\")\n    # Generate an BSD-style (RFC 3164) compliant timestamp with no timezone (Oct 25 13:08:00)\n    bsd = dt.strftime(\"%b %d %H:%M:%S\")\n\n    # Other variants of timestamps needed for this log sample\n    time = dt.strftime(\"%H:%M:%S.%f\")\n    date = dt.strftime(\"%Y-%m-%d\")\n    # Insert colon in tzoffset string; normally just 'tzoffset = dt.astimezone().strftime(\"%z\")'\n    # Could use helper function above; e.g. 'tzoffset = insert_char(dt.astimezone().strftime(\"%z\"), \":\", 3)'\n    tzoffset = dt.astimezone().strftime(\"%z\")\n    tzname = dt.astimezone().strftime(\"%Z\")\n\n    # Derive epoch timestamp for use in search string\n    # NOTE:  There are caveats with 'strftime(\"%s\")', see references below\n\n    # See https://stackoverflow.com/questions/11743019/convert-python-datetime-to-epoch-with-strftime\n    # See https://docs.python.org/3/library/datetime.html#datetime-objects\n    # Basically: Don't use 'utcnow()'\n\n    # Strict way to get epoch as a string (rather than float) avoiding naive objects\n    # epoch = dt.fromtimestamp(dt.timestamp()).strftime('%s')\n\n    # Since datetime.now().astimezone() is aware, strftime() should be safe and form below OK\n    # Trim last 3 or 7 characters of microsecond resolution to obtain milliseconds or whole seconds, respectively\n    epoch = dt.astimezone().strftime(\"%s.%f\")\n\n    return iso, bsd, time, date, tzoffset, tzname, epoch\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright 2019 Splunk, Inc.\n#\n# Use of this source code is governed by a BSD-2-clause-style\n# license that can be found in the LICENSE-BSD2 file or at\n# https://opensource.org/licenses/BSD-2-Clause\n\nfrom jinja2 import Environment\n\nfrom .sendmessage import *\nfrom .splunkutils import *\nfrom .timeutils import *\n\nimport pytest\n\nenv = Environment()\n\n# time format for Apr  5 22:51:54 2021\n# <187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\n# <187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat /mswitch/sap/mips64.ari failed: No such file or directory.\n# <188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\n# <191>{{ arubadate }} 10.10.10.10 dnsmasq: reading /etc/resolv.conf\n\ntestdata = [\n    \"<187>{{ arubadate }} {{ host }} authmgr[4130]: <124198> <4130> <ERRS> <{{ host }} 10.10.10.10>  {00:00:00:00:00:00-??} Missing server in attribute list, auth=VPN, utype=L3.\",\n    \"<187>{{ arubadate }} {{ host }} stm[4133]: <399803> <4133> <ERRS> <{{ host }} 10.10.10.10>  An internal system error has occurred at file sapm_ap_mgmt.c function sapm_get_img_build_version_str line 11853 error stat /mswitch/sap/mips64.ari failed: No such file or directory.\",\n    \"<188>{{ arubadate }} {{ host }} wms[4096]: <126005> <4096> <WARN> <{{ host }} 10.10.10.10> |ids| Interfering AP: The system classified an access point (BSSID 00:0e:8e:96:f4:32 and SSID  on CHANNEL 36) as interfering. Additional Info: Detector-AP-Name:00:0b:86:9e:6b:5f; Detector-AP-MAC:24:de:c6:70:2c:90; Detector-AP-Radio:1.\",\n    \"<188>{{ arubadate }} {{ host }} sapd[1362]: <127037> <WARN> |AP 00:0b:86:eb:4e:32@10.10.10.10 sapd| |ids-ap| AP(04:bd:88:8a:3a:60): Station Associated to Rogue AP: An AP detected a client a4:8d:3b:ae:68:68 associated to a rogue access point (BSSID 98:1e:19:31:63:b6 and SSID MySpectrumWiFib0-2G on CHANNEL 11).\",\n]\n\n\n@pytest.mark.parametrize(\"event\", testdata)\ndef test_aruba(\n    record_property, setup_wordlist, get_host_key, setup_splunk, setup_sc4s, event\n):\n    host = get_host_key\n\n    dt = datetime.datetime.now()\n    iso, bsd, time, date, tzoffset, tzname, epoch = time_operations(dt)\n    arubadate = dt.strftime(\"%b %d %H:%M:%S %Y\")\n\n    # Tune time functions\n    epoch = epoch[:-7]\n\n    mt = env.from_string(event + \"\\n\")\n    message = mt.render(mark=\"<188>\", bsd=bsd, host=host, arubadate=arubadate)\n\n    sendsingle(message, setup_sc4s[0], setup_sc4s[1][514])\n\n    st = env.from_string(\n        'search index=netops _time={{ epoch }} sourcetype=\"aruba:syslog\" host={{ host }}'\n    )\n    search = st.render(epoch=epoch, host=host)\n\n    resultCount, eventCount = splunk_single(setup_splunk, search)\n\n    record_property(\"host\", host)\n    record_property(\"resultCount\", resultCount)\n    record_property(\"message\", message)\n\n    assert resultCount == 1\n"
  },
  {
    "prompt": "\n\n### tests/test_crypto.py ###\n\n# Copyright (c) Jean-Paul Calderone\n# See LICENSE file for details.\n\n\"\"\"\nUnit tests for :py:mod:`OpenSSL.crypto`.\n\"\"\"\n\nfrom warnings import simplefilter\n\nimport base64\nfrom subprocess import PIPE, Popen\nfrom datetime import datetime, timedelta\n\nimport pytest\n\nfrom six import binary_type\n\nfrom cryptography import x509\nfrom cryptography.hazmat.backends.openssl.backend import backend\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\n\nimport flaky\n\nfrom OpenSSL.crypto import TYPE_RSA, TYPE_DSA, Error, PKey\nfrom OpenSSL.crypto import X509, X509Name\nfrom OpenSSL.crypto import (\n    X509Store,\n    X509StoreFlags,\n    X509StoreContext,\n    X509StoreContextError\n)\nfrom OpenSSL.crypto import X509Req\nfrom OpenSSL.crypto import X509Extension\nfrom OpenSSL.crypto import load_certificate, load_privatekey\nfrom OpenSSL.crypto import load_publickey, dump_publickey\nfrom OpenSSL.crypto import FILETYPE_PEM, FILETYPE_ASN1, FILETYPE_TEXT\nfrom OpenSSL.crypto import dump_certificate, load_certificate_request\nfrom OpenSSL.crypto import dump_certificate_request, dump_privatekey\nfrom OpenSSL.crypto import PKCS7, load_pkcs7_data\nfrom OpenSSL.crypto import PKCS12, load_pkcs12\nfrom OpenSSL.crypto import CRL, Revoked, dump_crl, load_crl\nfrom OpenSSL.crypto import NetscapeSPKI\nfrom OpenSSL.crypto import (\n    sign, verify, get_elliptic_curve, get_elliptic_curves)\n\nfrom .util import EqualityTestsMixin, is_consistent_type, WARNING_TYPE_EXPECTED\n\n\ndef normalize_privatekey_pem(pem):\n    return dump_privatekey(FILETYPE_PEM, load_privatekey(FILETYPE_PEM, pem))\n\n\nGOOD_CIPHER = \"blowfish\"\nBAD_CIPHER = \"zippers\"\n\nGOOD_DIGEST = \"SHA1\"\nBAD_DIGEST = \"monkeys\"\n\nold_root_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIIC7TCCAlagAwIBAgIIPQzE4MbeufQwDQYJKoZIhvcNAQEFBQAwWDELMAkGA1UE\nBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdDaGljYWdvMRAwDgYDVQQKEwdU\nZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3QgQ0EwIhgPMjAwOTAzMjUxMjM2\nNThaGA8yMDE3MDYxMTEyMzY1OFowWDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAklM\nMRAwDgYDVQQHEwdDaGljYWdvMRAwDgYDVQQKEwdUZXN0aW5nMRgwFgYDVQQDEw9U\nZXN0aW5nIFJvb3QgQ0EwgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAPmaQumL\nurpE527uSEHdL1pqcDRmWzu+98Y6YHzT/J7KWEamyMCNZ6fRW1JCR782UQ8a07fy\n2xXsKy4WdKaxyG8CcatwmXvpvRQ44dSANMihHELpANTdyVp6DCysED6wkQFurHlF\n1dshEaJw8b/ypDhmbVIo6Ci1xvCJqivbLFnbAgMBAAGjgbswgbgwHQYDVR0OBBYE\nFINVdy1eIfFJDAkk51QJEo3IfgSuMIGIBgNVHSMEgYAwfoAUg1V3LV4h8UkMCSTn\nVAkSjch+BK6hXKRaMFgxCzAJBgNVBAYTAlVTMQswCQYDVQQIEwJJTDEQMA4GA1UE\nBxMHQ2hpY2FnbzEQMA4GA1UEChMHVGVzdGluZzEYMBYGA1UEAxMPVGVzdGluZyBS\nb290IENBggg9DMTgxt659DAMBgNVHRMEBTADAQH/MA0GCSqGSIb3DQEBBQUAA4GB\nAGGCDazMJGoWNBpc03u6+smc95dEead2KlZXBATOdFT1VesY3+nUOqZhEhTGlDMi\nhkgaZnzoIq/Uamidegk4hirsCT/R+6vsKAAxNTcBjUeZjlykCJWy5ojShGftXIKY\nw/njVbKMXrvc83qmTdGl3TAM0fxQIpqgcglFLveEBgzn\n-----END CERTIFICATE-----\n\"\"\"\n\nroot_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIIC6TCCAlKgAwIBAgIIPQzE4MbeufQwDQYJKoZIhvcNAQEFBQAwWDELMAkGA1UE\nBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdDaGljYWdvMRAwDgYDVQQKEwdU\nZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3QgQ0EwHhcNMTcwNjExMjIzMjU5\nWhcNMzcwNjA2MjIzMjU5WjBYMQswCQYDVQQGEwJVUzELMAkGA1UECBMCSUwxEDAO\nBgNVBAcTB0NoaWNhZ28xEDAOBgNVBAoTB1Rlc3RpbmcxGDAWBgNVBAMTD1Rlc3Rp\nbmcgUm9vdCBDQTCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEA+ZpC6Yu6ukTn\nbu5IQd0vWmpwNGZbO773xjpgfNP8nspYRqbIwI1np9FbUkJHvzZRDxrTt/LbFewr\nLhZ0prHIbwJxq3CZe+m9FDjh1IA0yKEcQukA1N3JWnoMLKwQPrCRAW6seUXV2yER\nonDxv/KkOGZtUijoKLXG8ImqK9ssWdsCAwEAAaOBuzCBuDAdBgNVHQ4EFgQUg1V3\nLV4h8UkMCSTnVAkSjch+BK4wgYgGA1UdIwSBgDB+gBSDVXctXiHxSQwJJOdUCRKN\nyH4ErqFcpFowWDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdD\naGljYWdvMRAwDgYDVQQKEwdUZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3Qg\nQ0GCCD0MxODG3rn0MAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADgYEANFYQ\nR+T70VcZ+SnvURnwviFgCXeedBzCr21meo+DNHbkp2gudB9W8Xrned/wtUBVymy9\ngjB5jINfU7Lci0H57Evsw96UJJVfhXdUMHpqt1RGCoEd9FWnrDyrSy0NysnBT2bH\nlEqxh3aFEUx9IOQ4sgnx1/NOFXBpkRtivl6O0Ec=\n-----END CERTIFICATE-----\n\"\"\"\n\nroot_key_pem = b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIICXQIBAAKBgQD5mkLpi7q6ROdu7khB3S9aanA0Zls7vvfGOmB80/yeylhGpsjA\njWen0VtSQke/NlEPGtO38tsV7CsuFnSmschvAnGrcJl76b0UOOHUgDTIoRxC6QDU\n3claegwsrBA+sJEBbqx5RdXbIRGicPG/8qQ4Zm1SKOgotcbwiaor2yxZ2wIDAQAB\nAoGBAPCgMpmLxzwDaUmcFbTJUvlLW1hoxNNYSu2jIZm1k/hRAcE60JYwvBkgz3UB\nyMEh0AtLxYe0bFk6EHah11tMUPgscbCq73snJ++8koUw+csk22G65hOs51bVb7Aa\n6JBe67oLzdtvgCUFAA2qfrKzWRZzAdhUirQUZgySZk+Xq1pBAkEA/kZG0A6roTSM\nBVnx7LnPfsycKUsTumorpXiylZJjTi9XtmzxhrYN6wgZlDOOwOLgSQhszGpxVoMD\nu3gByT1b2QJBAPtL3mSKdvwRu/+40zaZLwvSJRxaj0mcE4BJOS6Oqs/hS1xRlrNk\nPpQ7WJ4yM6ZOLnXzm2mKyxm50Mv64109FtMCQQDOqS2KkjHaLowTGVxwC0DijMfr\nI9Lf8sSQk32J5VWCySWf5gGTfEnpmUa41gKTMJIbqZZLucNuDcOtzUaeWZlZAkA8\nttXigLnCqR486JDPTi9ZscoZkZ+w7y6e/hH8t6d5Vjt48JVyfjPIaJY+km58LcN3\n6AWSeGAdtRFHVzR7oHjVAkB4hutvxiOeiIVQNBhM6RSI9aBPMI21DoX2JRoxvNW2\ncbvAhow217X9V0dVerEOKxnNYspXRrh36h7k4mQA+sDq\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\nintermediate_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIICVzCCAcCgAwIBAgIRAMPzhm6//0Y/g2pmnHR2C4cwDQYJKoZIhvcNAQENBQAw\nWDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdDaGljYWdvMRAw\nDgYDVQQKEwdUZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3QgQ0EwHhcNMTQw\nODI4MDIwNDA4WhcNMjQwODI1MDIwNDA4WjBmMRUwEwYDVQQDEwxpbnRlcm1lZGlh\ndGUxDDAKBgNVBAoTA29yZzERMA8GA1UECxMIb3JnLXVuaXQxCzAJBgNVBAYTAlVT\nMQswCQYDVQQIEwJDQTESMBAGA1UEBxMJU2FuIERpZWdvMIGfMA0GCSqGSIb3DQEB\nAQUAA4GNADCBiQKBgQDYcEQw5lfbEQRjr5Yy4yxAHGV0b9Al+Lmu7wLHMkZ/ZMmK\nFGIbljbviiD1Nz97Oh2cpB91YwOXOTN2vXHq26S+A5xe8z/QJbBsyghMur88CjdT\n21H2qwMa+r5dCQwEhuGIiZ3KbzB/n4DTMYI5zy4IYPv0pjxShZn4aZTCCK2IUwID\nAQABoxMwETAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBDQUAA4GBAPIWSkLX\nQRMApOjjyC+tMxumT5e2pMqChHmxobQK4NMdrf2VCx+cRT6EmY8sK3/Xl/X8UBQ+\n9n5zXb1ZwhW/sTWgUvmOceJ4/XVs9FkdWOOn1J0XBch9ZIiFe/s5ASIgG7fUdcUF\n9mAWS6FK2ca3xIh5kIupCXOFa0dPvlw/YUFT\n-----END CERTIFICATE-----\n\"\"\"\n\nintermediate_key_pem = b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIICWwIBAAKBgQDYcEQw5lfbEQRjr5Yy4yxAHGV0b9Al+Lmu7wLHMkZ/ZMmKFGIb\nljbviiD1Nz97Oh2cpB91YwOXOTN2vXHq26S+A5xe8z/QJbBsyghMur88CjdT21H2\nqwMa+r5dCQwEhuGIiZ3KbzB/n4DTMYI5zy4IYPv0pjxShZn4aZTCCK2IUwIDAQAB\nAoGAfSZVV80pSeOKHTYfbGdNY/jHdU9eFUa/33YWriXU+77EhpIItJjkRRgivIfo\nrhFJpBSGmDLblaqepm8emsXMeH4+2QzOYIf0QGGP6E6scjTt1PLqdqKfVJ1a2REN\n147cujNcmFJb/5VQHHMpaPTgttEjlzuww4+BCDPsVRABWrkCQQD3loH36nLoQTtf\n+kQq0T6Bs9/UWkTAGo0ND81ALj0F8Ie1oeZg6RNT96RxZ3aVuFTESTv6/TbjWywO\nwdzlmV1vAkEA38rTJ6PTwaJlw5OttdDzAXGPB9tDmzh9oSi7cHwQQXizYd8MBYx4\nsjHUKD3dCQnb1dxJFhd3BT5HsnkRMbVZXQJAbXduH17ZTzcIOXc9jHDXYiFVZV5D\n52vV0WCbLzVCZc3jMrtSUKa8lPN5EWrdU3UchWybyG0MR5mX8S5lrF4SoQJAIyUD\nDBKaSqpqONCUUx1BTFS9FYrFjzbL4+c1qHCTTPTblt8kUCrDOZjBrKAqeiTmNSum\n/qUot9YUBF8m6BuGsQJATHHmdFy/fG1VLkyBp49CAa8tN3Z5r/CgTznI4DfMTf4C\nNbRHn2UmYlwQBa+L5lg9phewNe8aEwpPyPLoV85U8Q==\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\nserver_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIICJDCCAY2gAwIBAgIJAJn/HpR21r/8MA0GCSqGSIb3DQEBBQUAMFgxCzAJBgNV\nBAYTAlVTMQswCQYDVQQIDAJJTDEQMA4GA1UEBwwHQ2hpY2FnbzEQMA4GA1UECgwH\nVGVzdGluZzEYMBYGA1UEAwwPVGVzdGluZyBSb290IENBMB4XDTE3MDYxMjAwMTA1\nN1oXDTM3MDYwNzAwMTA1N1owGDEWMBQGA1UEAwwNbG92ZWx5IHNlcnZlcjCBnzAN\nBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAvqb4brndXS2kEL84qXbZXE6LYK+UrhNi\n70sdIM/24NVN7tXkPlOXqrMWhFHHml+aeSpPkH5b1vKnY1TcULmEubnNICtvjmZ5\nSGMQn+J+RmBs1SMd0EgY/0wBBQdlrlYp2QYgm8YC+zxTNSqWvhMFZAgHbj6Un5SS\nT8JGBqytjB0CAwEAAaM2MDQwHQYDVR0OBBYEFINVdy1eIfFJDAkk51QJEo3IfgSu\nMBMGA1UdJQQMMAoGCCsGAQUFBwMBMA0GCSqGSIb3DQEBBQUAA4GBAGki1K6WgHHJ\nqC6aY2EowjaWOXLO6jUZIhGk7BA7vMRfNug429AOZ4m5F6OQhzmJmlw67Jyu2FeI\nh0VtBuQoHPtjqZXF59oX6hMMmGLMs9pV0UA3fJs5MYA4/V5ZcQy0Ie0QoJNejLzE\n6V1Qz1rRTYLUyEcpI7ZCmBg2KQQI8YZI\n-----END CERTIFICATE-----\n\"\"\"\n\nserver_key_pem = normalize_privatekey_pem(b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIICWwIBAAKBgQC+pvhuud1dLaQQvzipdtlcTotgr5SuE2LvSx0gz/bg1U3u1eQ+\nU5eqsxaEUceaX5p5Kk+QflvW8qdjVNxQuYS5uc0gK2+OZnlIYxCf4n5GYGzVIx3Q\nSBj/TAEFB2WuVinZBiCbxgL7PFM1Kpa+EwVkCAduPpSflJJPwkYGrK2MHQIDAQAB\nAoGAbwuZ0AR6JveahBaczjfnSpiFHf+mve2UxoQdpyr6ROJ4zg/PLW5K/KXrC48G\nj6f3tXMrfKHcpEoZrQWUfYBRCUsGD5DCazEhD8zlxEHahIsqpwA0WWssJA2VOLEN\nj6DuV2pCFbw67rfTBkTSo32ahfXxEKev5KswZk0JIzH3ooECQQDgzS9AI89h0gs8\nDt+1m11Rzqo3vZML7ZIyGApUzVan+a7hbc33nbGRkAXjHaUBJO31it/H6dTO+uwX\nmsWwNG5ZAkEA2RyFKs5xR5USTFaKLWCgpH/ydV96KPOpBND7TKQx62snDenFNNbn\nFwwOhpahld+vqhYk+pfuWWUpQciE+Bu7ZQJASjfT4sQv4qbbKK/scePicnDdx9th\n4e1EeB9xwb+tXXXUo/6Bor/AcUNwfiQ6Zt9PZOK9sR3lMZSsP7rMi7kzuQJABie6\n1sXXjFH7nNJvRG4S39cIxq8YRYTy68II/dlB2QzGpKxV/POCxbJ/zu0CU79tuYK7\nNaeNCFfH3aeTrX0LyQJAMBWjWmeKM2G2sCExheeQK0ROnaBC8itCECD4Jsve4nqf\nr50+LF74iLXFwqysVCebPKMOpDWp/qQ1BbJQIPs7/A==\n-----END RSA PRIVATE KEY-----\n\"\"\")\n\nintermediate_server_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIICWDCCAcGgAwIBAgIRAPQFY9jfskSihdiNSNdt6GswDQYJKoZIhvcNAQENBQAw\nZjEVMBMGA1UEAxMMaW50ZXJtZWRpYXRlMQwwCgYDVQQKEwNvcmcxETAPBgNVBAsT\nCG9yZy11bml0MQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExEjAQBgNVBAcTCVNh\nbiBEaWVnbzAeFw0xNDA4MjgwMjEwNDhaFw0yNDA4MjUwMjEwNDhaMG4xHTAbBgNV\nBAMTFGludGVybWVkaWF0ZS1zZXJ2aWNlMQwwCgYDVQQKEwNvcmcxETAPBgNVBAsT\nCG9yZy11bml0MQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExEjAQBgNVBAcTCVNh\nbiBEaWVnbzCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEAqpJZygd+w1faLOr1\niOAmbBhx5SZWcTCZ/ZjHQTJM7GuPT624QkqsixFghRKdDROwpwnAP7gMRukLqiy4\n+kRuGT5OfyGggL95i2xqA+zehjj08lSTlvGHpePJgCyTavIy5+Ljsj4DKnKyuhxm\nbiXTRrH83NDgixVkObTEmh/OVK0CAwEAATANBgkqhkiG9w0BAQ0FAAOBgQBa0Npw\nUkzjaYEo1OUE1sTI6Mm4riTIHMak4/nswKh9hYup//WVOlr/RBSBtZ7Q/BwbjobN\n3bfAtV7eSAqBsfxYXyof7G1ALANQERkq3+oyLP1iVt08W1WOUlIMPhdCF/QuCwy6\nx9MJLhUCGLJPM+O2rAPWVD9wCmvq10ALsiH3yA==\n-----END CERTIFICATE-----\n\"\"\"\n\nintermediate_server_key_pem = b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIICXAIBAAKBgQCqklnKB37DV9os6vWI4CZsGHHlJlZxMJn9mMdBMkzsa49PrbhC\nSqyLEWCFEp0NE7CnCcA/uAxG6QuqLLj6RG4ZPk5/IaCAv3mLbGoD7N6GOPTyVJOW\n8Yel48mALJNq8jLn4uOyPgMqcrK6HGZuJdNGsfzc0OCLFWQ5tMSaH85UrQIDAQAB\nAoGAIQ594j5zna3/9WaPsTgnmhlesVctt4AAx/n827DA4ayyuHFlXUuVhtoWR5Pk\n5ezj9mtYW8DyeCegABnsu2vZni/CdvU6uiS1Hv6qM1GyYDm9KWgovIP9rQCDSGaz\nd57IWVGxx7ODFkm3gN5nxnSBOFVHytuW1J7FBRnEsehRroECQQDXHFOv82JuXDcz\nz3+4c74IEURdOHcbycxlppmK9kFqm5lsUdydnnGW+mvwDk0APOB7Wg7vyFyr393e\ndpmBDCzNAkEAyv6tVbTKUYhSjW+QhabJo896/EqQEYUmtMXxk4cQnKeR/Ao84Rkf\nEqD5IykMUfUI0jJU4DGX+gWZ10a7kNbHYQJAVFCuHNFxS4Cpwo0aqtnzKoZaHY/8\nX9ABZfafSHCtw3Op92M+7ikkrOELXdS9KdKyyqbKJAKNEHF3LbOfB44WIQJAA2N4\n9UNNVUsXRbElEnYUS529CdUczo4QdVgQjkvk5RiPAUwSdBd9Q0xYnFOlFwEmIowg\nipWJWe0aAlP18ZcEQQJBAL+5lekZ/GUdQoZ4HAsN5a9syrzavJ9VvU1KOOPorPZK\nnMRZbbQgP+aSB7yl6K0gaLaZ8XaK0pjxNBh6ASqg9f4=\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\nclient_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIICIjCCAYugAwIBAgIJAKxpFI5lODkjMA0GCSqGSIb3DQEBBQUAMFgxCzAJBgNV\nBAYTAlVTMQswCQYDVQQIDAJJTDEQMA4GA1UEBwwHQ2hpY2FnbzEQMA4GA1UECgwH\nVGVzdGluZzEYMBYGA1UEAwwPVGVzdGluZyBSb290IENBMB4XDTE3MDYxMjAwMDQx\nM1oXDTM3MDYwNzAwMDQxM1owFjEUMBIGA1UEAwwLdWdseSBjbGllbnQwgZ8wDQYJ\nKoZIhvcNAQEBBQADgY0AMIGJAoGBAMBmH9JG02bme0xPipvpjMSlOugyWrauf4at\nEdGJn7GQLD8IY2Fu0+Kvv9DFpSPboFKZCsfDVsYoRs+xaJbtt1dJ6ymX7EqKS7gb\n8q+eeZZ14keqyJd5Rm2q6swQtw9ADD3E8cS6GqpQm+8SgxOycISoYz7sO1ugJFqN\njId+W4BFAgMBAAGjNjA0MB0GA1UdDgQWBBSDVXctXiHxSQwJJOdUCRKNyH4ErjAT\nBgNVHSUEDDAKBggrBgEFBQcDAjANBgkqhkiG9w0BAQUFAAOBgQAMqcHyweaCOZNN\ndWQQOsBKQlL5wqVVZwucHPWqobjxpULKy9gS2ha2zbgkXcB/BnBOSwe0Fm+MJV0T\nNbnTghcGJNpEH7VKn4xSLvIGZmnZZWgxeIB16z4GhpkK2fShBJ+6GKZjsgjT0lSH\nJRgjHbWutZfZvbSHXr9n7PIphG1Ojg==\n-----END CERTIFICATE-----\n\"\"\"\n\nclient_key_pem = normalize_privatekey_pem(b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIICXgIBAAKBgQDAZh/SRtNm5ntMT4qb6YzEpTroMlq2rn+GrRHRiZ+xkCw/CGNh\nbtPir7/QxaUj26BSmQrHw1bGKEbPsWiW7bdXSespl+xKiku4G/KvnnmWdeJHqsiX\neUZtqurMELcPQAw9xPHEuhqqUJvvEoMTsnCEqGM+7DtboCRajYyHfluARQIDAQAB\nAoGATkZ+NceY5Glqyl4mD06SdcKfV65814vg2EL7V9t8+/mi9rYL8KztSXGlQWPX\nzuHgtRoMl78yQ4ZJYOBVo+nsx8KZNRCEBlE19bamSbQLCeQMenWnpeYyQUZ908gF\nh6L9qsFVJepgA9RDgAjyDoS5CaWCdCCPCH2lDkdcqC54SVUCQQDseuduc4wi8h4t\nV8AahUn9fn9gYfhoNuM0gdguTA0nPLVWz4hy1yJiWYQe0H7NLNNTmCKiLQaJpAbb\nTC6vE8C7AkEA0Ee8CMJUc20BnGEmxwgWcVuqFWaKCo8jTH1X38FlATUsyR3krjW2\ndL3yDD9NwHxsYP7nTKp/U8MV7U9IBn4y/wJBAJl7H0/BcLeRmuJk7IqJ7b635iYB\nD/9beFUw3MUXmQXZUfyYz39xf6CDZsu1GEdEC5haykeln3Of4M9d/4Kj+FcCQQCY\nsi6xwT7GzMDkk/ko684AV3KPc/h6G0yGtFIrMg7J3uExpR/VdH2KgwMkZXisSMvw\nJJEQjOMCVsEJlRk54WWjAkEAzoZNH6UhDdBK5F38rVt/y4SEHgbSfJHIAmPS32Kq\nf6GGcfNpip0Uk7q7udTKuX7Q/buZi/C4YW7u3VKAquv9NA==\n-----END RSA PRIVATE KEY-----\n\"\"\")\n\ncleartextCertificatePEM = b\"\"\"-----BEGIN CERTIFICATE-----\nMIIC6TCCAlKgAwIBAgIIPQzE4MbeufQwDQYJKoZIhvcNAQEFBQAwWDELMAkGA1UE\nBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdDaGljYWdvMRAwDgYDVQQKEwdU\nZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3QgQ0EwHhcNMTcwNjExMjIzMjU5\nWhcNMzcwNjA2MjIzMjU5WjBYMQswCQYDVQQGEwJVUzELMAkGA1UECBMCSUwxEDAO\nBgNVBAcTB0NoaWNhZ28xEDAOBgNVBAoTB1Rlc3RpbmcxGDAWBgNVBAMTD1Rlc3Rp\nbmcgUm9vdCBDQTCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEA+ZpC6Yu6ukTn\nbu5IQd0vWmpwNGZbO773xjpgfNP8nspYRqbIwI1np9FbUkJHvzZRDxrTt/LbFewr\nLhZ0prHIbwJxq3CZe+m9FDjh1IA0yKEcQukA1N3JWnoMLKwQPrCRAW6seUXV2yER\nonDxv/KkOGZtUijoKLXG8ImqK9ssWdsCAwEAAaOBuzCBuDAdBgNVHQ4EFgQUg1V3\nLV4h8UkMCSTnVAkSjch+BK4wgYgGA1UdIwSBgDB+gBSDVXctXiHxSQwJJOdUCRKN\nyH4ErqFcpFowWDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQHEwdD\naGljYWdvMRAwDgYDVQQKEwdUZXN0aW5nMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3Qg\nQ0GCCD0MxODG3rn0MAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADgYEANFYQ\nR+T70VcZ+SnvURnwviFgCXeedBzCr21meo+DNHbkp2gudB9W8Xrned/wtUBVymy9\ngjB5jINfU7Lci0H57Evsw96UJJVfhXdUMHpqt1RGCoEd9FWnrDyrSy0NysnBT2bH\nlEqxh3aFEUx9IOQ4sgnx1/NOFXBpkRtivl6O0Ec=\n-----END CERTIFICATE-----\n\"\"\"\n\ncleartextPrivateKeyPEM = normalize_privatekey_pem(b\"\"\"\\\n-----BEGIN RSA PRIVATE KEY-----\nMIICXQIBAAKBgQD5mkLpi7q6ROdu7khB3S9aanA0Zls7vvfGOmB80/yeylhGpsjA\njWen0VtSQke/NlEPGtO38tsV7CsuFnSmschvAnGrcJl76b0UOOHUgDTIoRxC6QDU\n3claegwsrBA+sJEBbqx5RdXbIRGicPG/8qQ4Zm1SKOgotcbwiaor2yxZ2wIDAQAB\nAoGBAPCgMpmLxzwDaUmcFbTJUvlLW1hoxNNYSu2jIZm1k/hRAcE60JYwvBkgz3UB\nyMEh0AtLxYe0bFk6EHah11tMUPgscbCq73snJ++8koUw+csk22G65hOs51bVb7Aa\n6JBe67oLzdtvgCUFAA2qfrKzWRZzAdhUirQUZgySZk+Xq1pBAkEA/kZG0A6roTSM\nBVnx7LnPfsycKUsTumorpXiylZJjTi9XtmzxhrYN6wgZlDOOwOLgSQhszGpxVoMD\nu3gByT1b2QJBAPtL3mSKdvwRu/+40zaZLwvSJRxaj0mcE4BJOS6Oqs/hS1xRlrNk\nPpQ7WJ4yM6ZOLnXzm2mKyxm50Mv64109FtMCQQDOqS2KkjHaLowTGVxwC0DijMfr\nI9Lf8sSQk32J5VWCySWf5gGTfEnpmUa41gKTMJIbqZZLucNuDcOtzUaeWZlZAkA8\nttXigLnCqR486JDPTi9ZscoZkZ+w7y6e/hH8t6d5Vjt48JVyfjPIaJY+km58LcN3\n6AWSeGAdtRFHVzR7oHjVAkB4hutvxiOeiIVQNBhM6RSI9aBPMI21DoX2JRoxvNW2\ncbvAhow217X9V0dVerEOKxnNYspXRrh36h7k4mQA+sDq\n-----END RSA PRIVATE KEY-----\n\"\"\")\n\ncleartextCertificateRequestPEM = b\"\"\"-----BEGIN CERTIFICATE REQUEST-----\nMIIBnjCCAQcCAQAwXjELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAklMMRAwDgYDVQQH\nEwdDaGljYWdvMRcwFQYDVQQKEw5NeSBDb21wYW55IEx0ZDEXMBUGA1UEAxMORnJl\nZGVyaWNrIERlYW4wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBANp6Y17WzKSw\nBsUWkXdqg6tnXy8H8hA1msCMWpc+/2KJ4mbv5NyD6UD+/SqagQqulPbF/DFea9nA\nE0zhmHJELcM8gUTIlXv/cgDWnmK4xj8YkjVUiCdqKRAKeuzLG1pGmwwF5lGeJpXN\nxQn5ecR0UYSOWj6TTGXB9VyUMQzCClcBAgMBAAGgADANBgkqhkiG9w0BAQUFAAOB\ngQAAJGuF/R/GGbeC7FbFW+aJgr9ee0Xbl6nlhu7pTe67k+iiKT2dsl2ti68MVTnu\nVrb3HUNqOkiwsJf6kCtq5oPn3QVYzTa76Dt2y3Rtzv6boRSlmlfrgS92GNma8JfR\noICQk3nAudi6zl1Dix3BCv1pUp5KMtGn3MeDEi6QFGy2rA==\n-----END CERTIFICATE REQUEST-----\n\"\"\"\n\nencryptedPrivateKeyPEM = b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nProc-Type: 4,ENCRYPTED\nDEK-Info: DES-EDE3-CBC,9573604A18579E9E\n\nSHOho56WxDkT0ht10UTeKc0F5u8cqIa01kzFAmETw0MAs8ezYtK15NPdCXUm3X/2\na17G7LSF5bkxOgZ7vpXyMzun/owrj7CzvLxyncyEFZWvtvzaAhPhvTJtTIB3kf8B\n8+qRcpTGK7NgXEgYBW5bj1y4qZkD4zCL9o9NQzsKI3Ie8i0239jsDOWR38AxjXBH\nmGwAQ4Z6ZN5dnmM4fhMIWsmFf19sNyAML4gHenQCHhmXbjXeVq47aC2ProInJbrm\n+00TcisbAQ40V9aehVbcDKtS4ZbMVDwncAjpXpcncC54G76N6j7F7wL7L/FuXa3A\nfvSVy9n2VfF/pJ3kYSflLHH2G/DFxjF7dl0GxhKPxJjp3IJi9VtuvmN9R2jZWLQF\ntfC8dXgy/P9CfFQhlinqBTEwgH0oZ/d4k4NVFDSdEMaSdmBAjlHpc+Vfdty3HVnV\nrKXj//wslsFNm9kIwJGIgKUa/n2jsOiydrsk1mgH7SmNCb3YHgZhbbnq0qLat/HC\ngHDt3FHpNQ31QzzL3yrenFB2L9osIsnRsDTPFNi4RX4SpDgNroxOQmyzCCV6H+d4\no1mcnNiZSdxLZxVKccq0AfRpHqpPAFnJcQHP6xyT9MZp6fBa0XkxDnt9kNU8H3Qw\n7SJWZ69VXjBUzMlQViLuaWMgTnL+ZVyFZf9hTF7U/ef4HMLMAVNdiaGG+G+AjCV/\nMbzjS007Oe4qqBnCWaFPSnJX6uLApeTbqAxAeyCql56ULW5x6vDMNC3dwjvS/CEh\n11n8RkgFIQA0AhuKSIg3CbuartRsJnWOLwgLTzsrKYL4yRog1RJrtw==\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\nencryptedPrivateKeyPEMPassphrase = b\"foobar\"\n\n\ncleartextPublicKeyPEM = b\"\"\"-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxszlc+b71LvlLS0ypt/l\ngT/JzSVJtnEqw9WUNGeiChywX2mmQLHEt7KP0JikqUFZOtPclNY823Q4pErMTSWC\n90qlUxI47vNJbXGRfmO2q6Zfw6SE+E9iUb74xezbOJLjBuUIkQzEKEFV+8taiRV+\nceg1v01yCT2+OjhQW3cxG42zxyRFmqesbQAUWgS3uhPrUQqYQUEiTmVhh4FBUKZ5\nXIneGUpX1S7mXRxTLH6YzRoGFqRoc9A0BBNcoXHTWnxV215k4TeHMFYE5RG0KYAS\n8Xk5iKICEXwnZreIt3jyygqoOKsKZMK/Zl2VhMGhJR6HXRpQCyASzEG7bgtROLhL\nywIDAQAB\n-----END PUBLIC KEY-----\n\"\"\"\n\n# Some PKCS#7 stuff.  Generated with the openssl command line:\n#\n#    openssl crl2pkcs7 -inform pem -outform pem -certfile s.pem -nocrl\n#\n# with a certificate and key (but the key should be irrelevant) in s.pem\npkcs7Data = b\"\"\"\\\n-----BEGIN PKCS7-----\nMIIDNwYJKoZIhvcNAQcCoIIDKDCCAyQCAQExADALBgkqhkiG9w0BBwGgggMKMIID\nBjCCAm+gAwIBAgIBATANBgkqhkiG9w0BAQQFADB7MQswCQYDVQQGEwJTRzERMA8G\nA1UEChMITTJDcnlwdG8xFDASBgNVBAsTC00yQ3J5cHRvIENBMSQwIgYDVQQDExtN\nMkNyeXB0byBDZXJ0aWZpY2F0ZSBNYXN0ZXIxHTAbBgkqhkiG9w0BCQEWDm5ncHNA\ncG9zdDEuY29tMB4XDTAwMDkxMDA5NTEzMFoXDTAyMDkxMDA5NTEzMFowUzELMAkG\nA1UEBhMCU0cxETAPBgNVBAoTCE0yQ3J5cHRvMRIwEAYDVQQDEwlsb2NhbGhvc3Qx\nHTAbBgkqhkiG9w0BCQEWDm5ncHNAcG9zdDEuY29tMFwwDQYJKoZIhvcNAQEBBQAD\nSwAwSAJBAKy+e3dulvXzV7zoTZWc5TzgApr8DmeQHTYC8ydfzH7EECe4R1Xh5kwI\nzOuuFfn178FBiS84gngaNcrFi0Z5fAkCAwEAAaOCAQQwggEAMAkGA1UdEwQCMAAw\nLAYJYIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0G\nA1UdDgQWBBTPhIKSvnsmYsBVNWjj0m3M2z0qVTCBpQYDVR0jBIGdMIGagBT7hyNp\n65w6kxXlxb8pUU/+7Sg4AaF/pH0wezELMAkGA1UEBhMCU0cxETAPBgNVBAoTCE0y\nQ3J5cHRvMRQwEgYDVQQLEwtNMkNyeXB0byBDQTEkMCIGA1UEAxMbTTJDcnlwdG8g\nQ2VydGlmaWNhdGUgTWFzdGVyMR0wGwYJKoZIhvcNAQkBFg5uZ3BzQHBvc3QxLmNv\nbYIBADANBgkqhkiG9w0BAQQFAAOBgQA7/CqT6PoHycTdhEStWNZde7M/2Yc6BoJu\nVwnW8YxGO8Sn6UJ4FeffZNcYZddSDKosw8LtPOeWoK3JINjAk5jiPQ2cww++7QGG\n/g5NDjxFZNDJP1dGiLAxPW6JXwov4v0FmdzfLOZ01jDcgQQZqEpYlgpuI5JEWUQ9\nHo4EzbYCOaEAMQA=\n-----END PKCS7-----\n\"\"\"\n\npkcs7DataASN1 = base64.b64decode(b\"\"\"\nMIIDNwYJKoZIhvcNAQcCoIIDKDCCAyQCAQExADALBgkqhkiG9w0BBwGgggMKMIID\nBjCCAm+gAwIBAgIBATANBgkqhkiG9w0BAQQFADB7MQswCQYDVQQGEwJTRzERMA8G\nA1UEChMITTJDcnlwdG8xFDASBgNVBAsTC00yQ3J5cHRvIENBMSQwIgYDVQQDExtN\nMkNyeXB0byBDZXJ0aWZpY2F0ZSBNYXN0ZXIxHTAbBgkqhkiG9w0BCQEWDm5ncHNA\ncG9zdDEuY29tMB4XDTAwMDkxMDA5NTEzMFoXDTAyMDkxMDA5NTEzMFowUzELMAkG\nA1UEBhMCU0cxETAPBgNVBAoTCE0yQ3J5cHRvMRIwEAYDVQQDEwlsb2NhbGhvc3Qx\nHTAbBgkqhkiG9w0BCQEWDm5ncHNAcG9zdDEuY29tMFwwDQYJKoZIhvcNAQEBBQAD\nSwAwSAJBAKy+e3dulvXzV7zoTZWc5TzgApr8DmeQHTYC8ydfzH7EECe4R1Xh5kwI\nzOuuFfn178FBiS84gngaNcrFi0Z5fAkCAwEAAaOCAQQwggEAMAkGA1UdEwQCMAAw\nLAYJYIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0G\nA1UdDgQWBBTPhIKSvnsmYsBVNWjj0m3M2z0qVTCBpQYDVR0jBIGdMIGagBT7hyNp\n65w6kxXlxb8pUU/+7Sg4AaF/pH0wezELMAkGA1UEBhMCU0cxETAPBgNVBAoTCE0y\nQ3J5cHRvMRQwEgYDVQQLEwtNMkNyeXB0byBDQTEkMCIGA1UEAxMbTTJDcnlwdG8g\nQ2VydGlmaWNhdGUgTWFzdGVyMR0wGwYJKoZIhvcNAQkBFg5uZ3BzQHBvc3QxLmNv\nbYIBADANBgkqhkiG9w0BAQQFAAOBgQA7/CqT6PoHycTdhEStWNZde7M/2Yc6BoJu\nVwnW8YxGO8Sn6UJ4FeffZNcYZddSDKosw8LtPOeWoK3JINjAk5jiPQ2cww++7QGG\n/g5NDjxFZNDJP1dGiLAxPW6JXwov4v0FmdzfLOZ01jDcgQQZqEpYlgpuI5JEWUQ9\nHo4EzbYCOaEAMQA=\n\"\"\")\n\ncrlData = b\"\"\"\\\n-----BEGIN X509 CRL-----\nMIIBWzCBxTANBgkqhkiG9w0BAQQFADBYMQswCQYDVQQGEwJVUzELMAkGA1UECBMC\nSUwxEDAOBgNVBAcTB0NoaWNhZ28xEDAOBgNVBAoTB1Rlc3RpbmcxGDAWBgNVBAMT\nD1Rlc3RpbmcgUm9vdCBDQRcNMDkwNzI2MDQzNDU2WhcNMTIwOTI3MDI0MTUyWjA8\nMBUCAgOrGA8yMDA5MDcyNTIzMzQ1NlowIwICAQAYDzIwMDkwNzI1MjMzNDU2WjAM\nMAoGA1UdFQQDCgEEMA0GCSqGSIb3DQEBBAUAA4GBAEBt7xTs2htdD3d4ErrcGAw1\n4dKcVnIWTutoI7xxen26Wwvh8VCsT7i/UeP+rBl9rC/kfjWjzQk3/zleaarGTpBT\n0yp4HXRFFoRhhSE/hP+eteaPXRgrsNRLHe9ZDd69wmh7J1wMDb0m81RG7kqcbsid\nvrzEeLDRiiPl92dyyWmu\n-----END X509 CRL-----\n\"\"\"\n\ncrlDataUnsupportedExtension = b\"\"\"\\\n-----BEGIN X509 CRL-----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\nC1xAg/AAq6w78yzYt18j5Mj0s6eeHi1YpHKw\n-----END X509 CRL-----\n\"\"\"\n\n\n# A broken RSA private key which can be used to test the error path through\n# PKey.check.\ninconsistentPrivateKeyPEM = b\"\"\"-----BEGIN RSA PRIVATE KEY-----\nMIIBPAIBAAJBAKy+e3dulvXzV7zoTZWc5TzgApr8DmeQHTYC8ydfzH7EECe4R1Xh\n5kwIzOuuFfn178FBiS84gngaNcrFi0Z5fAkCAwEaAQJBAIqm/bz4NA1H++Vx5Ewx\nOcKp3w19QSaZAwlGRtsUxrP7436QjnREM3Bm8ygU11BjkPVmtrKm6AayQfCHqJoT\nzIECIQDW0BoMoL0HOYM/mrTLhaykYAVqgIeJsPjvkEhTFXWBuQIhAM3deFAvWNu4\nnklUQ37XsCT2c9tmNt1LAT+slG2JOTTRAiAuXDtC/m3NYVwyHfFm+zKHRzHkClk2\nHjubeEgjpj32AQIhAJqMGTaZVOwevTXvvHwNeH+vRWsAYU/gbx+OQB+7VOcBAiEA\noolb6NMg/R3enNPvS1O4UU1H8wpaF77L4yiSWlE0p4w=\n-----END RSA PRIVATE KEY-----\n\"\"\"\n\n# certificate with NULL bytes in subjectAltName and common name\n\nnulbyteSubjectAltNamePEM = b\"\"\"-----BEGIN CERTIFICATE-----\nMIIE2DCCA8CgAwIBAgIBADANBgkqhkiG9w0BAQUFADCBxTELMAkGA1UEBhMCVVMx\nDzANBgNVBAgMBk9yZWdvbjESMBAGA1UEBwwJQmVhdmVydG9uMSMwIQYDVQQKDBpQ\neXRob24gU29mdHdhcmUgRm91bmRhdGlvbjEgMB4GA1UECwwXUHl0aG9uIENvcmUg\nRGV2ZWxvcG1lbnQxJDAiBgNVBAMMG251bGwucHl0aG9uLm9yZwBleGFtcGxlLm9y\nZzEkMCIGCSqGSIb3DQEJARYVcHl0aG9uLWRldkBweXRob24ub3JnMB4XDTEzMDgw\nNzEzMTE1MloXDTEzMDgwNzEzMTI1MlowgcUxCzAJBgNVBAYTAlVTMQ8wDQYDVQQI\nDAZPcmVnb24xEjAQBgNVBAcMCUJlYXZlcnRvbjEjMCEGA1UECgwaUHl0aG9uIFNv\nZnR3YXJlIEZvdW5kYXRpb24xIDAeBgNVBAsMF1B5dGhvbiBDb3JlIERldmVsb3Bt\nZW50MSQwIgYDVQQDDBtudWxsLnB5dGhvbi5vcmcAZXhhbXBsZS5vcmcxJDAiBgkq\nhkiG9w0BCQEWFXB5dGhvbi1kZXZAcHl0aG9uLm9yZzCCASIwDQYJKoZIhvcNAQEB\nBQADggEPADCCAQoCggEBALXq7cn7Rn1vO3aA3TrzA5QLp6bb7B3f/yN0CJ2XFj+j\npHs+Gw6WWSUDpybiiKnPec33BFawq3kyblnBMjBU61ioy5HwQqVkJ8vUVjGIUq3P\nvX/wBmQfzCe4o4uM89gpHyUL9UYGG8oCRa17dgqcv7u5rg0Wq2B1rgY+nHwx3JIv\nKRrgSwyRkGzpN8WQ1yrXlxWjgI9de0mPVDDUlywcWze1q2kwaEPTM3hLAmD1PESA\noY/n8A/RXoeeRs9i/Pm/DGUS8ZPINXk/yOzsR/XvvkTVroIeLZqfmFpnZeF0cHzL\n08LODkVJJ9zjLdT7SA4vnne4FEbAxDbKAq5qkYzaL4UCAwEAAaOB0DCBzTAMBgNV\nHRMBAf8EAjAAMB0GA1UdDgQWBBSIWlXAUv9hzVKjNQ/qWpwkOCL3XDALBgNVHQ8E\nBAMCBeAwgZAGA1UdEQSBiDCBhYIeYWx0bnVsbC5weXRob24ub3JnAGV4YW1wbGUu\nY29tgSBudWxsQHB5dGhvbi5vcmcAdXNlckBleGFtcGxlLm9yZ4YpaHR0cDovL251\nbGwucHl0aG9uLm9yZwBodHRwOi8vZXhhbXBsZS5vcmeHBMAAAgGHECABDbgAAAAA\nAAAAAAAAAAEwDQYJKoZIhvcNAQEFBQADggEBAKxPRe99SaghcI6IWT7UNkJw9aO9\ni9eo0Fj2MUqxpKbdb9noRDy2CnHWf7EIYZ1gznXPdwzSN4YCjV5d+Q9xtBaowT0j\nHPERs1ZuytCNNJTmhyqZ8q6uzMLoht4IqH/FBfpvgaeC5tBTnTT0rD5A/olXeimk\nkX4LxlEx5RAvpGB2zZVRGr6LobD9rVK91xuHYNIxxxfEGE8tCCWjp0+3ksri9SXx\nVHWBnbM9YaL32u3hxm8sYB/Yb8WSBavJCWJJqRStVRHM1koZlJmXNx2BX4vPo6iW\nRFEIPQsFZRLrtnCAiEhyT8bC2s/Njlu6ly9gtJZWSV46Q3ZjBL4q9sHKqZQ=\n-----END CERTIFICATE-----\"\"\"\n\nlarge_key_pem = b\"\"\"-----BEGIN RSA PRIVATE KEY-----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\nvYeU7Ab/\n-----END RSA PRIVATE KEY-----\"\"\"\n\nec_private_key_pem = b\"\"\"-----BEGIN PRIVATE KEY-----\nMIGHAgEAMBMGByqGSM49AgEGCCqGSM49AwEHBG0wawIBAQQgYirTZSx+5O8Y6tlG\ncka6W6btJiocdrdolfcukSoTEk+hRANCAAQkvPNu7Pa1GcsWU4v7ptNfqCJVq8Cx\nzo0MUVPQgwJ3aJtNM1QMOQUayCrRwfklg+D/rFSUwEUqtZh7fJDiFqz3\n-----END PRIVATE KEY-----\n\"\"\"\n\nec_root_key_pem = b\"\"\"-----BEGIN EC PRIVATE KEY-----\nMIGlAgEBBDEAz/HOBFPYLB0jLWeTpJn4Yc4m/C4mdWymVHBjOmnwiPHKT326iYN/\nZhmSs+RM94RsoAcGBSuBBAAioWQDYgAEwE5vDdla/nLpWAPAQ0yFGqwLuw4BcN2r\nU+sKab5EAEHzLeceRa8ffncYdCXNoVsBcdob1y66CFZMEWLetPTmGapyWkBAs6/L\n8kUlkU9OsE+7IVo4QQJkgV5gM+Dim1XE\n-----END EC PRIVATE KEY-----\n\"\"\"\n\nec_root_cert_pem = b\"\"\"-----BEGIN CERTIFICATE-----\nMIICLTCCAbKgAwIBAgIMWW/hwTl6ufz6/WkCMAoGCCqGSM49BAMDMFgxGDAWBgNV\nBAMTD1Rlc3RpbmcgUm9vdCBDQTEQMA4GA1UEChMHVGVzdGluZzEQMA4GA1UEBxMH\nQ2hpY2FnbzELMAkGA1UECBMCSUwxCzAJBgNVBAYTAlVTMCAXDTE3MDcxOTIyNDgz\nM1oYDzk5OTkxMjMxMjM1OTU5WjBYMRgwFgYDVQQDEw9UZXN0aW5nIFJvb3QgQ0Ex\nEDAOBgNVBAoTB1Rlc3RpbmcxEDAOBgNVBAcTB0NoaWNhZ28xCzAJBgNVBAgTAklM\nMQswCQYDVQQGEwJVUzB2MBAGByqGSM49AgEGBSuBBAAiA2IABMBObw3ZWv5y6VgD\nwENMhRqsC7sOAXDdq1PrCmm+RABB8y3nHkWvH353GHQlzaFbAXHaG9cuughWTBFi\n3rT05hmqclpAQLOvy/JFJZFPTrBPuyFaOEECZIFeYDPg4ptVxKNDMEEwDwYDVR0T\nAQH/BAUwAwEB/zAPBgNVHQ8BAf8EBQMDBwQAMB0GA1UdDgQWBBSoTrF0H2m8RDzB\nMnY2KReEPfz7ZjAKBggqhkjOPQQDAwNpADBmAjEA3+G1oVCxGjYX4iUN93QYcNHe\ne3fJQJwX9+KsHRut6qNZDUbvRbtO1YIAwB4UJZjwAjEAtXCPURS5A4McZHnSwgTi\nTd8GMrwKz0557OxxtKN6uVVy4ACFMqEw0zN/KJI1vxc9\n-----END CERTIFICATE-----\"\"\"\n\n\n@pytest.fixture\ndef x509_data():\n    \"\"\"\n    Create a new private key and start a certificate request (for a test\n    to finish in one way or another).\n    \"\"\"\n    # Basic setup stuff to generate a certificate\n    pkey = PKey()\n    pkey.generate_key(TYPE_RSA, 512)\n    req = X509Req()\n    req.set_pubkey(pkey)\n    # Authority good you have.\n    req.get_subject().commonName = \"Yoda root CA\"\n    x509 = X509()\n    subject = x509.get_subject()\n    subject.commonName = req.get_subject().commonName\n    x509.set_issuer(subject)\n    x509.set_pubkey(pkey)\n    now = datetime.now()\n    expire = datetime.now() + timedelta(days=100)\n    x509.set_notBefore(now.strftime(\"%Y%m%d%H%M%SZ\").encode())\n    x509.set_notAfter(expire.strftime(\"%Y%m%d%H%M%SZ\").encode())\n    yield pkey, x509\n\n\nclass TestX509Ext(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.X509Extension`.\n    \"\"\"\n\n    def test_str(self):\n        \"\"\"\n        The string representation of `X509Extension` instances as\n        returned by `str` includes stuff.\n        \"\"\"\n        # This isn't necessarily the best string representation.  Perhaps it\n        # will be changed/improved in the future.\n        assert (\n            str(X509Extension(b'basicConstraints', True, b'CA:false')) ==\n            'CA:FALSE'\n        )\n\n    def test_type(self):\n        \"\"\"\n        `X509Extension` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(\n            X509Extension,\n            'X509Extension', b'basicConstraints', True, b'CA:true')\n\n    def test_construction(self):\n        \"\"\"\n        `X509Extension` accepts an extension type name, a critical flag,\n        and an extension value and returns an `X509Extension` instance.\n        \"\"\"\n        basic = X509Extension(b'basicConstraints', True, b'CA:true')\n        assert isinstance(basic, X509Extension)\n\n        comment = X509Extension(b'nsComment', False, b'pyOpenSSL unit test')\n        assert isinstance(comment, X509Extension)\n\n    @pytest.mark.parametrize('type_name, critical, value', [\n        (b'thisIsMadeUp', False, b'hi'),\n        (b'basicConstraints', False, b'blah blah'),\n\n        # Exercise a weird one (an extension which uses the r2i method).  This\n        # exercises the codepath that requires a non-NULL ctx to be passed to\n        # X509V3_EXT_nconf.  It can't work now because we provide no\n        # configuration database.  It might be made to work in the future.\n        (b'proxyCertInfo', True,\n         b'language:id-ppl-anyLanguage,pathlen:1,policy:text:AB')\n    ])\n    def test_invalid_extension(self, type_name, critical, value):\n        \"\"\"\n        `X509Extension` raises something if it is passed a bad\n        extension name or value.\n        \"\"\"\n        with pytest.raises(Error):\n            X509Extension(type_name, critical, value)\n\n    @pytest.mark.parametrize('critical_flag', [True, False])\n    def test_get_critical(self, critical_flag):\n        \"\"\"\n        `X509ExtensionType.get_critical` returns the value of the\n        extension's critical flag.\n        \"\"\"\n        ext = X509Extension(b'basicConstraints', critical_flag, b'CA:true')\n        assert ext.get_critical() == critical_flag\n\n    @pytest.mark.parametrize('short_name, value', [\n        (b'basicConstraints', b'CA:true'),\n        (b'nsComment', b'foo bar'),\n    ])\n    def test_get_short_name(self, short_name, value):\n        \"\"\"\n        `X509ExtensionType.get_short_name` returns a string giving the\n        short type name of the extension.\n        \"\"\"\n        ext = X509Extension(short_name, True, value)\n        assert ext.get_short_name() == short_name\n\n    def test_get_data(self):\n        \"\"\"\n        `X509Extension.get_data` returns a string giving the data of\n        the extension.\n        \"\"\"\n        ext = X509Extension(b'basicConstraints', True, b'CA:true')\n        # Expect to get back the DER encoded form of CA:true.\n        assert ext.get_data() == b'0\\x03\\x01\\x01\\xff'\n\n    def test_unused_subject(self, x509_data):\n        \"\"\"\n        The `subject` parameter to `X509Extension` may be provided for an\n        extension which does not use it and is ignored in this case.\n        \"\"\"\n        pkey, x509 = x509_data\n        ext1 = X509Extension(\n            b'basicConstraints', False, b'CA:TRUE', subject=x509)\n        x509.add_extensions([ext1])\n        x509.sign(pkey, 'sha1')\n        # This is a little lame.  Can we think of a better way?\n        text = dump_certificate(FILETYPE_TEXT, x509)\n        assert b'X509v3 Basic Constraints:' in text\n        assert b'CA:TRUE' in text\n\n    def test_subject(self, x509_data):\n        \"\"\"\n        If an extension requires a subject, the `subject` parameter to\n        `X509Extension` provides its value.\n        \"\"\"\n        pkey, x509 = x509_data\n        ext3 = X509Extension(\n            b'subjectKeyIdentifier', False, b'hash', subject=x509)\n        x509.add_extensions([ext3])\n        x509.sign(pkey, 'sha1')\n        text = dump_certificate(FILETYPE_TEXT, x509)\n        assert b'X509v3 Subject Key Identifier:' in text\n\n    def test_missing_subject(self):\n        \"\"\"\n        If an extension requires a subject and the `subject` parameter\n        is given no value, something happens.\n        \"\"\"\n        with pytest.raises(Error):\n            X509Extension(b'subjectKeyIdentifier', False, b'hash')\n\n    @pytest.mark.parametrize('bad_obj', [\n        True,\n        object(),\n        \"hello\",\n        [],\n    ])\n    def test_invalid_subject(self, bad_obj):\n        \"\"\"\n        If the `subject` parameter is given a value which is not an\n        `X509` instance, `TypeError` is raised.\n        \"\"\"\n        with pytest.raises(TypeError):\n            X509Extension(\n                'basicConstraints', False, 'CA:TRUE', subject=bad_obj)\n\n    def test_unused_issuer(self, x509_data):\n        \"\"\"\n        The `issuer` parameter to `X509Extension` may be provided for an\n        extension which does not use it and is ignored in this case.\n        \"\"\"\n        pkey, x509 = x509_data\n        ext1 = X509Extension(\n            b'basicConstraints', False, b'CA:TRUE', issuer=x509)\n        x509.add_extensions([ext1])\n        x509.sign(pkey, 'sha1')\n        text = dump_certificate(FILETYPE_TEXT, x509)\n        assert b'X509v3 Basic Constraints:' in text\n        assert b'CA:TRUE' in text\n\n    def test_issuer(self, x509_data):\n        \"\"\"\n        If an extension requires an issuer, the `issuer` parameter to\n        `X509Extension` provides its value.\n        \"\"\"\n        pkey, x509 = x509_data\n        ext2 = X509Extension(\n            b'authorityKeyIdentifier', False, b'issuer:always',\n            issuer=x509)\n        x509.add_extensions([ext2])\n        x509.sign(pkey, 'sha1')\n        text = dump_certificate(FILETYPE_TEXT, x509)\n        assert b'X509v3 Authority Key Identifier:' in text\n        assert b'DirName:/CN=Yoda root CA' in text\n\n    def test_missing_issuer(self):\n        \"\"\"\n        If an extension requires an issue and the `issuer` parameter is\n        given no value, something happens.\n        \"\"\"\n        with pytest.raises(Error):\n            X509Extension(\n                b'authorityKeyIdentifier',\n                False, b'keyid:always,issuer:always')\n\n    @pytest.mark.parametrize('bad_obj', [\n        True,\n        object(),\n        \"hello\",\n        [],\n    ])\n    def test_invalid_issuer(self, bad_obj):\n        \"\"\"\n        If the `issuer` parameter is given a value which is not an\n        `X509` instance, `TypeError` is raised.\n        \"\"\"\n        with pytest.raises(TypeError):\n            X509Extension(\n                'basicConstraints', False, 'keyid:always,issuer:always',\n                issuer=bad_obj)\n\n\nclass TestPKey(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.PKey`.\n    \"\"\"\n\n    def test_convert_from_cryptography_private_key(self):\n        \"\"\"\n        PKey.from_cryptography_key creates a proper private PKey.\n        \"\"\"\n        key = serialization.load_pem_private_key(\n            intermediate_key_pem, None, backend\n        )\n        pkey = PKey.from_cryptography_key(key)\n\n        assert isinstance(pkey, PKey)\n        assert pkey.bits() == key.key_size\n        assert pkey._only_public is False\n        assert pkey._initialized is True\n\n    def test_convert_from_cryptography_public_key(self):\n        \"\"\"\n        PKey.from_cryptography_key creates a proper public PKey.\n        \"\"\"\n        key = serialization.load_pem_public_key(cleartextPublicKeyPEM, backend)\n        pkey = PKey.from_cryptography_key(key)\n\n        assert isinstance(pkey, PKey)\n        assert pkey.bits() == key.key_size\n        assert pkey._only_public is True\n        assert pkey._initialized is True\n\n    def test_convert_from_cryptography_unsupported_type(self):\n        \"\"\"\n        PKey.from_cryptography_key raises TypeError with an unsupported type.\n        \"\"\"\n        key = serialization.load_pem_private_key(\n            ec_private_key_pem, None, backend\n        )\n        with pytest.raises(TypeError):\n            PKey.from_cryptography_key(key)\n\n    def test_convert_public_pkey_to_cryptography_key(self):\n        \"\"\"\n        PKey.to_cryptography_key creates a proper cryptography public key.\n        \"\"\"\n        pkey = load_publickey(FILETYPE_PEM, cleartextPublicKeyPEM)\n        key = pkey.to_cryptography_key()\n\n        assert isinstance(key, rsa.RSAPublicKey)\n        assert pkey.bits() == key.key_size\n\n    def test_convert_private_pkey_to_cryptography_key(self):\n        \"\"\"\n        PKey.to_cryptography_key creates a proper cryptography private key.\n        \"\"\"\n        pkey = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        key = pkey.to_cryptography_key()\n\n        assert isinstance(key, rsa.RSAPrivateKey)\n        assert pkey.bits() == key.key_size\n\n    def test_type(self):\n        \"\"\"\n        `PKey` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(PKey, 'PKey')\n\n    def test_construction(self):\n        \"\"\"\n        `PKey` takes no arguments and returns a new `PKey` instance.\n        \"\"\"\n        key = PKey()\n        assert isinstance(key, PKey)\n\n    def test_pregeneration(self):\n        \"\"\"\n        `PKey.bits` and `PKey.type` return `0` before the key is generated.\n        `PKey.check` raises `TypeError` before the key is generated.\n        \"\"\"\n        key = PKey()\n        assert key.type() == 0\n        assert key.bits() == 0\n        with pytest.raises(TypeError):\n            key.check()\n\n    def test_failed_generation(self):\n        \"\"\"\n        `PKey.generate_key` takes two arguments, the first giving the key type\n        as one of `TYPE_RSA` or `TYPE_DSA` and the second giving the number of\n        bits to generate.  If an invalid type is specified or generation fails,\n        `Error` is raised.  If an invalid number of bits is specified,\n        `ValueError` or `Error` is raised.\n        \"\"\"\n        key = PKey()\n        with pytest.raises(TypeError):\n            key.generate_key(\"foo\", \"bar\")\n        with pytest.raises(Error):\n            key.generate_key(-1, 0)\n\n        with pytest.raises(ValueError):\n            key.generate_key(TYPE_RSA, -1)\n        with pytest.raises(ValueError):\n            key.generate_key(TYPE_RSA, 0)\n\n        with pytest.raises(TypeError):\n            key.generate_key(TYPE_RSA, object())\n\n        # XXX RSA generation for small values of bits is fairly buggy in a wide\n        # range of OpenSSL versions.  I need to figure out what the safe lower\n        # bound for a reasonable number of OpenSSL versions is and explicitly\n        # check for that in the wrapper.  The failure behavior is typically an\n        # infinite loop inside OpenSSL.\n\n        # with pytest.raises(Error):\n        #     key.generate_key(TYPE_RSA, 2)\n\n        # XXX DSA generation seems happy with any number of bits.  The DSS\n        # says bits must be between 512 and 1024 inclusive.  OpenSSL's DSA\n        # generator doesn't seem to care about the upper limit at all.  For\n        # the lower limit, it uses 512 if anything smaller is specified.\n        # So, it doesn't seem possible to make generate_key fail for\n        # TYPE_DSA with a bits argument which is at least an int.\n\n        # with pytest.raises(Error):\n        #     key.generate_key(TYPE_DSA, -7)\n\n    def test_rsa_generation(self):\n        \"\"\"\n        `PKey.generate_key` generates an RSA key when passed `TYPE_RSA` as a\n        type and a reasonable number of bits.\n        \"\"\"\n        bits = 512\n        key = PKey()\n        key.generate_key(TYPE_RSA, bits)\n        assert key.type() == TYPE_RSA\n        assert key.bits() == bits\n        assert key.check()\n\n    def test_dsa_generation(self):\n        \"\"\"\n        `PKey.generate_key` generates a DSA key when passed `TYPE_DSA` as a\n        type and a reasonable number of bits.\n        \"\"\"\n        # 512 is a magic number.  The DSS (Digital Signature Standard)\n        # allows a minimum of 512 bits for DSA.  DSA_generate_parameters\n        # will silently promote any value below 512 to 512.\n        bits = 512\n        key = PKey()\n        key.generate_key(TYPE_DSA, bits)\n        assert key.type() == TYPE_DSA\n        assert key.bits() == bits\n        with pytest.raises(TypeError):\n            key.check()\n\n    def test_regeneration(self):\n        \"\"\"\n        `PKey.generate_key` can be called multiple times on the same key to\n        generate new keys.\n        \"\"\"\n        key = PKey()\n        for type, bits in [(TYPE_RSA, 512), (TYPE_DSA, 576)]:\n            key.generate_key(type, bits)\n            assert key.type() == type\n            assert key.bits() == bits\n\n    def test_inconsistent_key(self):\n        \"\"\"\n        `PKey.check` returns `Error` if the key is not consistent.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, inconsistentPrivateKeyPEM)\n        with pytest.raises(Error):\n            key.check()\n\n    def test_check_public_key(self):\n        \"\"\"\n        `PKey.check` raises `TypeError` if only the public part of the key\n        is available.\n        \"\"\"\n        # A trick to get a public-only key\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        cert = X509()\n        cert.set_pubkey(key)\n        pub = cert.get_pubkey()\n        with pytest.raises(TypeError):\n            pub.check()\n\n\ndef x509_name(**attrs):\n    \"\"\"\n    Return a new X509Name with the given attributes.\n    \"\"\"\n    # XXX There's no other way to get a new X509Name yet.\n    name = X509().get_subject()\n    attrs = list(attrs.items())\n\n    # Make the order stable - order matters!\n    def key(attr):\n        return attr[1]\n    attrs.sort(key=key)\n    for k, v in attrs:\n        setattr(name, k, v)\n    return name\n\n\nclass TestX509Name(object):\n    \"\"\"\n    Unit tests for `OpenSSL.crypto.X509Name`.\n    \"\"\"\n\n    def test_type(self):\n        \"\"\"\n        The type of X509Name objects is `X509Name`.\n        \"\"\"\n        name = x509_name()\n        assert isinstance(name, X509Name)\n\n    def test_only_string_attributes(self):\n        \"\"\"\n        Attempting to set a non-`str` attribute name on an `X509Name` instance\n        causes `TypeError` to be raised.\n        \"\"\"\n        name = x509_name()\n        # Beyond these cases, you may also think that unicode should be\n        # rejected.  Sorry, you're wrong.  unicode is automatically converted\n        # to str outside of the control of X509Name, so there's no way to\n        # reject it.\n\n        # Also, this used to test str subclasses, but that test is less\n        # relevant now that the implementation is in Python instead of C.  Also\n        # PyPy automatically converts str subclasses to str when they are\n        # passed to setattr, so we can't test it on PyPy.  Apparently CPython\n        # does this sometimes as well.\n        with pytest.raises(TypeError):\n            setattr(name, None, \"hello\")\n        with pytest.raises(TypeError):\n            setattr(name, 30, \"hello\")\n\n    def test_set_invalid_attribute(self):\n        \"\"\"\n        Attempting to set any attribute name on an `X509Name` instance for\n        which no corresponding NID is defined causes `AttributeError` to be\n        raised.\n        \"\"\"\n        name = x509_name()\n        with pytest.raises(AttributeError):\n            setattr(name, \"no such thing\", None)\n\n    def test_attributes(self):\n        \"\"\"\n        `X509Name` instances have attributes for each standard (?)\n        X509Name field.\n        \"\"\"\n        name = x509_name()\n        name.commonName = \"foo\"\n        assert name.commonName == \"foo\"\n        assert name.CN == \"foo\"\n\n        name.CN = \"baz\"\n        assert name.commonName == \"baz\"\n        assert name.CN == \"baz\"\n\n        name.commonName = \"bar\"\n        assert name.commonName == \"bar\"\n        assert name.CN == \"bar\"\n\n        name.CN = \"quux\"\n        assert name.commonName == \"quux\"\n        assert name.CN == \"quux\"\n\n        assert name.OU is None\n\n        with pytest.raises(AttributeError):\n            name.foobar\n\n    def test_copy(self):\n        \"\"\"\n        `X509Name` creates a new `X509Name` instance with all the same\n        attributes as an existing `X509Name` instance when called with one.\n        \"\"\"\n        name = x509_name(commonName=\"foo\", emailAddress=\"bar@example.com\")\n\n        copy = X509Name(name)\n        assert copy.commonName == \"foo\"\n        assert copy.emailAddress == \"bar@example.com\"\n\n        # Mutate the copy and ensure the original is unmodified.\n        copy.commonName = \"baz\"\n        assert name.commonName == \"foo\"\n\n        # Mutate the original and ensure the copy is unmodified.\n        name.emailAddress = \"quux@example.com\"\n        assert copy.emailAddress == \"bar@example.com\"\n\n    def test_repr(self):\n        \"\"\"\n        `repr` passed an `X509Name` instance should return a string containing\n        a description of the type and the NIDs which have been set on it.\n        \"\"\"\n        name = x509_name(commonName=\"foo\", emailAddress=\"bar\")\n        assert repr(name) == \"<X509Name object '/emailAddress=bar/CN=foo'>\"\n\n    def test_comparison(self):\n        \"\"\"\n        `X509Name` instances should compare based on their NIDs.\n        \"\"\"\n        def _equality(a, b, assert_true, assert_false):\n            assert_true(a == b)\n            assert_false(a != b)\n            assert_true(b == a)\n            assert_false(b != a)\n\n        def assert_true(x):\n            assert x\n\n        def assert_false(x):\n            assert not x\n\n        def assert_equal(a, b):\n            _equality(a, b, assert_true, assert_false)\n\n        # Instances compare equal to themselves.\n        name = x509_name()\n        assert_equal(name, name)\n\n        # Empty instances should compare equal to each other.\n        assert_equal(x509_name(), x509_name())\n\n        # Instances with equal NIDs should compare equal to each other.\n        assert_equal(x509_name(commonName=\"foo\"),\n                     x509_name(commonName=\"foo\"))\n\n        # Instance with equal NIDs set using different aliases should compare\n        # equal to each other.\n        assert_equal(x509_name(commonName=\"foo\"),\n                     x509_name(CN=\"foo\"))\n\n        # Instances with more than one NID with the same values should compare\n        # equal to each other.\n        assert_equal(x509_name(CN=\"foo\", organizationalUnitName=\"bar\"),\n                     x509_name(commonName=\"foo\", OU=\"bar\"))\n\n        def assert_not_equal(a, b):\n            _equality(a, b, assert_false, assert_true)\n\n        # Instances with different values for the same NID should not compare\n        # equal to each other.\n        assert_not_equal(x509_name(CN=\"foo\"),\n                         x509_name(CN=\"bar\"))\n\n        # Instances with different NIDs should not compare equal to each other.\n        assert_not_equal(x509_name(CN=\"foo\"),\n                         x509_name(OU=\"foo\"))\n\n        assert_not_equal(x509_name(), object())\n\n        def _inequality(a, b, assert_true, assert_false):\n            assert_true(a < b)\n            assert_true(a <= b)\n            assert_true(b > a)\n            assert_true(b >= a)\n            assert_false(a > b)\n            assert_false(a >= b)\n            assert_false(b < a)\n            assert_false(b <= a)\n\n        def assert_less_than(a, b):\n            _inequality(a, b, assert_true, assert_false)\n\n        # An X509Name with a NID with a value which sorts less than the value\n        # of the same NID on another X509Name compares less than the other\n        # X509Name.\n        assert_less_than(x509_name(CN=\"abc\"),\n                         x509_name(CN=\"def\"))\n\n        def assert_greater_than(a, b):\n            _inequality(a, b, assert_false, assert_true)\n\n        # An X509Name with a NID with a value which sorts greater than the\n        # value of the same NID on another X509Name compares greater than the\n        # other X509Name.\n        assert_greater_than(x509_name(CN=\"def\"),\n                            x509_name(CN=\"abc\"))\n\n    def test_hash(self):\n        \"\"\"\n        `X509Name.hash` returns an integer hash based on the value of the name.\n        \"\"\"\n        a = x509_name(CN=\"foo\")\n        b = x509_name(CN=\"foo\")\n        assert a.hash() == b.hash()\n        a.CN = \"bar\"\n        assert a.hash() != b.hash()\n\n    def test_der(self):\n        \"\"\"\n        `X509Name.der` returns the DER encoded form of the name.\n        \"\"\"\n        a = x509_name(CN=\"foo\", C=\"US\")\n        assert (a.der() ==\n                b'0\\x1b1\\x0b0\\t\\x06\\x03U\\x04\\x06\\x13\\x02US'\n                b'1\\x0c0\\n\\x06\\x03U\\x04\\x03\\x0c\\x03foo')\n\n    def test_get_components(self):\n        \"\"\"\n        `X509Name.get_components` returns a `list` of two-tuples of `str`\n        giving the NIDs and associated values which make up the name.\n        \"\"\"\n        a = x509_name()\n        assert a.get_components() == []\n        a.CN = \"foo\"\n        assert a.get_components() == [(b\"CN\", b\"foo\")]\n        a.organizationalUnitName = \"bar\"\n        assert a.get_components() == [(b\"CN\", b\"foo\"), (b\"OU\", b\"bar\")]\n\n    def test_load_nul_byte_attribute(self):\n        \"\"\"\n        An `X509Name` from an `X509` instance loaded from a file can have a\n        NUL byte in the value of one of its attributes.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, nulbyteSubjectAltNamePEM)\n        subject = cert.get_subject()\n        assert \"null.python.org\\x00example.org\" == subject.commonName\n\n    def test_load_nul_byte_components(self):\n        \"\"\"\n        An `X509Name` from an `X509` instance loaded from a file can have a\n        NUL byte in the value of its components\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, nulbyteSubjectAltNamePEM)\n        subject = cert.get_subject()\n        components = subject.get_components()\n        ccn = [value for name, value in components if name == b'CN']\n        assert ccn[0] == b'null.python.org\\x00example.org'\n\n    def test_set_attribute_failure(self):\n        \"\"\"\n        If the value of an attribute cannot be set for some reason then\n        `Error` is raised.\n        \"\"\"\n        name = x509_name()\n        # This value is too long\n        with pytest.raises(Error):\n            setattr(name, \"O\", b\"x\" * 512)\n\n\nclass _PKeyInteractionTestsMixin:\n    \"\"\"\n    Tests which involve another thing and a PKey.\n    \"\"\"\n\n    def signable(self):\n        \"\"\"\n        Return something with a `set_pubkey`, `set_pubkey`, and `sign` method.\n        \"\"\"\n        raise NotImplementedError()\n\n    def test_sign_with_ungenerated(self):\n        \"\"\"\n        `X509Req.sign` raises `ValueError` when passed a `PKey` with no parts.\n        \"\"\"\n        request = self.signable()\n        key = PKey()\n        with pytest.raises(ValueError):\n            request.sign(key, GOOD_DIGEST)\n\n    def test_sign_with_public_key(self):\n        \"\"\"\n        `X509Req.sign` raises `ValueError` when passed a `PKey` with no private\n        part as the signing key.\n        \"\"\"\n        request = self.signable()\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        request.set_pubkey(key)\n        pub = request.get_pubkey()\n        with pytest.raises(ValueError):\n            request.sign(pub, GOOD_DIGEST)\n\n    def test_sign_with_unknown_digest(self):\n        \"\"\"\n        `X509Req.sign` raises `ValueError` when passed a digest name which is\n        not known.\n        \"\"\"\n        request = self.signable()\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        with pytest.raises(ValueError):\n            request.sign(key, BAD_DIGEST)\n\n    def test_sign(self):\n        \"\"\"\n        `X509Req.sign` succeeds when passed a private key object and a\n        valid digest function. `X509Req.verify` can be used to check\n        the signature.\n        \"\"\"\n        request = self.signable()\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        request.set_pubkey(key)\n        request.sign(key, GOOD_DIGEST)\n        # If the type has a verify method, cover that too.\n        if getattr(request, 'verify', None) is not None:\n            pub = request.get_pubkey()\n            assert request.verify(pub)\n            # Make another key that won't verify.\n            key = PKey()\n            key.generate_key(TYPE_RSA, 512)\n            with pytest.raises(Error):\n                request.verify(key)\n\n\nclass TestX509Req(_PKeyInteractionTestsMixin):\n    \"\"\"\n    Tests for `OpenSSL.crypto.X509Req`.\n    \"\"\"\n\n    def signable(self):\n        \"\"\"\n        Create and return a new `X509Req`.\n        \"\"\"\n        return X509Req()\n\n    def test_type(self):\n        \"\"\"\n        `X509Req` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(X509Req, 'X509Req')\n\n    def test_construction(self):\n        \"\"\"\n        `X509Req` takes no arguments and returns an `X509Req` instance.\n        \"\"\"\n        request = X509Req()\n        assert isinstance(request, X509Req)\n\n    def test_version(self):\n        \"\"\"\n        `X509Req.set_version` sets the X.509 version of the certificate\n        request. `X509Req.get_version` returns the X.509 version of the\n        certificate request. The initial value of the version is 0.\n        \"\"\"\n        request = X509Req()\n        assert request.get_version() == 0\n        request.set_version(1)\n        assert request.get_version() == 1\n        request.set_version(3)\n        assert request.get_version() == 3\n\n    def test_version_wrong_args(self):\n        \"\"\"\n        `X509Req.set_version` raises `TypeError` if called with a non-`int`\n        argument.\n        \"\"\"\n        request = X509Req()\n        with pytest.raises(TypeError):\n            request.set_version(\"foo\")\n\n    def test_get_subject(self):\n        \"\"\"\n        `X509Req.get_subject` returns an `X509Name` for the subject of the\n        request and which is valid even after the request object is\n        otherwise dead.\n        \"\"\"\n        request = X509Req()\n        subject = request.get_subject()\n        assert isinstance(subject, X509Name)\n        subject.commonName = \"foo\"\n        assert request.get_subject().commonName == \"foo\"\n        del request\n        subject.commonName = \"bar\"\n        assert subject.commonName == \"bar\"\n\n    def test_add_extensions(self):\n        \"\"\"\n        `X509Req.add_extensions` accepts a `list` of `X509Extension` instances\n        and adds them to the X509 request.\n        \"\"\"\n        request = X509Req()\n        request.add_extensions([\n            X509Extension(b'basicConstraints', True, b'CA:false')])\n        exts = request.get_extensions()\n        assert len(exts) == 1\n        assert exts[0].get_short_name() == b'basicConstraints'\n        assert exts[0].get_critical() == 1\n        assert exts[0].get_data() == b'0\\x00'\n\n    def test_get_extensions(self):\n        \"\"\"\n        `X509Req.get_extensions` returns a `list` of extensions added to this\n        X509 request.\n        \"\"\"\n        request = X509Req()\n        exts = request.get_extensions()\n        assert exts == []\n        request.add_extensions([\n            X509Extension(b'basicConstraints', True, b'CA:true'),\n            X509Extension(b'keyUsage', False, b'digitalSignature')])\n        exts = request.get_extensions()\n        assert len(exts) == 2\n        assert exts[0].get_short_name() == b'basicConstraints'\n        assert exts[0].get_critical() == 1\n        assert exts[0].get_data() == b'0\\x03\\x01\\x01\\xff'\n        assert exts[1].get_short_name() == b'keyUsage'\n        assert exts[1].get_critical() == 0\n        assert exts[1].get_data() == b'\\x03\\x02\\x07\\x80'\n\n    def test_add_extensions_wrong_args(self):\n        \"\"\"\n        `X509Req.add_extensions` raises `TypeError` if called with a\n        non-`list`.  Or it raises `ValueError` if called with a `list`\n        containing objects other than `X509Extension` instances.\n        \"\"\"\n        request = X509Req()\n        with pytest.raises(TypeError):\n            request.add_extensions(object())\n        with pytest.raises(ValueError):\n            request.add_extensions([object()])\n\n    def test_verify_wrong_args(self):\n        \"\"\"\n        `X509Req.verify` raises `TypeError` if passed anything other than a\n        `PKey` instance as its single argument.\n        \"\"\"\n        request = X509Req()\n        with pytest.raises(TypeError):\n            request.verify(object())\n\n    def test_verify_uninitialized_key(self):\n        \"\"\"\n        `X509Req.verify` raises `OpenSSL.crypto.Error` if called with a\n        `OpenSSL.crypto.PKey` which contains no key data.\n        \"\"\"\n        request = X509Req()\n        pkey = PKey()\n        with pytest.raises(Error):\n            request.verify(pkey)\n\n    def test_verify_wrong_key(self):\n        \"\"\"\n        `X509Req.verify` raises `OpenSSL.crypto.Error` if called with a\n        `OpenSSL.crypto.PKey` which does not represent the public part of the\n        key which signed the request.\n        \"\"\"\n        request = X509Req()\n        pkey = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        request.sign(pkey, GOOD_DIGEST)\n        another_pkey = load_privatekey(FILETYPE_PEM, client_key_pem)\n        with pytest.raises(Error):\n            request.verify(another_pkey)\n\n    def test_verify_success(self):\n        \"\"\"\n        `X509Req.verify` returns `True` if called with a `OpenSSL.crypto.PKey`\n        which represents the public part of the key which signed the request.\n        \"\"\"\n        request = X509Req()\n        pkey = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        request.sign(pkey, GOOD_DIGEST)\n        assert request.verify(pkey)\n\n    def test_convert_from_cryptography(self):\n        crypto_req = x509.load_pem_x509_csr(\n            cleartextCertificateRequestPEM, backend\n        )\n        req = X509Req.from_cryptography(crypto_req)\n        assert isinstance(req, X509Req)\n\n    def test_convert_from_cryptography_unsupported_type(self):\n        with pytest.raises(TypeError):\n            X509Req.from_cryptography(object())\n\n    def test_convert_to_cryptography_key(self):\n        req = load_certificate_request(\n            FILETYPE_PEM, cleartextCertificateRequestPEM\n        )\n        crypto_req = req.to_cryptography()\n        assert isinstance(crypto_req, x509.CertificateSigningRequest)\n\n\nclass TestX509(_PKeyInteractionTestsMixin):\n    \"\"\"\n    Tests for `OpenSSL.crypto.X509`.\n    \"\"\"\n    pemData = cleartextCertificatePEM + cleartextPrivateKeyPEM\n\n    extpem = \"\"\"\n-----BEGIN CERTIFICATE-----\nMIIC3jCCAkegAwIBAgIJAJHFjlcCgnQzMA0GCSqGSIb3DQEBBQUAMEcxCzAJBgNV\nBAYTAlNFMRUwEwYDVQQIEwxXZXN0ZXJib3R0b20xEjAQBgNVBAoTCUNhdGFsb2dp\neDENMAsGA1UEAxMEUm9vdDAeFw0wODA0MjIxNDQ1MzhaFw0wOTA0MjIxNDQ1Mzha\nMFQxCzAJBgNVBAYTAlNFMQswCQYDVQQIEwJXQjEUMBIGA1UEChMLT3Blbk1ldGFk\naXIxIjAgBgNVBAMTGW5vZGUxLm9tMi5vcGVubWV0YWRpci5vcmcwgZ8wDQYJKoZI\nhvcNAQEBBQADgY0AMIGJAoGBAPIcQMrwbk2nESF/0JKibj9i1x95XYAOwP+LarwT\nOp4EQbdlI9SY+uqYqlERhF19w7CS+S6oyqx0DRZSk4Y9dZ9j9/xgm2u/f136YS1u\nzgYFPvfUs6PqYLPSM8Bw+SjJ+7+2+TN+Tkiof9WP1cMjodQwOmdsiRbR0/J7+b1B\nhec1AgMBAAGjgcQwgcEwCQYDVR0TBAIwADAsBglghkgBhvhCAQ0EHxYdT3BlblNT\nTCBHZW5lcmF0ZWQgQ2VydGlmaWNhdGUwHQYDVR0OBBYEFIdHsBcMVVMbAO7j6NCj\n03HgLnHaMB8GA1UdIwQYMBaAFL2h9Bf9Mre4vTdOiHTGAt7BRY/8MEYGA1UdEQQ/\nMD2CDSouZXhhbXBsZS5vcmeCESoub20yLmV4bWFwbGUuY29thwSC7wgKgRNvbTJA\nb3Blbm1ldGFkaXIub3JnMA0GCSqGSIb3DQEBBQUAA4GBALd7WdXkp2KvZ7/PuWZA\nMPlIxyjS+Ly11+BNE0xGQRp9Wz+2lABtpgNqssvU156+HkKd02rGheb2tj7MX9hG\nuZzbwDAZzJPjzDQDD7d3cWsrVcfIdqVU7epHqIadnOF+X0ghJ39pAm6VVadnSXCt\nWpOdIpB8KksUTCzV591Nr1wd\n-----END CERTIFICATE-----\n    \"\"\"\n\n    def signable(self):\n        \"\"\"\n        Create and return a new `X509`.\n        \"\"\"\n        return X509()\n\n    def test_type(self):\n        \"\"\"\n        `X509` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(X509, 'X509')\n\n    def test_construction(self):\n        \"\"\"\n        `X509` takes no arguments and returns an instance of `X509`.\n        \"\"\"\n        certificate = X509()\n        assert isinstance(certificate, X509)\n        assert type(certificate).__name__ == 'X509'\n        assert type(certificate) == X509\n\n    def test_set_version_wrong_args(self):\n        \"\"\"\n        `X509.set_version` raises `TypeError` if invoked with an argument\n        not of type `int`.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.set_version(None)\n\n    def test_version(self):\n        \"\"\"\n        `X509.set_version` sets the certificate version number.\n        `X509.get_version` retrieves it.\n        \"\"\"\n        cert = X509()\n        cert.set_version(1234)\n        assert cert.get_version() == 1234\n\n    def test_serial_number(self):\n        \"\"\"\n        The serial number of an `X509` can be retrieved and\n        modified with `X509.get_serial_number` and\n        `X509.set_serial_number`.\n        \"\"\"\n        certificate = X509()\n        with pytest.raises(TypeError):\n            certificate.set_serial_number(\"1\")\n        assert certificate.get_serial_number() == 0\n        certificate.set_serial_number(1)\n        assert certificate.get_serial_number() == 1\n        certificate.set_serial_number(2 ** 32 + 1)\n        assert certificate.get_serial_number() == 2 ** 32 + 1\n        certificate.set_serial_number(2 ** 64 + 1)\n        assert certificate.get_serial_number() == 2 ** 64 + 1\n        certificate.set_serial_number(2 ** 128 + 1)\n        assert certificate.get_serial_number() == 2 ** 128 + 1\n\n    def _setBoundTest(self, which):\n        \"\"\"\n        `X509.set_notBefore` takes a string in the format of an\n        ASN1 GENERALIZEDTIME and sets the beginning of the certificate's\n        validity period to it.\n        \"\"\"\n        certificate = X509()\n        set = getattr(certificate, 'set_not' + which)\n        get = getattr(certificate, 'get_not' + which)\n\n        # Starts with no value.\n        assert get() is None\n\n        # GMT (Or is it UTC?) -exarkun\n        when = b\"20040203040506Z\"\n        set(when)\n        assert get() == when\n\n        # A plus two hours and thirty minutes offset\n        when = b\"20040203040506+0530\"\n        set(when)\n        assert get() == when\n\n        # A minus one hour fifteen minutes offset\n        when = b\"20040203040506-0115\"\n        set(when)\n        assert get() == when\n\n        # An invalid string results in a ValueError\n        with pytest.raises(ValueError):\n            set(b\"foo bar\")\n\n        # The wrong number of arguments results in a TypeError.\n        with pytest.raises(TypeError):\n            set()\n        with pytest.raises(TypeError):\n            set(b\"20040203040506Z\", b\"20040203040506Z\")\n        with pytest.raises(TypeError):\n            get(b\"foo bar\")\n\n    # XXX ASN1_TIME (not GENERALIZEDTIME)\n\n    def test_set_notBefore(self):\n        \"\"\"\n        `X509.set_notBefore` takes a string in the format of an\n        ASN1 GENERALIZEDTIME and sets the beginning of the certificate's\n        validity period to it.\n        \"\"\"\n        self._setBoundTest(\"Before\")\n\n    def test_set_notAfter(self):\n        \"\"\"\n        `X509.set_notAfter` takes a string in the format of an ASN1\n        GENERALIZEDTIME and sets the end of the certificate's validity period\n        to it.\n        \"\"\"\n        self._setBoundTest(\"After\")\n\n    def test_get_notBefore(self):\n        \"\"\"\n        `X509.get_notBefore` returns a string in the format of an\n        ASN1 GENERALIZEDTIME even for certificates which store it as UTCTIME\n        internally.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, old_root_cert_pem)\n        assert cert.get_notBefore() == b\"20090325123658Z\"\n\n    def test_get_notAfter(self):\n        \"\"\"\n        `X509.get_notAfter` returns a string in the format of an\n        ASN1 GENERALIZEDTIME even for certificates which store it as UTCTIME\n        internally.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, old_root_cert_pem)\n        assert cert.get_notAfter() == b\"20170611123658Z\"\n\n    def test_gmtime_adj_notBefore_wrong_args(self):\n        \"\"\"\n        `X509.gmtime_adj_notBefore` raises `TypeError` if called with a\n        non-`int` argument.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.gmtime_adj_notBefore(None)\n\n    @flaky.flaky\n    def test_gmtime_adj_notBefore(self):\n        \"\"\"\n        `X509.gmtime_adj_notBefore` changes the not-before timestamp to be the\n        current time plus the number of seconds passed in.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        not_before_min = (\n            datetime.utcnow().replace(microsecond=0) + timedelta(seconds=100)\n        )\n        cert.gmtime_adj_notBefore(100)\n        not_before = datetime.strptime(\n            cert.get_notBefore().decode(), \"%Y%m%d%H%M%SZ\"\n        )\n        not_before_max = datetime.utcnow() + timedelta(seconds=100)\n        assert not_before_min <= not_before <= not_before_max\n\n    def test_gmtime_adj_notAfter_wrong_args(self):\n        \"\"\"\n        `X509.gmtime_adj_notAfter` raises `TypeError` if called with a\n        non-`int` argument.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.gmtime_adj_notAfter(None)\n\n    @flaky.flaky\n    def test_gmtime_adj_notAfter(self):\n        \"\"\"\n        `X509.gmtime_adj_notAfter` changes the not-after timestamp\n        to be the current time plus the number of seconds passed in.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        not_after_min = (\n            datetime.utcnow().replace(microsecond=0) + timedelta(seconds=100)\n        )\n        cert.gmtime_adj_notAfter(100)\n        not_after = datetime.strptime(\n            cert.get_notAfter().decode(), \"%Y%m%d%H%M%SZ\"\n        )\n        not_after_max = datetime.utcnow() + timedelta(seconds=100)\n        assert not_after_min <= not_after <= not_after_max\n\n    def test_has_expired(self):\n        \"\"\"\n        `X509.has_expired` returns `True` if the certificate's not-after time\n        is in the past.\n        \"\"\"\n        cert = X509()\n        cert.gmtime_adj_notAfter(-1)\n        assert cert.has_expired()\n\n    def test_has_not_expired(self):\n        \"\"\"\n        `X509.has_expired` returns `False` if the certificate's not-after time\n        is in the future.\n        \"\"\"\n        cert = X509()\n        cert.gmtime_adj_notAfter(2)\n        assert not cert.has_expired()\n\n    def test_root_has_not_expired(self):\n        \"\"\"\n        `X509.has_expired` returns `False` if the certificate's not-after time\n        is in the future.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        assert not cert.has_expired()\n\n    def test_digest(self):\n        \"\"\"\n        `X509.digest` returns a string giving \":\"-separated hex-encoded\n        words of the digest of the certificate.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, old_root_cert_pem)\n        assert (\n            # This is MD5 instead of GOOD_DIGEST because the digest algorithm\n            # actually matters to the assertion (ie, another arbitrary, good\n            # digest will not product the same digest).\n            # Digest verified with the command:\n            # openssl x509 -in root_cert.pem -noout -fingerprint -md5\n            cert.digest(\"MD5\") ==\n            b\"19:B3:05:26:2B:F8:F2:FF:0B:8F:21:07:A8:28:B8:75\")\n\n    def _extcert(self, pkey, extensions):\n        cert = X509()\n        cert.set_pubkey(pkey)\n        cert.get_subject().commonName = \"Unit Tests\"\n        cert.get_issuer().commonName = \"Unit Tests\"\n        when = datetime.now().strftime(\"%Y%m%d%H%M%SZ\").encode(\"ascii\")\n        cert.set_notBefore(when)\n        cert.set_notAfter(when)\n\n        cert.add_extensions(extensions)\n        cert.sign(pkey, 'sha1')\n        return load_certificate(\n            FILETYPE_PEM, dump_certificate(FILETYPE_PEM, cert))\n\n    def test_extension_count(self):\n        \"\"\"\n        `X509.get_extension_count` returns the number of extensions\n        that are present in the certificate.\n        \"\"\"\n        pkey = load_privatekey(FILETYPE_PEM, client_key_pem)\n        ca = X509Extension(b'basicConstraints', True, b'CA:FALSE')\n        key = X509Extension(b'keyUsage', True, b'digitalSignature')\n        subjectAltName = X509Extension(\n            b'subjectAltName', True, b'DNS:example.com')\n\n        # Try a certificate with no extensions at all.\n        c = self._extcert(pkey, [])\n        assert c.get_extension_count() == 0\n\n        # And a certificate with one\n        c = self._extcert(pkey, [ca])\n        assert c.get_extension_count() == 1\n\n        # And a certificate with several\n        c = self._extcert(pkey, [ca, key, subjectAltName])\n        assert c.get_extension_count() == 3\n\n    def test_get_extension(self):\n        \"\"\"\n        `X509.get_extension` takes an integer and returns an\n        `X509Extension` corresponding to the extension at that index.\n        \"\"\"\n        pkey = load_privatekey(FILETYPE_PEM, client_key_pem)\n        ca = X509Extension(b'basicConstraints', True, b'CA:FALSE')\n        key = X509Extension(b'keyUsage', True, b'digitalSignature')\n        subjectAltName = X509Extension(\n            b'subjectAltName', False, b'DNS:example.com')\n\n        cert = self._extcert(pkey, [ca, key, subjectAltName])\n\n        ext = cert.get_extension(0)\n        assert isinstance(ext, X509Extension)\n        assert ext.get_critical()\n        assert ext.get_short_name() == b'basicConstraints'\n\n        ext = cert.get_extension(1)\n        assert isinstance(ext, X509Extension)\n        assert ext.get_critical()\n        assert ext.get_short_name() == b'keyUsage'\n\n        ext = cert.get_extension(2)\n        assert isinstance(ext, X509Extension)\n        assert not ext.get_critical()\n        assert ext.get_short_name() == b'subjectAltName'\n\n        with pytest.raises(IndexError):\n            cert.get_extension(-1)\n        with pytest.raises(IndexError):\n            cert.get_extension(4)\n        with pytest.raises(TypeError):\n            cert.get_extension(\"hello\")\n\n    def test_nullbyte_subjectAltName(self):\n        \"\"\"\n        The fields of a `subjectAltName` extension on an X509 may contain NUL\n        bytes and this value is reflected in the string representation of the\n        extension object.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, nulbyteSubjectAltNamePEM)\n\n        ext = cert.get_extension(3)\n        assert ext.get_short_name() == b'subjectAltName'\n        assert (\n            b\"DNS:altnull.python.org\\x00example.com, \"\n            b\"email:null@python.org\\x00user@example.org, \"\n            b\"URI:http://null.python.org\\x00http://example.org, \"\n            b\"IP Address:192.0.2.1, IP Address:2001:DB8:0:0:0:0:0:1\\n\" ==\n            str(ext).encode(\"ascii\"))\n\n    def test_invalid_digest_algorithm(self):\n        \"\"\"\n        `X509.digest` raises `ValueError` if called with an unrecognized hash\n        algorithm.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(ValueError):\n            cert.digest(BAD_DIGEST)\n\n    def test_get_subject(self):\n        \"\"\"\n        `X509.get_subject` returns an `X509Name` instance.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        subj = cert.get_subject()\n        assert isinstance(subj, X509Name)\n        assert (\n            subj.get_components() ==\n            [(b'C', b'US'), (b'ST', b'IL'), (b'L', b'Chicago'),\n             (b'O', b'Testing'), (b'CN', b'Testing Root CA')])\n\n    def test_set_subject_wrong_args(self):\n        \"\"\"\n        `X509.set_subject` raises a `TypeError` if called with an argument not\n        of type `X509Name`.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.set_subject(None)\n\n    def test_set_subject(self):\n        \"\"\"\n        `X509.set_subject` changes the subject of the certificate to the one\n        passed in.\n        \"\"\"\n        cert = X509()\n        name = cert.get_subject()\n        name.C = 'AU'\n        name.OU = 'Unit Tests'\n        cert.set_subject(name)\n        assert (\n            cert.get_subject().get_components() ==\n            [(b'C', b'AU'), (b'OU', b'Unit Tests')])\n\n    def test_get_issuer(self):\n        \"\"\"\n        `X509.get_issuer` returns an `X509Name` instance.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        subj = cert.get_issuer()\n        assert isinstance(subj, X509Name)\n        comp = subj.get_components()\n        assert (\n            comp ==\n            [(b'C', b'US'), (b'ST', b'IL'), (b'L', b'Chicago'),\n             (b'O', b'Testing'), (b'CN', b'Testing Root CA')])\n\n    def test_set_issuer_wrong_args(self):\n        \"\"\"\n        `X509.set_issuer` raises a `TypeError` if called with an argument not\n        of type `X509Name`.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.set_issuer(None)\n\n    def test_set_issuer(self):\n        \"\"\"\n        `X509.set_issuer` changes the issuer of the certificate to the\n        one passed in.\n        \"\"\"\n        cert = X509()\n        name = cert.get_issuer()\n        name.C = 'AU'\n        name.OU = 'Unit Tests'\n        cert.set_issuer(name)\n        assert (\n            cert.get_issuer().get_components() ==\n            [(b'C', b'AU'), (b'OU', b'Unit Tests')])\n\n    def test_get_pubkey_uninitialized(self):\n        \"\"\"\n        When called on a certificate with no public key, `X509.get_pubkey`\n        raises `OpenSSL.crypto.Error`.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(Error):\n            cert.get_pubkey()\n\n    def test_set_pubkey_wrong_type(self):\n        \"\"\"\n        `X509.set_pubkey` raises `TypeError` when given an object of the\n        wrong type.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.set_pubkey(object())\n\n    def test_subject_name_hash(self):\n        \"\"\"\n        `X509.subject_name_hash` returns the hash of the certificate's\n        subject name.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        # SHA1\n        assert cert.subject_name_hash() == 3278919224\n\n    def test_get_signature_algorithm(self):\n        \"\"\"\n        `X509.get_signature_algorithm` returns a string which means\n        the algorithm used to sign the certificate.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, self.pemData)\n        assert b\"sha1WithRSAEncryption\" == cert.get_signature_algorithm()\n\n    def test_get_undefined_signature_algorithm(self):\n        \"\"\"\n        `X509.get_signature_algorithm` raises `ValueError` if the signature\n        algorithm is undefined or unknown.\n        \"\"\"\n        # This certificate has been modified to indicate a bogus OID in the\n        # signature algorithm field so that OpenSSL does not recognize it.\n        certPEM = b\"\"\"\\\n-----BEGIN CERTIFICATE-----\nMIIC/zCCAmigAwIBAgIBATAGBgJ8BQUAMHsxCzAJBgNVBAYTAlNHMREwDwYDVQQK\nEwhNMkNyeXB0bzEUMBIGA1UECxMLTTJDcnlwdG8gQ0ExJDAiBgNVBAMTG00yQ3J5\ncHRvIENlcnRpZmljYXRlIE1hc3RlcjEdMBsGCSqGSIb3DQEJARYObmdwc0Bwb3N0\nMS5jb20wHhcNMDAwOTEwMDk1MTMwWhcNMDIwOTEwMDk1MTMwWjBTMQswCQYDVQQG\nEwJTRzERMA8GA1UEChMITTJDcnlwdG8xEjAQBgNVBAMTCWxvY2FsaG9zdDEdMBsG\nCSqGSIb3DQEJARYObmdwc0Bwb3N0MS5jb20wXDANBgkqhkiG9w0BAQEFAANLADBI\nAkEArL57d26W9fNXvOhNlZzlPOACmvwOZ5AdNgLzJ1/MfsQQJ7hHVeHmTAjM664V\n+fXvwUGJLziCeBo1ysWLRnl8CQIDAQABo4IBBDCCAQAwCQYDVR0TBAIwADAsBglg\nhkgBhvhCAQ0EHxYdT3BlblNTTCBHZW5lcmF0ZWQgQ2VydGlmaWNhdGUwHQYDVR0O\nBBYEFM+EgpK+eyZiwFU1aOPSbczbPSpVMIGlBgNVHSMEgZ0wgZqAFPuHI2nrnDqT\nFeXFvylRT/7tKDgBoX+kfTB7MQswCQYDVQQGEwJTRzERMA8GA1UEChMITTJDcnlw\ndG8xFDASBgNVBAsTC00yQ3J5cHRvIENBMSQwIgYDVQQDExtNMkNyeXB0byBDZXJ0\naWZpY2F0ZSBNYXN0ZXIxHTAbBgkqhkiG9w0BCQEWDm5ncHNAcG9zdDEuY29tggEA\nMA0GCSqGSIb3DQEBBAUAA4GBADv8KpPo+gfJxN2ERK1Y1l17sz/ZhzoGgm5XCdbx\njEY7xKfpQngV599k1xhl11IMqizDwu0855agrckg2MCTmOI9DZzDD77tAYb+Dk0O\nPEVk0Mk/V0aIsDE9bolfCi/i/QWZ3N8s5nTWMNyBBBmoSliWCm4jkkRZRD0ejgTN\ntgI5\n-----END CERTIFICATE-----\n\"\"\"\n        cert = load_certificate(FILETYPE_PEM, certPEM)\n        with pytest.raises(ValueError):\n            cert.get_signature_algorithm()\n\n    def test_sign_bad_pubkey_type(self):\n        \"\"\"\n        `X509.sign` raises `TypeError` when called with the wrong type.\n        \"\"\"\n        cert = X509()\n        with pytest.raises(TypeError):\n            cert.sign(object(), b\"sha256\")\n\n    def test_convert_from_cryptography(self):\n        crypto_cert = x509.load_pem_x509_certificate(\n            intermediate_cert_pem, backend\n        )\n        cert = X509.from_cryptography(crypto_cert)\n\n        assert isinstance(cert, X509)\n        assert cert.get_version() == crypto_cert.version.value\n\n    def test_convert_from_cryptography_unsupported_type(self):\n        with pytest.raises(TypeError):\n            X509.from_cryptography(object())\n\n    def test_convert_to_cryptography_key(self):\n        cert = load_certificate(FILETYPE_PEM, intermediate_cert_pem)\n        crypto_cert = cert.to_cryptography()\n\n        assert isinstance(crypto_cert, x509.Certificate)\n        assert crypto_cert.version.value == cert.get_version()\n\n\nclass TestX509Store(object):\n    \"\"\"\n    Test for `OpenSSL.crypto.X509Store`.\n    \"\"\"\n\n    def test_type(self):\n        \"\"\"\n        `X509Store` is a type object.\n        \"\"\"\n        assert is_consistent_type(X509Store, 'X509Store')\n\n    def test_add_cert(self):\n        \"\"\"\n        `X509Store.add_cert` adds a `X509` instance to the certificate store.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n        store = X509Store()\n        store.add_cert(cert)\n\n    @pytest.mark.parametrize('cert', [None, 1.0, 'cert', object()])\n    def test_add_cert_wrong_args(self, cert):\n        \"\"\"\n        `X509Store.add_cert` raises `TypeError` if passed a non-X509 object\n        as its first argument.\n        \"\"\"\n        store = X509Store()\n        with pytest.raises(TypeError):\n            store.add_cert(cert)\n\n    def test_add_cert_accepts_duplicate(self):\n        \"\"\"\n        `X509Store.add_cert` doesn't raise `OpenSSL.crypto.Error` if an attempt\n        is made to add the same certificate to the store more than once.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n        store = X509Store()\n        store.add_cert(cert)\n        store.add_cert(cert)\n\n\nclass TestPKCS12(object):\n    \"\"\"\n    Test for `OpenSSL.crypto.PKCS12` and `OpenSSL.crypto.load_pkcs12`.\n    \"\"\"\n    pemData = cleartextCertificatePEM + cleartextPrivateKeyPEM\n\n    def test_type(self):\n        \"\"\"\n        `PKCS12` is a type object.\n        \"\"\"\n        assert is_consistent_type(PKCS12, 'PKCS12')\n\n    def test_empty_construction(self):\n        \"\"\"\n        `PKCS12` returns a new instance of `PKCS12` with no certificate,\n        private key, CA certificates, or friendly name.\n        \"\"\"\n        p12 = PKCS12()\n        assert None is p12.get_certificate()\n        assert None is p12.get_privatekey()\n        assert None is p12.get_ca_certificates()\n        assert None is p12.get_friendlyname()\n\n    def test_type_errors(self):\n        \"\"\"\n        The `PKCS12` setter functions (`set_certificate`, `set_privatekey`,\n        `set_ca_certificates`, and `set_friendlyname`) raise `TypeError`\n        when passed objects of types other than those expected.\n        \"\"\"\n        p12 = PKCS12()\n        for bad_arg in [3, PKey(), X509]:\n            with pytest.raises(TypeError):\n                p12.set_certificate(bad_arg)\n        for bad_arg in [3, 'legbone', X509()]:\n            with pytest.raises(TypeError):\n                p12.set_privatekey(bad_arg)\n        for bad_arg in [3, X509(), (3, 4), (PKey(),)]:\n            with pytest.raises(TypeError):\n                p12.set_ca_certificates(bad_arg)\n        for bad_arg in [6, ('foo', 'bar')]:\n            with pytest.raises(TypeError):\n                p12.set_friendlyname(bad_arg)\n\n    def test_key_only(self):\n        \"\"\"\n        A `PKCS12` with only a private key can be exported using\n        `PKCS12.export` and loaded again using `load_pkcs12`.\n        \"\"\"\n        passwd = b\"blah\"\n        p12 = PKCS12()\n        pkey = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        p12.set_privatekey(pkey)\n        assert None is p12.get_certificate()\n        assert pkey == p12.get_privatekey()\n        try:\n            dumped_p12 = p12.export(passphrase=passwd, iter=2, maciter=3)\n        except Error:\n            # Some versions of OpenSSL will throw an exception\n            # for this nearly useless PKCS12 we tried to generate:\n            # [('PKCS12 routines', 'PKCS12_create', 'invalid null argument')]\n            return\n        p12 = load_pkcs12(dumped_p12, passwd)\n        assert None is p12.get_ca_certificates()\n        assert None is p12.get_certificate()\n\n        # OpenSSL fails to bring the key back to us.  So sad.  Perhaps in the\n        # future this will be improved.\n        assert isinstance(p12.get_privatekey(), (PKey, type(None)))\n\n    def test_cert_only(self):\n        \"\"\"\n        A `PKCS12` with only a certificate can be exported using\n        `PKCS12.export` and loaded again using `load_pkcs12`.\n        \"\"\"\n        passwd = b\"blah\"\n        p12 = PKCS12()\n        cert = load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n        p12.set_certificate(cert)\n        assert cert == p12.get_certificate()\n        assert None is p12.get_privatekey()\n        try:\n            dumped_p12 = p12.export(passphrase=passwd, iter=2, maciter=3)\n        except Error:\n            # Some versions of OpenSSL will throw an exception\n            # for this nearly useless PKCS12 we tried to generate:\n            # [('PKCS12 routines', 'PKCS12_create', 'invalid null argument')]\n            return\n        p12 = load_pkcs12(dumped_p12, passwd)\n        assert None is p12.get_privatekey()\n\n        # OpenSSL fails to bring the cert back to us.  Groany mcgroan.\n        assert isinstance(p12.get_certificate(), (X509, type(None)))\n\n        # Oh ho.  It puts the certificate into the ca certificates list, in\n        # fact.  Totally bogus, I would think.  Nevertheless, let's exploit\n        # that to check to see if it reconstructed the certificate we expected\n        # it to.  At some point, hopefully this will change so that\n        # p12.get_certificate() is actually what returns the loaded\n        # certificate.\n        assert (\n            cleartextCertificatePEM ==\n            dump_certificate(FILETYPE_PEM, p12.get_ca_certificates()[0]))\n\n    def gen_pkcs12(self, cert_pem=None, key_pem=None, ca_pem=None,\n                   friendly_name=None):\n        \"\"\"\n        Generate a PKCS12 object with components from PEM.  Verify that the set\n        functions return None.\n        \"\"\"\n        p12 = PKCS12()\n        if cert_pem:\n            ret = p12.set_certificate(load_certificate(FILETYPE_PEM, cert_pem))\n            assert ret is None\n        if key_pem:\n            ret = p12.set_privatekey(load_privatekey(FILETYPE_PEM, key_pem))\n            assert ret is None\n        if ca_pem:\n            ret = p12.set_ca_certificates(\n                (load_certificate(FILETYPE_PEM, ca_pem),)\n            )\n            assert ret is None\n        if friendly_name:\n            ret = p12.set_friendlyname(friendly_name)\n            assert ret is None\n        return p12\n\n    def check_recovery(self, p12_str, key=None, cert=None, ca=None, passwd=b\"\",\n                       extra=()):\n        \"\"\"\n        Use openssl program to confirm three components are recoverable from a\n        PKCS12 string.\n        \"\"\"\n        if key:\n            recovered_key = _runopenssl(\n                p12_str, b\"pkcs12\", b\"-nocerts\", b\"-nodes\", b\"-passin\",\n                b\"pass:\" + passwd, *extra)\n            assert recovered_key[-len(key):] == key\n        if cert:\n            recovered_cert = _runopenssl(\n                p12_str, b\"pkcs12\", b\"-clcerts\", b\"-nodes\", b\"-passin\",\n                b\"pass:\" + passwd, b\"-nokeys\", *extra)\n            assert recovered_cert[-len(cert):] == cert\n        if ca:\n            recovered_cert = _runopenssl(\n                p12_str, b\"pkcs12\", b\"-cacerts\", b\"-nodes\", b\"-passin\",\n                b\"pass:\" + passwd, b\"-nokeys\", *extra)\n            assert recovered_cert[-len(ca):] == ca\n\n    def verify_pkcs12_container(self, p12):\n        \"\"\"\n        Verify that the PKCS#12 container contains the correct client\n        certificate and private key.\n\n        :param p12: The PKCS12 instance to verify.\n        :type p12: `PKCS12`\n        \"\"\"\n        cert_pem = dump_certificate(FILETYPE_PEM, p12.get_certificate())\n        key_pem = dump_privatekey(FILETYPE_PEM, p12.get_privatekey())\n        assert (\n            (client_cert_pem, client_key_pem, None) ==\n            (cert_pem, key_pem, p12.get_ca_certificates()))\n\n    def test_load_pkcs12(self):\n        \"\"\"\n        A PKCS12 string generated using the openssl command line can be loaded\n        with `load_pkcs12` and its components extracted and examined.\n        \"\"\"\n        passwd = b\"whatever\"\n        pem = client_key_pem + client_cert_pem\n        p12_str = _runopenssl(\n            pem,\n            b\"pkcs12\",\n            b\"-export\",\n            b\"-clcerts\",\n            b\"-passout\",\n            b\"pass:\" + passwd\n        )\n        p12 = load_pkcs12(p12_str, passphrase=passwd)\n        self.verify_pkcs12_container(p12)\n\n    def test_load_pkcs12_text_passphrase(self):\n        \"\"\"\n        A PKCS12 string generated using the openssl command line can be loaded\n        with `load_pkcs12` and its components extracted and examined.\n        Using text as passphrase instead of bytes. DeprecationWarning expected.\n        \"\"\"\n        pem = client_key_pem + client_cert_pem\n        passwd = b\"whatever\"\n        p12_str = _runopenssl(pem, b\"pkcs12\", b\"-export\", b\"-clcerts\",\n                              b\"-passout\", b\"pass:\" + passwd)\n        with pytest.warns(DeprecationWarning) as w:\n            simplefilter(\"always\")\n            p12 = load_pkcs12(p12_str, passphrase=b\"whatever\".decode(\"ascii\"))\n            assert (\n                \"{0} for passphrase is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n\n        self.verify_pkcs12_container(p12)\n\n    def test_load_pkcs12_no_passphrase(self):\n        \"\"\"\n        A PKCS12 string generated using openssl command line can be loaded with\n        `load_pkcs12` without a passphrase and its components extracted\n        and examined.\n        \"\"\"\n        pem = client_key_pem + client_cert_pem\n        p12_str = _runopenssl(\n            pem, b\"pkcs12\", b\"-export\", b\"-clcerts\", b\"-passout\", b\"pass:\")\n        p12 = load_pkcs12(p12_str)\n        self.verify_pkcs12_container(p12)\n\n    def _dump_and_load(self, dump_passphrase, load_passphrase):\n        \"\"\"\n        A helper method to dump and load a PKCS12 object.\n        \"\"\"\n        p12 = self.gen_pkcs12(client_cert_pem, client_key_pem)\n        dumped_p12 = p12.export(passphrase=dump_passphrase, iter=2, maciter=3)\n        return load_pkcs12(dumped_p12, passphrase=load_passphrase)\n\n    def test_load_pkcs12_null_passphrase_load_empty(self):\n        \"\"\"\n        A PKCS12 string can be dumped with a null passphrase, loaded with an\n        empty passphrase with `load_pkcs12`, and its components\n        extracted and examined.\n        \"\"\"\n        self.verify_pkcs12_container(\n            self._dump_and_load(dump_passphrase=None, load_passphrase=b''))\n\n    def test_load_pkcs12_null_passphrase_load_null(self):\n        \"\"\"\n        A PKCS12 string can be dumped with a null passphrase, loaded with a\n        null passphrase with `load_pkcs12`, and its components\n        extracted and examined.\n        \"\"\"\n        self.verify_pkcs12_container(\n            self._dump_and_load(dump_passphrase=None, load_passphrase=None))\n\n    def test_load_pkcs12_empty_passphrase_load_empty(self):\n        \"\"\"\n        A PKCS12 string can be dumped with an empty passphrase, loaded with an\n        empty passphrase with `load_pkcs12`, and its components\n        extracted and examined.\n        \"\"\"\n        self.verify_pkcs12_container(\n            self._dump_and_load(dump_passphrase=b'', load_passphrase=b''))\n\n    def test_load_pkcs12_empty_passphrase_load_null(self):\n        \"\"\"\n        A PKCS12 string can be dumped with an empty passphrase, loaded with a\n        null passphrase with `load_pkcs12`, and its components\n        extracted and examined.\n        \"\"\"\n        self.verify_pkcs12_container(\n            self._dump_and_load(dump_passphrase=b'', load_passphrase=None))\n\n    def test_load_pkcs12_garbage(self):\n        \"\"\"\n        `load_pkcs12` raises `OpenSSL.crypto.Error` when passed\n        a string which is not a PKCS12 dump.\n        \"\"\"\n        passwd = 'whatever'\n        with pytest.raises(Error) as err:\n            load_pkcs12(b'fruit loops', passwd)\n        assert err.value.args[0][0][0] == 'asn1 encoding routines'\n        assert len(err.value.args[0][0]) == 3\n\n    def test_replace(self):\n        \"\"\"\n        `PKCS12.set_certificate` replaces the certificate in a PKCS12\n        cluster. `PKCS12.set_privatekey` replaces the private key.\n        `PKCS12.set_ca_certificates` replaces the CA certificates.\n        \"\"\"\n        p12 = self.gen_pkcs12(client_cert_pem, client_key_pem, root_cert_pem)\n        p12.set_certificate(load_certificate(FILETYPE_PEM, server_cert_pem))\n        p12.set_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        root_cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        client_cert = load_certificate(FILETYPE_PEM, client_cert_pem)\n        p12.set_ca_certificates([root_cert])  # not a tuple\n        assert 1 == len(p12.get_ca_certificates())\n        assert root_cert == p12.get_ca_certificates()[0]\n        p12.set_ca_certificates([client_cert, root_cert])\n        assert 2 == len(p12.get_ca_certificates())\n        assert client_cert == p12.get_ca_certificates()[0]\n        assert root_cert == p12.get_ca_certificates()[1]\n\n    def test_friendly_name(self):\n        \"\"\"\n        The *friendlyName* of a PKCS12 can be set and retrieved via\n        `PKCS12.get_friendlyname` and `PKCS12_set_friendlyname`, and a\n        `PKCS12` with a friendly name set can be dumped with `PKCS12.export`.\n        \"\"\"\n        passwd = b'Dogmeat[]{}!@#$%^&*()~`?/.,<>-_+=\";:'\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n        for friendly_name in [b'Serverlicious', None, b'###']:\n            p12.set_friendlyname(friendly_name)\n            assert p12.get_friendlyname() == friendly_name\n            dumped_p12 = p12.export(passphrase=passwd, iter=2, maciter=3)\n            reloaded_p12 = load_pkcs12(dumped_p12, passwd)\n            assert p12.get_friendlyname() == reloaded_p12.get_friendlyname()\n            # We would use the openssl program to confirm the friendly\n            # name, but it is not possible.  The pkcs12 command\n            # does not store the friendly name in the cert's\n            # alias, which we could then extract.\n            self.check_recovery(\n                dumped_p12, key=server_key_pem, cert=server_cert_pem,\n                ca=root_cert_pem, passwd=passwd)\n\n    def test_various_empty_passphrases(self):\n        \"\"\"\n        Test that missing, None, and '' passphrases are identical for PKCS12\n        export.\n        \"\"\"\n        p12 = self.gen_pkcs12(client_cert_pem, client_key_pem, root_cert_pem)\n        passwd = b\"\"\n        dumped_p12_empty = p12.export(iter=2, maciter=0, passphrase=passwd)\n        dumped_p12_none = p12.export(iter=3, maciter=2, passphrase=None)\n        dumped_p12_nopw = p12.export(iter=9, maciter=4)\n        for dumped_p12 in [dumped_p12_empty, dumped_p12_none, dumped_p12_nopw]:\n            self.check_recovery(\n                dumped_p12, key=client_key_pem, cert=client_cert_pem,\n                ca=root_cert_pem, passwd=passwd)\n\n    def test_removing_ca_cert(self):\n        \"\"\"\n        Passing `None` to `PKCS12.set_ca_certificates` removes all CA\n        certificates.\n        \"\"\"\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n        p12.set_ca_certificates(None)\n        assert None is p12.get_ca_certificates()\n\n    def test_export_without_mac(self):\n        \"\"\"\n        Exporting a PKCS12 with a `maciter` of `-1` excludes the MAC entirely.\n        \"\"\"\n        passwd = b\"Lake Michigan\"\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n        dumped_p12 = p12.export(maciter=-1, passphrase=passwd, iter=2)\n        self.check_recovery(\n            dumped_p12, key=server_key_pem, cert=server_cert_pem,\n            passwd=passwd, extra=(b\"-nomacver\",))\n\n    def test_load_without_mac(self):\n        \"\"\"\n        Loading a PKCS12 without a MAC does something other than crash.\n        \"\"\"\n        passwd = b\"Lake Michigan\"\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n        dumped_p12 = p12.export(maciter=-1, passphrase=passwd, iter=2)\n        try:\n            recovered_p12 = load_pkcs12(dumped_p12, passwd)\n            # The person who generated this PCKS12 should be flogged,\n            # or better yet we should have a means to determine\n            # whether a PCKS12 had a MAC that was verified.\n            # Anyway, libopenssl chooses to allow it, so the\n            # pyopenssl binding does as well.\n            assert isinstance(recovered_p12, PKCS12)\n        except Error:\n            # Failing here with an exception is preferred as some openssl\n            # versions do.\n            pass\n\n    def test_zero_len_list_for_ca(self):\n        \"\"\"\n        A PKCS12 with an empty CA certificates list can be exported.\n        \"\"\"\n        passwd = b'Hobie 18'\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem)\n        p12.set_ca_certificates([])\n        assert () == p12.get_ca_certificates()\n        dumped_p12 = p12.export(passphrase=passwd, iter=3)\n        self.check_recovery(\n            dumped_p12, key=server_key_pem, cert=server_cert_pem,\n            passwd=passwd)\n\n    def test_export_without_args(self):\n        \"\"\"\n        All the arguments to `PKCS12.export` are optional.\n        \"\"\"\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n        dumped_p12 = p12.export()  # no args\n        self.check_recovery(\n            dumped_p12, key=server_key_pem, cert=server_cert_pem, passwd=b\"\")\n\n    def test_export_without_bytes(self):\n        \"\"\"\n        Test `PKCS12.export` with text not bytes as passphrase\n        \"\"\"\n        p12 = self.gen_pkcs12(server_cert_pem, server_key_pem, root_cert_pem)\n\n        with pytest.warns(DeprecationWarning) as w:\n            simplefilter(\"always\")\n            dumped_p12 = p12.export(passphrase=b\"randomtext\".decode(\"ascii\"))\n            assert (\n                \"{0} for passphrase is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n        self.check_recovery(\n            dumped_p12,\n            key=server_key_pem,\n            cert=server_cert_pem,\n            passwd=b\"randomtext\"\n        )\n\n    def test_key_cert_mismatch(self):\n        \"\"\"\n        `PKCS12.export` raises an exception when a key and certificate\n        mismatch.\n        \"\"\"\n        p12 = self.gen_pkcs12(server_cert_pem, client_key_pem, root_cert_pem)\n        with pytest.raises(Error):\n            p12.export()\n\n\ndef _runopenssl(pem, *args):\n    \"\"\"\n    Run the command line openssl tool with the given arguments and write\n    the given PEM to its stdin.  Not safe for quotes.\n    \"\"\"\n    proc = Popen([b\"openssl\"] + list(args), stdin=PIPE, stdout=PIPE)\n    proc.stdin.write(pem)\n    proc.stdin.close()\n    output = proc.stdout.read()\n    proc.stdout.close()\n    proc.wait()\n    return output\n\n\nclass TestLoadPublicKey(object):\n    \"\"\"\n    Tests for :func:`load_publickey`.\n    \"\"\"\n    def test_loading_works(self):\n        \"\"\"\n        load_publickey loads public keys and sets correct attributes.\n        \"\"\"\n        key = load_publickey(FILETYPE_PEM, cleartextPublicKeyPEM)\n\n        assert True is key._only_public\n        assert 2048 == key.bits()\n        assert TYPE_RSA == key.type()\n\n    def test_invalid_type(self):\n        \"\"\"\n        load_publickey doesn't support FILETYPE_TEXT.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_publickey(FILETYPE_TEXT, cleartextPublicKeyPEM)\n\n    def test_invalid_key_format(self):\n        \"\"\"\n        load_publickey explodes on incorrect keys.\n        \"\"\"\n        with pytest.raises(Error):\n            load_publickey(FILETYPE_ASN1, cleartextPublicKeyPEM)\n\n    def test_tolerates_unicode_strings(self):\n        \"\"\"\n        load_publickey works with text strings, not just bytes.\n        \"\"\"\n        serialized = cleartextPublicKeyPEM.decode('ascii')\n        key = load_publickey(FILETYPE_PEM, serialized)\n        dumped_pem = dump_publickey(FILETYPE_PEM, key)\n\n        assert dumped_pem == cleartextPublicKeyPEM\n\n\nclass TestFunction(object):\n    \"\"\"\n    Tests for free-functions in the `OpenSSL.crypto` module.\n    \"\"\"\n\n    def test_load_privatekey_invalid_format(self):\n        \"\"\"\n        `load_privatekey` raises `ValueError` if passed an unknown filetype.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_privatekey(100, root_key_pem)\n\n    def test_load_privatekey_invalid_passphrase_type(self):\n        \"\"\"\n        `load_privatekey` raises `TypeError` if passed a passphrase that is\n        neither a `str` nor a callable.\n        \"\"\"\n        with pytest.raises(TypeError):\n            load_privatekey(\n                FILETYPE_PEM, encryptedPrivateKeyPEMPassphrase, object())\n\n    def test_load_privatekey_wrongPassphrase(self):\n        \"\"\"\n        `load_privatekey` raises `OpenSSL.crypto.Error` when it is passed an\n        encrypted PEM and an incorrect passphrase.\n        \"\"\"\n        with pytest.raises(Error) as err:\n            load_privatekey(FILETYPE_PEM, encryptedPrivateKeyPEM, b\"quack\")\n        assert err.value.args[0] != []\n\n    def test_load_privatekey_passphraseWrongType(self):\n        \"\"\"\n        `load_privatekey` raises `ValueError` when it is passeda passphrase\n        with a private key encoded in a format, that doesn't support\n        encryption.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        blob = dump_privatekey(FILETYPE_ASN1, key)\n        with pytest.raises(ValueError):\n            load_privatekey(FILETYPE_ASN1, blob, \"secret\")\n\n    def test_load_privatekey_passphrase(self):\n        \"\"\"\n        `load_privatekey` can create a `PKey` object from an encrypted PEM\n        string if given the passphrase.\n        \"\"\"\n        key = load_privatekey(\n            FILETYPE_PEM, encryptedPrivateKeyPEM,\n            encryptedPrivateKeyPEMPassphrase)\n        assert isinstance(key, PKey)\n\n    def test_load_privatekey_passphrase_exception(self):\n        \"\"\"\n        If the passphrase callback raises an exception, that exception is\n        raised by `load_privatekey`.\n        \"\"\"\n        def cb(ignored):\n            raise ArithmeticError\n\n        with pytest.raises(ArithmeticError):\n            load_privatekey(FILETYPE_PEM, encryptedPrivateKeyPEM, cb)\n\n    def test_load_privatekey_wrongPassphraseCallback(self):\n        \"\"\"\n        `load_privatekey` raises `OpenSSL.crypto.Error` when it\n        is passed an encrypted PEM and a passphrase callback which returns an\n        incorrect passphrase.\n        \"\"\"\n        called = []\n\n        def cb(*a):\n            called.append(None)\n            return b\"quack\"\n        with pytest.raises(Error) as err:\n            load_privatekey(FILETYPE_PEM, encryptedPrivateKeyPEM, cb)\n        assert called\n        assert err.value.args[0] != []\n\n    def test_load_privatekey_passphraseCallback(self):\n        \"\"\"\n        `load_privatekey` can create a `PKey` object from an encrypted PEM\n        string if given a passphrase callback which returns the correct\n        password.\n        \"\"\"\n        called = []\n\n        def cb(writing):\n            called.append(writing)\n            return encryptedPrivateKeyPEMPassphrase\n        key = load_privatekey(FILETYPE_PEM, encryptedPrivateKeyPEM, cb)\n        assert isinstance(key, PKey)\n        assert called == [False]\n\n    def test_load_privatekey_passphrase_wrong_return_type(self):\n        \"\"\"\n        `load_privatekey` raises `ValueError` if the passphrase callback\n        returns something other than a byte string.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_privatekey(\n                FILETYPE_PEM, encryptedPrivateKeyPEM, lambda *args: 3)\n\n    def test_dump_privatekey_wrong_args(self):\n        \"\"\"\n        `dump_privatekey` raises `TypeError` if called with a `cipher`\n        argument but no `passphrase` argument.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        with pytest.raises(TypeError):\n            dump_privatekey(FILETYPE_PEM, key, cipher=GOOD_CIPHER)\n\n    def test_dump_privatekey_not_rsa_key(self):\n        \"\"\"\n        `dump_privatekey` raises `TypeError` if called with a key that is\n        not RSA.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_DSA, 512)\n        with pytest.raises(TypeError):\n            dump_privatekey(FILETYPE_TEXT, key)\n\n    def test_dump_privatekey_invalid_pkey(self):\n        with pytest.raises(TypeError):\n            dump_privatekey(FILETYPE_TEXT, object())\n\n    def test_dump_privatekey_unknown_cipher(self):\n        \"\"\"\n        `dump_privatekey` raises `ValueError` if called with an unrecognized\n        cipher name.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        with pytest.raises(ValueError):\n            dump_privatekey(FILETYPE_PEM, key, BAD_CIPHER, \"passphrase\")\n\n    def test_dump_privatekey_invalid_passphrase_type(self):\n        \"\"\"\n        `dump_privatekey` raises `TypeError` if called with a passphrase which\n        is neither a `str` nor a callable.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        with pytest.raises(TypeError):\n            dump_privatekey(FILETYPE_PEM, key, GOOD_CIPHER, object())\n\n    def test_dump_privatekey_invalid_filetype(self):\n        \"\"\"\n        `dump_privatekey` raises `ValueError` if called with an unrecognized\n        filetype.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        with pytest.raises(ValueError):\n            dump_privatekey(100, key)\n\n    def test_load_privatekey_passphrase_callback_length(self):\n        \"\"\"\n        `crypto.load_privatekey` should raise an error when the passphrase\n        provided by the callback is too long, not silently truncate it.\n        \"\"\"\n        def cb(ignored):\n            return \"a\" * 1025\n\n        with pytest.raises(ValueError):\n            load_privatekey(FILETYPE_PEM, encryptedPrivateKeyPEM, cb)\n\n    def test_dump_privatekey_passphrase(self):\n        \"\"\"\n        `dump_privatekey` writes an encrypted PEM when given a passphrase.\n        \"\"\"\n        passphrase = b\"foo\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        pem = dump_privatekey(FILETYPE_PEM, key, GOOD_CIPHER, passphrase)\n        assert isinstance(pem, binary_type)\n        loadedKey = load_privatekey(FILETYPE_PEM, pem, passphrase)\n        assert isinstance(loadedKey, PKey)\n        assert loadedKey.type() == key.type()\n        assert loadedKey.bits() == key.bits()\n\n    def test_dump_privatekey_passphrase_wrong_type(self):\n        \"\"\"\n        `dump_privatekey` raises `ValueError` when it is passed a passphrase\n        with a private key encoded in a format, that doesn't support\n        encryption.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        with pytest.raises(ValueError):\n            dump_privatekey(FILETYPE_ASN1, key, GOOD_CIPHER, \"secret\")\n\n    def test_dump_certificate(self):\n        \"\"\"\n        `dump_certificate` writes PEM, DER, and text.\n        \"\"\"\n        pemData = cleartextCertificatePEM + cleartextPrivateKeyPEM\n        cert = load_certificate(FILETYPE_PEM, pemData)\n        dumped_pem = dump_certificate(FILETYPE_PEM, cert)\n        assert dumped_pem == cleartextCertificatePEM\n        dumped_der = dump_certificate(FILETYPE_ASN1, cert)\n        good_der = _runopenssl(dumped_pem, b\"x509\", b\"-outform\", b\"DER\")\n        assert dumped_der == good_der\n        cert2 = load_certificate(FILETYPE_ASN1, dumped_der)\n        dumped_pem2 = dump_certificate(FILETYPE_PEM, cert2)\n        assert dumped_pem2 == cleartextCertificatePEM\n        dumped_text = dump_certificate(FILETYPE_TEXT, cert)\n        good_text = _runopenssl(\n            dumped_pem, b\"x509\", b\"-noout\", b\"-text\", b\"-nameopt\", b\"\")\n        assert dumped_text == good_text\n\n    def test_dump_certificate_bad_type(self):\n        \"\"\"\n        `dump_certificate` raises a `ValueError` if it's called with\n        a bad type.\n        \"\"\"\n        cert = load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n        with pytest.raises(ValueError):\n            dump_certificate(object(), cert)\n\n    def test_dump_privatekey_pem(self):\n        \"\"\"\n        `dump_privatekey` writes a PEM\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        assert key.check()\n        dumped_pem = dump_privatekey(FILETYPE_PEM, key)\n        assert dumped_pem == cleartextPrivateKeyPEM\n\n    def test_dump_privatekey_asn1(self):\n        \"\"\"\n        `dump_privatekey` writes a DER\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        dumped_pem = dump_privatekey(FILETYPE_PEM, key)\n\n        dumped_der = dump_privatekey(FILETYPE_ASN1, key)\n        # XXX This OpenSSL call writes \"writing RSA key\" to standard out.  Sad.\n        good_der = _runopenssl(dumped_pem, b\"rsa\", b\"-outform\", b\"DER\")\n        assert dumped_der == good_der\n        key2 = load_privatekey(FILETYPE_ASN1, dumped_der)\n        dumped_pem2 = dump_privatekey(FILETYPE_PEM, key2)\n        assert dumped_pem2 == cleartextPrivateKeyPEM\n\n    def test_dump_privatekey_text(self):\n        \"\"\"\n        `dump_privatekey` writes a text\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        dumped_pem = dump_privatekey(FILETYPE_PEM, key)\n\n        dumped_text = dump_privatekey(FILETYPE_TEXT, key)\n        good_text = _runopenssl(dumped_pem, b\"rsa\", b\"-noout\", b\"-text\")\n        assert dumped_text == good_text\n\n    def test_dump_publickey_pem(self):\n        \"\"\"\n        dump_publickey writes a PEM.\n        \"\"\"\n        key = load_publickey(FILETYPE_PEM, cleartextPublicKeyPEM)\n        dumped_pem = dump_publickey(FILETYPE_PEM, key)\n        assert dumped_pem == cleartextPublicKeyPEM\n\n    def test_dump_publickey_asn1(self):\n        \"\"\"\n        dump_publickey writes a DER.\n        \"\"\"\n        key = load_publickey(FILETYPE_PEM, cleartextPublicKeyPEM)\n        dumped_der = dump_publickey(FILETYPE_ASN1, key)\n        key2 = load_publickey(FILETYPE_ASN1, dumped_der)\n        dumped_pem2 = dump_publickey(FILETYPE_PEM, key2)\n        assert dumped_pem2 == cleartextPublicKeyPEM\n\n    def test_dump_publickey_invalid_type(self):\n        \"\"\"\n        dump_publickey doesn't support FILETYPE_TEXT.\n        \"\"\"\n        key = load_publickey(FILETYPE_PEM, cleartextPublicKeyPEM)\n\n        with pytest.raises(ValueError):\n            dump_publickey(FILETYPE_TEXT, key)\n\n    def test_dump_certificate_request(self):\n        \"\"\"\n        `dump_certificate_request` writes a PEM, DER, and text.\n        \"\"\"\n        req = load_certificate_request(\n            FILETYPE_PEM, cleartextCertificateRequestPEM)\n        dumped_pem = dump_certificate_request(FILETYPE_PEM, req)\n        assert dumped_pem == cleartextCertificateRequestPEM\n        dumped_der = dump_certificate_request(FILETYPE_ASN1, req)\n        good_der = _runopenssl(dumped_pem, b\"req\", b\"-outform\", b\"DER\")\n        assert dumped_der == good_der\n        req2 = load_certificate_request(FILETYPE_ASN1, dumped_der)\n        dumped_pem2 = dump_certificate_request(FILETYPE_PEM, req2)\n        assert dumped_pem2 == cleartextCertificateRequestPEM\n        dumped_text = dump_certificate_request(FILETYPE_TEXT, req)\n        good_text = _runopenssl(\n            dumped_pem, b\"req\", b\"-noout\", b\"-text\", b\"-nameopt\", b\"\")\n        assert dumped_text == good_text\n        with pytest.raises(ValueError):\n            dump_certificate_request(100, req)\n\n    def test_dump_privatekey_passphrase_callback(self):\n        \"\"\"\n        `dump_privatekey` writes an encrypted PEM when given a callback\n        which returns the correct passphrase.\n        \"\"\"\n        passphrase = b\"foo\"\n        called = []\n\n        def cb(writing):\n            called.append(writing)\n            return passphrase\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        pem = dump_privatekey(FILETYPE_PEM, key, GOOD_CIPHER, cb)\n        assert isinstance(pem, binary_type)\n        assert called == [True]\n        loadedKey = load_privatekey(FILETYPE_PEM, pem, passphrase)\n        assert isinstance(loadedKey, PKey)\n        assert loadedKey.type() == key.type()\n        assert loadedKey.bits() == key.bits()\n\n    def test_dump_privatekey_passphrase_exception(self):\n        \"\"\"\n        `dump_privatekey` should not overwrite the exception raised\n        by the passphrase callback.\n        \"\"\"\n        def cb(ignored):\n            raise ArithmeticError\n\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        with pytest.raises(ArithmeticError):\n            dump_privatekey(FILETYPE_PEM, key, GOOD_CIPHER, cb)\n\n    def test_dump_privatekey_passphraseCallbackLength(self):\n        \"\"\"\n        `crypto.dump_privatekey` should raise an error when the passphrase\n        provided by the callback is too long, not silently truncate it.\n        \"\"\"\n        def cb(ignored):\n            return \"a\" * 1025\n\n        key = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n        with pytest.raises(ValueError):\n            dump_privatekey(FILETYPE_PEM, key, GOOD_CIPHER, cb)\n\n    def test_load_pkcs7_data_pem(self):\n        \"\"\"\n        `load_pkcs7_data` accepts a PKCS#7 string and returns an instance of\n        `PKCS`.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert isinstance(pkcs7, PKCS7)\n\n    def test_load_pkcs7_data_asn1(self):\n        \"\"\"\n        `load_pkcs7_data` accepts a bytes containing ASN1 data representing\n        PKCS#7 and returns an instance of `PKCS7`.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_ASN1, pkcs7DataASN1)\n        assert isinstance(pkcs7, PKCS7)\n\n    def test_load_pkcs7_data_invalid(self):\n        \"\"\"\n        If the data passed to `load_pkcs7_data` is invalid, `Error` is raised.\n        \"\"\"\n        with pytest.raises(Error):\n            load_pkcs7_data(FILETYPE_PEM, b\"foo\")\n\n    def test_load_pkcs7_type_invalid(self):\n        \"\"\"\n        If the type passed to `load_pkcs7_data`, `ValueError` is raised.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_pkcs7_data(object(), b\"foo\")\n\n\nclass TestLoadCertificate(object):\n    \"\"\"\n    Tests for `load_certificate_request`.\n    \"\"\"\n\n    def test_bad_file_type(self):\n        \"\"\"\n        If the file type passed to `load_certificate_request` is neither\n        `FILETYPE_PEM` nor `FILETYPE_ASN1` then `ValueError` is raised.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_certificate_request(object(), b\"\")\n        with pytest.raises(ValueError):\n            load_certificate(object(), b\"\")\n\n    def test_bad_certificate(self):\n        \"\"\"\n        If the bytes passed to `load_certificate` are not a valid certificate,\n        an exception is raised.\n        \"\"\"\n        with pytest.raises(Error):\n            load_certificate(FILETYPE_ASN1, b\"lol\")\n\n\nclass TestPKCS7(object):\n    \"\"\"\n    Tests for `PKCS7`.\n    \"\"\"\n\n    def test_type_is_signed(self):\n        \"\"\"\n        `PKCS7.type_is_signed` returns `True` if the PKCS7 object is of\n        the type *signed*.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert pkcs7.type_is_signed()\n\n    def test_type_is_enveloped(self):\n        \"\"\"\n        `PKCS7.type_is_enveloped` returns `False` if the PKCS7 object is not\n        of the type *enveloped*.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert not pkcs7.type_is_enveloped()\n\n    def test_type_is_signed_and_enveloped(self):\n        \"\"\"\n        `PKCS7.type_is_signedAndEnveloped` returns `False`\n        if the PKCS7 object is not of the type *signed and enveloped*.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert not pkcs7.type_is_signedAndEnveloped()\n\n    def test_type_is_data(self):\n        \"\"\"\n        `PKCS7.type_is_data` returns `False` if the PKCS7 object is not of\n        the type data.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert not pkcs7.type_is_data()\n\n    def test_get_type_name(self):\n        \"\"\"\n        `PKCS7.get_type_name` returns a `str` giving the\n        type name.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        assert pkcs7.get_type_name() == b'pkcs7-signedData'\n\n    def test_attribute(self):\n        \"\"\"\n        If an attribute other than one of the methods tested here is accessed\n        on an instance of `PKCS7`, `AttributeError` is raised.\n        \"\"\"\n        pkcs7 = load_pkcs7_data(FILETYPE_PEM, pkcs7Data)\n        with pytest.raises(AttributeError):\n            pkcs7.foo\n\n\nclass TestNetscapeSPKI(_PKeyInteractionTestsMixin):\n    \"\"\"\n    Tests for `OpenSSL.crypto.NetscapeSPKI`.\n    \"\"\"\n\n    def signable(self):\n        \"\"\"\n        Return a new `NetscapeSPKI` for use with signing tests.\n        \"\"\"\n        return NetscapeSPKI()\n\n    def test_type(self):\n        \"\"\"\n        `NetscapeSPKI` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(NetscapeSPKI, 'NetscapeSPKI')\n\n    def test_construction(self):\n        \"\"\"\n        `NetscapeSPKI` returns an instance of `NetscapeSPKI`.\n        \"\"\"\n        nspki = NetscapeSPKI()\n        assert isinstance(nspki, NetscapeSPKI)\n\n    def test_invalid_attribute(self):\n        \"\"\"\n        Accessing a non-existent attribute of a `NetscapeSPKI` instance\n        causes an `AttributeError` to be raised.\n        \"\"\"\n        nspki = NetscapeSPKI()\n        with pytest.raises(AttributeError):\n            nspki.foo\n\n    def test_b64_encode(self):\n        \"\"\"\n        `NetscapeSPKI.b64_encode` encodes the certificate to a base64 blob.\n        \"\"\"\n        nspki = NetscapeSPKI()\n        blob = nspki.b64_encode()\n        assert isinstance(blob, binary_type)\n\n\nclass TestRevoked(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.Revoked`.\n    \"\"\"\n    def test_ignores_unsupported_revoked_cert_extension_get_reason(self):\n        \"\"\"\n        The get_reason method on the Revoked class checks to see if the\n        extension is NID_crl_reason and should skip it otherwise. This test\n        loads a CRL with extensions it should ignore.\n        \"\"\"\n        crl = load_crl(FILETYPE_PEM, crlDataUnsupportedExtension)\n        revoked = crl.get_revoked()\n        reason = revoked[1].get_reason()\n        assert reason == b'Unspecified'\n\n    def test_ignores_unsupported_revoked_cert_extension_set_new_reason(self):\n        crl = load_crl(FILETYPE_PEM, crlDataUnsupportedExtension)\n        revoked = crl.get_revoked()\n        revoked[1].set_reason(None)\n        reason = revoked[1].get_reason()\n        assert reason is None\n\n    def test_construction(self):\n        \"\"\"\n        Confirm we can create `OpenSSL.crypto.Revoked`.  Check that it is\n        empty.\n        \"\"\"\n        revoked = Revoked()\n        assert isinstance(revoked, Revoked)\n        assert type(revoked) == Revoked\n        assert revoked.get_serial() == b'00'\n        assert revoked.get_rev_date() is None\n        assert revoked.get_reason() is None\n\n    def test_serial(self):\n        \"\"\"\n        Confirm we can set and get serial numbers from\n        `OpenSSL.crypto.Revoked`.  Confirm errors are handled with grace.\n        \"\"\"\n        revoked = Revoked()\n        ret = revoked.set_serial(b'10b')\n        assert ret is None\n        ser = revoked.get_serial()\n        assert ser == b'010B'\n\n        revoked.set_serial(b'31ppp')  # a type error would be nice\n        ser = revoked.get_serial()\n        assert ser == b'31'\n\n        with pytest.raises(ValueError):\n            revoked.set_serial(b'pqrst')\n        with pytest.raises(TypeError):\n            revoked.set_serial(100)\n\n    def test_date(self):\n        \"\"\"\n        Confirm we can set and get revocation dates from\n        `OpenSSL.crypto.Revoked`.  Confirm errors are handled with grace.\n        \"\"\"\n        revoked = Revoked()\n        date = revoked.get_rev_date()\n        assert date is None\n\n        now = datetime.now().strftime(\"%Y%m%d%H%M%SZ\").encode(\"ascii\")\n        ret = revoked.set_rev_date(now)\n        assert ret is None\n        date = revoked.get_rev_date()\n        assert date == now\n\n    def test_reason(self):\n        \"\"\"\n        Confirm we can set and get revocation reasons from\n        `OpenSSL.crypto.Revoked`.  The \"get\" need to work as \"set\".\n        Likewise, each reason of all_reasons() must work.\n        \"\"\"\n        revoked = Revoked()\n        for r in revoked.all_reasons():\n            for x in range(2):\n                ret = revoked.set_reason(r)\n                assert ret is None\n                reason = revoked.get_reason()\n                assert (\n                    reason.lower().replace(b' ', b'') ==\n                    r.lower().replace(b' ', b''))\n                r = reason  # again with the resp of get\n\n        revoked.set_reason(None)\n        assert revoked.get_reason() is None\n\n    @pytest.mark.parametrize('reason', [object(), 1.0, u'foo'])\n    def test_set_reason_wrong_args(self, reason):\n        \"\"\"\n        `Revoked.set_reason` raises `TypeError` if called with an argument\n        which is neither `None` nor a byte string.\n        \"\"\"\n        revoked = Revoked()\n        with pytest.raises(TypeError):\n            revoked.set_reason(reason)\n\n    def test_set_reason_invalid_reason(self):\n        \"\"\"\n        Calling `OpenSSL.crypto.Revoked.set_reason` with an argument which\n        isn't a valid reason results in `ValueError` being raised.\n        \"\"\"\n        revoked = Revoked()\n        with pytest.raises(ValueError):\n            revoked.set_reason(b'blue')\n\n\nclass TestCRL(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.CRL`.\n    \"\"\"\n    cert = load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n    pkey = load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM)\n\n    root_cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n    root_key = load_privatekey(FILETYPE_PEM, root_key_pem)\n    intermediate_cert = load_certificate(FILETYPE_PEM, intermediate_cert_pem)\n    intermediate_key = load_privatekey(FILETYPE_PEM, intermediate_key_pem)\n    intermediate_server_cert = load_certificate(\n        FILETYPE_PEM, intermediate_server_cert_pem)\n    intermediate_server_key = load_privatekey(\n        FILETYPE_PEM, intermediate_server_key_pem)\n\n    def test_construction(self):\n        \"\"\"\n        Confirm we can create `OpenSSL.crypto.CRL`.  Check\n        that it is empty\n        \"\"\"\n        crl = CRL()\n        assert isinstance(crl, CRL)\n        assert crl.get_revoked() is None\n\n    def _get_crl(self):\n        \"\"\"\n        Get a new ``CRL`` with a revocation.\n        \"\"\"\n        crl = CRL()\n        revoked = Revoked()\n        now = datetime.now().strftime(\"%Y%m%d%H%M%SZ\").encode(\"ascii\")\n        revoked.set_rev_date(now)\n        revoked.set_serial(b'3ab')\n        revoked.set_reason(b'sUpErSeDEd')\n        crl.add_revoked(revoked)\n        return crl\n\n    def test_export_pem(self):\n        \"\"\"\n        If not passed a format, ``CRL.export`` returns a \"PEM\" format string\n        representing a serial number, a revoked reason, and certificate issuer\n        information.\n        \"\"\"\n        # PEM format\n        dumped_crl = self._get_crl().export(\n            self.cert, self.pkey, days=20, digest=b\"sha256\"\n        )\n        crl = x509.load_pem_x509_crl(dumped_crl, backend)\n        revoked = crl.get_revoked_certificate_by_serial_number(0x03AB)\n        assert revoked is not None\n        assert crl.issuer == x509.Name([\n            x509.NameAttribute(x509.NameOID.COUNTRY_NAME, u\"US\"),\n            x509.NameAttribute(x509.NameOID.STATE_OR_PROVINCE_NAME, u\"IL\"),\n            x509.NameAttribute(x509.NameOID.LOCALITY_NAME, u\"Chicago\"),\n            x509.NameAttribute(x509.NameOID.ORGANIZATION_NAME, u\"Testing\"),\n            x509.NameAttribute(x509.NameOID.COMMON_NAME, u\"Testing Root CA\"),\n        ])\n\n    def test_export_der(self):\n        \"\"\"\n        If passed ``FILETYPE_ASN1`` for the format, ``CRL.export`` returns a\n        \"DER\" format string representing a serial number, a revoked reason, and\n        certificate issuer information.\n        \"\"\"\n        crl = self._get_crl()\n\n        # DER format\n        dumped_crl = self._get_crl().export(\n            self.cert, self.pkey, FILETYPE_ASN1, digest=b\"md5\"\n        )\n        crl = x509.load_der_x509_crl(dumped_crl, backend)\n        revoked = crl.get_revoked_certificate_by_serial_number(0x03AB)\n        assert revoked is not None\n        assert crl.issuer == x509.Name([\n            x509.NameAttribute(x509.NameOID.COUNTRY_NAME, u\"US\"),\n            x509.NameAttribute(x509.NameOID.STATE_OR_PROVINCE_NAME, u\"IL\"),\n            x509.NameAttribute(x509.NameOID.LOCALITY_NAME, u\"Chicago\"),\n            x509.NameAttribute(x509.NameOID.ORGANIZATION_NAME, u\"Testing\"),\n            x509.NameAttribute(x509.NameOID.COMMON_NAME, u\"Testing Root CA\"),\n        ])\n\n    # Flaky because we compare the output of running commands which sometimes\n    # varies by 1 second\n    @flaky.flaky\n    def test_export_text(self):\n        \"\"\"\n        If passed ``FILETYPE_TEXT`` for the format, ``CRL.export`` returns a\n        text format string like the one produced by the openssl command line\n        tool.\n        \"\"\"\n        crl = self._get_crl()\n\n        dumped_crl = crl.export(\n            self.cert, self.pkey, FILETYPE_ASN1, digest=b\"md5\"\n        )\n        text = _runopenssl(\n            dumped_crl, b\"crl\", b\"-noout\", b\"-text\", b\"-inform\", b\"DER\",\n            b\"-nameopt\", b\"\"\n        )\n\n        # text format\n        dumped_text = crl.export(\n            self.cert, self.pkey, type=FILETYPE_TEXT, digest=b\"md5\"\n        )\n        assert text == dumped_text\n\n    def test_export_custom_digest(self):\n        \"\"\"\n        If passed the name of a digest function, ``CRL.export`` uses a\n        signature algorithm based on that digest function.\n        \"\"\"\n        crl = self._get_crl()\n        dumped_crl = crl.export(self.cert, self.pkey, digest=b\"sha1\")\n        text = _runopenssl(dumped_crl, b\"crl\", b\"-noout\", b\"-text\")\n        text.index(b'Signature Algorithm: sha1')\n\n    def test_export_md5_digest(self):\n        \"\"\"\n        If passed md5 as the digest function, ``CRL.export`` uses md5 and does\n        not emit a deprecation warning.\n        \"\"\"\n        crl = self._get_crl()\n        with pytest.warns(None) as catcher:\n            simplefilter(\"always\")\n        assert 0 == len(catcher)\n        dumped_crl = crl.export(self.cert, self.pkey, digest=b\"md5\")\n        text = _runopenssl(dumped_crl, b\"crl\", b\"-noout\", b\"-text\")\n        text.index(b'Signature Algorithm: md5')\n\n    def test_export_default_digest(self):\n        \"\"\"\n        If not passed the name of a digest function, ``CRL.export`` raises a\n        ``TypeError``.\n        \"\"\"\n        crl = self._get_crl()\n        with pytest.raises(TypeError):\n            crl.export(self.cert, self.pkey)\n\n    def test_export_invalid(self):\n        \"\"\"\n        If `CRL.export` is used with an uninitialized `X509` instance,\n        `OpenSSL.crypto.Error` is raised.\n        \"\"\"\n        crl = CRL()\n        with pytest.raises(Error):\n            crl.export(X509(), PKey(), digest=b\"sha256\")\n\n    def test_add_revoked_keyword(self):\n        \"\"\"\n        `OpenSSL.CRL.add_revoked` accepts its single argument as the\n        ``revoked`` keyword argument.\n        \"\"\"\n        crl = CRL()\n        revoked = Revoked()\n        revoked.set_serial(b\"01\")\n        revoked.set_rev_date(b\"20160310020145Z\")\n        crl.add_revoked(revoked=revoked)\n        assert isinstance(crl.get_revoked()[0], Revoked)\n\n    def test_export_wrong_args(self):\n        \"\"\"\n        Calling `OpenSSL.CRL.export` with arguments other than the certificate,\n        private key, integer file type, and integer number of days it\n        expects, results in a `TypeError` being raised.\n        \"\"\"\n        crl = CRL()\n        with pytest.raises(TypeError):\n            crl.export(None, self.pkey, FILETYPE_PEM, 10)\n        with pytest.raises(TypeError):\n            crl.export(self.cert, None, FILETYPE_PEM, 10)\n        with pytest.raises(TypeError):\n            crl.export(self.cert, self.pkey, None, 10)\n        with pytest.raises(TypeError):\n            crl.export(self.cert, FILETYPE_PEM, None)\n\n    def test_export_unknown_filetype(self):\n        \"\"\"\n        Calling `OpenSSL.CRL.export` with a file type other than\n        `FILETYPE_PEM`, `FILETYPE_ASN1`, or\n        `FILETYPE_TEXT` results in a `ValueError` being raised.\n        \"\"\"\n        crl = CRL()\n        with pytest.raises(ValueError):\n            crl.export(self.cert, self.pkey, 100, 10, digest=b\"sha256\")\n\n    def test_export_unknown_digest(self):\n        \"\"\"\n        Calling `OpenSSL.CRL.export` with an unsupported digest results\n        in a `ValueError` being raised.\n        \"\"\"\n        crl = CRL()\n        with pytest.raises(ValueError):\n            crl.export(\n                self.cert, self.pkey, FILETYPE_PEM, 10, b\"strange-digest\")\n\n    def test_get_revoked(self):\n        \"\"\"\n        Use python to create a simple CRL with two revocations. Get back the\n        `Revoked` using `OpenSSL.CRL.get_revoked` and verify them.\n        \"\"\"\n        crl = CRL()\n\n        revoked = Revoked()\n        now = datetime.now().strftime(\"%Y%m%d%H%M%SZ\").encode(\"ascii\")\n        revoked.set_rev_date(now)\n        revoked.set_serial(b'3ab')\n        crl.add_revoked(revoked)\n        revoked.set_serial(b'100')\n        revoked.set_reason(b'sUpErSeDEd')\n        crl.add_revoked(revoked)\n\n        revs = crl.get_revoked()\n        assert len(revs) == 2\n        assert type(revs[0]) == Revoked\n        assert type(revs[1]) == Revoked\n        assert revs[0].get_serial() == b'03AB'\n        assert revs[1].get_serial() == b'0100'\n        assert revs[0].get_rev_date() == now\n        assert revs[1].get_rev_date() == now\n\n    def test_load_crl(self):\n        \"\"\"\n        Load a known CRL and inspect its revocations.  Both EM and DER formats\n        are loaded.\n        \"\"\"\n        crl = load_crl(FILETYPE_PEM, crlData)\n        revs = crl.get_revoked()\n        assert len(revs) == 2\n        assert revs[0].get_serial() == b'03AB'\n        assert revs[0].get_reason() is None\n        assert revs[1].get_serial() == b'0100'\n        assert revs[1].get_reason() == b'Superseded'\n\n        der = _runopenssl(crlData, b\"crl\", b\"-outform\", b\"DER\")\n        crl = load_crl(FILETYPE_ASN1, der)\n        revs = crl.get_revoked()\n        assert len(revs) == 2\n        assert revs[0].get_serial() == b'03AB'\n        assert revs[0].get_reason() is None\n        assert revs[1].get_serial() == b'0100'\n        assert revs[1].get_reason() == b'Superseded'\n\n    def test_load_crl_bad_filetype(self):\n        \"\"\"\n        Calling `OpenSSL.crypto.load_crl` with an unknown file type raises a\n        `ValueError`.\n        \"\"\"\n        with pytest.raises(ValueError):\n            load_crl(100, crlData)\n\n    def test_load_crl_bad_data(self):\n        \"\"\"\n        Calling `OpenSSL.crypto.load_crl` with file data which can't be loaded\n        raises a `OpenSSL.crypto.Error`.\n        \"\"\"\n        with pytest.raises(Error):\n            load_crl(FILETYPE_PEM, b\"hello, world\")\n\n    def test_get_issuer(self):\n        \"\"\"\n        Load a known CRL and assert its issuer's common name is what we expect\n        from the encoded crlData string.\n        \"\"\"\n        crl = load_crl(FILETYPE_PEM, crlData)\n        assert isinstance(crl.get_issuer(), X509Name)\n        assert crl.get_issuer().CN == 'Testing Root CA'\n\n    def test_dump_crl(self):\n        \"\"\"\n        The dumped CRL matches the original input.\n        \"\"\"\n        crl = load_crl(FILETYPE_PEM, crlData)\n        buf = dump_crl(FILETYPE_PEM, crl)\n        assert buf == crlData\n\n    def _make_test_crl(self, issuer_cert, issuer_key, certs=()):\n        \"\"\"\n        Create a CRL.\n\n        :param list[X509] certs: A list of certificates to revoke.\n        :rtype: CRL\n        \"\"\"\n        crl = CRL()\n        for cert in certs:\n            revoked = Revoked()\n            # FIXME: This string splicing is an unfortunate implementation\n            # detail that has been reported in\n            # https://github.com/pyca/pyopenssl/issues/258\n            serial = hex(cert.get_serial_number())[2:].encode('utf-8')\n            revoked.set_serial(serial)\n            revoked.set_reason(b'unspecified')\n            revoked.set_rev_date(b'20140601000000Z')\n            crl.add_revoked(revoked)\n        crl.set_version(1)\n        crl.set_lastUpdate(b'20140601000000Z')\n        crl.set_nextUpdate(b'20180601000000Z')\n        crl.sign(issuer_cert, issuer_key, digest=b'sha512')\n        return crl\n\n    def test_verify_with_revoked(self):\n        \"\"\"\n        `verify_certificate` raises error when an intermediate certificate is\n        revoked.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store.add_cert(self.intermediate_cert)\n        root_crl = self._make_test_crl(\n            self.root_cert, self.root_key, certs=[self.intermediate_cert])\n        intermediate_crl = self._make_test_crl(\n            self.intermediate_cert, self.intermediate_key, certs=[])\n        store.add_crl(root_crl)\n        store.add_crl(intermediate_crl)\n        store.set_flags(\n            X509StoreFlags.CRL_CHECK | X509StoreFlags.CRL_CHECK_ALL)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n        with pytest.raises(X509StoreContextError) as err:\n            store_ctx.verify_certificate()\n        assert err.value.args[0][2] == 'certificate revoked'\n\n    def test_verify_with_missing_crl(self):\n        \"\"\"\n        `verify_certificate` raises error when an intermediate certificate's\n        CRL is missing.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store.add_cert(self.intermediate_cert)\n        root_crl = self._make_test_crl(\n            self.root_cert, self.root_key, certs=[self.intermediate_cert])\n        store.add_crl(root_crl)\n        store.set_flags(\n            X509StoreFlags.CRL_CHECK | X509StoreFlags.CRL_CHECK_ALL)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n        with pytest.raises(X509StoreContextError) as err:\n            store_ctx.verify_certificate()\n        assert err.value.args[0][2] == 'unable to get certificate CRL'\n        assert err.value.certificate.get_subject().CN == 'intermediate-service'\n\n    def test_convert_from_cryptography(self):\n        crypto_crl = x509.load_pem_x509_crl(crlData, backend)\n        crl = CRL.from_cryptography(crypto_crl)\n        assert isinstance(crl, CRL)\n\n    def test_convert_from_cryptography_unsupported_type(self):\n        with pytest.raises(TypeError):\n            CRL.from_cryptography(object())\n\n    def test_convert_to_cryptography_key(self):\n        crl = load_crl(FILETYPE_PEM, crlData)\n        crypto_crl = crl.to_cryptography()\n        assert isinstance(crypto_crl, x509.CertificateRevocationList)\n\n\nclass TestX509StoreContext(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.X509StoreContext`.\n    \"\"\"\n    root_cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n    intermediate_cert = load_certificate(FILETYPE_PEM, intermediate_cert_pem)\n    intermediate_server_cert = load_certificate(\n        FILETYPE_PEM, intermediate_server_cert_pem)\n\n    def test_valid(self):\n        \"\"\"\n        `verify_certificate` returns ``None`` when called with a certificate\n        and valid chain.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store.add_cert(self.intermediate_cert)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n        assert store_ctx.verify_certificate() is None\n\n    def test_reuse(self):\n        \"\"\"\n        `verify_certificate` can be called multiple times with the same\n        ``X509StoreContext`` instance to produce the same result.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store.add_cert(self.intermediate_cert)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n        assert store_ctx.verify_certificate() is None\n        assert store_ctx.verify_certificate() is None\n\n    def test_trusted_self_signed(self):\n        \"\"\"\n        `verify_certificate` returns ``None`` when called with a self-signed\n        certificate and itself in the chain.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store_ctx = X509StoreContext(store, self.root_cert)\n        assert store_ctx.verify_certificate() is None\n\n    def test_untrusted_self_signed(self):\n        \"\"\"\n        `verify_certificate` raises error when a self-signed certificate is\n        verified without itself in the chain.\n        \"\"\"\n        store = X509Store()\n        store_ctx = X509StoreContext(store, self.root_cert)\n        with pytest.raises(X509StoreContextError) as exc:\n            store_ctx.verify_certificate()\n\n        assert exc.value.args[0][2] == 'self signed certificate'\n        assert exc.value.certificate.get_subject().CN == 'Testing Root CA'\n\n    def test_invalid_chain_no_root(self):\n        \"\"\"\n        `verify_certificate` raises error when a root certificate is missing\n        from the chain.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.intermediate_cert)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n\n        with pytest.raises(X509StoreContextError) as exc:\n            store_ctx.verify_certificate()\n\n        assert exc.value.args[0][2] == 'unable to get issuer certificate'\n        assert exc.value.certificate.get_subject().CN == 'intermediate'\n\n    def test_invalid_chain_no_intermediate(self):\n        \"\"\"\n        `verify_certificate` raises error when an intermediate certificate is\n        missing from the chain.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n\n        with pytest.raises(X509StoreContextError) as exc:\n            store_ctx.verify_certificate()\n\n        assert exc.value.args[0][2] == 'unable to get local issuer certificate'\n        assert exc.value.certificate.get_subject().CN == 'intermediate-service'\n\n    def test_modification_pre_verify(self):\n        \"\"\"\n        `verify_certificate` can use a store context modified after\n        instantiation.\n        \"\"\"\n        store_bad = X509Store()\n        store_bad.add_cert(self.intermediate_cert)\n        store_good = X509Store()\n        store_good.add_cert(self.root_cert)\n        store_good.add_cert(self.intermediate_cert)\n        store_ctx = X509StoreContext(store_bad, self.intermediate_server_cert)\n\n        with pytest.raises(X509StoreContextError) as exc:\n            store_ctx.verify_certificate()\n\n        assert exc.value.args[0][2] == 'unable to get issuer certificate'\n        assert exc.value.certificate.get_subject().CN == 'intermediate'\n\n        store_ctx.set_store(store_good)\n        assert store_ctx.verify_certificate() is None\n\n    def test_verify_with_time(self):\n        \"\"\"\n        `verify_certificate` raises error when the verification time is\n        set at notAfter.\n        \"\"\"\n        store = X509Store()\n        store.add_cert(self.root_cert)\n        store.add_cert(self.intermediate_cert)\n\n        expire_time = self.intermediate_server_cert.get_notAfter()\n        expire_datetime = datetime.strptime(\n            expire_time.decode('utf-8'), '%Y%m%d%H%M%SZ'\n        )\n        store.set_time(expire_datetime)\n\n        store_ctx = X509StoreContext(store, self.intermediate_server_cert)\n        with pytest.raises(X509StoreContextError) as exc:\n            store_ctx.verify_certificate()\n\n        assert exc.value.args[0][2] == 'certificate has expired'\n\n\nclass TestSignVerify(object):\n    \"\"\"\n    Tests for `OpenSSL.crypto.sign` and `OpenSSL.crypto.verify`.\n    \"\"\"\n\n    def test_sign_verify(self):\n        \"\"\"\n        `sign` generates a cryptographic signature which `verify` can check.\n        \"\"\"\n        content = (\n            b\"It was a bright cold day in April, and the clocks were striking \"\n            b\"thirteen. Winston Smith, his chin nuzzled into his breast in an \"\n            b\"effort to escape the vile wind, slipped quickly through the \"\n            b\"glass doors of Victory Mansions, though not quickly enough to \"\n            b\"prevent a swirl of gritty dust from entering along with him.\")\n\n        # sign the content with this private key\n        priv_key = load_privatekey(FILETYPE_PEM, root_key_pem)\n        # verify the content with this cert\n        good_cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        # certificate unrelated to priv_key, used to trigger an error\n        bad_cert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        for digest in ['md5', 'sha1']:\n            sig = sign(priv_key, content, digest)\n\n            # Verify the signature of content, will throw an exception if\n            # error.\n            verify(good_cert, sig, content, digest)\n\n            # This should fail because the certificate doesn't match the\n            # private key that was used to sign the content.\n            with pytest.raises(Error):\n                verify(bad_cert, sig, content, digest)\n\n            # This should fail because we've \"tainted\" the content after\n            # signing it.\n            with pytest.raises(Error):\n                verify(good_cert, sig, content + b\"tainted\", digest)\n\n        # test that unknown digest types fail\n        with pytest.raises(ValueError):\n            sign(priv_key, content, \"strange-digest\")\n        with pytest.raises(ValueError):\n            verify(good_cert, sig, content, \"strange-digest\")\n\n    def test_sign_verify_with_text(self):\n        \"\"\"\n        `sign` generates a cryptographic signature which\n        `verify` can check. Deprecation warnings raised because using\n        text instead of bytes as content\n        \"\"\"\n        content = (\n            b\"It was a bright cold day in April, and the clocks were striking \"\n            b\"thirteen. Winston Smith, his chin nuzzled into his breast in an \"\n            b\"effort to escape the vile wind, slipped quickly through the \"\n            b\"glass doors of Victory Mansions, though not quickly enough to \"\n            b\"prevent a swirl of gritty dust from entering along with him.\"\n        ).decode(\"ascii\")\n\n        priv_key = load_privatekey(FILETYPE_PEM, root_key_pem)\n        cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        for digest in ['md5', 'sha1']:\n            with pytest.warns(DeprecationWarning) as w:\n                simplefilter(\"always\")\n                sig = sign(priv_key, content, digest)\n            assert (\n                \"{0} for data is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n\n            with pytest.warns(DeprecationWarning) as w:\n                simplefilter(\"always\")\n                verify(cert, sig, content, digest)\n            assert (\n                \"{0} for data is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n\n    def test_sign_verify_ecdsa(self):\n        \"\"\"\n        `sign` generates a cryptographic signature which `verify` can check.\n        ECDSA Signatures in the X9.62 format may have variable length,\n        different from the length of the private key.\n        \"\"\"\n        content = (\n            b\"It was a bright cold day in April, and the clocks were striking \"\n            b\"thirteen. Winston Smith, his chin nuzzled into his breast in an \"\n            b\"effort to escape the vile wind, slipped quickly through the \"\n            b\"glass doors of Victory Mansions, though not quickly enough to \"\n            b\"prevent a swirl of gritty dust from entering along with him.\"\n        ).decode(\"ascii\")\n        priv_key = load_privatekey(FILETYPE_PEM, ec_root_key_pem)\n        cert = load_certificate(FILETYPE_PEM, ec_root_cert_pem)\n        sig = sign(priv_key, content, \"sha1\")\n        verify(cert, sig, content, \"sha1\")\n\n    def test_sign_nulls(self):\n        \"\"\"\n        `sign` produces a signature for a string with embedded nulls.\n        \"\"\"\n        content = b\"Watch out!  \\0  Did you see it?\"\n        priv_key = load_privatekey(FILETYPE_PEM, root_key_pem)\n        good_cert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        sig = sign(priv_key, content, \"sha1\")\n        verify(good_cert, sig, content, \"sha1\")\n\n    def test_sign_with_large_key(self):\n        \"\"\"\n        `sign` produces a signature for a string when using a long key.\n        \"\"\"\n        content = (\n            b\"It was a bright cold day in April, and the clocks were striking \"\n            b\"thirteen. Winston Smith, his chin nuzzled into his breast in an \"\n            b\"effort to escape the vile wind, slipped quickly through the \"\n            b\"glass doors of Victory Mansions, though not quickly enough to \"\n            b\"prevent a swirl of gritty dust from entering along with him.\")\n\n        priv_key = load_privatekey(FILETYPE_PEM, large_key_pem)\n        sign(priv_key, content, \"sha1\")\n\n\nclass TestEllipticCurve(object):\n    \"\"\"\n    Tests for `_EllipticCurve`, `get_elliptic_curve`, and\n    `get_elliptic_curves`.\n    \"\"\"\n\n    def test_set(self):\n        \"\"\"\n        `get_elliptic_curves` returns a `set`.\n        \"\"\"\n        assert isinstance(get_elliptic_curves(), set)\n\n    def test_a_curve(self):\n        \"\"\"\n        `get_elliptic_curve` can be used to retrieve a particular supported\n        curve.\n        \"\"\"\n        curves = get_elliptic_curves()\n        curve = next(iter(curves))\n        assert curve.name == get_elliptic_curve(curve.name).name\n\n    def test_not_a_curve(self):\n        \"\"\"\n        `get_elliptic_curve` raises `ValueError` if called with a name which\n        does not identify a supported curve.\n        \"\"\"\n        with pytest.raises(ValueError):\n            get_elliptic_curve(u\"this curve was just invented\")\n\n    def test_repr(self):\n        \"\"\"\n        The string representation of a curve object includes simply states the\n        object is a curve and what its name is.\n        \"\"\"\n        curves = get_elliptic_curves()\n        curve = next(iter(curves))\n        assert \"<Curve %r>\" % (curve.name,) == repr(curve)\n\n    def test_to_EC_KEY(self):\n        \"\"\"\n        The curve object can export a version of itself as an EC_KEY* via the\n        private `_EllipticCurve._to_EC_KEY`.\n        \"\"\"\n        curves = get_elliptic_curves()\n        curve = next(iter(curves))\n        # It's not easy to assert anything about this object.  However, see\n        # leakcheck/crypto.py for a test that demonstrates it at least does\n        # not leak memory.\n        curve._to_EC_KEY()\n\n\nclass EllipticCurveFactory(object):\n    \"\"\"\n    A helper to get the names of two curves.\n    \"\"\"\n\n    def __init__(self):\n        curves = iter(get_elliptic_curves())\n        self.curve_name = next(curves).name\n        self.another_curve_name = next(curves).name\n\n\nclass TestEllipticCurveEquality(EqualityTestsMixin):\n    \"\"\"\n    Tests `_EllipticCurve`'s implementation of ``==`` and ``!=``.\n    \"\"\"\n    curve_factory = EllipticCurveFactory()\n\n    if curve_factory.curve_name is None:\n        skip = \"There are no curves available there can be no curve objects.\"\n\n    def anInstance(self):\n        \"\"\"\n        Get the curve object for an arbitrary curve supported by the system.\n        \"\"\"\n        return get_elliptic_curve(self.curve_factory.curve_name)\n\n    def anotherInstance(self):\n        \"\"\"\n        Get the curve object for an arbitrary curve supported by the system -\n        but not the one returned by C{anInstance}.\n        \"\"\"\n        return get_elliptic_curve(self.curve_factory.another_curve_name)\n\n\nclass TestEllipticCurveHash(object):\n    \"\"\"\n    Tests for `_EllipticCurve`'s implementation of hashing (thus use as\n    an item in a `dict` or `set`).\n    \"\"\"\n    curve_factory = EllipticCurveFactory()\n\n    if curve_factory.curve_name is None:\n        skip = \"There are no curves available there can be no curve objects.\"\n\n    def test_contains(self):\n        \"\"\"\n        The ``in`` operator reports that a `set` containing a curve does\n        contain that curve.\n        \"\"\"\n        curve = get_elliptic_curve(self.curve_factory.curve_name)\n        curves = set([curve])\n        assert curve in curves\n\n    def test_does_not_contain(self):\n        \"\"\"\n        The ``in`` operator reports that a `set` not containing a curve\n        does not contain that curve.\n        \"\"\"\n        curve = get_elliptic_curve(self.curve_factory.curve_name)\n        curves = set([\n            get_elliptic_curve(self.curve_factory.another_curve_name)\n        ])\n        assert curve not in curves\n\n\n### tests/util.py ###\n\n# Copyright (C) Jean-Paul Calderone\n# Copyright (C) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\"\"\"\nHelpers for the OpenSSL test suite, largely copied from\nU{Twisted<http://twistedmatrix.com/>}.\n\"\"\"\n\nfrom six import PY3\n\n\n# This is the UTF-8 encoding of the SNOWMAN unicode code point.\nNON_ASCII = b\"\\xe2\\x98\\x83\".decode(\"utf-8\")\n\n\ndef is_consistent_type(theType, name, *constructionArgs):\n    \"\"\"\n    Perform various assertions about *theType* to ensure that it is a\n    well-defined type.  This is useful for extension types, where it's\n    pretty easy to do something wacky.  If something about the type is\n    unusual, an exception will be raised.\n\n    :param theType: The type object about which to make assertions.\n    :param name: A string giving the name of the type.\n    :param constructionArgs: Positional arguments to use with\n        *theType* to create an instance of it.\n    \"\"\"\n    assert theType.__name__ == name\n    assert isinstance(theType, type)\n    instance = theType(*constructionArgs)\n    assert type(instance) is theType\n    return True\n\n\nclass EqualityTestsMixin(object):\n    \"\"\"\n    A mixin defining tests for the standard implementation of C{==} and C{!=}.\n    \"\"\"\n\n    def anInstance(self):\n        \"\"\"\n        Return an instance of the class under test.  Each call to this method\n        must return a different object.  All objects returned must be equal to\n        each other.\n        \"\"\"\n        raise NotImplementedError()\n\n    def anotherInstance(self):\n        \"\"\"\n        Return an instance of the class under test.  Each call to this method\n        must return a different object.  The objects must not be equal to the\n        objects returned by C{anInstance}.  They may or may not be equal to\n        each other (they will not be compared against each other).\n        \"\"\"\n        raise NotImplementedError()\n\n    def test_identicalEq(self):\n        \"\"\"\n        An object compares equal to itself using the C{==} operator.\n        \"\"\"\n        o = self.anInstance()\n        assert (o == o)\n\n    def test_identicalNe(self):\n        \"\"\"\n        An object doesn't compare not equal to itself using the C{!=} operator.\n        \"\"\"\n        o = self.anInstance()\n        assert not (o != o)\n\n    def test_sameEq(self):\n        \"\"\"\n        Two objects that are equal to each other compare equal to each other\n        using the C{==} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = self.anInstance()\n        assert (a == b)\n\n    def test_sameNe(self):\n        \"\"\"\n        Two objects that are equal to each other do not compare not equal to\n        each other using the C{!=} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = self.anInstance()\n        assert not (a != b)\n\n    def test_differentEq(self):\n        \"\"\"\n        Two objects that are not equal to each other do not compare equal to\n        each other using the C{==} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = self.anotherInstance()\n        assert not (a == b)\n\n    def test_differentNe(self):\n        \"\"\"\n        Two objects that are not equal to each other compare not equal to each\n        other using the C{!=} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = self.anotherInstance()\n        assert (a != b)\n\n    def test_anotherTypeEq(self):\n        \"\"\"\n        The object does not compare equal to an object of an unrelated type\n        (which does not implement the comparison) using the C{==} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = object()\n        assert not (a == b)\n\n    def test_anotherTypeNe(self):\n        \"\"\"\n        The object compares not equal to an object of an unrelated type (which\n        does not implement the comparison) using the C{!=} operator.\n        \"\"\"\n        a = self.anInstance()\n        b = object()\n        assert (a != b)\n\n    def test_delegatedEq(self):\n        \"\"\"\n        The result of comparison using C{==} is delegated to the right-hand\n        operand if it is of an unrelated type.\n        \"\"\"\n        class Delegate(object):\n            def __eq__(self, other):\n                # Do something crazy and obvious.\n                return [self]\n\n        a = self.anInstance()\n        b = Delegate()\n        assert (a == b) == [b]\n\n    def test_delegateNe(self):\n        \"\"\"\n        The result of comparison using C{!=} is delegated to the right-hand\n        operand if it is of an unrelated type.\n        \"\"\"\n        class Delegate(object):\n            def __ne__(self, other):\n                # Do something crazy and obvious.\n                return [self]\n\n        a = self.anInstance()\n        b = Delegate()\n        assert (a != b) == [b]\n\n\n# The type name expected in warnings about using the wrong string type.\nif PY3:\n    WARNING_TYPE_EXPECTED = \"str\"\nelse:\n    WARNING_TYPE_EXPECTED = \"unicode\"\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# Copyright (C) Jean-Paul Calderone\n# See LICENSE for details.\n\n\"\"\"\nUnit tests for :mod:`OpenSSL.SSL`.\n\"\"\"\n\nimport datetime\nimport sys\nimport uuid\n\nfrom gc import collect, get_referrers\nfrom errno import (\n    EAFNOSUPPORT, ECONNREFUSED, EINPROGRESS, EWOULDBLOCK, EPIPE, ESHUTDOWN)\nfrom sys import platform, getfilesystemencoding\nfrom socket import AF_INET, AF_INET6, MSG_PEEK, SHUT_RDWR, error, socket\nfrom os import makedirs\nfrom os.path import join\nfrom weakref import ref\nfrom warnings import simplefilter\n\nimport pytest\n\nfrom pretend import raiser\n\nfrom six import PY3, text_type\n\nfrom cryptography import x509\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import hashes\nfrom cryptography.hazmat.primitives import serialization\nfrom cryptography.hazmat.primitives.asymmetric import rsa\nfrom cryptography.x509.oid import NameOID\n\n\nfrom OpenSSL.crypto import TYPE_RSA, FILETYPE_PEM\nfrom OpenSSL.crypto import PKey, X509, X509Extension, X509Store\nfrom OpenSSL.crypto import dump_privatekey, load_privatekey\nfrom OpenSSL.crypto import dump_certificate, load_certificate\nfrom OpenSSL.crypto import get_elliptic_curves\n\nfrom OpenSSL.SSL import OPENSSL_VERSION_NUMBER, SSLEAY_VERSION, SSLEAY_CFLAGS\nfrom OpenSSL.SSL import SSLEAY_PLATFORM, SSLEAY_DIR, SSLEAY_BUILT_ON\nfrom OpenSSL.SSL import SENT_SHUTDOWN, RECEIVED_SHUTDOWN\nfrom OpenSSL.SSL import (\n    SSLv2_METHOD, SSLv3_METHOD, SSLv23_METHOD, TLSv1_METHOD,\n    TLSv1_1_METHOD, TLSv1_2_METHOD)\nfrom OpenSSL.SSL import OP_SINGLE_DH_USE, OP_NO_SSLv2, OP_NO_SSLv3\nfrom OpenSSL.SSL import (\n    VERIFY_PEER, VERIFY_FAIL_IF_NO_PEER_CERT, VERIFY_CLIENT_ONCE, VERIFY_NONE)\n\nfrom OpenSSL import SSL\nfrom OpenSSL.SSL import (\n    SESS_CACHE_OFF, SESS_CACHE_CLIENT, SESS_CACHE_SERVER, SESS_CACHE_BOTH,\n    SESS_CACHE_NO_AUTO_CLEAR, SESS_CACHE_NO_INTERNAL_LOOKUP,\n    SESS_CACHE_NO_INTERNAL_STORE, SESS_CACHE_NO_INTERNAL)\n\nfrom OpenSSL.SSL import (\n    Error, SysCallError, WantReadError, WantWriteError, ZeroReturnError)\nfrom OpenSSL.SSL import (\n    Context, Session, Connection, SSLeay_version)\nfrom OpenSSL.SSL import _make_requires\n\nfrom OpenSSL._util import ffi as _ffi, lib as _lib\n\nfrom OpenSSL.SSL import (\n    OP_NO_QUERY_MTU, OP_COOKIE_EXCHANGE, OP_NO_TICKET, OP_NO_COMPRESSION,\n    MODE_RELEASE_BUFFERS)\n\nfrom OpenSSL.SSL import (\n    SSL_ST_CONNECT, SSL_ST_ACCEPT, SSL_ST_MASK,\n    SSL_CB_LOOP, SSL_CB_EXIT, SSL_CB_READ, SSL_CB_WRITE, SSL_CB_ALERT,\n    SSL_CB_READ_ALERT, SSL_CB_WRITE_ALERT, SSL_CB_ACCEPT_LOOP,\n    SSL_CB_ACCEPT_EXIT, SSL_CB_CONNECT_LOOP, SSL_CB_CONNECT_EXIT,\n    SSL_CB_HANDSHAKE_START, SSL_CB_HANDSHAKE_DONE)\n\ntry:\n    from OpenSSL.SSL import (\n        SSL_ST_INIT, SSL_ST_BEFORE, SSL_ST_OK, SSL_ST_RENEGOTIATE\n    )\nexcept ImportError:\n    SSL_ST_INIT = SSL_ST_BEFORE = SSL_ST_OK = SSL_ST_RENEGOTIATE = None\n\nfrom .util import WARNING_TYPE_EXPECTED, NON_ASCII, is_consistent_type\nfrom .test_crypto import (\n    cleartextCertificatePEM, cleartextPrivateKeyPEM,\n    client_cert_pem, client_key_pem, server_cert_pem, server_key_pem,\n    root_cert_pem)\n\n\n# openssl dhparam 1024 -out dh-1024.pem (note that 1024 is a small number of\n# bits to use)\ndhparam = \"\"\"\\\n-----BEGIN DH PARAMETERS-----\nMIGHAoGBALdUMvn+C9MM+y5BWZs11mSeH6HHoEq0UVbzVq7UojC1hbsZUuGukQ3a\nQh2/pwqb18BZFykrWB0zv/OkLa0kx4cuUgNrUVq1EFheBiX6YqryJ7t2sO09NQiO\nV7H54LmltOT/hEh6QWsJqb6BQgH65bswvV/XkYGja8/T0GzvbaVzAgEC\n-----END DH PARAMETERS-----\n\"\"\"\n\n\nskip_if_py3 = pytest.mark.skipif(PY3, reason=\"Python 2 only\")\n\n\ndef socket_any_family():\n    try:\n        return socket(AF_INET)\n    except error as e:\n        if e.errno == EAFNOSUPPORT:\n            return socket(AF_INET6)\n        raise\n\n\ndef loopback_address(socket):\n    if socket.family == AF_INET:\n        return \"127.0.0.1\"\n    else:\n        assert socket.family == AF_INET6\n        return \"::1\"\n\n\ndef join_bytes_or_unicode(prefix, suffix):\n    \"\"\"\n    Join two path components of either ``bytes`` or ``unicode``.\n\n    The return type is the same as the type of ``prefix``.\n    \"\"\"\n    # If the types are the same, nothing special is necessary.\n    if type(prefix) == type(suffix):\n        return join(prefix, suffix)\n\n    # Otherwise, coerce suffix to the type of prefix.\n    if isinstance(prefix, text_type):\n        return join(prefix, suffix.decode(getfilesystemencoding()))\n    else:\n        return join(prefix, suffix.encode(getfilesystemencoding()))\n\n\ndef verify_cb(conn, cert, errnum, depth, ok):\n    return ok\n\n\ndef socket_pair():\n    \"\"\"\n    Establish and return a pair of network sockets connected to each other.\n    \"\"\"\n    # Connect a pair of sockets\n    port = socket_any_family()\n    port.bind(('', 0))\n    port.listen(1)\n    client = socket(port.family)\n    client.setblocking(False)\n    client.connect_ex((loopback_address(port), port.getsockname()[1]))\n    client.setblocking(True)\n    server = port.accept()[0]\n\n    # Let's pass some unencrypted data to make sure our socket connection is\n    # fine.  Just one byte, so we don't have to worry about buffers getting\n    # filled up or fragmentation.\n    server.send(b\"x\")\n    assert client.recv(1024) == b\"x\"\n    client.send(b\"y\")\n    assert server.recv(1024) == b\"y\"\n\n    # Most of our callers want non-blocking sockets, make it easy for them.\n    server.setblocking(False)\n    client.setblocking(False)\n\n    return (server, client)\n\n\ndef handshake(client, server):\n    conns = [client, server]\n    while conns:\n        for conn in conns:\n            try:\n                conn.do_handshake()\n            except WantReadError:\n                pass\n            else:\n                conns.remove(conn)\n\n\ndef _create_certificate_chain():\n    \"\"\"\n    Construct and return a chain of certificates.\n\n        1. A new self-signed certificate authority certificate (cacert)\n        2. A new intermediate certificate signed by cacert (icert)\n        3. A new server certificate signed by icert (scert)\n    \"\"\"\n    caext = X509Extension(b'basicConstraints', False, b'CA:true')\n\n    # Step 1\n    cakey = PKey()\n    cakey.generate_key(TYPE_RSA, 1024)\n    cacert = X509()\n    cacert.get_subject().commonName = \"Authority Certificate\"\n    cacert.set_issuer(cacert.get_subject())\n    cacert.set_pubkey(cakey)\n    cacert.set_notBefore(b\"20000101000000Z\")\n    cacert.set_notAfter(b\"20200101000000Z\")\n    cacert.add_extensions([caext])\n    cacert.set_serial_number(0)\n    cacert.sign(cakey, \"sha1\")\n\n    # Step 2\n    ikey = PKey()\n    ikey.generate_key(TYPE_RSA, 1024)\n    icert = X509()\n    icert.get_subject().commonName = \"Intermediate Certificate\"\n    icert.set_issuer(cacert.get_subject())\n    icert.set_pubkey(ikey)\n    icert.set_notBefore(b\"20000101000000Z\")\n    icert.set_notAfter(b\"20200101000000Z\")\n    icert.add_extensions([caext])\n    icert.set_serial_number(0)\n    icert.sign(cakey, \"sha1\")\n\n    # Step 3\n    skey = PKey()\n    skey.generate_key(TYPE_RSA, 1024)\n    scert = X509()\n    scert.get_subject().commonName = \"Server Certificate\"\n    scert.set_issuer(icert.get_subject())\n    scert.set_pubkey(skey)\n    scert.set_notBefore(b\"20000101000000Z\")\n    scert.set_notAfter(b\"20200101000000Z\")\n    scert.add_extensions([\n        X509Extension(b'basicConstraints', True, b'CA:false')])\n    scert.set_serial_number(0)\n    scert.sign(ikey, \"sha1\")\n\n    return [(cakey, cacert), (ikey, icert), (skey, scert)]\n\n\ndef loopback_client_factory(socket, version=SSLv23_METHOD):\n    client = Connection(Context(version), socket)\n    client.set_connect_state()\n    return client\n\n\ndef loopback_server_factory(socket, version=SSLv23_METHOD):\n    ctx = Context(version)\n    ctx.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n    ctx.use_certificate(load_certificate(FILETYPE_PEM, server_cert_pem))\n    server = Connection(ctx, socket)\n    server.set_accept_state()\n    return server\n\n\ndef loopback(server_factory=None, client_factory=None):\n    \"\"\"\n    Create a connected socket pair and force two connected SSL sockets\n    to talk to each other via memory BIOs.\n    \"\"\"\n    if server_factory is None:\n        server_factory = loopback_server_factory\n    if client_factory is None:\n        client_factory = loopback_client_factory\n\n    (server, client) = socket_pair()\n    server = server_factory(server)\n    client = client_factory(client)\n\n    handshake(client, server)\n\n    server.setblocking(True)\n    client.setblocking(True)\n    return server, client\n\n\ndef interact_in_memory(client_conn, server_conn):\n    \"\"\"\n    Try to read application bytes from each of the two `Connection` objects.\n    Copy bytes back and forth between their send/receive buffers for as long\n    as there is anything to copy.  When there is nothing more to copy,\n    return `None`.  If one of them actually manages to deliver some application\n    bytes, return a two-tuple of the connection from which the bytes were read\n    and the bytes themselves.\n    \"\"\"\n    wrote = True\n    while wrote:\n        # Loop until neither side has anything to say\n        wrote = False\n\n        # Copy stuff from each side's send buffer to the other side's\n        # receive buffer.\n        for (read, write) in [(client_conn, server_conn),\n                              (server_conn, client_conn)]:\n\n            # Give the side a chance to generate some more bytes, or succeed.\n            try:\n                data = read.recv(2 ** 16)\n            except WantReadError:\n                # It didn't succeed, so we'll hope it generated some output.\n                pass\n            else:\n                # It did succeed, so we'll stop now and let the caller deal\n                # with it.\n                return (read, data)\n\n            while True:\n                # Keep copying as long as there's more stuff there.\n                try:\n                    dirty = read.bio_read(4096)\n                except WantReadError:\n                    # Okay, nothing more waiting to be sent.  Stop\n                    # processing this send buffer.\n                    break\n                else:\n                    # Keep track of the fact that someone generated some\n                    # output.\n                    wrote = True\n                    write.bio_write(dirty)\n\n\ndef handshake_in_memory(client_conn, server_conn):\n    \"\"\"\n    Perform the TLS handshake between two `Connection` instances connected to\n    each other via memory BIOs.\n    \"\"\"\n    client_conn.set_connect_state()\n    server_conn.set_accept_state()\n\n    for conn in [client_conn, server_conn]:\n        try:\n            conn.do_handshake()\n        except WantReadError:\n            pass\n\n    interact_in_memory(client_conn, server_conn)\n\n\nclass TestVersion(object):\n    \"\"\"\n    Tests for version information exposed by `OpenSSL.SSL.SSLeay_version` and\n    `OpenSSL.SSL.OPENSSL_VERSION_NUMBER`.\n    \"\"\"\n    def test_OPENSSL_VERSION_NUMBER(self):\n        \"\"\"\n        `OPENSSL_VERSION_NUMBER` is an integer with status in the low byte and\n        the patch, fix, minor, and major versions in the nibbles above that.\n        \"\"\"\n        assert isinstance(OPENSSL_VERSION_NUMBER, int)\n\n    def test_SSLeay_version(self):\n        \"\"\"\n        `SSLeay_version` takes a version type indicator and returns one of a\n        number of version strings based on that indicator.\n        \"\"\"\n        versions = {}\n        for t in [SSLEAY_VERSION, SSLEAY_CFLAGS, SSLEAY_BUILT_ON,\n                  SSLEAY_PLATFORM, SSLEAY_DIR]:\n            version = SSLeay_version(t)\n            versions[version] = t\n            assert isinstance(version, bytes)\n        assert len(versions) == 5\n\n\n@pytest.fixture\ndef ca_file(tmpdir):\n    \"\"\"\n    Create a valid PEM file with CA certificates and return the path.\n    \"\"\"\n    key = rsa.generate_private_key(\n        public_exponent=65537,\n        key_size=2048,\n        backend=default_backend()\n    )\n    public_key = key.public_key()\n\n    builder = x509.CertificateBuilder()\n    builder = builder.subject_name(x509.Name([\n        x509.NameAttribute(NameOID.COMMON_NAME, u\"pyopenssl.org\"),\n    ]))\n    builder = builder.issuer_name(x509.Name([\n        x509.NameAttribute(NameOID.COMMON_NAME, u\"pyopenssl.org\"),\n    ]))\n    one_day = datetime.timedelta(1, 0, 0)\n    builder = builder.not_valid_before(datetime.datetime.today() - one_day)\n    builder = builder.not_valid_after(datetime.datetime.today() + one_day)\n    builder = builder.serial_number(int(uuid.uuid4()))\n    builder = builder.public_key(public_key)\n    builder = builder.add_extension(\n        x509.BasicConstraints(ca=True, path_length=None), critical=True,\n    )\n\n    certificate = builder.sign(\n        private_key=key, algorithm=hashes.SHA256(),\n        backend=default_backend()\n    )\n\n    ca_file = tmpdir.join(\"test.pem\")\n    ca_file.write_binary(\n        certificate.public_bytes(\n            encoding=serialization.Encoding.PEM,\n        )\n    )\n\n    return str(ca_file).encode(\"ascii\")\n\n\n@pytest.fixture\ndef context():\n    \"\"\"\n    A simple TLS 1.0 context.\n    \"\"\"\n    return Context(TLSv1_METHOD)\n\n\nclass TestContext(object):\n    \"\"\"\n    Unit tests for `OpenSSL.SSL.Context`.\n    \"\"\"\n    @pytest.mark.parametrize(\"cipher_string\", [\n        b\"hello world:AES128-SHA\",\n        u\"hello world:AES128-SHA\",\n    ])\n    def test_set_cipher_list(self, context, cipher_string):\n        \"\"\"\n        `Context.set_cipher_list` accepts both byte and unicode strings\n        for naming the ciphers which connections created with the context\n        object will be able to choose from.\n        \"\"\"\n        context.set_cipher_list(cipher_string)\n        conn = Connection(context, None)\n\n        assert \"AES128-SHA\" in conn.get_cipher_list()\n\n    def test_set_cipher_list_wrong_type(self, context):\n        \"\"\"\n        `Context.set_cipher_list` raises `TypeError` when passed a non-string\n        argument.\n        \"\"\"\n        with pytest.raises(TypeError):\n            context.set_cipher_list(object())\n\n    def test_set_cipher_list_no_cipher_match(self, context):\n        \"\"\"\n        `Context.set_cipher_list` raises `OpenSSL.SSL.Error` with a\n        `\"no cipher match\"` reason string regardless of the TLS\n        version.\n        \"\"\"\n        with pytest.raises(Error) as excinfo:\n            context.set_cipher_list(b\"imaginary-cipher\")\n        assert excinfo.value.args == (\n                [\n                    (\n                        'SSL routines',\n                        'SSL_CTX_set_cipher_list',\n                        'no cipher match',\n                    ),\n                ],\n            )\n\n    def test_load_client_ca(self, context, ca_file):\n        \"\"\"\n        `Context.load_client_ca` works as far as we can tell.\n        \"\"\"\n        context.load_client_ca(ca_file)\n\n    def test_load_client_ca_invalid(self, context, tmpdir):\n        \"\"\"\n        `Context.load_client_ca` raises an Error if the ca file is invalid.\n        \"\"\"\n        ca_file = tmpdir.join(\"test.pem\")\n        ca_file.write(\"\")\n\n        with pytest.raises(Error) as e:\n            context.load_client_ca(str(ca_file).encode(\"ascii\"))\n\n        assert \"PEM routines\" == e.value.args[0][0][0]\n\n    def test_load_client_ca_unicode(self, context, ca_file):\n        \"\"\"\n        Passing the path as unicode raises a warning but works.\n        \"\"\"\n        pytest.deprecated_call(\n            context.load_client_ca, ca_file.decode(\"ascii\")\n        )\n\n    def test_set_session_id(self, context):\n        \"\"\"\n        `Context.set_session_id` works as far as we can tell.\n        \"\"\"\n        context.set_session_id(b\"abc\")\n\n    def test_set_session_id_fail(self, context):\n        \"\"\"\n        `Context.set_session_id` errors are propagated.\n        \"\"\"\n        with pytest.raises(Error) as e:\n            context.set_session_id(b\"abc\" * 1000)\n\n        assert [\n            (\"SSL routines\",\n             \"SSL_CTX_set_session_id_context\",\n             \"ssl session id context too long\")\n        ] == e.value.args[0]\n\n    def test_set_session_id_unicode(self, context):\n        \"\"\"\n        `Context.set_session_id` raises a warning if a unicode string is\n        passed.\n        \"\"\"\n        pytest.deprecated_call(context.set_session_id, u\"abc\")\n\n    def test_method(self):\n        \"\"\"\n        `Context` can be instantiated with one of `SSLv2_METHOD`,\n        `SSLv3_METHOD`, `SSLv23_METHOD`, `TLSv1_METHOD`, `TLSv1_1_METHOD`,\n        or `TLSv1_2_METHOD`.\n        \"\"\"\n        methods = [SSLv23_METHOD, TLSv1_METHOD]\n        for meth in methods:\n            Context(meth)\n\n        maybe = [SSLv2_METHOD, SSLv3_METHOD, TLSv1_1_METHOD, TLSv1_2_METHOD]\n        for meth in maybe:\n            try:\n                Context(meth)\n            except (Error, ValueError):\n                # Some versions of OpenSSL have SSLv2 / TLSv1.1 / TLSv1.2, some\n                # don't.  Difficult to say in advance.\n                pass\n\n        with pytest.raises(TypeError):\n            Context(\"\")\n        with pytest.raises(ValueError):\n            Context(10)\n\n    def test_type(self):\n        \"\"\"\n        `Context` can be used to create instances of that type.\n        \"\"\"\n        assert is_consistent_type(Context, 'Context', TLSv1_METHOD)\n\n    def test_use_privatekey(self):\n        \"\"\"\n        `Context.use_privatekey` takes an `OpenSSL.crypto.PKey` instance.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_privatekey(key)\n        with pytest.raises(TypeError):\n            ctx.use_privatekey(\"\")\n\n    def test_use_privatekey_file_missing(self, tmpfile):\n        \"\"\"\n        `Context.use_privatekey_file` raises `OpenSSL.SSL.Error` when passed\n        the name of a file which does not exist.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            ctx.use_privatekey_file(tmpfile)\n\n    def _use_privatekey_file_test(self, pemfile, filetype):\n        \"\"\"\n        Verify that calling ``Context.use_privatekey_file`` with the given\n        arguments does not raise an exception.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n\n        with open(pemfile, \"wt\") as pem:\n            pem.write(\n                dump_privatekey(FILETYPE_PEM, key).decode(\"ascii\")\n            )\n\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_privatekey_file(pemfile, filetype)\n\n    @pytest.mark.parametrize('filetype', [object(), \"\", None, 1.0])\n    def test_wrong_privatekey_file_wrong_args(self, tmpfile, filetype):\n        \"\"\"\n        `Context.use_privatekey_file` raises `TypeError` when called with\n        a `filetype` which is not a valid file encoding.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            ctx.use_privatekey_file(tmpfile, filetype)\n\n    def test_use_privatekey_file_bytes(self, tmpfile):\n        \"\"\"\n        A private key can be specified from a file by passing a ``bytes``\n        instance giving the file name to ``Context.use_privatekey_file``.\n        \"\"\"\n        self._use_privatekey_file_test(\n            tmpfile + NON_ASCII.encode(getfilesystemencoding()),\n            FILETYPE_PEM,\n        )\n\n    def test_use_privatekey_file_unicode(self, tmpfile):\n        \"\"\"\n        A private key can be specified from a file by passing a ``unicode``\n        instance giving the file name to ``Context.use_privatekey_file``.\n        \"\"\"\n        self._use_privatekey_file_test(\n            tmpfile.decode(getfilesystemencoding()) + NON_ASCII,\n            FILETYPE_PEM,\n        )\n\n    def test_use_certificate_wrong_args(self):\n        \"\"\"\n        `Context.use_certificate_wrong_args` raises `TypeError` when not passed\n        exactly one `OpenSSL.crypto.X509` instance as an argument.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            ctx.use_certificate(\"hello, world\")\n\n    def test_use_certificate_uninitialized(self):\n        \"\"\"\n        `Context.use_certificate` raises `OpenSSL.SSL.Error` when passed a\n        `OpenSSL.crypto.X509` instance which has not been initialized\n        (ie, which does not actually have any certificate data).\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            ctx.use_certificate(X509())\n\n    def test_use_certificate(self):\n        \"\"\"\n        `Context.use_certificate` sets the certificate which will be\n        used to identify connections created using the context.\n        \"\"\"\n        # TODO\n        # Hard to assert anything.  But we could set a privatekey then ask\n        # OpenSSL if the cert and key agree using check_privatekey.  Then as\n        # long as check_privatekey works right we're good...\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM)\n        )\n\n    def test_use_certificate_file_wrong_args(self):\n        \"\"\"\n        `Context.use_certificate_file` raises `TypeError` if the first\n        argument is not a byte string or the second argument is not an integer.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            ctx.use_certificate_file(object(), FILETYPE_PEM)\n        with pytest.raises(TypeError):\n            ctx.use_certificate_file(b\"somefile\", object())\n        with pytest.raises(TypeError):\n            ctx.use_certificate_file(object(), FILETYPE_PEM)\n\n    def test_use_certificate_file_missing(self, tmpfile):\n        \"\"\"\n        `Context.use_certificate_file` raises `OpenSSL.SSL.Error` if passed\n        the name of a file which does not exist.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            ctx.use_certificate_file(tmpfile)\n\n    def _use_certificate_file_test(self, certificate_file):\n        \"\"\"\n        Verify that calling ``Context.use_certificate_file`` with the given\n        filename doesn't raise an exception.\n        \"\"\"\n        # TODO\n        # Hard to assert anything.  But we could set a privatekey then ask\n        # OpenSSL if the cert and key agree using check_privatekey.  Then as\n        # long as check_privatekey works right we're good...\n        with open(certificate_file, \"wb\") as pem_file:\n            pem_file.write(cleartextCertificatePEM)\n\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_certificate_file(certificate_file)\n\n    def test_use_certificate_file_bytes(self, tmpfile):\n        \"\"\"\n        `Context.use_certificate_file` sets the certificate (given as a\n        `bytes` filename) which will be used to identify connections created\n        using the context.\n        \"\"\"\n        filename = tmpfile + NON_ASCII.encode(getfilesystemencoding())\n        self._use_certificate_file_test(filename)\n\n    def test_use_certificate_file_unicode(self, tmpfile):\n        \"\"\"\n        `Context.use_certificate_file` sets the certificate (given as a\n        `bytes` filename) which will be used to identify connections created\n        using the context.\n        \"\"\"\n        filename = tmpfile.decode(getfilesystemencoding()) + NON_ASCII\n        self._use_certificate_file_test(filename)\n\n    def test_check_privatekey_valid(self):\n        \"\"\"\n        `Context.check_privatekey` returns `None` if the `Context` instance\n        has been configured to use a matched key and certificate pair.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, client_key_pem)\n        cert = load_certificate(FILETYPE_PEM, client_cert_pem)\n        context = Context(TLSv1_METHOD)\n        context.use_privatekey(key)\n        context.use_certificate(cert)\n        assert None is context.check_privatekey()\n\n    def test_check_privatekey_invalid(self):\n        \"\"\"\n        `Context.check_privatekey` raises `Error` if the `Context` instance\n        has been configured to use a key and certificate pair which don't\n        relate to each other.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, client_key_pem)\n        cert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        context = Context(TLSv1_METHOD)\n        context.use_privatekey(key)\n        context.use_certificate(cert)\n        with pytest.raises(Error):\n            context.check_privatekey()\n\n    def test_app_data(self):\n        \"\"\"\n        `Context.set_app_data` stores an object for later retrieval\n        using `Context.get_app_data`.\n        \"\"\"\n        app_data = object()\n        context = Context(TLSv1_METHOD)\n        context.set_app_data(app_data)\n        assert context.get_app_data() is app_data\n\n    def test_set_options_wrong_args(self):\n        \"\"\"\n        `Context.set_options` raises `TypeError` if called with\n        a non-`int` argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_options(None)\n\n    def test_set_options(self):\n        \"\"\"\n        `Context.set_options` returns the new options value.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        options = context.set_options(OP_NO_SSLv2)\n        assert options & OP_NO_SSLv2 == OP_NO_SSLv2\n\n    def test_set_mode_wrong_args(self):\n        \"\"\"\n        `Context.set_mode` raises `TypeError` if called with\n        a non-`int` argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_mode(None)\n\n    def test_set_mode(self):\n        \"\"\"\n        `Context.set_mode` accepts a mode bitvector and returns the\n        newly set mode.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        assert MODE_RELEASE_BUFFERS & context.set_mode(MODE_RELEASE_BUFFERS)\n\n    def test_set_timeout_wrong_args(self):\n        \"\"\"\n        `Context.set_timeout` raises `TypeError` if called with\n        a non-`int` argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_timeout(None)\n\n    def test_timeout(self):\n        \"\"\"\n        `Context.set_timeout` sets the session timeout for all connections\n        created using the context object. `Context.get_timeout` retrieves\n        this value.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        context.set_timeout(1234)\n        assert context.get_timeout() == 1234\n\n    def test_set_verify_depth_wrong_args(self):\n        \"\"\"\n        `Context.set_verify_depth` raises `TypeError` if called with a\n        non-`int` argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_verify_depth(None)\n\n    def test_verify_depth(self):\n        \"\"\"\n        `Context.set_verify_depth` sets the number of certificates in\n        a chain to follow before giving up.  The value can be retrieved with\n        `Context.get_verify_depth`.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        context.set_verify_depth(11)\n        assert context.get_verify_depth() == 11\n\n    def _write_encrypted_pem(self, passphrase, tmpfile):\n        \"\"\"\n        Write a new private key out to a new file, encrypted using the given\n        passphrase.  Return the path to the new file.\n        \"\"\"\n        key = PKey()\n        key.generate_key(TYPE_RSA, 512)\n        pem = dump_privatekey(FILETYPE_PEM, key, \"blowfish\", passphrase)\n        with open(tmpfile, 'w') as fObj:\n            fObj.write(pem.decode('ascii'))\n        return tmpfile\n\n    def test_set_passwd_cb_wrong_args(self):\n        \"\"\"\n        `Context.set_passwd_cb` raises `TypeError` if called with a\n        non-callable first argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_passwd_cb(None)\n\n    def test_set_passwd_cb(self, tmpfile):\n        \"\"\"\n        `Context.set_passwd_cb` accepts a callable which will be invoked when\n        a private key is loaded from an encrypted PEM.\n        \"\"\"\n        passphrase = b\"foobar\"\n        pemFile = self._write_encrypted_pem(passphrase, tmpfile)\n        calledWith = []\n\n        def passphraseCallback(maxlen, verify, extra):\n            calledWith.append((maxlen, verify, extra))\n            return passphrase\n        context = Context(TLSv1_METHOD)\n        context.set_passwd_cb(passphraseCallback)\n        context.use_privatekey_file(pemFile)\n        assert len(calledWith) == 1\n        assert isinstance(calledWith[0][0], int)\n        assert isinstance(calledWith[0][1], int)\n        assert calledWith[0][2] is None\n\n    def test_passwd_callback_exception(self, tmpfile):\n        \"\"\"\n        `Context.use_privatekey_file` propagates any exception raised\n        by the passphrase callback.\n        \"\"\"\n        pemFile = self._write_encrypted_pem(b\"monkeys are nice\", tmpfile)\n\n        def passphraseCallback(maxlen, verify, extra):\n            raise RuntimeError(\"Sorry, I am a fail.\")\n\n        context = Context(TLSv1_METHOD)\n        context.set_passwd_cb(passphraseCallback)\n        with pytest.raises(RuntimeError):\n            context.use_privatekey_file(pemFile)\n\n    def test_passwd_callback_false(self, tmpfile):\n        \"\"\"\n        `Context.use_privatekey_file` raises `OpenSSL.SSL.Error` if the\n        passphrase callback returns a false value.\n        \"\"\"\n        pemFile = self._write_encrypted_pem(b\"monkeys are nice\", tmpfile)\n\n        def passphraseCallback(maxlen, verify, extra):\n            return b\"\"\n\n        context = Context(TLSv1_METHOD)\n        context.set_passwd_cb(passphraseCallback)\n        with pytest.raises(Error):\n            context.use_privatekey_file(pemFile)\n\n    def test_passwd_callback_non_string(self, tmpfile):\n        \"\"\"\n        `Context.use_privatekey_file` raises `OpenSSL.SSL.Error` if the\n        passphrase callback returns a true non-string value.\n        \"\"\"\n        pemFile = self._write_encrypted_pem(b\"monkeys are nice\", tmpfile)\n\n        def passphraseCallback(maxlen, verify, extra):\n            return 10\n\n        context = Context(TLSv1_METHOD)\n        context.set_passwd_cb(passphraseCallback)\n        # TODO: Surely this is the wrong error?\n        with pytest.raises(ValueError):\n            context.use_privatekey_file(pemFile)\n\n    def test_passwd_callback_too_long(self, tmpfile):\n        \"\"\"\n        If the passphrase returned by the passphrase callback returns a string\n        longer than the indicated maximum length, it is truncated.\n        \"\"\"\n        # A priori knowledge!\n        passphrase = b\"x\" * 1024\n        pemFile = self._write_encrypted_pem(passphrase, tmpfile)\n\n        def passphraseCallback(maxlen, verify, extra):\n            assert maxlen == 1024\n            return passphrase + b\"y\"\n\n        context = Context(TLSv1_METHOD)\n        context.set_passwd_cb(passphraseCallback)\n        # This shall succeed because the truncated result is the correct\n        # passphrase.\n        context.use_privatekey_file(pemFile)\n\n    def test_set_info_callback(self):\n        \"\"\"\n        `Context.set_info_callback` accepts a callable which will be\n        invoked when certain information about an SSL connection is available.\n        \"\"\"\n        (server, client) = socket_pair()\n\n        clientSSL = Connection(Context(TLSv1_METHOD), client)\n        clientSSL.set_connect_state()\n\n        called = []\n\n        def info(conn, where, ret):\n            called.append((conn, where, ret))\n        context = Context(TLSv1_METHOD)\n        context.set_info_callback(info)\n        context.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM))\n        context.use_privatekey(\n            load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM))\n\n        serverSSL = Connection(context, server)\n        serverSSL.set_accept_state()\n\n        handshake(clientSSL, serverSSL)\n\n        # The callback must always be called with a Connection instance as the\n        # first argument.  It would probably be better to split this into\n        # separate tests for client and server side info callbacks so we could\n        # assert it is called with the right Connection instance.  It would\n        # also be good to assert *something* about `where` and `ret`.\n        notConnections = [\n            conn for (conn, where, ret) in called\n            if not isinstance(conn, Connection)]\n        assert [] == notConnections, (\n            \"Some info callback arguments were not Connection instances.\")\n\n    def _load_verify_locations_test(self, *args):\n        \"\"\"\n        Create a client context which will verify the peer certificate and call\n        its `load_verify_locations` method with the given arguments.\n        Then connect it to a server and ensure that the handshake succeeds.\n        \"\"\"\n        (server, client) = socket_pair()\n\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.load_verify_locations(*args)\n        # Require that the server certificate verify properly or the\n        # connection will fail.\n        clientContext.set_verify(\n            VERIFY_PEER,\n            lambda conn, cert, errno, depth, preverify_ok: preverify_ok)\n\n        clientSSL = Connection(clientContext, client)\n        clientSSL.set_connect_state()\n\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM))\n        serverContext.use_privatekey(\n            load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM))\n\n        serverSSL = Connection(serverContext, server)\n        serverSSL.set_accept_state()\n\n        # Without load_verify_locations above, the handshake\n        # will fail:\n        # Error: [('SSL routines', 'SSL3_GET_SERVER_CERTIFICATE',\n        #          'certificate verify failed')]\n        handshake(clientSSL, serverSSL)\n\n        cert = clientSSL.get_peer_certificate()\n        assert cert.get_subject().CN == 'Testing Root CA'\n\n    def _load_verify_cafile(self, cafile):\n        \"\"\"\n        Verify that if path to a file containing a certificate is passed to\n        `Context.load_verify_locations` for the ``cafile`` parameter, that\n        certificate is used as a trust root for the purposes of verifying\n        connections created using that `Context`.\n        \"\"\"\n        with open(cafile, 'w') as fObj:\n            fObj.write(cleartextCertificatePEM.decode('ascii'))\n\n        self._load_verify_locations_test(cafile)\n\n    def test_load_verify_bytes_cafile(self, tmpfile):\n        \"\"\"\n        `Context.load_verify_locations` accepts a file name as a `bytes`\n        instance and uses the certificates within for verification purposes.\n        \"\"\"\n        cafile = tmpfile + NON_ASCII.encode(getfilesystemencoding())\n        self._load_verify_cafile(cafile)\n\n    def test_load_verify_unicode_cafile(self, tmpfile):\n        \"\"\"\n        `Context.load_verify_locations` accepts a file name as a `unicode`\n        instance and uses the certificates within for verification purposes.\n        \"\"\"\n        self._load_verify_cafile(\n            tmpfile.decode(getfilesystemencoding()) + NON_ASCII\n        )\n\n    def test_load_verify_invalid_file(self, tmpfile):\n        \"\"\"\n        `Context.load_verify_locations` raises `Error` when passed a\n        non-existent cafile.\n        \"\"\"\n        clientContext = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            clientContext.load_verify_locations(tmpfile)\n\n    def _load_verify_directory_locations_capath(self, capath):\n        \"\"\"\n        Verify that if path to a directory containing certificate files is\n        passed to ``Context.load_verify_locations`` for the ``capath``\n        parameter, those certificates are used as trust roots for the purposes\n        of verifying connections created using that ``Context``.\n        \"\"\"\n        makedirs(capath)\n        # Hash values computed manually with c_rehash to avoid depending on\n        # c_rehash in the test suite.  One is from OpenSSL 0.9.8, the other\n        # from OpenSSL 1.0.0.\n        for name in [b'c7adac82.0', b'c3705638.0']:\n            cafile = join_bytes_or_unicode(capath, name)\n            with open(cafile, 'w') as fObj:\n                fObj.write(cleartextCertificatePEM.decode('ascii'))\n\n        self._load_verify_locations_test(None, capath)\n\n    def test_load_verify_directory_bytes_capath(self, tmpfile):\n        \"\"\"\n        `Context.load_verify_locations` accepts a directory name as a `bytes`\n        instance and uses the certificates within for verification purposes.\n        \"\"\"\n        self._load_verify_directory_locations_capath(\n            tmpfile + NON_ASCII.encode(getfilesystemencoding())\n        )\n\n    def test_load_verify_directory_unicode_capath(self, tmpfile):\n        \"\"\"\n        `Context.load_verify_locations` accepts a directory name as a `unicode`\n        instance and uses the certificates within for verification purposes.\n        \"\"\"\n        self._load_verify_directory_locations_capath(\n            tmpfile.decode(getfilesystemencoding()) + NON_ASCII\n        )\n\n    def test_load_verify_locations_wrong_args(self):\n        \"\"\"\n        `Context.load_verify_locations` raises `TypeError` if with non-`str`\n        arguments.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.load_verify_locations(object())\n        with pytest.raises(TypeError):\n            context.load_verify_locations(object(), object())\n\n    @pytest.mark.skipif(\n        not platform.startswith(\"linux\"),\n        reason=\"Loading fallback paths is a linux-specific behavior to \"\n        \"accommodate pyca/cryptography manylinux1 wheels\"\n    )\n    def test_fallback_default_verify_paths(self, monkeypatch):\n        \"\"\"\n        Test that we load certificates successfully on linux from the fallback\n        path. To do this we set the _CRYPTOGRAPHY_MANYLINUX1_CA_FILE and\n        _CRYPTOGRAPHY_MANYLINUX1_CA_DIR vars to be equal to whatever the\n        current OpenSSL default is and we disable\n        SSL_CTX_SET_default_verify_paths so that it can't find certs unless\n        it loads via fallback.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        monkeypatch.setattr(\n            _lib, \"SSL_CTX_set_default_verify_paths\", lambda x: 1\n        )\n        monkeypatch.setattr(\n            SSL,\n            \"_CRYPTOGRAPHY_MANYLINUX1_CA_FILE\",\n            _ffi.string(_lib.X509_get_default_cert_file())\n        )\n        monkeypatch.setattr(\n            SSL,\n            \"_CRYPTOGRAPHY_MANYLINUX1_CA_DIR\",\n            _ffi.string(_lib.X509_get_default_cert_dir())\n        )\n        context.set_default_verify_paths()\n        store = context.get_cert_store()\n        sk_obj = _lib.X509_STORE_get0_objects(store._store)\n        assert sk_obj != _ffi.NULL\n        num = _lib.sk_X509_OBJECT_num(sk_obj)\n        assert num != 0\n\n    def test_check_env_vars(self, monkeypatch):\n        \"\"\"\n        Test that we return True/False appropriately if the env vars are set.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        dir_var = \"CUSTOM_DIR_VAR\"\n        file_var = \"CUSTOM_FILE_VAR\"\n        assert context._check_env_vars_set(dir_var, file_var) is False\n        monkeypatch.setenv(dir_var, \"value\")\n        monkeypatch.setenv(file_var, \"value\")\n        assert context._check_env_vars_set(dir_var, file_var) is True\n        assert context._check_env_vars_set(dir_var, file_var) is True\n\n    def test_verify_no_fallback_if_env_vars_set(self, monkeypatch):\n        \"\"\"\n        Test that we don't use the fallback path if env vars are set.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        monkeypatch.setattr(\n            _lib, \"SSL_CTX_set_default_verify_paths\", lambda x: 1\n        )\n        dir_env_var = _ffi.string(\n            _lib.X509_get_default_cert_dir_env()\n        ).decode(\"ascii\")\n        file_env_var = _ffi.string(\n            _lib.X509_get_default_cert_file_env()\n        ).decode(\"ascii\")\n        monkeypatch.setenv(dir_env_var, \"value\")\n        monkeypatch.setenv(file_env_var, \"value\")\n        context.set_default_verify_paths()\n\n        monkeypatch.setattr(\n            context,\n            \"_fallback_default_verify_paths\",\n            raiser(SystemError)\n        )\n        context.set_default_verify_paths()\n\n    @pytest.mark.skipif(\n        platform == \"win32\",\n        reason=\"set_default_verify_paths appears not to work on Windows.  \"\n        \"See LP#404343 and LP#404344.\"\n    )\n    def test_set_default_verify_paths(self):\n        \"\"\"\n        `Context.set_default_verify_paths` causes the platform-specific CA\n        certificate locations to be used for verification purposes.\n        \"\"\"\n        # Testing this requires a server with a certificate signed by one\n        # of the CAs in the platform CA location.  Getting one of those\n        # costs money.  Fortunately (or unfortunately, depending on your\n        # perspective), it's easy to think of a public server on the\n        # internet which has such a certificate.  Connecting to the network\n        # in a unit test is bad, but it's the only way I can think of to\n        # really test this. -exarkun\n        context = Context(SSLv23_METHOD)\n        context.set_default_verify_paths()\n        context.set_verify(\n            VERIFY_PEER,\n            lambda conn, cert, errno, depth, preverify_ok: preverify_ok)\n\n        client = socket_any_family()\n        client.connect((\"encrypted.google.com\", 443))\n        clientSSL = Connection(context, client)\n        clientSSL.set_connect_state()\n        clientSSL.set_tlsext_host_name(b\"encrypted.google.com\")\n        clientSSL.do_handshake()\n        clientSSL.send(b\"GET / HTTP/1.0\\r\\n\\r\\n\")\n        assert clientSSL.recv(1024)\n\n    def test_fallback_path_is_not_file_or_dir(self):\n        \"\"\"\n        Test that when passed empty arrays or paths that do not exist no\n        errors are raised.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        context._fallback_default_verify_paths([], [])\n        context._fallback_default_verify_paths(\n            [\"/not/a/file\"], [\"/not/a/dir\"]\n        )\n\n    def test_add_extra_chain_cert_invalid_cert(self):\n        \"\"\"\n        `Context.add_extra_chain_cert` raises `TypeError` if called with an\n        object which is not an instance of `X509`.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.add_extra_chain_cert(object())\n\n    def _handshake_test(self, serverContext, clientContext):\n        \"\"\"\n        Verify that a client and server created with the given contexts can\n        successfully handshake and communicate.\n        \"\"\"\n        serverSocket, clientSocket = socket_pair()\n\n        server = Connection(serverContext, serverSocket)\n        server.set_accept_state()\n\n        client = Connection(clientContext, clientSocket)\n        client.set_connect_state()\n\n        # Make them talk to each other.\n        # interact_in_memory(client, server)\n        for _ in range(3):\n            for s in [client, server]:\n                try:\n                    s.do_handshake()\n                except WantReadError:\n                    pass\n\n    def test_set_verify_callback_connection_argument(self):\n        \"\"\"\n        The first argument passed to the verify callback is the\n        `Connection` instance for which verification is taking place.\n        \"\"\"\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_privatekey(\n            load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM))\n        serverContext.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM))\n        serverConnection = Connection(serverContext, None)\n\n        class VerifyCallback(object):\n            def callback(self, connection, *args):\n                self.connection = connection\n                return 1\n\n        verify = VerifyCallback()\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.set_verify(VERIFY_PEER, verify.callback)\n        clientConnection = Connection(clientContext, None)\n        clientConnection.set_connect_state()\n\n        handshake_in_memory(clientConnection, serverConnection)\n\n        assert verify.connection is clientConnection\n\n    def test_x509_in_verify_works(self):\n        \"\"\"\n        We had a bug where the X509 cert instantiated in the callback wrapper\n        didn't __init__ so it was missing objects needed when calling\n        get_subject. This test sets up a handshake where we call get_subject\n        on the cert provided to the verify callback.\n        \"\"\"\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_privatekey(\n            load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM))\n        serverContext.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM))\n        serverConnection = Connection(serverContext, None)\n\n        def verify_cb_get_subject(conn, cert, errnum, depth, ok):\n            assert cert.get_subject()\n            return 1\n\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.set_verify(VERIFY_PEER, verify_cb_get_subject)\n        clientConnection = Connection(clientContext, None)\n        clientConnection.set_connect_state()\n\n        handshake_in_memory(clientConnection, serverConnection)\n\n    def test_set_verify_callback_exception(self):\n        \"\"\"\n        If the verify callback passed to `Context.set_verify` raises an\n        exception, verification fails and the exception is propagated to the\n        caller of `Connection.do_handshake`.\n        \"\"\"\n        serverContext = Context(TLSv1_2_METHOD)\n        serverContext.use_privatekey(\n            load_privatekey(FILETYPE_PEM, cleartextPrivateKeyPEM))\n        serverContext.use_certificate(\n            load_certificate(FILETYPE_PEM, cleartextCertificatePEM))\n\n        clientContext = Context(TLSv1_2_METHOD)\n\n        def verify_callback(*args):\n            raise Exception(\"silly verify failure\")\n        clientContext.set_verify(VERIFY_PEER, verify_callback)\n\n        with pytest.raises(Exception) as exc:\n            self._handshake_test(serverContext, clientContext)\n\n        assert \"silly verify failure\" == str(exc.value)\n\n    def test_add_extra_chain_cert(self, tmpdir):\n        \"\"\"\n        `Context.add_extra_chain_cert` accepts an `X509`\n        instance to add to the certificate chain.\n\n        See `_create_certificate_chain` for the details of the\n        certificate chain tested.\n\n        The chain is tested by starting a server with scert and connecting\n        to it with a client which trusts cacert and requires verification to\n        succeed.\n        \"\"\"\n        chain = _create_certificate_chain()\n        [(cakey, cacert), (ikey, icert), (skey, scert)] = chain\n\n        # Dump the CA certificate to a file because that's the only way to load\n        # it as a trusted CA in the client context.\n        for cert, name in [(cacert, 'ca.pem'),\n                           (icert, 'i.pem'),\n                           (scert, 's.pem')]:\n            with tmpdir.join(name).open('w') as f:\n                f.write(dump_certificate(FILETYPE_PEM, cert).decode('ascii'))\n\n        for key, name in [(cakey, 'ca.key'),\n                          (ikey, 'i.key'),\n                          (skey, 's.key')]:\n            with tmpdir.join(name).open('w') as f:\n                f.write(dump_privatekey(FILETYPE_PEM, key).decode('ascii'))\n\n        # Create the server context\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_privatekey(skey)\n        serverContext.use_certificate(scert)\n        # The client already has cacert, we only need to give them icert.\n        serverContext.add_extra_chain_cert(icert)\n\n        # Create the client\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.set_verify(\n            VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT, verify_cb)\n        clientContext.load_verify_locations(str(tmpdir.join(\"ca.pem\")))\n\n        # Try it out.\n        self._handshake_test(serverContext, clientContext)\n\n    def _use_certificate_chain_file_test(self, certdir):\n        \"\"\"\n        Verify that `Context.use_certificate_chain_file` reads a\n        certificate chain from a specified file.\n\n        The chain is tested by starting a server with scert and connecting to\n        it with a client which trusts cacert and requires verification to\n        succeed.\n        \"\"\"\n        chain = _create_certificate_chain()\n        [(cakey, cacert), (ikey, icert), (skey, scert)] = chain\n\n        makedirs(certdir)\n\n        chainFile = join_bytes_or_unicode(certdir, \"chain.pem\")\n        caFile = join_bytes_or_unicode(certdir, \"ca.pem\")\n\n        # Write out the chain file.\n        with open(chainFile, 'wb') as fObj:\n            # Most specific to least general.\n            fObj.write(dump_certificate(FILETYPE_PEM, scert))\n            fObj.write(dump_certificate(FILETYPE_PEM, icert))\n            fObj.write(dump_certificate(FILETYPE_PEM, cacert))\n\n        with open(caFile, 'w') as fObj:\n            fObj.write(dump_certificate(FILETYPE_PEM, cacert).decode('ascii'))\n\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_certificate_chain_file(chainFile)\n        serverContext.use_privatekey(skey)\n\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.set_verify(\n            VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT, verify_cb)\n        clientContext.load_verify_locations(caFile)\n\n        self._handshake_test(serverContext, clientContext)\n\n    def test_use_certificate_chain_file_bytes(self, tmpfile):\n        \"\"\"\n        ``Context.use_certificate_chain_file`` accepts the name of a file (as\n        an instance of ``bytes``) to specify additional certificates to use to\n        construct and verify a trust chain.\n        \"\"\"\n        self._use_certificate_chain_file_test(\n            tmpfile + NON_ASCII.encode(getfilesystemencoding())\n        )\n\n    def test_use_certificate_chain_file_unicode(self, tmpfile):\n        \"\"\"\n        ``Context.use_certificate_chain_file`` accepts the name of a file (as\n        an instance of ``unicode``) to specify additional certificates to use\n        to construct and verify a trust chain.\n        \"\"\"\n        self._use_certificate_chain_file_test(\n            tmpfile.decode(getfilesystemencoding()) + NON_ASCII\n        )\n\n    def test_use_certificate_chain_file_wrong_args(self):\n        \"\"\"\n        `Context.use_certificate_chain_file` raises `TypeError` if passed a\n        non-byte string single argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.use_certificate_chain_file(object())\n\n    def test_use_certificate_chain_file_missing_file(self, tmpfile):\n        \"\"\"\n        `Context.use_certificate_chain_file` raises `OpenSSL.SSL.Error` when\n        passed a bad chain file name (for example, the name of a file which\n        does not exist).\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            context.use_certificate_chain_file(tmpfile)\n\n    def test_set_verify_mode(self):\n        \"\"\"\n        `Context.get_verify_mode` returns the verify mode flags previously\n        passed to `Context.set_verify`.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        assert context.get_verify_mode() == 0\n        context.set_verify(\n            VERIFY_PEER | VERIFY_CLIENT_ONCE, lambda *args: None)\n        assert context.get_verify_mode() == (VERIFY_PEER | VERIFY_CLIENT_ONCE)\n\n    @pytest.mark.parametrize('mode', [None, 1.0, object(), 'mode'])\n    def test_set_verify_wrong_mode_arg(self, mode):\n        \"\"\"\n        `Context.set_verify` raises `TypeError` if the first argument is\n        not an integer.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_verify(mode=mode, callback=lambda *args: None)\n\n    @pytest.mark.parametrize('callback', [None, 1.0, 'mode', ('foo', 'bar')])\n    def test_set_verify_wrong_callable_arg(self, callback):\n        \"\"\"\n        `Context.set_verify` raises `TypeError` if the second argument\n        is not callable.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_verify(mode=VERIFY_PEER, callback=callback)\n\n    def test_load_tmp_dh_wrong_args(self):\n        \"\"\"\n        `Context.load_tmp_dh` raises `TypeError` if called with a\n        non-`str` argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.load_tmp_dh(object())\n\n    def test_load_tmp_dh_missing_file(self):\n        \"\"\"\n        `Context.load_tmp_dh` raises `OpenSSL.SSL.Error` if the\n        specified file does not exist.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            context.load_tmp_dh(b\"hello\")\n\n    def _load_tmp_dh_test(self, dhfilename):\n        \"\"\"\n        Verify that calling ``Context.load_tmp_dh`` with the given filename\n        does not raise an exception.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with open(dhfilename, \"w\") as dhfile:\n            dhfile.write(dhparam)\n\n        context.load_tmp_dh(dhfilename)\n        # XXX What should I assert here? -exarkun\n\n    def test_load_tmp_dh_bytes(self, tmpfile):\n        \"\"\"\n        `Context.load_tmp_dh` loads Diffie-Hellman parameters from the\n        specified file (given as ``bytes``).\n        \"\"\"\n        self._load_tmp_dh_test(\n            tmpfile + NON_ASCII.encode(getfilesystemencoding()),\n        )\n\n    def test_load_tmp_dh_unicode(self, tmpfile):\n        \"\"\"\n        `Context.load_tmp_dh` loads Diffie-Hellman parameters from the\n        specified file (given as ``unicode``).\n        \"\"\"\n        self._load_tmp_dh_test(\n            tmpfile.decode(getfilesystemencoding()) + NON_ASCII,\n        )\n\n    def test_set_tmp_ecdh(self):\n        \"\"\"\n        `Context.set_tmp_ecdh` sets the elliptic curve for Diffie-Hellman to\n        the specified curve.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        for curve in get_elliptic_curves():\n            if curve.name.startswith(u\"Oakley-\"):\n                # Setting Oakley-EC2N-4 and Oakley-EC2N-3 adds\n                # ('bignum routines', 'BN_mod_inverse', 'no inverse') to the\n                # error queue on OpenSSL 1.0.2.\n                continue\n            # The only easily \"assertable\" thing is that it does not raise an\n            # exception.\n            context.set_tmp_ecdh(curve)\n\n    def test_set_session_cache_mode_wrong_args(self):\n        \"\"\"\n        `Context.set_session_cache_mode` raises `TypeError` if called with\n        a non-integer argument.\n        called with other than one integer argument.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_session_cache_mode(object())\n\n    def test_session_cache_mode(self):\n        \"\"\"\n        `Context.set_session_cache_mode` specifies how sessions are cached.\n        The setting can be retrieved via `Context.get_session_cache_mode`.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        context.set_session_cache_mode(SESS_CACHE_OFF)\n        off = context.set_session_cache_mode(SESS_CACHE_BOTH)\n        assert SESS_CACHE_OFF == off\n        assert SESS_CACHE_BOTH == context.get_session_cache_mode()\n\n    def test_get_cert_store(self):\n        \"\"\"\n        `Context.get_cert_store` returns a `X509Store` instance.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        store = context.get_cert_store()\n        assert isinstance(store, X509Store)\n\n    def test_set_tlsext_use_srtp_not_bytes(self):\n        \"\"\"\n        `Context.set_tlsext_use_srtp' enables negotiating SRTP keying material.\n\n        It raises a TypeError if the list of profiles is not a byte string.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            context.set_tlsext_use_srtp(text_type('SRTP_AES128_CM_SHA1_80'))\n\n    def test_set_tlsext_use_srtp_invalid_profile(self):\n        \"\"\"\n        `Context.set_tlsext_use_srtp' enables negotiating SRTP keying material.\n\n        It raises an Error if the call to OpenSSL fails.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        with pytest.raises(Error):\n            context.set_tlsext_use_srtp(b'SRTP_BOGUS')\n\n    def test_set_tlsext_use_srtp_valid(self):\n        \"\"\"\n        `Context.set_tlsext_use_srtp' enables negotiating SRTP keying material.\n\n        It does not return anything.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        assert context.set_tlsext_use_srtp(b'SRTP_AES128_CM_SHA1_80') is None\n\n\nclass TestServerNameCallback(object):\n    \"\"\"\n    Tests for `Context.set_tlsext_servername_callback` and its\n    interaction with `Connection`.\n    \"\"\"\n    def test_old_callback_forgotten(self):\n        \"\"\"\n        If `Context.set_tlsext_servername_callback` is used to specify\n        a new callback, the one it replaces is dereferenced.\n        \"\"\"\n        def callback(connection):  # pragma: no cover\n            pass\n\n        def replacement(connection):  # pragma: no cover\n            pass\n\n        context = Context(TLSv1_METHOD)\n        context.set_tlsext_servername_callback(callback)\n\n        tracker = ref(callback)\n        del callback\n\n        context.set_tlsext_servername_callback(replacement)\n\n        # One run of the garbage collector happens to work on CPython.  PyPy\n        # doesn't collect the underlying object until a second run for whatever\n        # reason.  That's fine, it still demonstrates our code has properly\n        # dropped the reference.\n        collect()\n        collect()\n\n        callback = tracker()\n        if callback is not None:\n            referrers = get_referrers(callback)\n            if len(referrers) > 1:  # pragma: nocover\n                pytest.fail(\"Some references remain: %r\" % (referrers,))\n\n    def test_no_servername(self):\n        \"\"\"\n        When a client specifies no server name, the callback passed to\n        `Context.set_tlsext_servername_callback` is invoked and the\n        result of `Connection.get_servername` is `None`.\n        \"\"\"\n        args = []\n\n        def servername(conn):\n            args.append((conn, conn.get_servername()))\n        context = Context(TLSv1_METHOD)\n        context.set_tlsext_servername_callback(servername)\n\n        # Lose our reference to it.  The Context is responsible for keeping it\n        # alive now.\n        del servername\n        collect()\n\n        # Necessary to actually accept the connection\n        context.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(context, None)\n        server.set_accept_state()\n\n        client = Connection(Context(TLSv1_METHOD), None)\n        client.set_connect_state()\n\n        interact_in_memory(server, client)\n\n        assert args == [(server, None)]\n\n    def test_servername(self):\n        \"\"\"\n        When a client specifies a server name in its hello message, the\n        callback passed to `Contexts.set_tlsext_servername_callback` is\n        invoked and the result of `Connection.get_servername` is that\n        server name.\n        \"\"\"\n        args = []\n\n        def servername(conn):\n            args.append((conn, conn.get_servername()))\n        context = Context(TLSv1_METHOD)\n        context.set_tlsext_servername_callback(servername)\n\n        # Necessary to actually accept the connection\n        context.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(context, None)\n        server.set_accept_state()\n\n        client = Connection(Context(TLSv1_METHOD), None)\n        client.set_connect_state()\n        client.set_tlsext_host_name(b\"foo1.example.com\")\n\n        interact_in_memory(server, client)\n\n        assert args == [(server, b\"foo1.example.com\")]\n\n\n@pytest.mark.skipif(\n    not _lib.Cryptography_HAS_NEXTPROTONEG, reason=\"NPN is not available\"\n)\nclass TestNextProtoNegotiation(object):\n    \"\"\"\n    Test for Next Protocol Negotiation in PyOpenSSL.\n    \"\"\"\n    def test_npn_success(self):\n        \"\"\"\n        Tests that clients and servers that agree on the negotiated next\n        protocol can correct establish a connection, and that the agreed\n        protocol is reported by the connections.\n        \"\"\"\n        advertise_args = []\n        select_args = []\n\n        def advertise(conn):\n            advertise_args.append((conn,))\n            return [b'http/1.1', b'spdy/2']\n\n        def select(conn, options):\n            select_args.append((conn, options))\n            return b'spdy/2'\n\n        server_context = Context(TLSv1_METHOD)\n        server_context.set_npn_advertise_callback(advertise)\n\n        client_context = Context(TLSv1_METHOD)\n        client_context.set_npn_select_callback(select)\n\n        # Necessary to actually accept the connection\n        server_context.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(server_context, None)\n        server.set_accept_state()\n\n        client = Connection(client_context, None)\n        client.set_connect_state()\n\n        interact_in_memory(server, client)\n\n        assert advertise_args == [(server,)]\n        assert select_args == [(client, [b'http/1.1', b'spdy/2'])]\n\n        assert server.get_next_proto_negotiated() == b'spdy/2'\n        assert client.get_next_proto_negotiated() == b'spdy/2'\n\n    def test_npn_client_fail(self):\n        \"\"\"\n        Tests that when clients and servers cannot agree on what protocol\n        to use next that the TLS connection does not get established.\n        \"\"\"\n        advertise_args = []\n        select_args = []\n\n        def advertise(conn):\n            advertise_args.append((conn,))\n            return [b'http/1.1', b'spdy/2']\n\n        def select(conn, options):\n            select_args.append((conn, options))\n            return b''\n\n        server_context = Context(TLSv1_METHOD)\n        server_context.set_npn_advertise_callback(advertise)\n\n        client_context = Context(TLSv1_METHOD)\n        client_context.set_npn_select_callback(select)\n\n        # Necessary to actually accept the connection\n        server_context.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(server_context, None)\n        server.set_accept_state()\n\n        client = Connection(client_context, None)\n        client.set_connect_state()\n\n        # If the client doesn't return anything, the connection will fail.\n        with pytest.raises(Error):\n            interact_in_memory(server, client)\n\n        assert advertise_args == [(server,)]\n        assert select_args == [(client, [b'http/1.1', b'spdy/2'])]\n\n    def test_npn_select_error(self):\n        \"\"\"\n        Test that we can handle exceptions in the select callback. If\n        select fails it should be fatal to the connection.\n        \"\"\"\n        advertise_args = []\n\n        def advertise(conn):\n            advertise_args.append((conn,))\n            return [b'http/1.1', b'spdy/2']\n\n        def select(conn, options):\n            raise TypeError\n\n        server_context = Context(TLSv1_METHOD)\n        server_context.set_npn_advertise_callback(advertise)\n\n        client_context = Context(TLSv1_METHOD)\n        client_context.set_npn_select_callback(select)\n\n        # Necessary to actually accept the connection\n        server_context.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(server_context, None)\n        server.set_accept_state()\n\n        client = Connection(client_context, None)\n        client.set_connect_state()\n\n        # If the callback throws an exception it should be raised here.\n        with pytest.raises(TypeError):\n            interact_in_memory(server, client)\n        assert advertise_args == [(server,), ]\n\n    def test_npn_advertise_error(self):\n        \"\"\"\n        Test that we can handle exceptions in the advertise callback. If\n        advertise fails no NPN is advertised to the client.\n        \"\"\"\n        select_args = []\n\n        def advertise(conn):\n            raise TypeError\n\n        def select(conn, options):  # pragma: nocover\n            \"\"\"\n            Assert later that no args are actually appended.\n            \"\"\"\n            select_args.append((conn, options))\n            return b''\n\n        server_context = Context(TLSv1_METHOD)\n        server_context.set_npn_advertise_callback(advertise)\n\n        client_context = Context(TLSv1_METHOD)\n        client_context.set_npn_select_callback(select)\n\n        # Necessary to actually accept the connection\n        server_context.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_context.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n\n        # Do a little connection to trigger the logic\n        server = Connection(server_context, None)\n        server.set_accept_state()\n\n        client = Connection(client_context, None)\n        client.set_connect_state()\n\n        # If the client doesn't return anything, the connection will fail.\n        with pytest.raises(TypeError):\n            interact_in_memory(server, client)\n        assert select_args == []\n\n\nclass TestApplicationLayerProtoNegotiation(object):\n    \"\"\"\n    Tests for ALPN in PyOpenSSL.\n    \"\"\"\n    # Skip tests on versions that don't support ALPN.\n    if _lib.Cryptography_HAS_ALPN:\n\n        def test_alpn_success(self):\n            \"\"\"\n            Clients and servers that agree on the negotiated ALPN protocol can\n            correct establish a connection, and the agreed protocol is reported\n            by the connections.\n            \"\"\"\n            select_args = []\n\n            def select(conn, options):\n                select_args.append((conn, options))\n                return b'spdy/2'\n\n            client_context = Context(TLSv1_METHOD)\n            client_context.set_alpn_protos([b'http/1.1', b'spdy/2'])\n\n            server_context = Context(TLSv1_METHOD)\n            server_context.set_alpn_select_callback(select)\n\n            # Necessary to actually accept the connection\n            server_context.use_privatekey(\n                load_privatekey(FILETYPE_PEM, server_key_pem))\n            server_context.use_certificate(\n                load_certificate(FILETYPE_PEM, server_cert_pem))\n\n            # Do a little connection to trigger the logic\n            server = Connection(server_context, None)\n            server.set_accept_state()\n\n            client = Connection(client_context, None)\n            client.set_connect_state()\n\n            interact_in_memory(server, client)\n\n            assert select_args == [(server, [b'http/1.1', b'spdy/2'])]\n\n            assert server.get_alpn_proto_negotiated() == b'spdy/2'\n            assert client.get_alpn_proto_negotiated() == b'spdy/2'\n\n        def test_alpn_set_on_connection(self):\n            \"\"\"\n            The same as test_alpn_success, but setting the ALPN protocols on\n            the connection rather than the context.\n            \"\"\"\n            select_args = []\n\n            def select(conn, options):\n                select_args.append((conn, options))\n                return b'spdy/2'\n\n            # Setup the client context but don't set any ALPN protocols.\n            client_context = Context(TLSv1_METHOD)\n\n            server_context = Context(TLSv1_METHOD)\n            server_context.set_alpn_select_callback(select)\n\n            # Necessary to actually accept the connection\n            server_context.use_privatekey(\n                load_privatekey(FILETYPE_PEM, server_key_pem))\n            server_context.use_certificate(\n                load_certificate(FILETYPE_PEM, server_cert_pem))\n\n            # Do a little connection to trigger the logic\n            server = Connection(server_context, None)\n            server.set_accept_state()\n\n            # Set the ALPN protocols on the client connection.\n            client = Connection(client_context, None)\n            client.set_alpn_protos([b'http/1.1', b'spdy/2'])\n            client.set_connect_state()\n\n            interact_in_memory(server, client)\n\n            assert select_args == [(server, [b'http/1.1', b'spdy/2'])]\n\n            assert server.get_alpn_proto_negotiated() == b'spdy/2'\n            assert client.get_alpn_proto_negotiated() == b'spdy/2'\n\n        def test_alpn_server_fail(self):\n            \"\"\"\n            When clients and servers cannot agree on what protocol to use next\n            the TLS connection does not get established.\n            \"\"\"\n            select_args = []\n\n            def select(conn, options):\n                select_args.append((conn, options))\n                return b''\n\n            client_context = Context(TLSv1_METHOD)\n            client_context.set_alpn_protos([b'http/1.1', b'spdy/2'])\n\n            server_context = Context(TLSv1_METHOD)\n            server_context.set_alpn_select_callback(select)\n\n            # Necessary to actually accept the connection\n            server_context.use_privatekey(\n                load_privatekey(FILETYPE_PEM, server_key_pem))\n            server_context.use_certificate(\n                load_certificate(FILETYPE_PEM, server_cert_pem))\n\n            # Do a little connection to trigger the logic\n            server = Connection(server_context, None)\n            server.set_accept_state()\n\n            client = Connection(client_context, None)\n            client.set_connect_state()\n\n            # If the client doesn't return anything, the connection will fail.\n            with pytest.raises(Error):\n                interact_in_memory(server, client)\n\n            assert select_args == [(server, [b'http/1.1', b'spdy/2'])]\n\n        def test_alpn_no_server(self):\n            \"\"\"\n            When clients and servers cannot agree on what protocol to use next\n            because the server doesn't offer ALPN, no protocol is negotiated.\n            \"\"\"\n            client_context = Context(TLSv1_METHOD)\n            client_context.set_alpn_protos([b'http/1.1', b'spdy/2'])\n\n            server_context = Context(TLSv1_METHOD)\n\n            # Necessary to actually accept the connection\n            server_context.use_privatekey(\n                load_privatekey(FILETYPE_PEM, server_key_pem))\n            server_context.use_certificate(\n                load_certificate(FILETYPE_PEM, server_cert_pem))\n\n            # Do a little connection to trigger the logic\n            server = Connection(server_context, None)\n            server.set_accept_state()\n\n            client = Connection(client_context, None)\n            client.set_connect_state()\n\n            # Do the dance.\n            interact_in_memory(server, client)\n\n            assert client.get_alpn_proto_negotiated() == b''\n\n        def test_alpn_callback_exception(self):\n            \"\"\"\n            We can handle exceptions in the ALPN select callback.\n            \"\"\"\n            select_args = []\n\n            def select(conn, options):\n                select_args.append((conn, options))\n                raise TypeError()\n\n            client_context = Context(TLSv1_METHOD)\n            client_context.set_alpn_protos([b'http/1.1', b'spdy/2'])\n\n            server_context = Context(TLSv1_METHOD)\n            server_context.set_alpn_select_callback(select)\n\n            # Necessary to actually accept the connection\n            server_context.use_privatekey(\n                load_privatekey(FILETYPE_PEM, server_key_pem))\n            server_context.use_certificate(\n                load_certificate(FILETYPE_PEM, server_cert_pem))\n\n            # Do a little connection to trigger the logic\n            server = Connection(server_context, None)\n            server.set_accept_state()\n\n            client = Connection(client_context, None)\n            client.set_connect_state()\n\n            with pytest.raises(TypeError):\n                interact_in_memory(server, client)\n            assert select_args == [(server, [b'http/1.1', b'spdy/2'])]\n\n    else:\n        # No ALPN.\n        def test_alpn_not_implemented(self):\n            \"\"\"\n            If ALPN is not in OpenSSL, we should raise NotImplementedError.\n            \"\"\"\n            # Test the context methods first.\n            context = Context(TLSv1_METHOD)\n            with pytest.raises(NotImplementedError):\n                context.set_alpn_protos(None)\n            with pytest.raises(NotImplementedError):\n                context.set_alpn_select_callback(None)\n\n            # Now test a connection.\n            conn = Connection(context)\n            with pytest.raises(NotImplementedError):\n                conn.set_alpn_protos(None)\n\n\nclass TestSession(object):\n    \"\"\"\n    Unit tests for :py:obj:`OpenSSL.SSL.Session`.\n    \"\"\"\n    def test_construction(self):\n        \"\"\"\n        :py:class:`Session` can be constructed with no arguments, creating\n        a new instance of that type.\n        \"\"\"\n        new_session = Session()\n        assert isinstance(new_session, Session)\n\n\nclass TestConnection(object):\n    \"\"\"\n    Unit tests for `OpenSSL.SSL.Connection`.\n    \"\"\"\n    # XXX get_peer_certificate -> None\n    # XXX sock_shutdown\n    # XXX master_key -> TypeError\n    # XXX server_random -> TypeError\n    # XXX connect -> TypeError\n    # XXX connect_ex -> TypeError\n    # XXX set_connect_state -> TypeError\n    # XXX set_accept_state -> TypeError\n    # XXX do_handshake -> TypeError\n    # XXX bio_read -> TypeError\n    # XXX recv -> TypeError\n    # XXX send -> TypeError\n    # XXX bio_write -> TypeError\n\n    def test_type(self):\n        \"\"\"\n        `Connection` can be used to create instances of that type.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        assert is_consistent_type(Connection, 'Connection', ctx, None)\n\n    @pytest.mark.parametrize('bad_context', [object(), 'context', None, 1])\n    def test_wrong_args(self, bad_context):\n        \"\"\"\n        `Connection.__init__` raises `TypeError` if called with a non-`Context`\n        instance argument.\n        \"\"\"\n        with pytest.raises(TypeError):\n            Connection(bad_context)\n\n    def test_get_context(self):\n        \"\"\"\n        `Connection.get_context` returns the `Context` instance used to\n        construct the `Connection` instance.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        connection = Connection(context, None)\n        assert connection.get_context() is context\n\n    def test_set_context_wrong_args(self):\n        \"\"\"\n        `Connection.set_context` raises `TypeError` if called with a\n        non-`Context` instance argument.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        connection = Connection(ctx, None)\n        with pytest.raises(TypeError):\n            connection.set_context(object())\n        with pytest.raises(TypeError):\n            connection.set_context(\"hello\")\n        with pytest.raises(TypeError):\n            connection.set_context(1)\n        assert ctx is connection.get_context()\n\n    def test_set_context(self):\n        \"\"\"\n        `Connection.set_context` specifies a new `Context` instance to be\n        used for the connection.\n        \"\"\"\n        original = Context(SSLv23_METHOD)\n        replacement = Context(TLSv1_METHOD)\n        connection = Connection(original, None)\n        connection.set_context(replacement)\n        assert replacement is connection.get_context()\n        # Lose our references to the contexts, just in case the Connection\n        # isn't properly managing its own contributions to their reference\n        # counts.\n        del original, replacement\n        collect()\n\n    def test_set_tlsext_host_name_wrong_args(self):\n        \"\"\"\n        If `Connection.set_tlsext_host_name` is called with a non-byte string\n        argument or a byte string with an embedded NUL, `TypeError` is raised.\n        \"\"\"\n        conn = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(TypeError):\n            conn.set_tlsext_host_name(object())\n        with pytest.raises(TypeError):\n            conn.set_tlsext_host_name(b\"with\\0null\")\n\n        if PY3:\n            # On Python 3.x, don't accidentally implicitly convert from text.\n            with pytest.raises(TypeError):\n                conn.set_tlsext_host_name(b\"example.com\".decode(\"ascii\"))\n\n    def test_pending(self):\n        \"\"\"\n        `Connection.pending` returns the number of bytes available for\n        immediate read.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        assert connection.pending() == 0\n\n    def test_peek(self):\n        \"\"\"\n        `Connection.recv` peeks into the connection if `socket.MSG_PEEK` is\n        passed.\n        \"\"\"\n        server, client = loopback()\n        server.send(b'xy')\n        assert client.recv(2, MSG_PEEK) == b'xy'\n        assert client.recv(2, MSG_PEEK) == b'xy'\n        assert client.recv(2) == b'xy'\n\n    def test_connect_wrong_args(self):\n        \"\"\"\n        `Connection.connect` raises `TypeError` if called with a non-address\n        argument.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), socket_any_family())\n        with pytest.raises(TypeError):\n            connection.connect(None)\n\n    def test_connect_refused(self):\n        \"\"\"\n        `Connection.connect` raises `socket.error` if the underlying socket\n        connect method raises it.\n        \"\"\"\n        client = socket_any_family()\n        context = Context(TLSv1_METHOD)\n        clientSSL = Connection(context, client)\n        # pytest.raises here doesn't work because of a bug in py.test on Python\n        # 2.6: https://github.com/pytest-dev/pytest/issues/988\n        try:\n            clientSSL.connect((loopback_address(client), 1))\n        except error as e:\n            exc = e\n        assert exc.args[0] == ECONNREFUSED\n\n    def test_connect(self):\n        \"\"\"\n        `Connection.connect` establishes a connection to the specified address.\n        \"\"\"\n        port = socket_any_family()\n        port.bind(('', 0))\n        port.listen(3)\n\n        clientSSL = Connection(Context(TLSv1_METHOD), socket(port.family))\n        clientSSL.connect((loopback_address(port), port.getsockname()[1]))\n        # XXX An assertion?  Or something?\n\n    @pytest.mark.skipif(\n        platform == \"darwin\",\n        reason=\"connect_ex sometimes causes a kernel panic on OS X 10.6.4\"\n    )\n    def test_connect_ex(self):\n        \"\"\"\n        If there is a connection error, `Connection.connect_ex` returns the\n        errno instead of raising an exception.\n        \"\"\"\n        port = socket_any_family()\n        port.bind(('', 0))\n        port.listen(3)\n\n        clientSSL = Connection(Context(TLSv1_METHOD), socket(port.family))\n        clientSSL.setblocking(False)\n        result = clientSSL.connect_ex(port.getsockname())\n        expected = (EINPROGRESS, EWOULDBLOCK)\n        assert result in expected\n\n    def test_accept(self):\n        \"\"\"\n        `Connection.accept` accepts a pending connection attempt and returns a\n        tuple of a new `Connection` (the accepted client) and the address the\n        connection originated from.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        ctx.use_certificate(load_certificate(FILETYPE_PEM, server_cert_pem))\n        port = socket_any_family()\n        portSSL = Connection(ctx, port)\n        portSSL.bind(('', 0))\n        portSSL.listen(3)\n\n        clientSSL = Connection(Context(TLSv1_METHOD), socket(port.family))\n\n        # Calling portSSL.getsockname() here to get the server IP address\n        # sounds great, but frequently fails on Windows.\n        clientSSL.connect((loopback_address(port), portSSL.getsockname()[1]))\n\n        serverSSL, address = portSSL.accept()\n\n        assert isinstance(serverSSL, Connection)\n        assert serverSSL.get_context() is ctx\n        assert address == clientSSL.getsockname()\n\n    def test_shutdown_wrong_args(self):\n        \"\"\"\n        `Connection.set_shutdown` raises `TypeError` if called with arguments\n        other than integers.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(TypeError):\n            connection.set_shutdown(None)\n\n    def test_shutdown(self):\n        \"\"\"\n        `Connection.shutdown` performs an SSL-level connection shutdown.\n        \"\"\"\n        server, client = loopback()\n        assert not server.shutdown()\n        assert server.get_shutdown() == SENT_SHUTDOWN\n        with pytest.raises(ZeroReturnError):\n            client.recv(1024)\n        assert client.get_shutdown() == RECEIVED_SHUTDOWN\n        client.shutdown()\n        assert client.get_shutdown() == (SENT_SHUTDOWN | RECEIVED_SHUTDOWN)\n        with pytest.raises(ZeroReturnError):\n            server.recv(1024)\n        assert server.get_shutdown() == (SENT_SHUTDOWN | RECEIVED_SHUTDOWN)\n\n    def test_shutdown_closed(self):\n        \"\"\"\n        If the underlying socket is closed, `Connection.shutdown` propagates\n        the write error from the low level write call.\n        \"\"\"\n        server, client = loopback()\n        server.sock_shutdown(2)\n        with pytest.raises(SysCallError) as exc:\n            server.shutdown()\n        if platform == \"win32\":\n            assert exc.value.args[0] == ESHUTDOWN\n        else:\n            assert exc.value.args[0] == EPIPE\n\n    def test_shutdown_truncated(self):\n        \"\"\"\n        If the underlying connection is truncated, `Connection.shutdown`\n        raises an `Error`.\n        \"\"\"\n        server_ctx = Context(TLSv1_METHOD)\n        client_ctx = Context(TLSv1_METHOD)\n        server_ctx.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_ctx.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n        server = Connection(server_ctx, None)\n        client = Connection(client_ctx, None)\n        handshake_in_memory(client, server)\n        assert not server.shutdown()\n        with pytest.raises(WantReadError):\n            server.shutdown()\n        server.bio_shutdown()\n        with pytest.raises(Error):\n            server.shutdown()\n\n    def test_set_shutdown(self):\n        \"\"\"\n        `Connection.set_shutdown` sets the state of the SSL connection\n        shutdown process.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), socket_any_family())\n        connection.set_shutdown(RECEIVED_SHUTDOWN)\n        assert connection.get_shutdown() == RECEIVED_SHUTDOWN\n\n    def test_state_string(self):\n        \"\"\"\n        `Connection.state_string` verbosely describes the current state of\n        the `Connection`.\n        \"\"\"\n        server, client = socket_pair()\n        server = loopback_server_factory(server)\n        client = loopback_client_factory(client)\n\n        assert server.get_state_string() in [\n            b\"before/accept initialization\", b\"before SSL initialization\"\n        ]\n        assert client.get_state_string() in [\n            b\"before/connect initialization\", b\"before SSL initialization\"\n        ]\n\n    def test_app_data(self):\n        \"\"\"\n        Any object can be set as app data by passing it to\n        `Connection.set_app_data` and later retrieved with\n        `Connection.get_app_data`.\n        \"\"\"\n        conn = Connection(Context(TLSv1_METHOD), None)\n        assert None is conn.get_app_data()\n        app_data = object()\n        conn.set_app_data(app_data)\n        assert conn.get_app_data() is app_data\n\n    def test_makefile(self):\n        \"\"\"\n        `Connection.makefile` is not implemented and calling that\n        method raises `NotImplementedError`.\n        \"\"\"\n        conn = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(NotImplementedError):\n            conn.makefile()\n\n    def test_get_certificate(self):\n        \"\"\"\n        `Connection.get_certificate` returns the local certificate.\n        \"\"\"\n        chain = _create_certificate_chain()\n        [(cakey, cacert), (ikey, icert), (skey, scert)] = chain\n\n        context = Context(TLSv1_METHOD)\n        context.use_certificate(scert)\n        client = Connection(context, None)\n        cert = client.get_certificate()\n        assert cert is not None\n        assert \"Server Certificate\" == cert.get_subject().CN\n\n    def test_get_certificate_none(self):\n        \"\"\"\n        `Connection.get_certificate` returns the local certificate.\n\n        If there is no certificate, it returns None.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        client = Connection(context, None)\n        cert = client.get_certificate()\n        assert cert is None\n\n    def test_get_peer_cert_chain(self):\n        \"\"\"\n        `Connection.get_peer_cert_chain` returns a list of certificates\n        which the connected server returned for the certification verification.\n        \"\"\"\n        chain = _create_certificate_chain()\n        [(cakey, cacert), (ikey, icert), (skey, scert)] = chain\n\n        serverContext = Context(TLSv1_METHOD)\n        serverContext.use_privatekey(skey)\n        serverContext.use_certificate(scert)\n        serverContext.add_extra_chain_cert(icert)\n        serverContext.add_extra_chain_cert(cacert)\n        server = Connection(serverContext, None)\n        server.set_accept_state()\n\n        # Create the client\n        clientContext = Context(TLSv1_METHOD)\n        clientContext.set_verify(VERIFY_NONE, verify_cb)\n        client = Connection(clientContext, None)\n        client.set_connect_state()\n\n        interact_in_memory(client, server)\n\n        chain = client.get_peer_cert_chain()\n        assert len(chain) == 3\n        assert \"Server Certificate\" == chain[0].get_subject().CN\n        assert \"Intermediate Certificate\" == chain[1].get_subject().CN\n        assert \"Authority Certificate\" == chain[2].get_subject().CN\n\n    def test_get_peer_cert_chain_none(self):\n        \"\"\"\n        `Connection.get_peer_cert_chain` returns `None` if the peer sends\n        no certificate chain.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        ctx.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        ctx.use_certificate(load_certificate(FILETYPE_PEM, server_cert_pem))\n        server = Connection(ctx, None)\n        server.set_accept_state()\n        client = Connection(Context(TLSv1_METHOD), None)\n        client.set_connect_state()\n        interact_in_memory(client, server)\n        assert None is server.get_peer_cert_chain()\n\n    def test_get_session_unconnected(self):\n        \"\"\"\n        `Connection.get_session` returns `None` when used with an object\n        which has not been connected.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        server = Connection(ctx, None)\n        session = server.get_session()\n        assert None is session\n\n    def test_server_get_session(self):\n        \"\"\"\n        On the server side of a connection, `Connection.get_session` returns a\n        `Session` instance representing the SSL session for that connection.\n        \"\"\"\n        server, client = loopback()\n        session = server.get_session()\n        assert isinstance(session, Session)\n\n    def test_client_get_session(self):\n        \"\"\"\n        On the client side of a connection, `Connection.get_session`\n        returns a `Session` instance representing the SSL session for\n        that connection.\n        \"\"\"\n        server, client = loopback()\n        session = client.get_session()\n        assert isinstance(session, Session)\n\n    def test_set_session_wrong_args(self):\n        \"\"\"\n        `Connection.set_session` raises `TypeError` if called with an object\n        that is not an instance of `Session`.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        connection = Connection(ctx, None)\n        with pytest.raises(TypeError):\n            connection.set_session(123)\n        with pytest.raises(TypeError):\n            connection.set_session(\"hello\")\n        with pytest.raises(TypeError):\n            connection.set_session(object())\n\n    def test_client_set_session(self):\n        \"\"\"\n        `Connection.set_session`, when used prior to a connection being\n        established, accepts a `Session` instance and causes an attempt to\n        re-use the session it represents when the SSL handshake is performed.\n        \"\"\"\n        key = load_privatekey(FILETYPE_PEM, server_key_pem)\n        cert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        ctx = Context(TLSv1_2_METHOD)\n        ctx.use_privatekey(key)\n        ctx.use_certificate(cert)\n        ctx.set_session_id(\"unity-test\")\n\n        def makeServer(socket):\n            server = Connection(ctx, socket)\n            server.set_accept_state()\n            return server\n\n        originalServer, originalClient = loopback(\n            server_factory=makeServer)\n        originalSession = originalClient.get_session()\n\n        def makeClient(socket):\n            client = loopback_client_factory(socket)\n            client.set_session(originalSession)\n            return client\n        resumedServer, resumedClient = loopback(\n            server_factory=makeServer,\n            client_factory=makeClient)\n\n        # This is a proxy: in general, we have no access to any unique\n        # identifier for the session (new enough versions of OpenSSL expose\n        # a hash which could be usable, but \"new enough\" is very, very new).\n        # Instead, exploit the fact that the master key is re-used if the\n        # session is re-used.  As long as the master key for the two\n        # connections is the same, the session was re-used!\n        assert originalServer.master_key() == resumedServer.master_key()\n\n    def test_set_session_wrong_method(self):\n        \"\"\"\n        If `Connection.set_session` is passed a `Session` instance associated\n        with a context using a different SSL method than the `Connection`\n        is using, a `OpenSSL.SSL.Error` is raised.\n        \"\"\"\n        # Make this work on both OpenSSL 1.0.0, which doesn't support TLSv1.2\n        # and also on OpenSSL 1.1.0 which doesn't support SSLv3. (SSL_ST_INIT\n        # is a way to check for 1.1.0)\n        if SSL_ST_INIT is None:\n            v1 = TLSv1_2_METHOD\n            v2 = TLSv1_METHOD\n        elif hasattr(_lib, \"SSLv3_method\"):\n            v1 = TLSv1_METHOD\n            v2 = SSLv3_METHOD\n        else:\n            pytest.skip(\"Test requires either OpenSSL 1.1.0 or SSLv3\")\n\n        key = load_privatekey(FILETYPE_PEM, server_key_pem)\n        cert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        ctx = Context(v1)\n        ctx.use_privatekey(key)\n        ctx.use_certificate(cert)\n        ctx.set_session_id(\"unity-test\")\n\n        def makeServer(socket):\n            server = Connection(ctx, socket)\n            server.set_accept_state()\n            return server\n\n        def makeOriginalClient(socket):\n            client = Connection(Context(v1), socket)\n            client.set_connect_state()\n            return client\n\n        originalServer, originalClient = loopback(\n            server_factory=makeServer, client_factory=makeOriginalClient)\n        originalSession = originalClient.get_session()\n\n        def makeClient(socket):\n            # Intentionally use a different, incompatible method here.\n            client = Connection(Context(v2), socket)\n            client.set_connect_state()\n            client.set_session(originalSession)\n            return client\n\n        with pytest.raises(Error):\n            loopback(client_factory=makeClient, server_factory=makeServer)\n\n    def test_wantWriteError(self):\n        \"\"\"\n        `Connection` methods which generate output raise\n        `OpenSSL.SSL.WantWriteError` if writing to the connection's BIO\n        fail indicating a should-write state.\n        \"\"\"\n        client_socket, server_socket = socket_pair()\n        # Fill up the client's send buffer so Connection won't be able to write\n        # anything.  Only write a single byte at a time so we can be sure we\n        # completely fill the buffer.  Even though the socket API is allowed to\n        # signal a short write via its return value it seems this doesn't\n        # always happen on all platforms (FreeBSD and OS X particular) for the\n        # very last bit of available buffer space.\n        msg = b\"x\"\n        for i in range(1024 * 1024 * 64):\n            try:\n                client_socket.send(msg)\n            except error as e:\n                if e.errno == EWOULDBLOCK:\n                    break\n                raise\n        else:\n            pytest.fail(\n                \"Failed to fill socket buffer, cannot test BIO want write\")\n\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, client_socket)\n        # Client's speak first, so make it an SSL client\n        conn.set_connect_state()\n        with pytest.raises(WantWriteError):\n            conn.do_handshake()\n\n    # XXX want_read\n\n    def test_get_finished_before_connect(self):\n        \"\"\"\n        `Connection.get_finished` returns `None` before TLS handshake\n        is completed.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        connection = Connection(ctx, None)\n        assert connection.get_finished() is None\n\n    def test_get_peer_finished_before_connect(self):\n        \"\"\"\n        `Connection.get_peer_finished` returns `None` before TLS handshake\n        is completed.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        connection = Connection(ctx, None)\n        assert connection.get_peer_finished() is None\n\n    def test_get_finished(self):\n        \"\"\"\n        `Connection.get_finished` method returns the TLS Finished message send\n        from client, or server. Finished messages are send during\n        TLS handshake.\n        \"\"\"\n        server, client = loopback()\n\n        assert server.get_finished() is not None\n        assert len(server.get_finished()) > 0\n\n    def test_get_peer_finished(self):\n        \"\"\"\n        `Connection.get_peer_finished` method returns the TLS Finished\n        message received from client, or server. Finished messages are send\n        during TLS handshake.\n        \"\"\"\n        server, client = loopback()\n\n        assert server.get_peer_finished() is not None\n        assert len(server.get_peer_finished()) > 0\n\n    def test_tls_finished_message_symmetry(self):\n        \"\"\"\n        The TLS Finished message send by server must be the TLS Finished\n        message received by client.\n\n        The TLS Finished message send by client must be the TLS Finished\n        message received by server.\n        \"\"\"\n        server, client = loopback()\n\n        assert server.get_finished() == client.get_peer_finished()\n        assert client.get_finished() == server.get_peer_finished()\n\n    def test_get_cipher_name_before_connect(self):\n        \"\"\"\n        `Connection.get_cipher_name` returns `None` if no connection\n        has been established.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        assert conn.get_cipher_name() is None\n\n    def test_get_cipher_name(self):\n        \"\"\"\n        `Connection.get_cipher_name` returns a `unicode` string giving the\n        name of the currently used cipher.\n        \"\"\"\n        server, client = loopback()\n        server_cipher_name, client_cipher_name = \\\n            server.get_cipher_name(), client.get_cipher_name()\n\n        assert isinstance(server_cipher_name, text_type)\n        assert isinstance(client_cipher_name, text_type)\n\n        assert server_cipher_name == client_cipher_name\n\n    def test_get_cipher_version_before_connect(self):\n        \"\"\"\n        `Connection.get_cipher_version` returns `None` if no connection\n        has been established.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        assert conn.get_cipher_version() is None\n\n    def test_get_cipher_version(self):\n        \"\"\"\n        `Connection.get_cipher_version` returns a `unicode` string giving\n        the protocol name of the currently used cipher.\n        \"\"\"\n        server, client = loopback()\n        server_cipher_version, client_cipher_version = \\\n            server.get_cipher_version(), client.get_cipher_version()\n\n        assert isinstance(server_cipher_version, text_type)\n        assert isinstance(client_cipher_version, text_type)\n\n        assert server_cipher_version == client_cipher_version\n\n    def test_get_cipher_bits_before_connect(self):\n        \"\"\"\n        `Connection.get_cipher_bits` returns `None` if no connection has\n        been established.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        assert conn.get_cipher_bits() is None\n\n    def test_get_cipher_bits(self):\n        \"\"\"\n        `Connection.get_cipher_bits` returns the number of secret bits\n        of the currently used cipher.\n        \"\"\"\n        server, client = loopback()\n        server_cipher_bits, client_cipher_bits = \\\n            server.get_cipher_bits(), client.get_cipher_bits()\n\n        assert isinstance(server_cipher_bits, int)\n        assert isinstance(client_cipher_bits, int)\n\n        assert server_cipher_bits == client_cipher_bits\n\n    def test_get_protocol_version_name(self):\n        \"\"\"\n        `Connection.get_protocol_version_name()` returns a string giving the\n        protocol version of the current connection.\n        \"\"\"\n        server, client = loopback()\n        client_protocol_version_name = client.get_protocol_version_name()\n        server_protocol_version_name = server.get_protocol_version_name()\n\n        assert isinstance(server_protocol_version_name, text_type)\n        assert isinstance(client_protocol_version_name, text_type)\n\n        assert server_protocol_version_name == client_protocol_version_name\n\n    def test_get_protocol_version(self):\n        \"\"\"\n        `Connection.get_protocol_version()` returns an integer\n        giving the protocol version of the current connection.\n        \"\"\"\n        server, client = loopback()\n        client_protocol_version = client.get_protocol_version()\n        server_protocol_version = server.get_protocol_version()\n\n        assert isinstance(server_protocol_version, int)\n        assert isinstance(client_protocol_version, int)\n\n        assert server_protocol_version == client_protocol_version\n\n    def test_wantReadError(self):\n        \"\"\"\n        `Connection.bio_read` raises `OpenSSL.SSL.WantReadError` if there are\n        no bytes available to be read from the BIO.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        with pytest.raises(WantReadError):\n            conn.bio_read(1024)\n\n    @pytest.mark.parametrize('bufsize', [1.0, None, object(), 'bufsize'])\n    def test_bio_read_wrong_args(self, bufsize):\n        \"\"\"\n        `Connection.bio_read` raises `TypeError` if passed a non-integer\n        argument.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        with pytest.raises(TypeError):\n            conn.bio_read(bufsize)\n\n    def test_buffer_size(self):\n        \"\"\"\n        `Connection.bio_read` accepts an integer giving the maximum number\n        of bytes to read and return.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        conn = Connection(ctx, None)\n        conn.set_connect_state()\n        try:\n            conn.do_handshake()\n        except WantReadError:\n            pass\n        data = conn.bio_read(2)\n        assert 2 == len(data)\n\n\nclass TestConnectionGetCipherList(object):\n    \"\"\"\n    Tests for `Connection.get_cipher_list`.\n    \"\"\"\n    def test_result(self):\n        \"\"\"\n        `Connection.get_cipher_list` returns a list of `bytes` giving the\n        names of the ciphers which might be used.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        ciphers = connection.get_cipher_list()\n        assert isinstance(ciphers, list)\n        for cipher in ciphers:\n            assert isinstance(cipher, str)\n\n\nclass VeryLarge(bytes):\n    \"\"\"\n    Mock object so that we don't have to allocate 2**31 bytes\n    \"\"\"\n    def __len__(self):\n        return 2**31\n\n\nclass TestConnectionSend(object):\n    \"\"\"\n    Tests for `Connection.send`.\n    \"\"\"\n    def test_wrong_args(self):\n        \"\"\"\n        When called with arguments other than string argument for its first\n        parameter, `Connection.send` raises `TypeError`.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(TypeError):\n            connection.send(object())\n\n    def test_short_bytes(self):\n        \"\"\"\n        When passed a short byte string, `Connection.send` transmits all of it\n        and returns the number of bytes sent.\n        \"\"\"\n        server, client = loopback()\n        count = server.send(b'xy')\n        assert count == 2\n        assert client.recv(2) == b'xy'\n\n    def test_text(self):\n        \"\"\"\n        When passed a text, `Connection.send` transmits all of it and\n        returns the number of bytes sent. It also raises a DeprecationWarning.\n        \"\"\"\n        server, client = loopback()\n        with pytest.warns(DeprecationWarning) as w:\n            simplefilter(\"always\")\n            count = server.send(b\"xy\".decode(\"ascii\"))\n            assert (\n                \"{0} for buf is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n        assert count == 2\n        assert client.recv(2) == b'xy'\n\n    def test_short_memoryview(self):\n        \"\"\"\n        When passed a memoryview onto a small number of bytes,\n        `Connection.send` transmits all of them and returns the number\n        of bytes sent.\n        \"\"\"\n        server, client = loopback()\n        count = server.send(memoryview(b'xy'))\n        assert count == 2\n        assert client.recv(2) == b'xy'\n\n    @skip_if_py3\n    def test_short_buffer(self):\n        \"\"\"\n        When passed a buffer containing a small number of bytes,\n        `Connection.send` transmits all of them and returns the number\n        of bytes sent.\n        \"\"\"\n        server, client = loopback()\n        count = server.send(buffer(b'xy'))\n        assert count == 2\n        assert client.recv(2) == b'xy'\n\n    @pytest.mark.skipif(\n        sys.maxsize < 2**31,\n        reason=\"sys.maxsize < 2**31 - test requires 64 bit\"\n    )\n    def test_buf_too_large(self):\n        \"\"\"\n        When passed a buffer containing >= 2**31 bytes,\n        `Connection.send` bails out as SSL_write only\n        accepts an int for the buffer length.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(ValueError) as exc_info:\n            connection.send(VeryLarge())\n        exc_info.match(r\"Cannot send more than .+ bytes at once\")\n\n\ndef _make_memoryview(size):\n    \"\"\"\n    Create a new ``memoryview`` wrapped around a ``bytearray`` of the given\n    size.\n    \"\"\"\n    return memoryview(bytearray(size))\n\n\nclass TestConnectionRecvInto(object):\n    \"\"\"\n    Tests for `Connection.recv_into`.\n    \"\"\"\n    def _no_length_test(self, factory):\n        \"\"\"\n        Assert that when the given buffer is passed to `Connection.recv_into`,\n        whatever bytes are available to be received that fit into that buffer\n        are written into that buffer.\n        \"\"\"\n        output_buffer = factory(5)\n\n        server, client = loopback()\n        server.send(b'xy')\n\n        assert client.recv_into(output_buffer) == 2\n        assert output_buffer == bytearray(b'xy\\x00\\x00\\x00')\n\n    def test_bytearray_no_length(self):\n        \"\"\"\n        `Connection.recv_into` can be passed a `bytearray` instance and data\n        in the receive buffer is written to it.\n        \"\"\"\n        self._no_length_test(bytearray)\n\n    def _respects_length_test(self, factory):\n        \"\"\"\n        Assert that when the given buffer is passed to `Connection.recv_into`\n        along with a value for `nbytes` that is less than the size of that\n        buffer, only `nbytes` bytes are written into the buffer.\n        \"\"\"\n        output_buffer = factory(10)\n\n        server, client = loopback()\n        server.send(b'abcdefghij')\n\n        assert client.recv_into(output_buffer, 5) == 5\n        assert output_buffer == bytearray(b'abcde\\x00\\x00\\x00\\x00\\x00')\n\n    def test_bytearray_respects_length(self):\n        \"\"\"\n        When called with a `bytearray` instance, `Connection.recv_into`\n        respects the `nbytes` parameter and doesn't copy in more than that\n        number of bytes.\n        \"\"\"\n        self._respects_length_test(bytearray)\n\n    def _doesnt_overfill_test(self, factory):\n        \"\"\"\n        Assert that if there are more bytes available to be read from the\n        receive buffer than would fit into the buffer passed to\n        `Connection.recv_into`, only as many as fit are written into it.\n        \"\"\"\n        output_buffer = factory(5)\n\n        server, client = loopback()\n        server.send(b'abcdefghij')\n\n        assert client.recv_into(output_buffer) == 5\n        assert output_buffer == bytearray(b'abcde')\n        rest = client.recv(5)\n        assert b'fghij' == rest\n\n    def test_bytearray_doesnt_overfill(self):\n        \"\"\"\n        When called with a `bytearray` instance, `Connection.recv_into`\n        respects the size of the array and doesn't write more bytes into it\n        than will fit.\n        \"\"\"\n        self._doesnt_overfill_test(bytearray)\n\n    def test_bytearray_really_doesnt_overfill(self):\n        \"\"\"\n        When called with a `bytearray` instance and an `nbytes` value that is\n        too large, `Connection.recv_into` respects the size of the array and\n        not the `nbytes` value and doesn't write more bytes into the buffer\n        than will fit.\n        \"\"\"\n        self._doesnt_overfill_test(bytearray)\n\n    def test_peek(self):\n        server, client = loopback()\n        server.send(b'xy')\n\n        for _ in range(2):\n            output_buffer = bytearray(5)\n            assert client.recv_into(output_buffer, flags=MSG_PEEK) == 2\n            assert output_buffer == bytearray(b'xy\\x00\\x00\\x00')\n\n    def test_memoryview_no_length(self):\n        \"\"\"\n        `Connection.recv_into` can be passed a `memoryview` instance and data\n        in the receive buffer is written to it.\n        \"\"\"\n        self._no_length_test(_make_memoryview)\n\n    def test_memoryview_respects_length(self):\n        \"\"\"\n        When called with a `memoryview` instance, `Connection.recv_into`\n        respects the ``nbytes`` parameter and doesn't copy more than that\n        number of bytes in.\n        \"\"\"\n        self._respects_length_test(_make_memoryview)\n\n    def test_memoryview_doesnt_overfill(self):\n        \"\"\"\n        When called with a `memoryview` instance, `Connection.recv_into`\n        respects the size of the array and doesn't write more bytes into it\n        than will fit.\n        \"\"\"\n        self._doesnt_overfill_test(_make_memoryview)\n\n    def test_memoryview_really_doesnt_overfill(self):\n        \"\"\"\n        When called with a `memoryview` instance and an `nbytes` value that is\n        too large, `Connection.recv_into` respects the size of the array and\n        not the `nbytes` value and doesn't write more bytes into the buffer\n        than will fit.\n        \"\"\"\n        self._doesnt_overfill_test(_make_memoryview)\n\n\nclass TestConnectionSendall(object):\n    \"\"\"\n    Tests for `Connection.sendall`.\n    \"\"\"\n    def test_wrong_args(self):\n        \"\"\"\n        When called with arguments other than a string argument for its first\n        parameter, `Connection.sendall` raises `TypeError`.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        with pytest.raises(TypeError):\n            connection.sendall(object())\n\n    def test_short(self):\n        \"\"\"\n        `Connection.sendall` transmits all of the bytes in the string\n        passed to it.\n        \"\"\"\n        server, client = loopback()\n        server.sendall(b'x')\n        assert client.recv(1) == b'x'\n\n    def test_text(self):\n        \"\"\"\n        `Connection.sendall` transmits all the content in the string passed\n        to it, raising a DeprecationWarning in case of this being a text.\n        \"\"\"\n        server, client = loopback()\n        with pytest.warns(DeprecationWarning) as w:\n            simplefilter(\"always\")\n            server.sendall(b\"x\".decode(\"ascii\"))\n            assert (\n                \"{0} for buf is no longer accepted, use bytes\".format(\n                    WARNING_TYPE_EXPECTED\n                ) == str(w[-1].message))\n        assert client.recv(1) == b\"x\"\n\n    def test_short_memoryview(self):\n        \"\"\"\n        When passed a memoryview onto a small number of bytes,\n        `Connection.sendall` transmits all of them.\n        \"\"\"\n        server, client = loopback()\n        server.sendall(memoryview(b'x'))\n        assert client.recv(1) == b'x'\n\n    @skip_if_py3\n    def test_short_buffers(self):\n        \"\"\"\n        When passed a buffer containing a small number of bytes,\n        `Connection.sendall` transmits all of them.\n        \"\"\"\n        server, client = loopback()\n        server.sendall(buffer(b'x'))\n        assert client.recv(1) == b'x'\n\n    def test_long(self):\n        \"\"\"\n        `Connection.sendall` transmits all the bytes in the string passed to it\n        even if this requires multiple calls of an underlying write function.\n        \"\"\"\n        server, client = loopback()\n        # Should be enough, underlying SSL_write should only do 16k at a time.\n        # On Windows, after 32k of bytes the write will block (forever\n        # - because no one is yet reading).\n        message = b'x' * (1024 * 32 - 1) + b'y'\n        server.sendall(message)\n        accum = []\n        received = 0\n        while received < len(message):\n            data = client.recv(1024)\n            accum.append(data)\n            received += len(data)\n        assert message == b''.join(accum)\n\n    def test_closed(self):\n        \"\"\"\n        If the underlying socket is closed, `Connection.sendall` propagates the\n        write error from the low level write call.\n        \"\"\"\n        server, client = loopback()\n        server.sock_shutdown(2)\n        with pytest.raises(SysCallError) as err:\n            server.sendall(b\"hello, world\")\n        if platform == \"win32\":\n            assert err.value.args[0] == ESHUTDOWN\n        else:\n            assert err.value.args[0] == EPIPE\n\n\nclass TestConnectionRenegotiate(object):\n    \"\"\"\n    Tests for SSL renegotiation APIs.\n    \"\"\"\n    def test_total_renegotiations(self):\n        \"\"\"\n        `Connection.total_renegotiations` returns `0` before any renegotiations\n        have happened.\n        \"\"\"\n        connection = Connection(Context(TLSv1_METHOD), None)\n        assert connection.total_renegotiations() == 0\n\n    def test_renegotiate(self):\n        \"\"\"\n        Go through a complete renegotiation cycle.\n        \"\"\"\n        server, client = loopback(\n            lambda s: loopback_server_factory(s, TLSv1_2_METHOD),\n            lambda s: loopback_client_factory(s, TLSv1_2_METHOD),\n        )\n\n        server.send(b\"hello world\")\n\n        assert b\"hello world\" == client.recv(len(b\"hello world\"))\n\n        assert 0 == server.total_renegotiations()\n        assert False is server.renegotiate_pending()\n\n        assert True is server.renegotiate()\n\n        assert True is server.renegotiate_pending()\n\n        server.setblocking(False)\n        client.setblocking(False)\n\n        client.do_handshake()\n        server.do_handshake()\n\n        assert 1 == server.total_renegotiations()\n        while False is server.renegotiate_pending():\n            pass\n\n\nclass TestError(object):\n    \"\"\"\n    Unit tests for `OpenSSL.SSL.Error`.\n    \"\"\"\n    def test_type(self):\n        \"\"\"\n        `Error` is an exception type.\n        \"\"\"\n        assert issubclass(Error, Exception)\n        assert Error.__name__ == 'Error'\n\n\nclass TestConstants(object):\n    \"\"\"\n    Tests for the values of constants exposed in `OpenSSL.SSL`.\n\n    These are values defined by OpenSSL intended only to be used as flags to\n    OpenSSL APIs.  The only assertions it seems can be made about them is\n    their values.\n    \"\"\"\n    @pytest.mark.skipif(\n        OP_NO_QUERY_MTU is None,\n        reason=\"OP_NO_QUERY_MTU unavailable - OpenSSL version may be too old\"\n    )\n    def test_op_no_query_mtu(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.OP_NO_QUERY_MTU` is 0x1000, the value\n        of `SSL_OP_NO_QUERY_MTU` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert OP_NO_QUERY_MTU == 0x1000\n\n    @pytest.mark.skipif(\n        OP_COOKIE_EXCHANGE is None,\n        reason=\"OP_COOKIE_EXCHANGE unavailable - \"\n        \"OpenSSL version may be too old\"\n    )\n    def test_op_cookie_exchange(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.OP_COOKIE_EXCHANGE` is 0x2000, the\n        value of `SSL_OP_COOKIE_EXCHANGE` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert OP_COOKIE_EXCHANGE == 0x2000\n\n    @pytest.mark.skipif(\n        OP_NO_TICKET is None,\n        reason=\"OP_NO_TICKET unavailable - OpenSSL version may be too old\"\n    )\n    def test_op_no_ticket(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.OP_NO_TICKET` is 0x4000, the value of\n        `SSL_OP_NO_TICKET` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert OP_NO_TICKET == 0x4000\n\n    @pytest.mark.skipif(\n        OP_NO_COMPRESSION is None,\n        reason=\"OP_NO_COMPRESSION unavailable - OpenSSL version may be too old\"\n    )\n    def test_op_no_compression(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.OP_NO_COMPRESSION` is 0x20000, the\n        value of `SSL_OP_NO_COMPRESSION` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert OP_NO_COMPRESSION == 0x20000\n\n    def test_sess_cache_off(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_OFF` 0x0, the value of\n        `SSL_SESS_CACHE_OFF` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert 0x0 == SESS_CACHE_OFF\n\n    def test_sess_cache_client(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_CLIENT` 0x1, the value of\n        `SSL_SESS_CACHE_CLIENT` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert 0x1 == SESS_CACHE_CLIENT\n\n    def test_sess_cache_server(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_SERVER` 0x2, the value of\n        `SSL_SESS_CACHE_SERVER` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert 0x2 == SESS_CACHE_SERVER\n\n    def test_sess_cache_both(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_BOTH` 0x3, the value of\n        `SSL_SESS_CACHE_BOTH` defined by `openssl/ssl.h`.\n        \"\"\"\n        assert 0x3 == SESS_CACHE_BOTH\n\n    def test_sess_cache_no_auto_clear(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_NO_AUTO_CLEAR` 0x80, the\n        value of `SSL_SESS_CACHE_NO_AUTO_CLEAR` defined by\n        `openssl/ssl.h`.\n        \"\"\"\n        assert 0x80 == SESS_CACHE_NO_AUTO_CLEAR\n\n    def test_sess_cache_no_internal_lookup(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_NO_INTERNAL_LOOKUP` 0x100,\n        the value of `SSL_SESS_CACHE_NO_INTERNAL_LOOKUP` defined by\n        `openssl/ssl.h`.\n        \"\"\"\n        assert 0x100 == SESS_CACHE_NO_INTERNAL_LOOKUP\n\n    def test_sess_cache_no_internal_store(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_NO_INTERNAL_STORE` 0x200,\n        the value of `SSL_SESS_CACHE_NO_INTERNAL_STORE` defined by\n        `openssl/ssl.h`.\n        \"\"\"\n        assert 0x200 == SESS_CACHE_NO_INTERNAL_STORE\n\n    def test_sess_cache_no_internal(self):\n        \"\"\"\n        The value of `OpenSSL.SSL.SESS_CACHE_NO_INTERNAL` 0x300, the\n        value of `SSL_SESS_CACHE_NO_INTERNAL` defined by\n        `openssl/ssl.h`.\n        \"\"\"\n        assert 0x300 == SESS_CACHE_NO_INTERNAL\n\n\nclass TestMemoryBIO(object):\n    \"\"\"\n    Tests for `OpenSSL.SSL.Connection` using a memory BIO.\n    \"\"\"\n    def _server(self, sock):\n        \"\"\"\n        Create a new server-side SSL `Connection` object wrapped around `sock`.\n        \"\"\"\n        # Create the server side Connection.  This is mostly setup boilerplate\n        # - use TLSv1, use a particular certificate, etc.\n        server_ctx = Context(TLSv1_METHOD)\n        server_ctx.set_options(OP_NO_SSLv2 | OP_NO_SSLv3 | OP_SINGLE_DH_USE)\n        server_ctx.set_verify(\n            VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT | VERIFY_CLIENT_ONCE,\n            verify_cb\n        )\n        server_store = server_ctx.get_cert_store()\n        server_ctx.use_privatekey(\n            load_privatekey(FILETYPE_PEM, server_key_pem))\n        server_ctx.use_certificate(\n            load_certificate(FILETYPE_PEM, server_cert_pem))\n        server_ctx.check_privatekey()\n        server_store.add_cert(load_certificate(FILETYPE_PEM, root_cert_pem))\n        # Here the Connection is actually created.  If None is passed as the\n        # 2nd parameter, it indicates a memory BIO should be created.\n        server_conn = Connection(server_ctx, sock)\n        server_conn.set_accept_state()\n        return server_conn\n\n    def _client(self, sock):\n        \"\"\"\n        Create a new client-side SSL `Connection` object wrapped around `sock`.\n        \"\"\"\n        # Now create the client side Connection.  Similar boilerplate to the\n        # above.\n        client_ctx = Context(TLSv1_METHOD)\n        client_ctx.set_options(OP_NO_SSLv2 | OP_NO_SSLv3 | OP_SINGLE_DH_USE)\n        client_ctx.set_verify(\n            VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT | VERIFY_CLIENT_ONCE,\n            verify_cb\n        )\n        client_store = client_ctx.get_cert_store()\n        client_ctx.use_privatekey(\n            load_privatekey(FILETYPE_PEM, client_key_pem))\n        client_ctx.use_certificate(\n            load_certificate(FILETYPE_PEM, client_cert_pem))\n        client_ctx.check_privatekey()\n        client_store.add_cert(load_certificate(FILETYPE_PEM, root_cert_pem))\n        client_conn = Connection(client_ctx, sock)\n        client_conn.set_connect_state()\n        return client_conn\n\n    def test_memory_connect(self):\n        \"\"\"\n        Two `Connection`s which use memory BIOs can be manually connected by\n        reading from the output of each and writing those bytes to the input of\n        the other and in this way establish a connection and exchange\n        application-level bytes with each other.\n        \"\"\"\n        server_conn = self._server(None)\n        client_conn = self._client(None)\n\n        # There should be no key or nonces yet.\n        assert server_conn.master_key() is None\n        assert server_conn.client_random() is None\n        assert server_conn.server_random() is None\n\n        # First, the handshake needs to happen.  We'll deliver bytes back and\n        # forth between the client and server until neither of them feels like\n        # speaking any more.\n        assert interact_in_memory(client_conn, server_conn) is None\n\n        # Now that the handshake is done, there should be a key and nonces.\n        assert server_conn.master_key() is not None\n        assert server_conn.client_random() is not None\n        assert server_conn.server_random() is not None\n        assert server_conn.client_random() == client_conn.client_random()\n        assert server_conn.server_random() == client_conn.server_random()\n        assert server_conn.client_random() != server_conn.server_random()\n        assert client_conn.client_random() != client_conn.server_random()\n\n        # Export key material for other uses.\n        cekm = client_conn.export_keying_material(b'LABEL', 32)\n        sekm = server_conn.export_keying_material(b'LABEL', 32)\n        assert cekm is not None\n        assert sekm is not None\n        assert cekm == sekm\n        assert len(sekm) == 32\n\n        # Export key material for other uses with additional context.\n        cekmc = client_conn.export_keying_material(b'LABEL', 32, b'CONTEXT')\n        sekmc = server_conn.export_keying_material(b'LABEL', 32, b'CONTEXT')\n        assert cekmc is not None\n        assert sekmc is not None\n        assert cekmc == sekmc\n        assert cekmc != cekm\n        assert sekmc != sekm\n        # Export with alternate label\n        cekmt = client_conn.export_keying_material(b'test', 32, b'CONTEXT')\n        sekmt = server_conn.export_keying_material(b'test', 32, b'CONTEXT')\n        assert cekmc != cekmt\n        assert sekmc != sekmt\n\n        # Here are the bytes we'll try to send.\n        important_message = b'One if by land, two if by sea.'\n\n        server_conn.write(important_message)\n        assert (\n            interact_in_memory(client_conn, server_conn) ==\n            (client_conn, important_message))\n\n        client_conn.write(important_message[::-1])\n        assert (\n            interact_in_memory(client_conn, server_conn) ==\n            (server_conn, important_message[::-1]))\n\n    def test_socket_connect(self):\n        \"\"\"\n        Just like `test_memory_connect` but with an actual socket.\n\n        This is primarily to rule out the memory BIO code as the source of any\n        problems encountered while passing data over a `Connection` (if\n        this test fails, there must be a problem outside the memory BIO code,\n        as no memory BIO is involved here).  Even though this isn't a memory\n        BIO test, it's convenient to have it here.\n        \"\"\"\n        server_conn, client_conn = loopback()\n\n        important_message = b\"Help me Obi Wan Kenobi, you're my only hope.\"\n        client_conn.send(important_message)\n        msg = server_conn.recv(1024)\n        assert msg == important_message\n\n        # Again in the other direction, just for fun.\n        important_message = important_message[::-1]\n        server_conn.send(important_message)\n        msg = client_conn.recv(1024)\n        assert msg == important_message\n\n    def test_socket_overrides_memory(self):\n        \"\"\"\n        Test that `OpenSSL.SSL.bio_read` and `OpenSSL.SSL.bio_write` don't\n        work on `OpenSSL.SSL.Connection`() that use sockets.\n        \"\"\"\n        context = Context(TLSv1_METHOD)\n        client = socket_any_family()\n        clientSSL = Connection(context, client)\n        with pytest.raises(TypeError):\n            clientSSL.bio_read(100)\n        with pytest.raises(TypeError):\n            clientSSL.bio_write(\"foo\")\n        with pytest.raises(TypeError):\n            clientSSL.bio_shutdown()\n\n    def test_outgoing_overflow(self):\n        \"\"\"\n        If more bytes than can be written to the memory BIO are passed to\n        `Connection.send` at once, the number of bytes which were written is\n        returned and that many bytes from the beginning of the input can be\n        read from the other end of the connection.\n        \"\"\"\n        server = self._server(None)\n        client = self._client(None)\n\n        interact_in_memory(client, server)\n\n        size = 2 ** 15\n        sent = client.send(b\"x\" * size)\n        # Sanity check.  We're trying to test what happens when the entire\n        # input can't be sent.  If the entire input was sent, this test is\n        # meaningless.\n        assert sent < size\n\n        receiver, received = interact_in_memory(client, server)\n        assert receiver is server\n\n        # We can rely on all of these bytes being received at once because\n        # loopback passes 2 ** 16 to recv - more than 2 ** 15.\n        assert len(received) == sent\n\n    def test_shutdown(self):\n        \"\"\"\n        `Connection.bio_shutdown` signals the end of the data stream\n        from which the `Connection` reads.\n        \"\"\"\n        server = self._server(None)\n        server.bio_shutdown()\n        with pytest.raises(Error) as err:\n            server.recv(1024)\n        # We don't want WantReadError or ZeroReturnError or anything - it's a\n        # handshake failure.\n        assert type(err.value) in [Error, SysCallError]\n\n    def test_unexpected_EOF(self):\n        \"\"\"\n        If the connection is lost before an orderly SSL shutdown occurs,\n        `OpenSSL.SSL.SysCallError` is raised with a message of\n        \"Unexpected EOF\".\n        \"\"\"\n        server_conn, client_conn = loopback()\n        client_conn.sock_shutdown(SHUT_RDWR)\n        with pytest.raises(SysCallError) as err:\n            server_conn.recv(1024)\n        assert err.value.args == (-1, \"Unexpected EOF\")\n\n    def _check_client_ca_list(self, func):\n        \"\"\"\n        Verify the return value of the `get_client_ca_list` method for\n        server and client connections.\n\n        :param func: A function which will be called with the server context\n            before the client and server are connected to each other.  This\n            function should specify a list of CAs for the server to send to the\n            client and return that same list.  The list will be used to verify\n            that `get_client_ca_list` returns the proper value at\n            various times.\n        \"\"\"\n        server = self._server(None)\n        client = self._client(None)\n        assert client.get_client_ca_list() == []\n        assert server.get_client_ca_list() == []\n        ctx = server.get_context()\n        expected = func(ctx)\n        assert client.get_client_ca_list() == []\n        assert server.get_client_ca_list() == expected\n        interact_in_memory(client, server)\n        assert client.get_client_ca_list() == expected\n        assert server.get_client_ca_list() == expected\n\n    def test_set_client_ca_list_errors(self):\n        \"\"\"\n        `Context.set_client_ca_list` raises a `TypeError` if called with a\n        non-list or a list that contains objects other than X509Names.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            ctx.set_client_ca_list(\"spam\")\n        with pytest.raises(TypeError):\n            ctx.set_client_ca_list([\"spam\"])\n\n    def test_set_empty_ca_list(self):\n        \"\"\"\n        If passed an empty list, `Context.set_client_ca_list` configures the\n        context to send no CA names to the client and, on both the server and\n        client sides, `Connection.get_client_ca_list` returns an empty list\n        after the connection is set up.\n        \"\"\"\n        def no_ca(ctx):\n            ctx.set_client_ca_list([])\n            return []\n        self._check_client_ca_list(no_ca)\n\n    def test_set_one_ca_list(self):\n        \"\"\"\n        If passed a list containing a single X509Name,\n        `Context.set_client_ca_list` configures the context to send\n        that CA name to the client and, on both the server and client sides,\n        `Connection.get_client_ca_list` returns a list containing that\n        X509Name after the connection is set up.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        cadesc = cacert.get_subject()\n\n        def single_ca(ctx):\n            ctx.set_client_ca_list([cadesc])\n            return [cadesc]\n        self._check_client_ca_list(single_ca)\n\n    def test_set_multiple_ca_list(self):\n        \"\"\"\n        If passed a list containing multiple X509Name objects,\n        `Context.set_client_ca_list` configures the context to send\n        those CA names to the client and, on both the server and client sides,\n        `Connection.get_client_ca_list` returns a list containing those\n        X509Names after the connection is set up.\n        \"\"\"\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        clcert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        sedesc = secert.get_subject()\n        cldesc = clcert.get_subject()\n\n        def multiple_ca(ctx):\n            L = [sedesc, cldesc]\n            ctx.set_client_ca_list(L)\n            return L\n        self._check_client_ca_list(multiple_ca)\n\n    def test_reset_ca_list(self):\n        \"\"\"\n        If called multiple times, only the X509Names passed to the final call\n        of `Context.set_client_ca_list` are used to configure the CA\n        names sent to the client.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        clcert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        cadesc = cacert.get_subject()\n        sedesc = secert.get_subject()\n        cldesc = clcert.get_subject()\n\n        def changed_ca(ctx):\n            ctx.set_client_ca_list([sedesc, cldesc])\n            ctx.set_client_ca_list([cadesc])\n            return [cadesc]\n        self._check_client_ca_list(changed_ca)\n\n    def test_mutated_ca_list(self):\n        \"\"\"\n        If the list passed to `Context.set_client_ca_list` is mutated\n        afterwards, this does not affect the list of CA names sent to the\n        client.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        cadesc = cacert.get_subject()\n        sedesc = secert.get_subject()\n\n        def mutated_ca(ctx):\n            L = [cadesc]\n            ctx.set_client_ca_list([cadesc])\n            L.append(sedesc)\n            return [cadesc]\n        self._check_client_ca_list(mutated_ca)\n\n    def test_add_client_ca_wrong_args(self):\n        \"\"\"\n        `Context.add_client_ca` raises `TypeError` if called with\n        a non-X509 object.\n        \"\"\"\n        ctx = Context(TLSv1_METHOD)\n        with pytest.raises(TypeError):\n            ctx.add_client_ca(\"spam\")\n\n    def test_one_add_client_ca(self):\n        \"\"\"\n        A certificate's subject can be added as a CA to be sent to the client\n        with `Context.add_client_ca`.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        cadesc = cacert.get_subject()\n\n        def single_ca(ctx):\n            ctx.add_client_ca(cacert)\n            return [cadesc]\n        self._check_client_ca_list(single_ca)\n\n    def test_multiple_add_client_ca(self):\n        \"\"\"\n        Multiple CA names can be sent to the client by calling\n        `Context.add_client_ca` with multiple X509 objects.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        cadesc = cacert.get_subject()\n        sedesc = secert.get_subject()\n\n        def multiple_ca(ctx):\n            ctx.add_client_ca(cacert)\n            ctx.add_client_ca(secert)\n            return [cadesc, sedesc]\n        self._check_client_ca_list(multiple_ca)\n\n    def test_set_and_add_client_ca(self):\n        \"\"\"\n        A call to `Context.set_client_ca_list` followed by a call to\n        `Context.add_client_ca` results in using the CA names from the\n        first call and the CA name from the second call.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        clcert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        cadesc = cacert.get_subject()\n        sedesc = secert.get_subject()\n        cldesc = clcert.get_subject()\n\n        def mixed_set_add_ca(ctx):\n            ctx.set_client_ca_list([cadesc, sedesc])\n            ctx.add_client_ca(clcert)\n            return [cadesc, sedesc, cldesc]\n        self._check_client_ca_list(mixed_set_add_ca)\n\n    def test_set_after_add_client_ca(self):\n        \"\"\"\n        A call to `Context.set_client_ca_list` after a call to\n        `Context.add_client_ca` replaces the CA name specified by the\n        former call with the names specified by the latter call.\n        \"\"\"\n        cacert = load_certificate(FILETYPE_PEM, root_cert_pem)\n        secert = load_certificate(FILETYPE_PEM, server_cert_pem)\n        clcert = load_certificate(FILETYPE_PEM, server_cert_pem)\n\n        cadesc = cacert.get_subject()\n        sedesc = secert.get_subject()\n\n        def set_replaces_add_ca(ctx):\n            ctx.add_client_ca(clcert)\n            ctx.set_client_ca_list([cadesc])\n            ctx.add_client_ca(secert)\n            return [cadesc, sedesc]\n        self._check_client_ca_list(set_replaces_add_ca)\n\n\nclass TestInfoConstants(object):\n    \"\"\"\n    Tests for assorted constants exposed for use in info callbacks.\n    \"\"\"\n    def test_integers(self):\n        \"\"\"\n        All of the info constants are integers.\n\n        This is a very weak test.  It would be nice to have one that actually\n        verifies that as certain info events happen, the value passed to the\n        info callback matches up with the constant exposed by OpenSSL.SSL.\n        \"\"\"\n        for const in [\n            SSL_ST_CONNECT, SSL_ST_ACCEPT, SSL_ST_MASK,\n            SSL_CB_LOOP, SSL_CB_EXIT, SSL_CB_READ, SSL_CB_WRITE, SSL_CB_ALERT,\n            SSL_CB_READ_ALERT, SSL_CB_WRITE_ALERT, SSL_CB_ACCEPT_LOOP,\n            SSL_CB_ACCEPT_EXIT, SSL_CB_CONNECT_LOOP, SSL_CB_CONNECT_EXIT,\n            SSL_CB_HANDSHAKE_START, SSL_CB_HANDSHAKE_DONE\n        ]:\n            assert isinstance(const, int)\n\n        # These constants don't exist on OpenSSL 1.1.0\n        for const in [\n            SSL_ST_INIT, SSL_ST_BEFORE, SSL_ST_OK, SSL_ST_RENEGOTIATE\n        ]:\n            assert const is None or isinstance(const, int)\n\n\nclass TestRequires(object):\n    \"\"\"\n    Tests for the decorator factory used to conditionally raise\n    NotImplementedError when older OpenSSLs are used.\n    \"\"\"\n    def test_available(self):\n        \"\"\"\n        When the OpenSSL functionality is available the decorated functions\n        work appropriately.\n        \"\"\"\n        feature_guard = _make_requires(True, \"Error text\")\n        results = []\n\n        @feature_guard\n        def inner():\n            results.append(True)\n            return True\n\n        assert inner() is True\n        assert [True] == results\n\n    def test_unavailable(self):\n        \"\"\"\n        When the OpenSSL functionality is not available the decorated function\n        does not execute and NotImplementedError is raised.\n        \"\"\"\n        feature_guard = _make_requires(False, \"Error text\")\n\n        @feature_guard\n        def inner():  # pragma: nocover\n            pytest.fail(\"Should not be called\")\n\n        with pytest.raises(NotImplementedError) as e:\n            inner()\n\n        assert \"Error text\" in str(e.value)\n\n\nclass TestOCSP(object):\n    \"\"\"\n    Tests for PyOpenSSL's OCSP stapling support.\n    \"\"\"\n    sample_ocsp_data = b\"this is totally ocsp data\"\n\n    def _client_connection(self, callback, data, request_ocsp=True):\n        \"\"\"\n        Builds a client connection suitable for using OCSP.\n\n        :param callback: The callback to register for OCSP.\n        :param data: The opaque data object that will be handed to the\n            OCSP callback.\n        :param request_ocsp: Whether the client will actually ask for OCSP\n            stapling. Useful for testing only.\n        \"\"\"\n        ctx = Context(SSLv23_METHOD)\n        ctx.set_ocsp_client_callback(callback, data)\n        client = Connection(ctx)\n\n        if request_ocsp:\n            client.request_ocsp()\n\n        client.set_connect_state()\n        return client\n\n    def _server_connection(self, callback, data):\n        \"\"\"\n        Builds a server connection suitable for using OCSP.\n\n        :param callback: The callback to register for OCSP.\n        :param data: The opaque data object that will be handed to the\n            OCSP callback.\n        \"\"\"\n        ctx = Context(SSLv23_METHOD)\n        ctx.use_privatekey(load_privatekey(FILETYPE_PEM, server_key_pem))\n        ctx.use_certificate(load_certificate(FILETYPE_PEM, server_cert_pem))\n        ctx.set_ocsp_server_callback(callback, data)\n        server = Connection(ctx)\n        server.set_accept_state()\n        return server\n\n    def test_callbacks_arent_called_by_default(self):\n        \"\"\"\n        If both the client and the server have registered OCSP callbacks, but\n        the client does not send the OCSP request, neither callback gets\n        called.\n        \"\"\"\n        def ocsp_callback(*args, **kwargs):  # pragma: nocover\n            pytest.fail(\"Should not be called\")\n\n        client = self._client_connection(\n            callback=ocsp_callback, data=None, request_ocsp=False\n        )\n        server = self._server_connection(callback=ocsp_callback, data=None)\n        handshake_in_memory(client, server)\n\n    def test_client_negotiates_without_server(self):\n        \"\"\"\n        If the client wants to do OCSP but the server does not, the handshake\n        succeeds, and the client callback fires with an empty byte string.\n        \"\"\"\n        called = []\n\n        def ocsp_callback(conn, ocsp_data, ignored):\n            called.append(ocsp_data)\n            return True\n\n        client = self._client_connection(callback=ocsp_callback, data=None)\n        server = loopback_server_factory(socket=None)\n        handshake_in_memory(client, server)\n\n        assert len(called) == 1\n        assert called[0] == b''\n\n    def test_client_receives_servers_data(self):\n        \"\"\"\n        The data the server sends in its callback is received by the client.\n        \"\"\"\n        calls = []\n\n        def server_callback(*args, **kwargs):\n            return self.sample_ocsp_data\n\n        def client_callback(conn, ocsp_data, ignored):\n            calls.append(ocsp_data)\n            return True\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n        handshake_in_memory(client, server)\n\n        assert len(calls) == 1\n        assert calls[0] == self.sample_ocsp_data\n\n    def test_callbacks_are_invoked_with_connections(self):\n        \"\"\"\n        The first arguments to both callbacks are their respective connections.\n        \"\"\"\n        client_calls = []\n        server_calls = []\n\n        def client_callback(conn, *args, **kwargs):\n            client_calls.append(conn)\n            return True\n\n        def server_callback(conn, *args, **kwargs):\n            server_calls.append(conn)\n            return self.sample_ocsp_data\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n        handshake_in_memory(client, server)\n\n        assert len(client_calls) == 1\n        assert len(server_calls) == 1\n        assert client_calls[0] is client\n        assert server_calls[0] is server\n\n    def test_opaque_data_is_passed_through(self):\n        \"\"\"\n        Both callbacks receive an opaque, user-provided piece of data in their\n        callbacks as the final argument.\n        \"\"\"\n        calls = []\n\n        def server_callback(*args):\n            calls.append(args)\n            return self.sample_ocsp_data\n\n        def client_callback(*args):\n            calls.append(args)\n            return True\n\n        sentinel = object()\n\n        client = self._client_connection(\n            callback=client_callback, data=sentinel\n        )\n        server = self._server_connection(\n            callback=server_callback, data=sentinel\n        )\n        handshake_in_memory(client, server)\n\n        assert len(calls) == 2\n        assert calls[0][-1] is sentinel\n        assert calls[1][-1] is sentinel\n\n    def test_server_returns_empty_string(self):\n        \"\"\"\n        If the server returns an empty bytestring from its callback, the\n        client callback is called with the empty bytestring.\n        \"\"\"\n        client_calls = []\n\n        def server_callback(*args):\n            return b''\n\n        def client_callback(conn, ocsp_data, ignored):\n            client_calls.append(ocsp_data)\n            return True\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n        handshake_in_memory(client, server)\n\n        assert len(client_calls) == 1\n        assert client_calls[0] == b''\n\n    def test_client_returns_false_terminates_handshake(self):\n        \"\"\"\n        If the client returns False from its callback, the handshake fails.\n        \"\"\"\n        def server_callback(*args):\n            return self.sample_ocsp_data\n\n        def client_callback(*args):\n            return False\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n\n        with pytest.raises(Error):\n            handshake_in_memory(client, server)\n\n    def test_exceptions_in_client_bubble_up(self):\n        \"\"\"\n        The callbacks thrown in the client callback bubble up to the caller.\n        \"\"\"\n        class SentinelException(Exception):\n            pass\n\n        def server_callback(*args):\n            return self.sample_ocsp_data\n\n        def client_callback(*args):\n            raise SentinelException()\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n\n        with pytest.raises(SentinelException):\n            handshake_in_memory(client, server)\n\n    def test_exceptions_in_server_bubble_up(self):\n        \"\"\"\n        The callbacks thrown in the server callback bubble up to the caller.\n        \"\"\"\n        class SentinelException(Exception):\n            pass\n\n        def server_callback(*args):\n            raise SentinelException()\n\n        def client_callback(*args):  # pragma: nocover\n            pytest.fail(\"Should not be called\")\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n\n        with pytest.raises(SentinelException):\n            handshake_in_memory(client, server)\n\n    def test_server_must_return_bytes(self):\n        \"\"\"\n        The server callback must return a bytestring, or a TypeError is thrown.\n        \"\"\"\n        def server_callback(*args):\n            return self.sample_ocsp_data.decode('ascii')\n\n        def client_callback(*args):  # pragma: nocover\n            pytest.fail(\"Should not be called\")\n\n        client = self._client_connection(callback=client_callback, data=None)\n        server = self._server_connection(callback=server_callback, data=None)\n\n        with pytest.raises(TypeError):\n            handshake_in_memory(client, server)\n"
  },
  {
    "prompt": "\n\n### rasa/core/test.py ###\n\nimport logging\nimport os\nimport warnings\nimport typing\nfrom collections import defaultdict, namedtuple\nfrom typing import Any, Dict, List, Optional, Text, Tuple\n\nfrom rasa import telemetry\nfrom rasa.core.policies.policy import PolicyPrediction\nfrom rasa.shared.exceptions import RasaException\nimport rasa.shared.utils.io\nfrom rasa.core.channels import UserMessage\nfrom rasa.shared.nlu.training_data.message import Message\nfrom rasa.shared.core.training_data.story_writer.yaml_story_writer import (\n    YAMLStoryWriter,\n)\nfrom rasa.shared.core.domain import Domain\nfrom rasa.nlu.constants import (\n    ENTITY_ATTRIBUTE_TEXT,\n    RESPONSE_SELECTOR_DEFAULT_INTENT,\n    RESPONSE_SELECTOR_RETRIEVAL_INTENTS,\n)\nfrom rasa.shared.nlu.constants import (\n    INTENT,\n    ENTITIES,\n    ENTITY_ATTRIBUTE_VALUE,\n    ENTITY_ATTRIBUTE_START,\n    ENTITY_ATTRIBUTE_END,\n    EXTRACTOR,\n    ENTITY_ATTRIBUTE_TYPE,\n    INTENT_RESPONSE_KEY,\n    INTENT_NAME_KEY,\n    RESPONSE,\n    RESPONSE_SELECTOR,\n    FULL_RETRIEVAL_INTENT_NAME_KEY,\n)\nfrom rasa.constants import RESULTS_FILE, PERCENTAGE_KEY\nfrom rasa.shared.core.events import ActionExecuted, UserUttered\nfrom rasa.shared.core.trackers import DialogueStateTracker\nfrom rasa.shared.nlu.training_data.formats.readerwriter import TrainingDataWriter\nfrom rasa.shared.utils.io import DEFAULT_ENCODING\n\nif typing.TYPE_CHECKING:\n    from rasa.core.agent import Agent\n    from rasa.core.processor import MessageProcessor\n    from rasa.shared.core.generator import TrainingDataGenerator\n\n\nCONFUSION_MATRIX_STORIES_FILE = \"story_confusion_matrix.png\"\nREPORT_STORIES_FILE = \"story_report.json\"\nFAILED_STORIES_FILE = \"failed_test_stories.yml\"\nSUCCESSFUL_STORIES_FILE = \"successful_test_stories.yml\"\n\n\nlogger = logging.getLogger(__name__)\n\nStoryEvaluation = namedtuple(\n    \"StoryEvaluation\",\n    [\n        \"evaluation_store\",\n        \"failed_stories\",\n        \"successful_stories\",\n        \"action_list\",\n        \"in_training_data_fraction\",\n    ],\n)\n\n\nclass WrongPredictionException(RasaException, ValueError):\n    \"\"\"Raised if a wrong prediction is encountered.\"\"\"\n\n\nclass EvaluationStore:\n    \"\"\"Class storing action, intent and entity predictions and targets.\"\"\"\n\n    def __init__(\n        self,\n        action_predictions: Optional[List[Text]] = None,\n        action_targets: Optional[List[Text]] = None,\n        intent_predictions: Optional[List[Text]] = None,\n        intent_targets: Optional[List[Text]] = None,\n        entity_predictions: Optional[List[Dict[Text, Any]]] = None,\n        entity_targets: Optional[List[Dict[Text, Any]]] = None,\n    ) -> None:\n        self.action_predictions = action_predictions or []\n        self.action_targets = action_targets or []\n        self.intent_predictions = intent_predictions or []\n        self.intent_targets = intent_targets or []\n        self.entity_predictions = entity_predictions or []\n        self.entity_targets = entity_targets or []\n\n    def add_to_store(\n        self,\n        action_predictions: Optional[List[Text]] = None,\n        action_targets: Optional[List[Text]] = None,\n        intent_predictions: Optional[List[Text]] = None,\n        intent_targets: Optional[List[Text]] = None,\n        entity_predictions: Optional[List[Dict[Text, Any]]] = None,\n        entity_targets: Optional[List[Dict[Text, Any]]] = None,\n    ) -> None:\n        \"\"\"Add items or lists of items to the store\"\"\"\n\n        self.action_predictions.extend(action_predictions or [])\n        self.action_targets.extend(action_targets or [])\n        self.intent_targets.extend(intent_targets or [])\n        self.intent_predictions.extend(intent_predictions or [])\n        self.entity_predictions.extend(entity_predictions or [])\n        self.entity_targets.extend(entity_targets or [])\n\n    def merge_store(self, other: \"EvaluationStore\") -> None:\n        \"\"\"Add the contents of other to self\"\"\"\n        self.add_to_store(\n            action_predictions=other.action_predictions,\n            action_targets=other.action_targets,\n            intent_predictions=other.intent_predictions,\n            intent_targets=other.intent_targets,\n            entity_predictions=other.entity_predictions,\n            entity_targets=other.entity_targets,\n        )\n\n    def has_prediction_target_mismatch(self) -> bool:\n        return (\n            self.intent_predictions != self.intent_targets\n            or self.entity_predictions != self.entity_targets\n            or self.action_predictions != self.action_targets\n        )\n\n    @staticmethod\n    def _compare_entities(\n        entity_predictions: List[Dict[Text, Any]],\n        entity_targets: List[Dict[Text, Any]],\n        i_pred: int,\n        i_target: int,\n    ) -> int:\n        \"\"\"\n        Compare the current predicted and target entities and decide which one\n        comes first. If the predicted entity comes first it returns -1,\n        while it returns 1 if the target entity comes first.\n        If target and predicted are aligned it returns 0\n        \"\"\"\n        pred = None\n        target = None\n        if i_pred < len(entity_predictions):\n            pred = entity_predictions[i_pred]\n        if i_target < len(entity_targets):\n            target = entity_targets[i_target]\n        if target and pred:\n            # Check which entity has the lower \"start\" value\n            if pred.get(\"start\") < target.get(\"start\"):\n                return -1\n            elif target.get(\"start\") < pred.get(\"start\"):\n                return 1\n            else:\n                # Since both have the same \"start\" values,\n                # check which one has the lower \"end\" value\n                if pred.get(\"end\") < target.get(\"end\"):\n                    return -1\n                elif target.get(\"end\") < pred.get(\"end\"):\n                    return 1\n                else:\n                    # The entities have the same \"start\" and \"end\" values\n                    return 0\n        return 1 if target else -1\n\n    @staticmethod\n    def _generate_entity_training_data(entity: Dict[Text, Any]) -> Text:\n        return TrainingDataWriter.generate_entity(entity.get(\"text\"), entity)\n\n    def serialise(self) -> Tuple[List[Text], List[Text]]:\n        \"\"\"Turn targets and predictions to lists of equal size for sklearn.\"\"\"\n        texts = sorted(\n            list(\n                set(\n                    [e.get(\"text\") for e in self.entity_targets]\n                    + [e.get(\"text\") for e in self.entity_predictions]\n                )\n            )\n        )\n\n        aligned_entity_targets = []\n        aligned_entity_predictions = []\n\n        for text in texts:\n            # sort the entities of this sentence to compare them directly\n            entity_targets = sorted(\n                filter(lambda x: x.get(\"text\") == text, self.entity_targets),\n                key=lambda x: x.get(\"start\"),\n            )\n            entity_predictions = sorted(\n                filter(lambda x: x.get(\"text\") == text, self.entity_predictions),\n                key=lambda x: x.get(\"start\"),\n            )\n\n            i_pred, i_target = 0, 0\n\n            while i_pred < len(entity_predictions) or i_target < len(entity_targets):\n                cmp = self._compare_entities(\n                    entity_predictions, entity_targets, i_pred, i_target\n                )\n                if cmp == -1:  # predicted comes first\n                    aligned_entity_predictions.append(\n                        self._generate_entity_training_data(entity_predictions[i_pred])\n                    )\n                    aligned_entity_targets.append(\"None\")\n                    i_pred += 1\n                elif cmp == 1:  # target entity comes first\n                    aligned_entity_targets.append(\n                        self._generate_entity_training_data(entity_targets[i_target])\n                    )\n                    aligned_entity_predictions.append(\"None\")\n                    i_target += 1\n                else:  # target and predicted entity are aligned\n                    aligned_entity_predictions.append(\n                        self._generate_entity_training_data(entity_predictions[i_pred])\n                    )\n                    aligned_entity_targets.append(\n                        self._generate_entity_training_data(entity_targets[i_target])\n                    )\n                    i_pred += 1\n                    i_target += 1\n\n        targets = self.action_targets + self.intent_targets + aligned_entity_targets\n\n        predictions = (\n            self.action_predictions\n            + self.intent_predictions\n            + aligned_entity_predictions\n        )\n        return targets, predictions\n\n\nclass WronglyPredictedAction(ActionExecuted):\n    \"\"\"The model predicted the wrong action.\n\n    Mostly used to mark wrong predictions and be able to\n    dump them as stories.\"\"\"\n\n    type_name = \"wrong_action\"\n\n    def __init__(\n        self,\n        action_name_target: Text,\n        action_name_prediction: Text,\n        policy: Optional[Text] = None,\n        confidence: Optional[float] = None,\n        timestamp: Optional[float] = None,\n        metadata: Optional[Dict] = None,\n    ) -> None:\n        self.action_name_prediction = action_name_prediction\n        super().__init__(action_name_target, policy, confidence, timestamp, metadata)\n\n    def inline_comment(self) -> Text:\n        \"\"\"A comment attached to this event. Used during dumping.\"\"\"\n        return f\"predicted: {self.action_name_prediction}\"\n\n    def as_story_string(self) -> Text:\n        return f\"{self.action_name}   <!-- {self.inline_comment()} -->\"\n\n\nclass EndToEndUserUtterance(UserUttered):\n    \"\"\"End-to-end user utterance.\n\n    Mostly used to print the full end-to-end user message in the\n    `failed_test_stories.yml` output file.\"\"\"\n\n    def as_story_string(self, e2e: bool = True) -> Text:\n        return super().as_story_string(e2e=True)\n\n\nclass WronglyClassifiedUserUtterance(UserUttered):\n    \"\"\"The NLU model predicted the wrong user utterance.\n\n    Mostly used to mark wrong predictions and be able to\n    dump them as stories.\"\"\"\n\n    type_name = \"wrong_utterance\"\n\n    def __init__(self, event: UserUttered, eval_store: EvaluationStore) -> None:\n\n        if not eval_store.intent_predictions:\n            self.predicted_intent = None\n        else:\n            self.predicted_intent = eval_store.intent_predictions[0]\n        self.predicted_entities = eval_store.entity_predictions\n\n        intent = {\"name\": eval_store.intent_targets[0]}\n\n        super().__init__(\n            event.text,\n            intent,\n            eval_store.entity_targets,\n            event.parse_data,\n            event.timestamp,\n            event.input_channel,\n        )\n\n    def inline_comment(self) -> Text:\n        \"\"\"A comment attached to this event. Used during dumping.\"\"\"\n        from rasa.shared.core.events import md_format_message\n\n        predicted_message = md_format_message(\n            self.text, self.predicted_intent, self.predicted_entities\n        )\n        return f\"predicted: {self.predicted_intent}: {predicted_message}\"\n\n    def as_story_string(self, e2e: bool = True) -> Text:\n        from rasa.shared.core.events import md_format_message\n\n        correct_message = md_format_message(\n            self.text, self.intent.get(\"name\"), self.entities\n        )\n        return (\n            f\"{self.intent.get('name')}: {correct_message}   \"\n            f\"<!-- {self.inline_comment()} -->\"\n        )\n\n\nasync def _create_data_generator(\n    resource_name: Text,\n    agent: \"Agent\",\n    max_stories: Optional[int] = None,\n    use_e2e: bool = False,\n) -> \"TrainingDataGenerator\":\n    from rasa.shared.core.generator import TrainingDataGenerator\n\n    from rasa.core import training\n\n    story_graph = await training.extract_story_graph(\n        resource_name, agent.domain, use_e2e\n    )\n    return TrainingDataGenerator(\n        story_graph,\n        agent.domain,\n        use_story_concatenation=False,\n        augmentation_factor=0,\n        tracker_limit=max_stories,\n    )\n\n\ndef _clean_entity_results(\n    text: Text, entity_results: List[Dict[Text, Any]]\n) -> List[Dict[Text, Any]]:\n    \"\"\"Extract only the token variables from an entity dict.\"\"\"\n    cleaned_entities = []\n\n    for r in tuple(entity_results):\n        cleaned_entity = {ENTITY_ATTRIBUTE_TEXT: text}\n        for k in (\n            ENTITY_ATTRIBUTE_START,\n            ENTITY_ATTRIBUTE_END,\n            ENTITY_ATTRIBUTE_TYPE,\n            ENTITY_ATTRIBUTE_VALUE,\n        ):\n            if k in set(r):\n                if k == ENTITY_ATTRIBUTE_VALUE and EXTRACTOR in set(r):\n                    # convert values to strings for evaluation as\n                    # target values are all of type string\n                    r[k] = str(r[k])\n                cleaned_entity[k] = r[k]\n        cleaned_entities.append(cleaned_entity)\n\n    return cleaned_entities\n\n\ndef _get_full_retrieval_intent(parsed: Dict[Text, Any]) -> Text:\n    \"\"\"Return full retrieval intent, if it's present, or normal intent otherwise.\n\n    Args:\n        parsed: Predicted parsed data.\n\n    Returns:\n        The extracted intent.\n    \"\"\"\n    base_intent = parsed.get(INTENT, {}).get(INTENT_NAME_KEY)\n    response_selector = parsed.get(RESPONSE_SELECTOR, {})\n\n    # return normal intent if it's not a retrieval intent\n    if base_intent not in response_selector.get(\n        RESPONSE_SELECTOR_RETRIEVAL_INTENTS, {}\n    ):\n        return base_intent\n\n    # extract full retrieval intent\n    # if the response selector parameter was not specified in config,\n    # the response selector contains a \"default\" key\n    if RESPONSE_SELECTOR_DEFAULT_INTENT in response_selector:\n        full_retrieval_intent = (\n            response_selector.get(RESPONSE_SELECTOR_DEFAULT_INTENT, {})\n            .get(RESPONSE, {})\n            .get(INTENT_RESPONSE_KEY)\n        )\n        return full_retrieval_intent if full_retrieval_intent else base_intent\n\n    # if specified, the response selector contains the base intent as key\n    full_retrieval_intent = (\n        response_selector.get(base_intent, {})\n        .get(RESPONSE, {})\n        .get(INTENT_RESPONSE_KEY)\n    )\n    return full_retrieval_intent if full_retrieval_intent else base_intent\n\n\ndef _collect_user_uttered_predictions(\n    event: UserUttered,\n    predicted: Dict[Text, Any],\n    partial_tracker: DialogueStateTracker,\n    fail_on_prediction_errors: bool,\n) -> EvaluationStore:\n    user_uttered_eval_store = EvaluationStore()\n\n    # intent from the test story, may either be base intent or full retrieval intent\n    base_intent = event.intent.get(INTENT_NAME_KEY)\n    full_retrieval_intent = event.intent.get(FULL_RETRIEVAL_INTENT_NAME_KEY)\n    intent_gold = full_retrieval_intent if full_retrieval_intent else base_intent\n\n    # predicted intent: note that this is only the base intent at this point\n    predicted_base_intent = predicted.get(INTENT, {}).get(INTENT_NAME_KEY)\n\n    # if the test story only provides the base intent AND the prediction was correct,\n    # we are not interested in full retrieval intents and skip this section.\n    # In any other case we are interested in the full retrieval intent (e.g. for report)\n    if intent_gold != predicted_base_intent:\n        predicted_base_intent = _get_full_retrieval_intent(predicted)\n\n    user_uttered_eval_store.add_to_store(\n        intent_predictions=[predicted_base_intent], intent_targets=[intent_gold]\n    )\n\n    entity_gold = event.entities\n    predicted_entities = predicted.get(ENTITIES)\n\n    if entity_gold or predicted_entities:\n        user_uttered_eval_store.add_to_store(\n            entity_targets=_clean_entity_results(event.text, entity_gold),\n            entity_predictions=_clean_entity_results(event.text, predicted_entities),\n        )\n\n    if user_uttered_eval_store.has_prediction_target_mismatch():\n        partial_tracker.update(\n            WronglyClassifiedUserUtterance(event, user_uttered_eval_store)\n        )\n        if fail_on_prediction_errors:\n            story_dump = YAMLStoryWriter().dumps(partial_tracker.as_story().story_steps)\n            raise WrongPredictionException(\n                f\"NLU model predicted a wrong intent. Failed Story:\"\n                f\" \\n\\n{story_dump}\"\n            )\n    else:\n        end_to_end_user_utterance = EndToEndUserUtterance(\n            event.text, event.intent, event.entities\n        )\n        partial_tracker.update(end_to_end_user_utterance)\n\n    return user_uttered_eval_store\n\n\ndef emulate_loop_rejection(partial_tracker: DialogueStateTracker) -> None:\n    \"\"\"Add `ActionExecutionRejected` event to the tracker.\n\n    During evaluation, we don't run action server, therefore in order to correctly\n    test unhappy paths of the loops, we need to emulate loop rejection.\n\n    Args:\n        partial_tracker: a :class:`rasa.core.trackers.DialogueStateTracker`\n    \"\"\"\n    from rasa.shared.core.events import ActionExecutionRejected\n\n    rejected_action_name: Text = partial_tracker.active_loop_name\n    partial_tracker.update(ActionExecutionRejected(rejected_action_name))\n\n\ndef _collect_action_executed_predictions(\n    processor: \"MessageProcessor\",\n    partial_tracker: DialogueStateTracker,\n    event: ActionExecuted,\n    fail_on_prediction_errors: bool,\n    circuit_breaker_tripped: bool,\n) -> Tuple[EvaluationStore, PolicyPrediction]:\n    from rasa.core.policies.form_policy import FormPolicy\n\n    action_executed_eval_store = EvaluationStore()\n\n    gold = event.action_name or event.action_text\n\n    if circuit_breaker_tripped:\n        prediction = PolicyPrediction([], policy_name=None)\n        predicted = \"circuit breaker tripped\"\n    else:\n        action, prediction = processor.predict_next_action(partial_tracker)\n        predicted = action.name()\n\n        if (\n            prediction.policy_name\n            and predicted != gold\n            and _form_might_have_been_rejected(\n                processor.domain, partial_tracker, predicted\n            )\n        ):\n            # Wrong action was predicted,\n            # but it might be Ok if form action is rejected.\n            emulate_loop_rejection(partial_tracker)\n            # try again\n            action, prediction = processor.predict_next_action(partial_tracker)\n\n            # Even if the prediction is also wrong, we don't have to undo the emulation\n            # of the action rejection as we know that the user explicitly specified\n            # that something else than the form was supposed to run.\n            predicted = action.name()\n\n    action_executed_eval_store.add_to_store(\n        action_predictions=[predicted], action_targets=[gold]\n    )\n\n    if action_executed_eval_store.has_prediction_target_mismatch():\n        partial_tracker.update(\n            WronglyPredictedAction(\n                gold,\n                predicted,\n                prediction.policy_name,\n                prediction.max_confidence,\n                event.timestamp,\n            )\n        )\n        if fail_on_prediction_errors:\n            story_dump = YAMLStoryWriter().dumps(partial_tracker.as_story().story_steps)\n            error_msg = (\n                f\"Model predicted a wrong action. Failed Story: \" f\"\\n\\n{story_dump}\"\n            )\n            if FormPolicy.__name__ in prediction.policy_name:\n                error_msg += (\n                    \"FormAction is not run during \"\n                    \"evaluation therefore it is impossible to know \"\n                    \"if validation failed or this story is wrong. \"\n                    \"If the story is correct, add it to the \"\n                    \"training stories and retrain.\"\n                )\n            raise WrongPredictionException(error_msg)\n    else:\n        partial_tracker.update(\n            ActionExecuted(\n                predicted,\n                prediction.policy_name,\n                prediction.max_confidence,\n                event.timestamp,\n            )\n        )\n\n    return action_executed_eval_store, prediction\n\n\ndef _form_might_have_been_rejected(\n    domain: Domain, tracker: DialogueStateTracker, predicted_action_name: Text\n) -> bool:\n    return (\n        tracker.active_loop_name == predicted_action_name\n        and predicted_action_name in domain.form_names\n    )\n\n\nasync def _predict_tracker_actions(\n    tracker: DialogueStateTracker,\n    agent: \"Agent\",\n    fail_on_prediction_errors: bool = False,\n    use_e2e: bool = False,\n) -> Tuple[EvaluationStore, DialogueStateTracker, List[Dict[Text, Any]]]:\n\n    processor = agent.create_processor()\n    tracker_eval_store = EvaluationStore()\n\n    events = list(tracker.events)\n\n    partial_tracker = DialogueStateTracker.from_events(\n        tracker.sender_id,\n        events[:1],\n        agent.domain.slots,\n        sender_source=tracker.sender_source,\n    )\n\n    tracker_actions = []\n    should_predict_another_action = True\n    num_predicted_actions = 0\n\n    for event in events[1:]:\n        if isinstance(event, ActionExecuted):\n            circuit_breaker_tripped = processor.is_action_limit_reached(\n                num_predicted_actions, should_predict_another_action\n            )\n            (action_executed_result, prediction) = _collect_action_executed_predictions(\n                processor,\n                partial_tracker,\n                event,\n                fail_on_prediction_errors,\n                circuit_breaker_tripped,\n            )\n            tracker_eval_store.merge_store(action_executed_result)\n            tracker_actions.append(\n                {\n                    \"action\": action_executed_result.action_targets[0],\n                    \"predicted\": action_executed_result.action_predictions[0],\n                    \"policy\": prediction.policy_name,\n                    \"confidence\": prediction.max_confidence,\n                }\n            )\n            should_predict_another_action = processor.should_predict_another_action(\n                action_executed_result.action_predictions[0]\n            )\n            num_predicted_actions += 1\n\n        elif use_e2e and isinstance(event, UserUttered):\n            # This means that user utterance didn't have a user message, only intent,\n            # so we can skip the NLU part and take the parse data directly.\n            # Indirectly that means that the test story was in YAML format.\n            if not event.text:\n                predicted = event.parse_data\n            # Indirectly that means that the test story was either:\n            # in YAML format containing a user message, or in Markdown format.\n            # Leaving that as it is because Markdown is in legacy mode.\n            else:\n                predicted = await processor.parse_message(UserMessage(event.text))\n            user_uttered_result = _collect_user_uttered_predictions(\n                event, predicted, partial_tracker, fail_on_prediction_errors\n            )\n\n            tracker_eval_store.merge_store(user_uttered_result)\n        else:\n            partial_tracker.update(event)\n        if isinstance(event, UserUttered):\n            num_predicted_actions = 0\n\n    return tracker_eval_store, partial_tracker, tracker_actions\n\n\ndef _in_training_data_fraction(action_list: List[Dict[Text, Any]]) -> float:\n    \"\"\"Given a list of action items, returns the fraction of actions\n\n    that were predicted using one of the Memoization policies.\"\"\"\n    from rasa.core.policies.ensemble import SimplePolicyEnsemble\n\n    in_training_data = [\n        a[\"action\"]\n        for a in action_list\n        if a[\"policy\"] and not SimplePolicyEnsemble.is_not_in_training_data(a[\"policy\"])\n    ]\n\n    return len(in_training_data) / len(action_list) if action_list else 0\n\n\nasync def _collect_story_predictions(\n    completed_trackers: List[\"DialogueStateTracker\"],\n    agent: \"Agent\",\n    fail_on_prediction_errors: bool = False,\n    use_e2e: bool = False,\n) -> Tuple[StoryEvaluation, int]:\n    \"\"\"Test the stories from a file, running them through the stored model.\"\"\"\n    from rasa.test import get_evaluation_metrics\n    from tqdm import tqdm\n\n    story_eval_store = EvaluationStore()\n    failed = []\n    success = []\n    correct_dialogues = []\n    number_of_stories = len(completed_trackers)\n\n    logger.info(f\"Evaluating {number_of_stories} stories\\nProgress:\")\n\n    action_list = []\n\n    for tracker in tqdm(completed_trackers):\n        (\n            tracker_results,\n            predicted_tracker,\n            tracker_actions,\n        ) = await _predict_tracker_actions(\n            tracker, agent, fail_on_prediction_errors, use_e2e\n        )\n\n        story_eval_store.merge_store(tracker_results)\n\n        action_list.extend(tracker_actions)\n\n        if tracker_results.has_prediction_target_mismatch():\n            # there is at least one wrong prediction\n            failed.append(predicted_tracker)\n            correct_dialogues.append(0)\n        else:\n            correct_dialogues.append(1)\n            success.append(predicted_tracker)\n\n    logger.info(\"Finished collecting predictions.\")\n    with warnings.catch_warnings():\n        from sklearn.exceptions import UndefinedMetricWarning\n\n        warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n        report, precision, f1, accuracy = get_evaluation_metrics(\n            [1] * len(completed_trackers), correct_dialogues\n        )\n\n    in_training_data_fraction = _in_training_data_fraction(action_list)\n\n    _log_evaluation_table(\n        [1] * len(completed_trackers),\n        \"END-TO-END\" if use_e2e else \"CONVERSATION\",\n        report,\n        precision,\n        f1,\n        accuracy,\n        in_training_data_fraction,\n        include_report=False,\n    )\n\n    return (\n        StoryEvaluation(\n            evaluation_store=story_eval_store,\n            failed_stories=failed,\n            successful_stories=success,\n            action_list=action_list,\n            in_training_data_fraction=in_training_data_fraction,\n        ),\n        number_of_stories,\n    )\n\n\ndef _log_stories(trackers: List[DialogueStateTracker], file_path: Text) -> None:\n    \"\"\"Write given stories to the given file.\"\"\"\n\n    with open(file_path, \"w\", encoding=DEFAULT_ENCODING) as f:\n        if not trackers:\n            f.write(\"# None of the test stories failed - all good!\")\n        else:\n            stories = [tracker.as_story(include_source=True) for tracker in trackers]\n            steps = [step for story in stories for step in story.story_steps]\n            f.write(YAMLStoryWriter().dumps(steps))\n\n\nasync def test(\n    stories: Text,\n    agent: \"Agent\",\n    max_stories: Optional[int] = None,\n    out_directory: Optional[Text] = None,\n    fail_on_prediction_errors: bool = False,\n    e2e: bool = False,\n    disable_plotting: bool = False,\n    successes: bool = False,\n    errors: bool = True,\n) -> Dict[Text, Any]:\n    \"\"\"Run the evaluation of the stories, optionally plot the results.\n\n    Args:\n        stories: the stories to evaluate on\n        agent: the agent\n        max_stories: maximum number of stories to consider\n        out_directory: path to directory to results to\n        fail_on_prediction_errors: boolean indicating whether to fail on prediction\n            errors or not\n        e2e: boolean indicating whether to use end to end evaluation or not\n        disable_plotting: boolean indicating whether to disable plotting or not\n        successes: boolean indicating whether to write down successful predictions or\n            not\n        errors: boolean indicating whether to write down incorrect predictions or not\n\n    Returns:\n        Evaluation summary.\n    \"\"\"\n    from rasa.test import get_evaluation_metrics\n\n    generator = await _create_data_generator(stories, agent, max_stories, e2e)\n    completed_trackers = generator.generate_story_trackers()\n\n    story_evaluation, _ = await _collect_story_predictions(\n        completed_trackers, agent, fail_on_prediction_errors, e2e\n    )\n\n    evaluation_store = story_evaluation.evaluation_store\n\n    with warnings.catch_warnings():\n        from sklearn.exceptions import UndefinedMetricWarning\n\n        warnings.simplefilter(\"ignore\", UndefinedMetricWarning)\n\n        targets, predictions = evaluation_store.serialise()\n\n        if out_directory:\n            report, precision, f1, accuracy = get_evaluation_metrics(\n                targets, predictions, output_dict=True\n            )\n\n            report_filename = os.path.join(out_directory, REPORT_STORIES_FILE)\n            rasa.shared.utils.io.dump_obj_as_json_to_file(report_filename, report)\n            logger.info(f\"Stories report saved to {report_filename}.\")\n        else:\n            report, precision, f1, accuracy = get_evaluation_metrics(\n                targets, predictions, output_dict=True\n            )\n\n    telemetry.track_core_model_test(len(generator.story_graph.story_steps), e2e, agent)\n\n    _log_evaluation_table(\n        evaluation_store.action_targets,\n        \"ACTION\",\n        report,\n        precision,\n        f1,\n        accuracy,\n        story_evaluation.in_training_data_fraction,\n        include_report=False,\n    )\n\n    if not disable_plotting and out_directory:\n        _plot_story_evaluation(\n            evaluation_store.action_targets,\n            evaluation_store.action_predictions,\n            out_directory,\n        )\n\n    if errors and out_directory:\n        _log_stories(\n            story_evaluation.failed_stories,\n            os.path.join(out_directory, FAILED_STORIES_FILE),\n        )\n    if successes and out_directory:\n        _log_stories(\n            story_evaluation.successful_stories,\n            os.path.join(out_directory, SUCCESSFUL_STORIES_FILE),\n        )\n\n    return {\n        \"report\": report,\n        \"precision\": precision,\n        \"f1\": f1,\n        \"accuracy\": accuracy,\n        \"actions\": story_evaluation.action_list,\n        \"in_training_data_fraction\": story_evaluation.in_training_data_fraction,\n        \"is_end_to_end_evaluation\": e2e,\n    }\n\n\ndef _log_evaluation_table(\n    golds: List[Any],\n    name: Text,\n    report: Dict[Text, Any],\n    precision: float,\n    f1: float,\n    accuracy: float,\n    in_training_data_fraction: float,\n    include_report: bool = True,\n) -> None:  # pragma: no cover\n    \"\"\"Log the sklearn evaluation metrics.\"\"\"\n    logger.info(f\"Evaluation Results on {name} level:\")\n    logger.info(f\"\\tCorrect:          {int(len(golds) * accuracy)} / {len(golds)}\")\n    logger.info(f\"\\tF1-Score:         {f1:.3f}\")\n    logger.info(f\"\\tPrecision:        {precision:.3f}\")\n    logger.info(f\"\\tAccuracy:         {accuracy:.3f}\")\n    logger.info(f\"\\tIn-data fraction: {in_training_data_fraction:.3g}\")\n\n    if include_report:\n        logger.info(f\"\\tClassification report: \\n{report}\")\n\n\ndef _plot_story_evaluation(\n    targets: List[Text], predictions: List[Text], output_directory: Optional[Text]\n) -> None:\n    \"\"\"Plot a confusion matrix of story evaluation.\"\"\"\n    from sklearn.metrics import confusion_matrix\n    from sklearn.utils.multiclass import unique_labels\n    from rasa.utils.plotting import plot_confusion_matrix\n\n    confusion_matrix_filename = CONFUSION_MATRIX_STORIES_FILE\n    if output_directory:\n        confusion_matrix_filename = os.path.join(\n            output_directory, confusion_matrix_filename\n        )\n\n    cnf_matrix = confusion_matrix(targets, predictions)\n\n    plot_confusion_matrix(\n        cnf_matrix,\n        classes=unique_labels(targets, predictions),\n        title=\"Action Confusion matrix\",\n        output_file=confusion_matrix_filename,\n    )\n\n\nasync def compare_models_in_dir(\n    model_dir: Text, stories_file: Text, output: Text\n) -> None:\n    \"\"\"Evaluate multiple trained models in a directory on a test set.\n\n    Args:\n        model_dir: path to directory that contains the models to evaluate\n        stories_file: path to the story file\n        output: output directory to store results to\n    \"\"\"\n    number_correct = defaultdict(list)\n\n    for run in rasa.shared.utils.io.list_subdirectories(model_dir):\n        number_correct_in_run = defaultdict(list)\n\n        for model in sorted(rasa.shared.utils.io.list_files(run)):\n            if not model.endswith(\"tar.gz\"):\n                continue\n\n            # The model files are named like <config-name>PERCENTAGE_KEY<number>.tar.gz\n            # Remove the percentage key and number from the name to get the config name\n            config_name = os.path.basename(model).split(PERCENTAGE_KEY)[0]\n            number_of_correct_stories = await _evaluate_core_model(model, stories_file)\n            number_correct_in_run[config_name].append(number_of_correct_stories)\n\n        for k, v in number_correct_in_run.items():\n            number_correct[k].append(v)\n\n    rasa.shared.utils.io.dump_obj_as_json_to_file(\n        os.path.join(output, RESULTS_FILE), number_correct\n    )\n\n\nasync def compare_models(models: List[Text], stories_file: Text, output: Text) -> None:\n    \"\"\"Evaluate provided trained models on a test set.\n\n    Args:\n        models: list of trained model paths\n        stories_file: path to the story file\n        output: output directory to store results to\n    \"\"\"\n    number_correct = defaultdict(list)\n\n    for model in models:\n        number_of_correct_stories = await _evaluate_core_model(model, stories_file)\n        number_correct[os.path.basename(model)].append(number_of_correct_stories)\n\n    rasa.shared.utils.io.dump_obj_as_json_to_file(\n        os.path.join(output, RESULTS_FILE), number_correct\n    )\n\n\nasync def _evaluate_core_model(model: Text, stories_file: Text) -> int:\n    from rasa.core.agent import Agent\n\n    logger.info(f\"Evaluating model '{model}'\")\n\n    agent = Agent.load(model)\n    generator = await _create_data_generator(stories_file, agent)\n    completed_trackers = generator.generate_story_trackers()\n    story_eval_store, number_of_stories = await _collect_story_predictions(\n        completed_trackers, agent\n    )\n    failed_stories = story_eval_store.failed_stories\n    return number_of_stories - len(failed_stories)\n\n\n### rasa/utils/io.py ###\n\nimport asyncio\nimport logging\nimport os\nimport pickle\nimport tarfile\nimport tempfile\nimport warnings\nimport zipfile\nfrom asyncio import AbstractEventLoop\nfrom io import BytesIO as IOReader\nfrom pathlib import Path\nfrom typing import Text, Any, Union, List, Type, Callable, TYPE_CHECKING\n\nimport rasa.shared.constants\nimport rasa.shared.utils.io\n\nif TYPE_CHECKING:\n    from prompt_toolkit.validation import Validator\n\n\ndef configure_colored_logging(loglevel: Text) -> None:\n    import coloredlogs\n\n    loglevel = loglevel or os.environ.get(\n        rasa.shared.constants.ENV_LOG_LEVEL, rasa.shared.constants.DEFAULT_LOG_LEVEL\n    )\n\n    field_styles = coloredlogs.DEFAULT_FIELD_STYLES.copy()\n    field_styles[\"asctime\"] = {}\n    level_styles = coloredlogs.DEFAULT_LEVEL_STYLES.copy()\n    level_styles[\"debug\"] = {}\n    coloredlogs.install(\n        level=loglevel,\n        use_chroot=False,\n        fmt=\"%(asctime)s %(levelname)-8s %(name)s  - %(message)s\",\n        level_styles=level_styles,\n        field_styles=field_styles,\n    )\n\n\ndef enable_async_loop_debugging(\n    event_loop: AbstractEventLoop, slow_callback_duration: float = 0.1\n) -> AbstractEventLoop:\n    logging.info(\n        \"Enabling coroutine debugging. Loop id {}.\".format(id(asyncio.get_event_loop()))\n    )\n\n    # Enable debugging\n    event_loop.set_debug(True)\n\n    # Make the threshold for \"slow\" tasks very very small for\n    # illustration. The default is 0.1 (= 100 milliseconds).\n    event_loop.slow_callback_duration = slow_callback_duration\n\n    # Report all mistakes managing asynchronous resources.\n    warnings.simplefilter(\"always\", ResourceWarning)\n    return event_loop\n\n\ndef pickle_dump(filename: Union[Text, Path], obj: Any) -> None:\n    \"\"\"Saves object to file.\n\n    Args:\n        filename: the filename to save the object to\n        obj: the object to store\n    \"\"\"\n    with open(filename, \"wb\") as f:\n        pickle.dump(obj, f)\n\n\ndef pickle_load(filename: Union[Text, Path]) -> Any:\n    \"\"\"Loads an object from a file.\n\n    Args:\n        filename: the filename to load the object from\n\n    Returns: the loaded object\n    \"\"\"\n    with open(filename, \"rb\") as f:\n        return pickle.load(f)\n\n\ndef unarchive(byte_array: bytes, directory: Text) -> Text:\n    \"\"\"Tries to unpack a byte array interpreting it as an archive.\n\n    Tries to use tar first to unpack, if that fails, zip will be used.\"\"\"\n\n    try:\n        tar = tarfile.open(fileobj=IOReader(byte_array))\n        tar.extractall(directory)\n        tar.close()\n        return directory\n    except tarfile.TarError:\n        zip_ref = zipfile.ZipFile(IOReader(byte_array))\n        zip_ref.extractall(directory)\n        zip_ref.close()\n        return directory\n\n\ndef create_temporary_file(data: Any, suffix: Text = \"\", mode: Text = \"w+\") -> Text:\n    \"\"\"Creates a tempfile.NamedTemporaryFile object for data.\n\n    mode defines NamedTemporaryFile's  mode parameter in py3.\"\"\"\n\n    encoding = None if \"b\" in mode else rasa.shared.utils.io.DEFAULT_ENCODING\n    f = tempfile.NamedTemporaryFile(\n        mode=mode, suffix=suffix, delete=False, encoding=encoding\n    )\n    f.write(data)\n\n    f.close()\n    return f.name\n\n\ndef create_temporary_directory() -> Text:\n    \"\"\"Creates a tempfile.TemporaryDirectory.\"\"\"\n    f = tempfile.TemporaryDirectory()\n    return f.name\n\n\ndef create_path(file_path: Text) -> None:\n    \"\"\"Makes sure all directories in the 'file_path' exists.\"\"\"\n\n    parent_dir = os.path.dirname(os.path.abspath(file_path))\n    if not os.path.exists(parent_dir):\n        os.makedirs(parent_dir)\n\n\ndef file_type_validator(\n    valid_file_types: List[Text], error_message: Text\n) -> Type[\"Validator\"]:\n    \"\"\"Creates a `Validator` class which can be used with `questionary` to validate\n    file paths.\n    \"\"\"\n\n    def is_valid(path: Text) -> bool:\n        return path is not None and any(\n            [path.endswith(file_type) for file_type in valid_file_types]\n        )\n\n    return create_validator(is_valid, error_message)\n\n\ndef not_empty_validator(error_message: Text) -> Type[\"Validator\"]:\n    \"\"\"Creates a `Validator` class which can be used with `questionary` to validate\n    that the user entered something other than whitespace.\n    \"\"\"\n\n    def is_valid(input: Text) -> bool:\n        return input is not None and input.strip() != \"\"\n\n    return create_validator(is_valid, error_message)\n\n\ndef create_validator(\n    function: Callable[[Text], bool], error_message: Text\n) -> Type[\"Validator\"]:\n    \"\"\"Helper method to create `Validator` classes from callable functions. Should be\n    removed when questionary supports `Validator` objects.\"\"\"\n\n    from prompt_toolkit.validation import Validator, ValidationError\n    from prompt_toolkit.document import Document\n\n    class FunctionValidator(Validator):\n        @staticmethod\n        def validate(document: Document) -> None:\n            is_valid = function(document.text)\n            if not is_valid:\n                raise ValidationError(message=error_message)\n\n    return FunctionValidator\n\n\ndef zip_folder(folder: Text) -> Text:\n    \"\"\"Create an archive from a folder.\"\"\"\n    import shutil\n\n    zipped_path = tempfile.NamedTemporaryFile(delete=False)\n    zipped_path.close()\n\n    # WARN: not thread-safe!\n    return shutil.make_archive(zipped_path.name, \"zip\", folder)\n\n\ndef json_unpickle(file_name: Union[Text, Path]) -> Any:\n    \"\"\"Unpickle an object from file using json.\n\n    Args:\n        file_name: the file to load the object from\n\n    Returns: the object\n    \"\"\"\n    import jsonpickle.ext.numpy as jsonpickle_numpy\n    import jsonpickle\n\n    jsonpickle_numpy.register_handlers()\n\n    file_content = rasa.shared.utils.io.read_file(file_name)\n    return jsonpickle.loads(file_content)\n\n\ndef json_pickle(file_name: Union[Text, Path], obj: Any) -> None:\n    \"\"\"Pickle an object to a file using json.\n\n    Args:\n        file_name: the file to store the object to\n        obj: the object to store\n    \"\"\"\n    import jsonpickle.ext.numpy as jsonpickle_numpy\n    import jsonpickle\n\n    jsonpickle_numpy.register_handlers()\n\n    rasa.shared.utils.io.write_text_file(jsonpickle.dumps(obj), file_name)\n\n\n### rasa/core/agent.py ###\n\nfrom asyncio import CancelledError\nimport logging\nimport os\nimport shutil\nimport tempfile\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, List, Optional, Text, Tuple, Union\nimport uuid\n\nimport aiohttp\nfrom aiohttp import ClientError\n\nimport rasa\nfrom rasa.core import jobs, training\nfrom rasa.core.channels.channel import OutputChannel, UserMessage\nfrom rasa.core.constants import DEFAULT_REQUEST_TIMEOUT\nfrom rasa.shared.core.domain import Domain\nfrom rasa.core.exceptions import AgentNotReady\nimport rasa.core.interpreter\nfrom rasa.shared.constants import (\n    DEFAULT_SENDER_ID,\n    DEFAULT_DOMAIN_PATH,\n    DEFAULT_CORE_SUBDIRECTORY_NAME,\n)\nfrom rasa.shared.exceptions import InvalidParameterException, RasaException\nfrom rasa.shared.nlu.interpreter import NaturalLanguageInterpreter, RegexInterpreter\nfrom rasa.core.lock_store import InMemoryLockStore, LockStore\nfrom rasa.core.nlg import NaturalLanguageGenerator\nfrom rasa.core.policies.ensemble import PolicyEnsemble, SimplePolicyEnsemble\nfrom rasa.core.policies.memoization import MemoizationPolicy\nfrom rasa.core.policies.policy import Policy, PolicyPrediction\nfrom rasa.core.processor import MessageProcessor\nfrom rasa.core.tracker_store import (\n    FailSafeTrackerStore,\n    InMemoryTrackerStore,\n    TrackerStore,\n)\nfrom rasa.shared.core.trackers import DialogueStateTracker\nimport rasa.core.utils\nfrom rasa.exceptions import ModelNotFound\nfrom rasa.shared.importers.importer import TrainingDataImporter\nfrom rasa.model import (\n    get_latest_model,\n    get_model,\n    get_model_subdirectories,\n    unpack_model,\n)\nfrom rasa.nlu.utils import is_url\nimport rasa.shared.utils.io\nfrom rasa.shared.nlu.training_data.training_data import TrainingData\nfrom rasa.utils.endpoints import EndpointConfig\nimport rasa.utils.io\n\nlogger = logging.getLogger(__name__)\n\n\nasync def load_from_server(agent: \"Agent\", model_server: EndpointConfig) -> \"Agent\":\n    \"\"\"Load a persisted model from a server.\"\"\"\n\n    # We are going to pull the model once first, and then schedule a recurring\n    # job. the benefit of this approach is that we can be sure that there\n    # is a model after this function completes -> allows to do proper\n    # \"is alive\" check on a startup server's `/status` endpoint. If the server\n    # is started, we can be sure that it also already loaded (or tried to)\n    # a model.\n    await _update_model_from_server(model_server, agent)\n\n    wait_time_between_pulls = model_server.kwargs.get(\"wait_time_between_pulls\", 100)\n\n    if wait_time_between_pulls:\n        # continuously pull the model every `wait_time_between_pulls` seconds\n        await schedule_model_pulling(model_server, int(wait_time_between_pulls), agent)\n\n    return agent\n\n\ndef _load_interpreter(\n    agent: \"Agent\", nlu_path: Optional[Text]\n) -> NaturalLanguageInterpreter:\n    \"\"\"Load the NLU interpreter at `nlu_path`.\n\n    Args:\n        agent: Instance of `Agent` to inspect for an interpreter if `nlu_path` is\n            `None`.\n        nlu_path: NLU model path.\n\n    Returns:\n        The NLU interpreter.\n    \"\"\"\n    if nlu_path:\n        return rasa.core.interpreter.create_interpreter(nlu_path)\n\n    return agent.interpreter or RegexInterpreter()\n\n\ndef _load_domain_and_policy_ensemble(\n    core_path: Optional[Text],\n) -> Tuple[Optional[Domain], Optional[PolicyEnsemble]]:\n    \"\"\"Load the domain and policy ensemble from the model at `core_path`.\n\n    Args:\n        core_path: Core model path.\n\n    Returns:\n        An instance of `Domain` and `PolicyEnsemble` if `core_path` is not `None`.\n    \"\"\"\n    policy_ensemble = None\n    domain = None\n\n    if core_path:\n        policy_ensemble = PolicyEnsemble.load(core_path)\n        domain_path = os.path.join(os.path.abspath(core_path), DEFAULT_DOMAIN_PATH)\n        domain = Domain.load(domain_path)\n\n    return domain, policy_ensemble\n\n\ndef _load_and_set_updated_model(\n    agent: \"Agent\", model_directory: Text, fingerprint: Text\n) -> None:\n    \"\"\"Load the persisted model into memory and set the model on the agent.\n\n    Args:\n        agent: Instance of `Agent` to update with the new model.\n        model_directory: Rasa model directory.\n        fingerprint: Fingerprint of the supplied model at `model_directory`.\n    \"\"\"\n    logger.debug(f\"Found new model with fingerprint {fingerprint}. Loading...\")\n\n    core_path, nlu_path = get_model_subdirectories(model_directory)\n\n    interpreter = _load_interpreter(agent, nlu_path)\n    domain, policy_ensemble = _load_domain_and_policy_ensemble(core_path)\n\n    agent.update_model(\n        domain, policy_ensemble, fingerprint, interpreter, model_directory\n    )\n\n    logger.debug(\"Finished updating agent to new model.\")\n\n\nasync def _update_model_from_server(\n    model_server: EndpointConfig, agent: \"Agent\"\n) -> None:\n    \"\"\"Load a zipped Rasa Core model from a URL and update the passed agent.\"\"\"\n\n    if not is_url(model_server.url):\n        raise aiohttp.InvalidURL(model_server.url)\n\n    model_directory = tempfile.mkdtemp()\n    remove_dir = True\n\n    try:\n        new_fingerprint = await _pull_model_and_fingerprint(\n            model_server, agent.fingerprint, model_directory\n        )\n\n        if new_fingerprint:\n            _load_and_set_updated_model(agent, model_directory, new_fingerprint)\n            remove_dir = False\n        else:\n            logger.debug(f\"No new model found at URL {model_server.url}\")\n    except Exception:  # skipcq: PYL-W0703\n        # TODO: Make this exception more specific, possibly print different log\n        # for each one.\n        logger.exception(\n            \"Failed to update model. The previous model will stay loaded instead.\"\n        )\n    finally:\n        if remove_dir:\n            shutil.rmtree(model_directory)\n\n\nasync def _pull_model_and_fingerprint(\n    model_server: EndpointConfig, fingerprint: Optional[Text], model_directory: Text\n) -> Optional[Text]:\n    \"\"\"Queries the model server.\n\n    Args:\n        model_server: Model server endpoint information.\n        fingerprint: Current model fingerprint.\n        model_directory: Directory where to download model to.\n\n    Returns:\n        Value of the response's <ETag> header which contains the model\n        hash. Returns `None` if no new model is found.\n    \"\"\"\n    headers = {\"If-None-Match\": fingerprint}\n\n    logger.debug(f\"Requesting model from server {model_server.url}...\")\n\n    async with model_server.session() as session:\n        try:\n            params = model_server.combine_parameters()\n            async with session.request(\n                \"GET\",\n                model_server.url,\n                timeout=DEFAULT_REQUEST_TIMEOUT,\n                headers=headers,\n                params=params,\n            ) as resp:\n\n                if resp.status in [204, 304]:\n                    logger.debug(\n                        \"Model server returned {} status code, \"\n                        \"indicating that no new model is available. \"\n                        \"Current fingerprint: {}\"\n                        \"\".format(resp.status, fingerprint)\n                    )\n                    return None\n                elif resp.status == 404:\n                    logger.debug(\n                        \"Model server could not find a model at the requested \"\n                        \"endpoint '{}'. It's possible that no model has been \"\n                        \"trained, or that the requested tag hasn't been \"\n                        \"assigned.\".format(model_server.url)\n                    )\n                    return None\n                elif resp.status != 200:\n                    logger.debug(\n                        \"Tried to fetch model from server, but server response \"\n                        \"status code is {}. We'll retry later...\"\n                        \"\".format(resp.status)\n                    )\n                    return None\n\n                rasa.utils.io.unarchive(await resp.read(), model_directory)\n                logger.debug(\n                    \"Unzipped model to '{}'\".format(os.path.abspath(model_directory))\n                )\n\n                # return the new fingerprint\n                return resp.headers.get(\"ETag\")\n\n        except aiohttp.ClientError as e:\n            logger.debug(\n                \"Tried to fetch model from server, but \"\n                \"couldn't reach server. We'll retry later... \"\n                \"Error: {}.\".format(e)\n            )\n            return None\n\n\nasync def _run_model_pulling_worker(\n    model_server: EndpointConfig, agent: \"Agent\"\n) -> None:\n    # noinspection PyBroadException\n    try:\n        await _update_model_from_server(model_server, agent)\n    except CancelledError:\n        logger.warning(\"Stopping model pulling (cancelled).\")\n    except ClientError:\n        logger.exception(\n            \"An exception was raised while fetching a model. Continuing anyways...\"\n        )\n\n\nasync def schedule_model_pulling(\n    model_server: EndpointConfig, wait_time_between_pulls: int, agent: \"Agent\"\n):\n    (await jobs.scheduler()).add_job(\n        _run_model_pulling_worker,\n        \"interval\",\n        seconds=wait_time_between_pulls,\n        args=[model_server, agent],\n        id=\"pull-model-from-server\",\n        replace_existing=True,\n    )\n\n\nasync def load_agent(\n    model_path: Optional[Text] = None,\n    model_server: Optional[EndpointConfig] = None,\n    remote_storage: Optional[Text] = None,\n    interpreter: Optional[NaturalLanguageInterpreter] = None,\n    generator: Union[EndpointConfig, NaturalLanguageGenerator] = None,\n    tracker_store: Optional[TrackerStore] = None,\n    lock_store: Optional[LockStore] = None,\n    action_endpoint: Optional[EndpointConfig] = None,\n):\n    try:\n        if model_server is not None:\n            return await load_from_server(\n                Agent(\n                    interpreter=interpreter,\n                    generator=generator,\n                    tracker_store=tracker_store,\n                    lock_store=lock_store,\n                    action_endpoint=action_endpoint,\n                    model_server=model_server,\n                    remote_storage=remote_storage,\n                ),\n                model_server,\n            )\n\n        elif remote_storage is not None:\n            return Agent.load_from_remote_storage(\n                remote_storage,\n                model_path,\n                interpreter=interpreter,\n                generator=generator,\n                tracker_store=tracker_store,\n                lock_store=lock_store,\n                action_endpoint=action_endpoint,\n                model_server=model_server,\n            )\n\n        elif model_path is not None and os.path.exists(model_path):\n            return Agent.load_local_model(\n                model_path,\n                interpreter=interpreter,\n                generator=generator,\n                tracker_store=tracker_store,\n                lock_store=lock_store,\n                action_endpoint=action_endpoint,\n                model_server=model_server,\n                remote_storage=remote_storage,\n            )\n\n        else:\n            rasa.shared.utils.io.raise_warning(\n                \"No valid configuration given to load agent.\"\n            )\n            return None\n\n    except Exception as e:\n        logger.error(f\"Could not load model due to {e}.\")\n        raise\n\n\nclass Agent:\n    \"\"\"The Agent class provides a convenient interface for the most important\n    Rasa functionality.\n\n    This includes training, handling messages, loading a dialogue model,\n    getting the next action, and handling a channel.\"\"\"\n\n    def __init__(\n        self,\n        domain: Union[Text, Domain, None] = None,\n        policies: Union[PolicyEnsemble, List[Policy], None] = None,\n        interpreter: Optional[NaturalLanguageInterpreter] = None,\n        generator: Union[EndpointConfig, NaturalLanguageGenerator, None] = None,\n        tracker_store: Optional[TrackerStore] = None,\n        lock_store: Optional[LockStore] = None,\n        action_endpoint: Optional[EndpointConfig] = None,\n        fingerprint: Optional[Text] = None,\n        model_directory: Optional[Text] = None,\n        model_server: Optional[EndpointConfig] = None,\n        remote_storage: Optional[Text] = None,\n        path_to_model_archive: Optional[Text] = None,\n    ):\n        # Initializing variables with the passed parameters.\n        self.domain = self._create_domain(domain)\n        self.policy_ensemble = self._create_ensemble(policies)\n\n        if self.domain is not None:\n            self.domain.add_requested_slot()\n            self.domain.add_knowledge_base_slots()\n            self.domain.add_categorical_slot_default_value()\n\n        PolicyEnsemble.check_domain_ensemble_compatibility(\n            self.policy_ensemble, self.domain\n        )\n\n        self.interpreter = rasa.core.interpreter.create_interpreter(interpreter)\n\n        self.nlg = NaturalLanguageGenerator.create(generator, self.domain)\n        self.tracker_store = self.create_tracker_store(tracker_store, self.domain)\n        self.lock_store = self._create_lock_store(lock_store)\n        self.action_endpoint = action_endpoint\n\n        self._set_fingerprint(fingerprint)\n        self.model_directory = model_directory\n        self.model_server = model_server\n        self.remote_storage = remote_storage\n        self.path_to_model_archive = path_to_model_archive\n\n    def update_model(\n        self,\n        domain: Optional[Domain],\n        policy_ensemble: Optional[PolicyEnsemble],\n        fingerprint: Optional[Text],\n        interpreter: Optional[NaturalLanguageInterpreter] = None,\n        model_directory: Optional[Text] = None,\n    ) -> None:\n        self.domain = self._create_domain(domain)\n        self.policy_ensemble = policy_ensemble\n\n        if interpreter:\n            self.interpreter = rasa.core.interpreter.create_interpreter(interpreter)\n\n        self._set_fingerprint(fingerprint)\n\n        # update domain on all instances\n        self.tracker_store.domain = domain\n        if hasattr(self.nlg, \"templates\"):\n            self.nlg.templates = domain.templates if domain else {}\n\n        self.model_directory = model_directory\n\n    @classmethod\n    def load(\n        cls,\n        model_path: Union[Text, Path],\n        interpreter: Optional[NaturalLanguageInterpreter] = None,\n        generator: Union[EndpointConfig, NaturalLanguageGenerator] = None,\n        tracker_store: Optional[TrackerStore] = None,\n        lock_store: Optional[LockStore] = None,\n        action_endpoint: Optional[EndpointConfig] = None,\n        model_server: Optional[EndpointConfig] = None,\n        remote_storage: Optional[Text] = None,\n        path_to_model_archive: Optional[Text] = None,\n    ) -> \"Agent\":\n        \"\"\"Load a persisted model from the passed path.\"\"\"\n        try:\n            if not model_path:\n                raise ModelNotFound(\"No path specified.\")\n            if not os.path.exists(model_path):\n                raise ModelNotFound(f\"No file or directory at '{model_path}'.\")\n            if os.path.isfile(model_path):\n                model_path = get_model(str(model_path))\n        except ModelNotFound as e:\n            raise ModelNotFound(\n                f\"You are trying to load a model from '{model_path}', \"\n                f\"which is not possible. \\n\"\n                f\"The model path should be a 'tar.gz' file or a directory \"\n                f\"containing the various model files in the sub-directories \"\n                f\"'core' and 'nlu'. \\n\\n\"\n                f\"If you want to load training data instead of a model, use \"\n                f\"`agent.load_data(...)` instead. {e}\"\n            )\n\n        core_model, nlu_model = get_model_subdirectories(model_path)\n\n        if not interpreter and nlu_model:\n            interpreter = rasa.core.interpreter.create_interpreter(nlu_model)\n\n        domain = None\n        ensemble = None\n\n        if core_model:\n            domain = Domain.load(os.path.join(core_model, DEFAULT_DOMAIN_PATH))\n            ensemble = PolicyEnsemble.load(core_model) if core_model else None\n\n            # ensures the domain hasn't changed between test and train\n            domain.compare_with_specification(core_model)\n\n        return cls(\n            domain=domain,\n            policies=ensemble,\n            interpreter=interpreter,\n            generator=generator,\n            tracker_store=tracker_store,\n            lock_store=lock_store,\n            action_endpoint=action_endpoint,\n            model_directory=model_path,\n            model_server=model_server,\n            remote_storage=remote_storage,\n            path_to_model_archive=path_to_model_archive,\n        )\n\n    def is_core_ready(self) -> bool:\n        \"\"\"Check if all necessary components and policies are ready to use the agent.\"\"\"\n        return self.is_ready() and self.policy_ensemble is not None\n\n    def is_ready(self) -> bool:\n        \"\"\"Check if all necessary components are instantiated to use agent.\n\n        Policies might not be available, if this is an NLU only agent.\"\"\"\n\n        return self.tracker_store is not None and self.interpreter is not None\n\n    async def parse_message_using_nlu_interpreter(\n        self, message_data: Text, tracker: DialogueStateTracker = None\n    ) -> Dict[Text, Any]:\n        \"\"\"Handles message text and intent payload input messages.\n\n        The return value of this function is parsed_data.\n\n        Args:\n            message_data (Text): Contain the received message in text or\\\n            intent payload format.\n            tracker (DialogueStateTracker): Contains the tracker to be\\\n            used by the interpreter.\n\n        Returns:\n            The parsed message.\n\n            Example:\n\n                {\\\n                    \"text\": '/greet{\"name\":\"Rasa\"}',\\\n                    \"intent\": {\"name\": \"greet\", \"confidence\": 1.0},\\\n                    \"intent_ranking\": [{\"name\": \"greet\", \"confidence\": 1.0}],\\\n                    \"entities\": [{\"entity\": \"name\", \"start\": 6,\\\n                                  \"end\": 21, \"value\": \"Rasa\"}],\\\n                }\n\n        \"\"\"\n\n        processor = self.create_processor()\n        message = UserMessage(message_data)\n        return await processor.parse_message(message, tracker)\n\n    async def handle_message(\n        self,\n        message: UserMessage,\n        message_preprocessor: Optional[Callable[[Text], Text]] = None,\n        **kwargs,\n    ) -> Optional[List[Dict[Text, Any]]]:\n        \"\"\"Handle a single message.\"\"\"\n\n        def noop(_: Any) -> None:\n            logger.info(\"Ignoring message as there is no agent to handle it.\")\n\n        if not self.is_ready():\n            return noop(message)\n\n        processor = self.create_processor(message_preprocessor)\n\n        async with self.lock_store.lock(message.sender_id):\n            return await processor.handle_message(message)\n\n    # noinspection PyUnusedLocal\n    async def predict_next(\n        self, sender_id: Text, **kwargs: Any\n    ) -> Optional[Dict[Text, Any]]:\n        \"\"\"Handle a single message.\"\"\"\n\n        processor = self.create_processor()\n        return await processor.predict_next(sender_id)\n\n    # noinspection PyUnusedLocal\n    async def log_message(\n        self,\n        message: UserMessage,\n        message_preprocessor: Optional[Callable[[Text], Text]] = None,\n        **kwargs: Any,\n    ) -> DialogueStateTracker:\n        \"\"\"Append a message to a dialogue - does not predict actions.\"\"\"\n        processor = self.create_processor(message_preprocessor)\n\n        return await processor.log_message(message)\n\n    async def execute_action(\n        self,\n        sender_id: Text,\n        action: Text,\n        output_channel: OutputChannel,\n        policy: Optional[Text],\n        confidence: Optional[float],\n    ) -> Optional[DialogueStateTracker]:\n        \"\"\"Handle a single message.\"\"\"\n        processor = self.create_processor()\n        prediction = PolicyPrediction.for_action_name(\n            self.domain, action, policy, confidence or 0.0\n        )\n        return await processor.execute_action(\n            sender_id, action, output_channel, self.nlg, prediction\n        )\n\n    async def trigger_intent(\n        self,\n        intent_name: Text,\n        entities: List[Dict[Text, Any]],\n        output_channel: OutputChannel,\n        tracker: DialogueStateTracker,\n    ) -> None:\n        \"\"\"Trigger a user intent, e.g. triggered by an external event.\"\"\"\n\n        processor = self.create_processor()\n        await processor.trigger_external_user_uttered(\n            intent_name, entities, tracker, output_channel\n        )\n\n    async def handle_text(\n        self,\n        text_message: Union[Text, Dict[Text, Any]],\n        message_preprocessor: Optional[Callable[[Text], Text]] = None,\n        output_channel: Optional[OutputChannel] = None,\n        sender_id: Optional[Text] = DEFAULT_SENDER_ID,\n    ) -> Optional[List[Dict[Text, Any]]]:\n        \"\"\"Handle a single message.\n\n        If a message preprocessor is passed, the message will be passed to that\n        function first and the return value is then used as the\n        input for the dialogue engine.\n\n        The return value of this function depends on the ``output_channel``. If\n        the output channel is not set, set to ``None``, or set\n        to ``CollectingOutputChannel`` this function will return the messages\n        the bot wants to respond.\n\n        :Example:\n\n            >>> from rasa.core.agent import Agent\n            >>> from rasa.core.interpreter import RasaNLUInterpreter\n            >>> agent = Agent.load(\"examples/moodbot/models\")\n            >>> await agent.handle_text(\"hello\")\n            [u'how can I help you?']\n\n        \"\"\"\n\n        if isinstance(text_message, str):\n            text_message = {\"text\": text_message}\n\n        msg = UserMessage(text_message.get(\"text\"), output_channel, sender_id)\n\n        return await self.handle_message(msg, message_preprocessor)\n\n    def toggle_memoization(self, activate: bool) -> None:\n        \"\"\"Toggles the memoization on and off.\n\n        If a memoization policy is present in the ensemble, this will toggle\n        the prediction of that policy. When set to ``False`` the Memoization\n        policies present in the policy ensemble will not make any predictions.\n        Hence, the prediction result from the ensemble always needs to come\n        from a different policy (e.g. ``TEDPolicy``). Useful to test\n        prediction\n        capabilities of an ensemble when ignoring memorized turns from the\n        training data.\"\"\"\n\n        if not self.policy_ensemble:\n            return\n\n        for p in self.policy_ensemble.policies:\n            # explicitly ignore inheritance (e.g. augmented memoization policy)\n            if type(p) is MemoizationPolicy:\n                p.toggle(activate)\n\n    def _max_history(self) -> int:\n        \"\"\"Find maximum max_history.\"\"\"\n\n        max_histories = [\n            policy.featurizer.max_history\n            for policy in self.policy_ensemble.policies\n            if policy.featurizer\n            and hasattr(policy.featurizer, \"max_history\")\n            and policy.featurizer.max_history is not None\n        ]\n\n        return max(max_histories or [0])\n\n    def _are_all_featurizers_using_a_max_history(self) -> bool:\n        \"\"\"Check if all featurizers are MaxHistoryTrackerFeaturizer.\"\"\"\n\n        def has_max_history_featurizer(policy: Policy) -> bool:\n            return (\n                policy.featurizer\n                and hasattr(policy.featurizer, \"max_history\")\n                and policy.featurizer.max_history is not None\n            )\n\n        for p in self.policy_ensemble.policies:\n            if p.featurizer and not has_max_history_featurizer(p):\n                return False\n        return True\n\n    async def load_data(\n        self,\n        training_resource: Union[Text, TrainingDataImporter],\n        remove_duplicates: bool = True,\n        unique_last_num_states: Optional[int] = None,\n        augmentation_factor: int = 50,\n        tracker_limit: Optional[int] = None,\n        use_story_concatenation: bool = True,\n        debug_plots: bool = False,\n        exclusion_percentage: Optional[int] = None,\n    ) -> List[DialogueStateTracker]:\n        \"\"\"Load training data from a resource.\"\"\"\n\n        max_history = self._max_history()\n\n        if unique_last_num_states is None:\n            # for speed up of data generation\n            # automatically detect unique_last_num_states\n            # if it was not set and\n            # if all featurizers are MaxHistoryTrackerFeaturizer\n            if self._are_all_featurizers_using_a_max_history():\n                unique_last_num_states = max_history\n        elif unique_last_num_states < max_history:\n            # possibility of data loss\n            rasa.shared.utils.io.raise_warning(\n                f\"unique_last_num_states={unique_last_num_states} but \"\n                f\"maximum max_history={max_history}. \"\n                f\"Possibility of data loss. \"\n                f\"It is recommended to set \"\n                f\"unique_last_num_states to \"\n                f\"at least maximum max_history.\"\n            )\n\n        return await training.load_data(\n            training_resource,\n            self.domain,\n            remove_duplicates,\n            unique_last_num_states,\n            augmentation_factor,\n            tracker_limit,\n            use_story_concatenation,\n            debug_plots,\n            exclusion_percentage=exclusion_percentage,\n        )\n\n    def train(\n        self, training_trackers: List[DialogueStateTracker], **kwargs: Any\n    ) -> None:\n        \"\"\"Train the policies / policy ensemble using dialogue data from file.\n\n        Args:\n            training_trackers: trackers to train on\n            **kwargs: additional arguments passed to the underlying ML\n                           trainer (e.g. keras parameters)\n        \"\"\"\n        if not self.is_core_ready():\n            raise AgentNotReady(\"Can't train without a policy ensemble.\")\n\n        logger.debug(f\"Agent trainer got kwargs: {kwargs}\")\n\n        self.policy_ensemble.train(\n            training_trackers, self.domain, interpreter=self.interpreter, **kwargs\n        )\n        self._set_fingerprint()\n\n    def _set_fingerprint(self, fingerprint: Optional[Text] = None) -> None:\n\n        if fingerprint:\n            self.fingerprint = fingerprint\n        else:\n            self.fingerprint = uuid.uuid4().hex\n\n    @staticmethod\n    def _clear_model_directory(model_path: Text) -> None:\n        \"\"\"Remove existing files from model directory.\n\n        Only removes files if the directory seems to contain a previously\n        persisted model. Otherwise does nothing to avoid deleting\n        `/` by accident.\"\"\"\n\n        if not os.path.exists(model_path):\n            return\n\n        domain_spec_path = os.path.join(model_path, \"metadata.json\")\n        # check if there were a model before\n        if os.path.exists(domain_spec_path):\n            logger.info(\n                \"Model directory {} exists and contains old \"\n                \"model files. All files will be overwritten.\"\n                \"\".format(model_path)\n            )\n            shutil.rmtree(model_path)\n        else:\n            logger.debug(\n                \"Model directory {} exists, but does not contain \"\n                \"all old model files. Some files might be \"\n                \"overwritten.\".format(model_path)\n            )\n\n    def persist(self, model_path: Text) -> None:\n        \"\"\"Persists this agent into a directory for later loading and usage.\"\"\"\n\n        if not self.is_core_ready():\n            raise AgentNotReady(\"Can't persist without a policy ensemble.\")\n\n        if not model_path.endswith(DEFAULT_CORE_SUBDIRECTORY_NAME):\n            model_path = os.path.join(model_path, DEFAULT_CORE_SUBDIRECTORY_NAME)\n\n        self._clear_model_directory(model_path)\n\n        self.policy_ensemble.persist(model_path)\n        self.domain.persist(os.path.join(model_path, DEFAULT_DOMAIN_PATH))\n        self.domain.persist_specification(model_path)\n\n        logger.info(\"Persisted model to '{}'\".format(os.path.abspath(model_path)))\n\n    async def visualize(\n        self,\n        resource_name: Text,\n        output_file: Text,\n        max_history: Optional[int] = None,\n        nlu_training_data: Optional[TrainingData] = None,\n        should_merge_nodes: bool = True,\n        fontsize: int = 12,\n    ) -> None:\n        \"\"\"Visualize the loaded training data from the resource.\"\"\"\n        from rasa.shared.core.training_data.visualization import visualize_stories\n        from rasa.shared.core.training_data import loading\n\n        # if the user doesn't provide a max history, we will use the\n        # largest value from any policy\n        max_history = max_history or self._max_history()\n\n        story_steps = await loading.load_data_from_resource(resource_name, self.domain)\n        await visualize_stories(\n            story_steps,\n            self.domain,\n            output_file,\n            max_history,\n            self.interpreter,\n            nlu_training_data,\n            should_merge_nodes,\n            fontsize,\n        )\n\n    def create_processor(\n        self, preprocessor: Optional[Callable[[Text], Text]] = None\n    ) -> MessageProcessor:\n        \"\"\"Instantiates a processor based on the set state of the agent.\"\"\"\n        # Checks that the interpreter and tracker store are set and\n        # creates a processor\n        if not self.is_ready():\n            raise AgentNotReady(\n                \"Agent needs to be prepared before usage. You need to set an \"\n                \"interpreter and a tracker store.\"\n            )\n\n        return MessageProcessor(\n            self.interpreter,\n            self.policy_ensemble,\n            self.domain,\n            self.tracker_store,\n            self.nlg,\n            action_endpoint=self.action_endpoint,\n            message_preprocessor=preprocessor,\n        )\n\n    @staticmethod\n    def _create_domain(domain: Union[Domain, Text, None]) -> Domain:\n\n        if isinstance(domain, str):\n            domain = Domain.load(domain)\n            domain.check_missing_templates()\n            return domain\n        elif isinstance(domain, Domain):\n            return domain\n        elif domain is None:\n            return Domain.empty()\n        else:\n            raise InvalidParameterException(\n                f\"Invalid param `domain`. Expected a path to a domain \"\n                f\"specification or a domain instance. But got \"\n                f\"type '{type(domain)}' with value '{domain}'.\"\n            )\n\n    @staticmethod\n    def create_tracker_store(\n        store: Optional[TrackerStore], domain: Domain\n    ) -> TrackerStore:\n        if store is not None:\n            store.domain = domain\n            tracker_store = store\n        else:\n            tracker_store = InMemoryTrackerStore(domain)\n\n        return FailSafeTrackerStore(tracker_store)\n\n    @staticmethod\n    def _create_lock_store(store: Optional[LockStore]) -> LockStore:\n        if store is not None:\n            return store\n\n        return InMemoryLockStore()\n\n    @staticmethod\n    def _create_ensemble(\n        policies: Union[List[Policy], PolicyEnsemble, None]\n    ) -> Optional[PolicyEnsemble]:\n        if policies is None:\n            return None\n        if isinstance(policies, list):\n            return SimplePolicyEnsemble(policies)\n        elif isinstance(policies, PolicyEnsemble):\n            return policies\n        else:\n            passed_type = type(policies).__name__\n            raise InvalidParameterException(\n                f\"Invalid param `policies`. Passed object is \"\n                f\"of type '{passed_type}', but should be policy, an array of \"\n                f\"policies, or a policy ensemble.\"\n            )\n\n    @staticmethod\n    def load_local_model(\n        model_path: Text,\n        interpreter: Optional[NaturalLanguageInterpreter] = None,\n        generator: Union[EndpointConfig, NaturalLanguageGenerator] = None,\n        tracker_store: Optional[TrackerStore] = None,\n        lock_store: Optional[LockStore] = None,\n        action_endpoint: Optional[EndpointConfig] = None,\n        model_server: Optional[EndpointConfig] = None,\n        remote_storage: Optional[Text] = None,\n    ) -> \"Agent\":\n        if os.path.isfile(model_path):\n            model_archive = model_path\n        else:\n            model_archive = get_latest_model(model_path)\n\n        if model_archive is None:\n            rasa.shared.utils.io.raise_warning(\n                f\"Could not load local model in '{model_path}'.\"\n            )\n            return Agent()\n\n        working_directory = tempfile.mkdtemp()\n        unpacked_model = unpack_model(model_archive, working_directory)\n\n        return Agent.load(\n            unpacked_model,\n            interpreter=interpreter,\n            generator=generator,\n            tracker_store=tracker_store,\n            lock_store=lock_store,\n            action_endpoint=action_endpoint,\n            model_server=model_server,\n            remote_storage=remote_storage,\n            path_to_model_archive=model_archive,\n        )\n\n    @staticmethod\n    def load_from_remote_storage(\n        remote_storage: Text,\n        model_name: Text,\n        interpreter: Optional[NaturalLanguageInterpreter] = None,\n        generator: Union[EndpointConfig, NaturalLanguageGenerator] = None,\n        tracker_store: Optional[TrackerStore] = None,\n        lock_store: Optional[LockStore] = None,\n        action_endpoint: Optional[EndpointConfig] = None,\n        model_server: Optional[EndpointConfig] = None,\n    ) -> Optional[\"Agent\"]:\n        from rasa.nlu.persistor import get_persistor\n\n        persistor = get_persistor(remote_storage)\n\n        if persistor is not None:\n            target_path = tempfile.mkdtemp()\n            persistor.retrieve(model_name, target_path)\n\n            return Agent.load(\n                target_path,\n                interpreter=interpreter,\n                generator=generator,\n                tracker_store=tracker_store,\n                lock_store=lock_store,\n                action_endpoint=action_endpoint,\n                model_server=model_server,\n                remote_storage=remote_storage,\n            )\n\n        return None\n\n\n### rasa/nlu/test.py ###\n\nimport itertools\nimport os\nimport logging\nimport numpy as np\nfrom collections import defaultdict, namedtuple\nfrom tqdm import tqdm\nfrom typing import (\n    Iterable,\n    Iterator,\n    Tuple,\n    List,\n    Set,\n    Optional,\n    Text,\n    Union,\n    Dict,\n    Any,\n)\n\nfrom rasa import telemetry\nimport rasa.shared.utils.io\nimport rasa.utils.plotting as plot_utils\nimport rasa.utils.io as io_utils\nimport rasa.utils.common\n\nfrom rasa.constants import TEST_DATA_FILE, TRAIN_DATA_FILE, NLG_DATA_FILE\nimport rasa.nlu.classifiers.fallback_classifier\nfrom rasa.nlu.constants import (\n    RESPONSE_SELECTOR_DEFAULT_INTENT,\n    RESPONSE_SELECTOR_PROPERTY_NAME,\n    RESPONSE_SELECTOR_PREDICTION_KEY,\n    TOKENS_NAMES,\n    ENTITY_ATTRIBUTE_CONFIDENCE_TYPE,\n    ENTITY_ATTRIBUTE_CONFIDENCE_ROLE,\n    ENTITY_ATTRIBUTE_CONFIDENCE_GROUP,\n)\nfrom rasa.shared.nlu.constants import (\n    TEXT,\n    INTENT,\n    INTENT_RESPONSE_KEY,\n    ENTITIES,\n    EXTRACTOR,\n    PRETRAINED_EXTRACTORS,\n    ENTITY_ATTRIBUTE_TYPE,\n    ENTITY_ATTRIBUTE_GROUP,\n    ENTITY_ATTRIBUTE_ROLE,\n    NO_ENTITY_TAG,\n    INTENT_NAME_KEY,\n    PREDICTED_CONFIDENCE_KEY,\n)\nfrom rasa.model import get_model\nfrom rasa.nlu.components import ComponentBuilder\nfrom rasa.nlu.config import RasaNLUModelConfig\nfrom rasa.nlu.model import Interpreter, Trainer, TrainingData\nfrom rasa.nlu.components import Component\nfrom rasa.nlu.tokenizers.tokenizer import Token\nfrom rasa.utils.tensorflow.constants import ENTITY_RECOGNITION\n\nlogger = logging.getLogger(__name__)\n\n# Exclude 'EntitySynonymMapper' and 'ResponseSelector' as their super class\n# performs entity extraction but those two classifiers don't\nENTITY_PROCESSORS = {\"EntitySynonymMapper\", \"ResponseSelector\"}\n\nEXTRACTORS_WITH_CONFIDENCES = {\"CRFEntityExtractor\", \"DIETClassifier\"}\n\nCVEvaluationResult = namedtuple(\"Results\", \"train test\")\n\nNO_ENTITY = \"no_entity\"\n\nIntentEvaluationResult = namedtuple(\n    \"IntentEvaluationResult\", \"intent_target intent_prediction message confidence\"\n)\n\nResponseSelectionEvaluationResult = namedtuple(\n    \"ResponseSelectionEvaluationResult\",\n    \"intent_response_key_target intent_response_key_prediction message confidence\",\n)\n\nEntityEvaluationResult = namedtuple(\n    \"EntityEvaluationResult\", \"entity_targets entity_predictions tokens message\"\n)\n\nIntentMetrics = Dict[Text, List[float]]\nEntityMetrics = Dict[Text, Dict[Text, List[float]]]\nResponseSelectionMetrics = Dict[Text, List[float]]\n\n\ndef log_evaluation_table(\n    report: Text, precision: float, f1: float, accuracy: float\n) -> None:  # pragma: no cover\n    \"\"\"Log the sklearn evaluation metrics.\"\"\"\n    logger.info(f\"F1-Score:  {f1}\")\n    logger.info(f\"Precision: {precision}\")\n    logger.info(f\"Accuracy:  {accuracy}\")\n    logger.info(f\"Classification report: \\n{report}\")\n\n\ndef remove_empty_intent_examples(\n    intent_results: List[IntentEvaluationResult],\n) -> List[IntentEvaluationResult]:\n    \"\"\"Remove those examples without an intent.\n\n    Args:\n        intent_results: intent evaluation results\n\n    Returns: intent evaluation results\n    \"\"\"\n    filtered = []\n    for r in intent_results:\n        # substitute None values with empty string\n        # to enable sklearn evaluation\n        if r.intent_prediction is None:\n            r = r._replace(intent_prediction=\"\")\n\n        if r.intent_target != \"\" and r.intent_target is not None:\n            filtered.append(r)\n\n    return filtered\n\n\ndef remove_empty_response_examples(\n    response_results: List[ResponseSelectionEvaluationResult],\n) -> List[ResponseSelectionEvaluationResult]:\n    \"\"\"Remove those examples without a response.\n\n    Args:\n        response_results: response selection evaluation results\n\n    Returns: response selection evaluation results\n    \"\"\"\n\n    filtered = []\n    for r in response_results:\n        # substitute None values with empty string\n        # to enable sklearn evaluation\n        if r.intent_response_key_prediction is None:\n            r = r._replace(intent_response_key_prediction=\"\")\n\n        if r.intent_response_key_target:\n            filtered.append(r)\n\n    return filtered\n\n\ndef drop_intents_below_freq(\n    training_data: TrainingData, cutoff: int = 5\n) -> TrainingData:\n    \"\"\"Remove intent groups with less than cutoff instances.\n\n    Args:\n        training_data: training data\n        cutoff: threshold\n\n    Returns: updated training data\n    \"\"\"\n    logger.debug(\n        \"Raw data intent examples: {}\".format(len(training_data.intent_examples))\n    )\n    keep_examples = [\n        ex\n        for ex in training_data.intent_examples\n        if training_data.number_of_examples_per_intent[ex.get(INTENT)] >= cutoff\n    ]\n\n    return TrainingData(\n        keep_examples,\n        training_data.entity_synonyms,\n        training_data.regex_features,\n        responses=training_data.responses,\n    )\n\n\ndef write_intent_successes(\n    intent_results: List[IntentEvaluationResult], successes_filename: Text\n) -> None:\n    \"\"\"Write successful intent predictions to a file.\n\n    Args:\n        intent_results: intent evaluation result\n        successes_filename: filename of file to save successful predictions to\n    \"\"\"\n    successes = [\n        {\n            \"text\": r.message,\n            \"intent\": r.intent_target,\n            \"intent_prediction\": {\n                INTENT_NAME_KEY: r.intent_prediction,\n                \"confidence\": r.confidence,\n            },\n        }\n        for r in intent_results\n        if r.intent_target == r.intent_prediction\n    ]\n\n    if successes:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(successes_filename, successes)\n        logger.info(f\"Successful intent predictions saved to {successes_filename}.\")\n        logger.debug(f\"\\n\\nSuccessfully predicted the following intents: \\n{successes}\")\n    else:\n        logger.info(\"No successful intent predictions found.\")\n\n\ndef write_intent_errors(\n    intent_results: List[IntentEvaluationResult], errors_filename: Text\n) -> None:\n    \"\"\"Write incorrect intent predictions to a file.\n\n    Args:\n        intent_results: intent evaluation result\n        errors_filename: filename of file to save incorrect predictions to\n    \"\"\"\n    errors = [\n        {\n            \"text\": r.message,\n            \"intent\": r.intent_target,\n            \"intent_prediction\": {\n                INTENT_NAME_KEY: r.intent_prediction,\n                \"confidence\": r.confidence,\n            },\n        }\n        for r in intent_results\n        if r.intent_target != r.intent_prediction\n    ]\n\n    if errors:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(errors_filename, errors)\n        logger.info(f\"Incorrect intent predictions saved to {errors_filename}.\")\n        logger.debug(\n            \"\\n\\nThese intent examples could not be classified \"\n            \"correctly: \\n{}\".format(errors)\n        )\n    else:\n        logger.info(\"Your model predicted all intents successfully.\")\n\n\ndef write_response_successes(\n    response_results: List[ResponseSelectionEvaluationResult], successes_filename: Text\n) -> None:\n    \"\"\"Write successful response selection predictions to a file.\n\n    Args:\n        response_results: response selection evaluation result\n        successes_filename: filename of file to save successful predictions to\n    \"\"\"\n\n    successes = [\n        {\n            \"text\": r.message,\n            \"intent_response_key_target\": r.intent_response_key_target,\n            \"intent_response_key_prediction\": {\n                \"name\": r.intent_response_key_prediction,\n                \"confidence\": r.confidence,\n            },\n        }\n        for r in response_results\n        if r.intent_response_key_prediction == r.intent_response_key_target\n    ]\n\n    if successes:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(successes_filename, successes)\n        logger.info(f\"Successful response predictions saved to {successes_filename}.\")\n        logger.debug(\n            f\"\\n\\nSuccessfully predicted the following responses: \\n{successes}\"\n        )\n    else:\n        logger.info(\"No successful response predictions found.\")\n\n\ndef write_response_errors(\n    response_results: List[ResponseSelectionEvaluationResult], errors_filename: Text\n) -> None:\n    \"\"\"Write incorrect response selection predictions to a file.\n\n    Args:\n        response_results: response selection evaluation result\n        errors_filename: filename of file to save incorrect predictions to\n    \"\"\"\n    errors = [\n        {\n            \"text\": r.message,\n            \"intent_response_key_target\": r.intent_response_key_target,\n            \"intent_response_key_prediction\": {\n                \"name\": r.intent_response_key_prediction,\n                \"confidence\": r.confidence,\n            },\n        }\n        for r in response_results\n        if r.intent_response_key_prediction != r.intent_response_key_target\n    ]\n\n    if errors:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(errors_filename, errors)\n        logger.info(f\"Incorrect response predictions saved to {errors_filename}.\")\n        logger.debug(\n            \"\\n\\nThese response examples could not be classified \"\n            \"correctly: \\n{}\".format(errors)\n        )\n    else:\n        logger.info(\"Your model predicted all responses successfully.\")\n\n\ndef plot_attribute_confidences(\n    results: Union[\n        List[IntentEvaluationResult], List[ResponseSelectionEvaluationResult]\n    ],\n    hist_filename: Optional[Text],\n    target_key: Text,\n    prediction_key: Text,\n    title: Text,\n) -> None:\n    \"\"\"Create histogram of confidence distribution.\n\n    Args:\n        results: evaluation results\n        hist_filename: filename to save plot to\n        target_key: key of target in results\n        prediction_key: key of predictions in results\n        title: title of plot\n    \"\"\"\n    pos_hist = [\n        r.confidence\n        for r in results\n        if getattr(r, target_key) == getattr(r, prediction_key)\n    ]\n\n    neg_hist = [\n        r.confidence\n        for r in results\n        if getattr(r, target_key) != getattr(r, prediction_key)\n    ]\n\n    plot_utils.plot_histogram([pos_hist, neg_hist], title, hist_filename)\n\n\ndef plot_entity_confidences(\n    merged_targets: List[Text],\n    merged_predictions: List[Text],\n    merged_confidences: List[float],\n    hist_filename: Text,\n    title: Text,\n) -> None:\n    \"\"\"Create histogram of confidence distribution.\n\n    Args:\n        results: evaluation results\n        hist_filename: filename to save plot to\n        target_key: key of target in results\n        prediction_key: key of predictions in results\n        title: title of plot\n    \"\"\"\n    pos_hist = [\n        confidence\n        for target, prediction, confidence in zip(\n            merged_targets, merged_predictions, merged_confidences\n        )\n        if target != NO_ENTITY and target == prediction\n    ]\n\n    neg_hist = [\n        confidence\n        for target, prediction, confidence in zip(\n            merged_targets, merged_predictions, merged_confidences\n        )\n        if prediction not in (NO_ENTITY, target)\n    ]\n\n    plot_utils.plot_histogram([pos_hist, neg_hist], title, hist_filename)\n\n\ndef evaluate_response_selections(\n    response_selection_results: List[ResponseSelectionEvaluationResult],\n    output_directory: Optional[Text],\n    successes: bool,\n    errors: bool,\n    disable_plotting: bool,\n) -> Dict:  # pragma: no cover\n    \"\"\"Creates summary statistics for response selection.\n\n    Only considers those examples with a set response.\n    Others are filtered out. Returns a dictionary of containing the\n    evaluation result.\n\n    Args:\n        response_selection_results: response selection evaluation results\n        output_directory: directory to store files to\n        successes: if True success are written down to disk\n        errors: if True errors are written down to disk\n        disable_plotting: if True no plots are created\n\n    Returns: dictionary with evaluation results\n    \"\"\"\n    import sklearn.metrics\n    import sklearn.utils.multiclass\n    from rasa.test import get_evaluation_metrics\n\n    # remove empty response targets\n    num_examples = len(response_selection_results)\n    response_selection_results = remove_empty_response_examples(\n        response_selection_results\n    )\n\n    logger.info(\n        f\"Response Selection Evaluation: Only considering those \"\n        f\"{len(response_selection_results)} examples that have a defined response out \"\n        f\"of {num_examples} examples.\"\n    )\n\n    (\n        target_intent_response_keys,\n        predicted_intent_response_keys,\n    ) = _targets_predictions_from(\n        response_selection_results,\n        \"intent_response_key_target\",\n        \"intent_response_key_prediction\",\n    )\n\n    confusion_matrix = sklearn.metrics.confusion_matrix(\n        target_intent_response_keys, predicted_intent_response_keys\n    )\n    labels = sklearn.utils.multiclass.unique_labels(\n        target_intent_response_keys, predicted_intent_response_keys\n    )\n\n    if output_directory:\n        report, precision, f1, accuracy = get_evaluation_metrics(\n            target_intent_response_keys,\n            predicted_intent_response_keys,\n            output_dict=True,\n        )\n        report = _add_confused_labels_to_report(report, confusion_matrix, labels)\n\n        report_filename = os.path.join(\n            output_directory, \"response_selection_report.json\"\n        )\n        rasa.shared.utils.io.dump_obj_as_json_to_file(report_filename, report)\n        logger.info(f\"Classification report saved to {report_filename}.\")\n\n    else:\n        report, precision, f1, accuracy = get_evaluation_metrics(\n            target_intent_response_keys, predicted_intent_response_keys\n        )\n        if isinstance(report, str):\n            log_evaluation_table(report, precision, f1, accuracy)\n\n    if successes:\n        successes_filename = \"response_selection_successes.json\"\n        if output_directory:\n            successes_filename = os.path.join(output_directory, successes_filename)\n        # save classified samples to file for debugging\n        write_response_successes(response_selection_results, successes_filename)\n\n    if errors:\n        errors_filename = \"response_selection_errors.json\"\n        if output_directory:\n            errors_filename = os.path.join(output_directory, errors_filename)\n        # log and save misclassified samples to file for debugging\n        write_response_errors(response_selection_results, errors_filename)\n\n    if not disable_plotting:\n        confusion_matrix_filename = \"response_selection_confusion_matrix.png\"\n        if output_directory:\n            confusion_matrix_filename = os.path.join(\n                output_directory, confusion_matrix_filename\n            )\n\n        plot_utils.plot_confusion_matrix(\n            confusion_matrix,\n            classes=labels,\n            title=\"Response Selection Confusion Matrix\",\n            output_file=confusion_matrix_filename,\n        )\n\n        histogram_filename = \"response_selection_histogram.png\"\n        if output_directory:\n            histogram_filename = os.path.join(output_directory, histogram_filename)\n        plot_attribute_confidences(\n            response_selection_results,\n            histogram_filename,\n            \"intent_response_key_target\",\n            \"intent_response_key_prediction\",\n            title=\"Response Selection Prediction Confidence Distribution\",\n        )\n\n    predictions = [\n        {\n            \"text\": res.message,\n            \"intent_response_key_target\": res.intent_response_key_target,\n            \"intent_response_key_prediction\": res.intent_response_key_prediction,\n            \"confidence\": res.confidence,\n        }\n        for res in response_selection_results\n    ]\n\n    return {\n        \"predictions\": predictions,\n        \"report\": report,\n        \"precision\": precision,\n        \"f1_score\": f1,\n        \"accuracy\": accuracy,\n    }\n\n\ndef _add_confused_labels_to_report(\n    report: Dict[Text, Dict[Text, Any]],\n    confusion_matrix: np.ndarray,\n    labels: List[Text],\n    exclude_labels: Optional[List[Text]] = None,\n) -> Dict[Text, Dict[Text, Union[Dict, Any]]]:\n    \"\"\"Adds a field \"confused_with\" to the evaluation report.\n\n    The value is a dict of {\"false_positive_label\": false_positive_count} pairs.\n    If there are no false positives in the confusion matrix,\n    the dict will be empty. Typically we include the two most\n    commonly false positive labels, three in the rare case that\n    the diagonal element in the confusion matrix is not one of the\n    three highest values in the row.\n\n    Args:\n        report: the evaluation report\n        confusion_matrix: confusion matrix\n        labels: list of labels\n\n    Returns: updated evaluation report\n    \"\"\"\n    if exclude_labels is None:\n        exclude_labels = []\n\n    # sort confusion matrix by false positives\n    indices = np.argsort(confusion_matrix, axis=1)\n    n_candidates = min(3, len(labels))\n\n    for label in labels:\n        if label in exclude_labels:\n            continue\n        # it is possible to predict intent 'None'\n        if report.get(label):\n            report[label][\"confused_with\"] = {}\n\n    for i, label in enumerate(labels):\n        if label in exclude_labels:\n            continue\n        for j in range(n_candidates):\n            label_idx = indices[i, -(1 + j)]\n            false_pos_label = labels[label_idx]\n            false_positives = int(confusion_matrix[i, label_idx])\n            if (\n                false_pos_label != label\n                and false_pos_label not in exclude_labels\n                and false_positives > 0\n            ):\n                report[label][\"confused_with\"][false_pos_label] = false_positives\n\n    return report\n\n\ndef evaluate_intents(\n    intent_results: List[IntentEvaluationResult],\n    output_directory: Optional[Text],\n    successes: bool,\n    errors: bool,\n    disable_plotting: bool,\n) -> Dict:  # pragma: no cover\n    \"\"\"Creates summary statistics for intents.\n\n    Only considers those examples with a set intent. Others are filtered out.\n    Returns a dictionary of containing the evaluation result.\n\n    Args:\n        intent_results: intent evaluation results\n        output_directory: directory to store files to\n        successes: if True correct predictions are written to disk\n        errors: if True incorrect predictions are written to disk\n        disable_plotting: if True no plots are created\n\n    Returns: dictionary with evaluation results\n    \"\"\"\n    import sklearn.metrics\n    import sklearn.utils.multiclass\n    from rasa.test import get_evaluation_metrics\n\n    # remove empty intent targets\n    num_examples = len(intent_results)\n    intent_results = remove_empty_intent_examples(intent_results)\n\n    logger.info(\n        f\"Intent Evaluation: Only considering those {len(intent_results)} examples \"\n        f\"that have a defined intent out of {num_examples} examples.\"\n    )\n\n    target_intents, predicted_intents = _targets_predictions_from(\n        intent_results, \"intent_target\", \"intent_prediction\"\n    )\n\n    confusion_matrix = sklearn.metrics.confusion_matrix(\n        target_intents, predicted_intents\n    )\n    labels = sklearn.utils.multiclass.unique_labels(target_intents, predicted_intents)\n\n    if output_directory:\n        report, precision, f1, accuracy = get_evaluation_metrics(\n            target_intents, predicted_intents, output_dict=True\n        )\n        report = _add_confused_labels_to_report(report, confusion_matrix, labels)\n\n        report_filename = os.path.join(output_directory, \"intent_report.json\")\n        rasa.shared.utils.io.dump_obj_as_json_to_file(report_filename, report)\n        logger.info(f\"Classification report saved to {report_filename}.\")\n\n    else:\n        report, precision, f1, accuracy = get_evaluation_metrics(\n            target_intents, predicted_intents\n        )\n        if isinstance(report, str):\n            log_evaluation_table(report, precision, f1, accuracy)\n\n    if successes and output_directory:\n        successes_filename = os.path.join(output_directory, \"intent_successes.json\")\n        # save classified samples to file for debugging\n        write_intent_successes(intent_results, successes_filename)\n\n    if errors and output_directory:\n        errors_filename = os.path.join(output_directory, \"intent_errors.json\")\n        # log and save misclassified samples to file for debugging\n        write_intent_errors(intent_results, errors_filename)\n\n    if not disable_plotting:\n        confusion_matrix_filename = \"intent_confusion_matrix.png\"\n        if output_directory:\n            confusion_matrix_filename = os.path.join(\n                output_directory, confusion_matrix_filename\n            )\n        plot_utils.plot_confusion_matrix(\n            confusion_matrix,\n            classes=labels,\n            title=\"Intent Confusion matrix\",\n            output_file=confusion_matrix_filename,\n        )\n\n        histogram_filename = \"intent_histogram.png\"\n        if output_directory:\n            histogram_filename = os.path.join(output_directory, histogram_filename)\n        plot_attribute_confidences(\n            intent_results,\n            histogram_filename,\n            \"intent_target\",\n            \"intent_prediction\",\n            title=\"Intent Prediction Confidence Distribution\",\n        )\n\n    predictions = [\n        {\n            \"text\": res.message,\n            \"intent\": res.intent_target,\n            \"predicted\": res.intent_prediction,\n            \"confidence\": res.confidence,\n        }\n        for res in intent_results\n    ]\n\n    return {\n        \"predictions\": predictions,\n        \"report\": report,\n        \"precision\": precision,\n        \"f1_score\": f1,\n        \"accuracy\": accuracy,\n    }\n\n\ndef merge_labels(\n    aligned_predictions: List[Dict], extractor: Optional[Text] = None\n) -> List[Text]:\n    \"\"\"Concatenates all labels of the aligned predictions.\n\n    Takes the aligned prediction labels which are grouped for each message\n    and concatenates them.\n\n    Args:\n        aligned_predictions: aligned predictions\n        extractor: entity extractor name\n\n    Returns: concatenated predictions\n    \"\"\"\n\n    if extractor:\n        label_lists = [ap[\"extractor_labels\"][extractor] for ap in aligned_predictions]\n    else:\n        label_lists = [ap[\"target_labels\"] for ap in aligned_predictions]\n\n    return list(itertools.chain(*label_lists))\n\n\ndef merge_confidences(\n    aligned_predictions: List[Dict], extractor: Optional[Text] = None\n) -> List[float]:\n    \"\"\"Concatenates all confidences of the aligned predictions.\n\n    Takes the aligned prediction confidences which are grouped for each message\n    and concatenates them.\n\n    Args:\n        aligned_predictions: aligned predictions\n        extractor: entity extractor name\n\n    Returns: concatenated confidences\n    \"\"\"\n\n    label_lists = [ap[\"confidences\"][extractor] for ap in aligned_predictions]\n    return list(itertools.chain(*label_lists))\n\n\ndef substitute_labels(labels: List[Text], old: Text, new: Text) -> List[Text]:\n    \"\"\"Replaces label names in a list of labels.\n\n    Args:\n        labels: list of labels\n        old: old label name that should be replaced\n        new: new label name\n\n    Returns: updated labels\n    \"\"\"\n    return [new if label == old else label for label in labels]\n\n\ndef write_incorrect_entity_predictions(\n    entity_results: List[EntityEvaluationResult],\n    merged_targets: List[Text],\n    merged_predictions: List[Text],\n    error_filename: Text,\n) -> None:\n    \"\"\"Write incorrect entity predictions to a file.\n\n    Args:\n        entity_results: response selection evaluation result\n        merged_predictions: list of predicted entity labels\n        merged_targets: list of true entity labels\n        error_filename: filename of file to save incorrect predictions to\n    \"\"\"\n    errors = collect_incorrect_entity_predictions(\n        entity_results, merged_predictions, merged_targets\n    )\n\n    if errors:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(error_filename, errors)\n        logger.info(f\"Incorrect entity predictions saved to {error_filename}.\")\n        logger.debug(\n            \"\\n\\nThese intent examples could not be classified \"\n            \"correctly: \\n{}\".format(errors)\n        )\n    else:\n        logger.info(\"Your model predicted all entities successfully.\")\n\n\ndef collect_incorrect_entity_predictions(\n    entity_results: List[EntityEvaluationResult],\n    merged_predictions: List[Text],\n    merged_targets: List[Text],\n):\n    \"\"\"Get incorrect entity predictions.\n\n    Args:\n        entity_results: entity evaluation results\n        merged_predictions: list of predicted entity labels\n        merged_targets: list of true entity labels\n\n    Returns: list of incorrect predictions\n    \"\"\"\n    errors = []\n    offset = 0\n    for entity_result in entity_results:\n        for i in range(offset, offset + len(entity_result.tokens)):\n            if merged_targets[i] != merged_predictions[i]:\n                errors.append(\n                    {\n                        \"text\": entity_result.message,\n                        \"entities\": entity_result.entity_targets,\n                        \"predicted_entities\": entity_result.entity_predictions,\n                    }\n                )\n                break\n        offset += len(entity_result.tokens)\n    return errors\n\n\ndef write_successful_entity_predictions(\n    entity_results: List[EntityEvaluationResult],\n    merged_targets: List[Text],\n    merged_predictions: List[Text],\n    successes_filename: Text,\n) -> None:\n    \"\"\"Write correct entity predictions to a file.\n\n    Args:\n        entity_results: response selection evaluation result\n        merged_predictions: list of predicted entity labels\n        merged_targets: list of true entity labels\n        successes_filename: filename of file to save correct predictions to\n    \"\"\"\n    successes = collect_successful_entity_predictions(\n        entity_results, merged_predictions, merged_targets\n    )\n\n    if successes:\n        rasa.shared.utils.io.dump_obj_as_json_to_file(successes_filename, successes)\n        logger.info(f\"Successful entity predictions saved to {successes_filename}.\")\n        logger.debug(\n            f\"\\n\\nSuccessfully predicted the following entities: \\n{successes}\"\n        )\n    else:\n        logger.info(\"No successful entity prediction found.\")\n\n\ndef collect_successful_entity_predictions(\n    entity_results: List[EntityEvaluationResult],\n    merged_predictions: List[Text],\n    merged_targets: List[Text],\n):\n    \"\"\"Get correct entity predictions.\n\n    Args:\n        entity_results: entity evaluation results\n        merged_predictions: list of predicted entity labels\n        merged_targets: list of true entity labels\n\n    Returns: list of correct predictions\n    \"\"\"\n    successes = []\n    offset = 0\n    for entity_result in entity_results:\n        for i in range(offset, offset + len(entity_result.tokens)):\n            if (\n                merged_targets[i] == merged_predictions[i]\n                and merged_targets[i] != NO_ENTITY\n            ):\n                successes.append(\n                    {\n                        \"text\": entity_result.message,\n                        \"entities\": entity_result.entity_targets,\n                        \"predicted_entities\": entity_result.entity_predictions,\n                    }\n                )\n                break\n        offset += len(entity_result.tokens)\n    return successes\n\n\ndef evaluate_entities(\n    entity_results: List[EntityEvaluationResult],\n    extractors: Set[Text],\n    output_directory: Optional[Text],\n    successes: bool,\n    errors: bool,\n    disable_plotting: bool,\n) -> Dict:  # pragma: no cover\n    \"\"\"Creates summary statistics for each entity extractor.\n\n    Logs precision, recall, and F1 per entity type for each extractor.\n\n    Args:\n        entity_results: entity evaluation results\n        extractors: entity extractors to consider\n        output_directory: directory to store files to\n        successes: if True correct predictions are written to disk\n        errors: if True incorrect predictions are written to disk\n        disable_plotting: if True no plots are created\n\n    Returns: dictionary with evaluation results\n    \"\"\"\n    import sklearn.metrics\n    import sklearn.utils.multiclass\n    from rasa.test import get_evaluation_metrics\n\n    aligned_predictions = align_all_entity_predictions(entity_results, extractors)\n    merged_targets = merge_labels(aligned_predictions)\n    merged_targets = substitute_labels(merged_targets, NO_ENTITY_TAG, NO_ENTITY)\n\n    result = {}\n\n    for extractor in extractors:\n        merged_predictions = merge_labels(aligned_predictions, extractor)\n        merged_predictions = substitute_labels(\n            merged_predictions, NO_ENTITY_TAG, NO_ENTITY\n        )\n\n        logger.info(f\"Evaluation for entity extractor: {extractor} \")\n\n        confusion_matrix = sklearn.metrics.confusion_matrix(\n            merged_targets, merged_predictions\n        )\n        labels = sklearn.utils.multiclass.unique_labels(\n            merged_targets, merged_predictions\n        )\n\n        if output_directory:\n            report_filename = f\"{extractor}_report.json\"\n            extractor_report_filename = os.path.join(output_directory, report_filename)\n\n            report, precision, f1, accuracy = get_evaluation_metrics(\n                merged_targets,\n                merged_predictions,\n                output_dict=True,\n                exclude_label=NO_ENTITY,\n            )\n            report = _add_confused_labels_to_report(\n                report, confusion_matrix, labels, [NO_ENTITY]\n            )\n\n            rasa.shared.utils.io.dump_obj_as_json_to_file(\n                extractor_report_filename, report\n            )\n\n            logger.info(\n                \"Classification report for '{}' saved to '{}'.\"\n                \"\".format(extractor, extractor_report_filename)\n            )\n\n        else:\n            report, precision, f1, accuracy = get_evaluation_metrics(\n                merged_targets,\n                merged_predictions,\n                output_dict=False,\n                exclude_label=NO_ENTITY,\n            )\n            if isinstance(report, str):\n                log_evaluation_table(report, precision, f1, accuracy)\n\n        if successes:\n            successes_filename = f\"{extractor}_successes.json\"\n            if output_directory:\n                successes_filename = os.path.join(output_directory, successes_filename)\n            # save classified samples to file for debugging\n            write_successful_entity_predictions(\n                entity_results, merged_targets, merged_predictions, successes_filename\n            )\n\n        if errors:\n            errors_filename = f\"{extractor}_errors.json\"\n            if output_directory:\n                errors_filename = os.path.join(output_directory, errors_filename)\n            # log and save misclassified samples to file for debugging\n            write_incorrect_entity_predictions(\n                entity_results, merged_targets, merged_predictions, errors_filename\n            )\n\n        if not disable_plotting:\n            confusion_matrix_filename = f\"{extractor}_confusion_matrix.png\"\n            if output_directory:\n                confusion_matrix_filename = os.path.join(\n                    output_directory, confusion_matrix_filename\n                )\n            plot_utils.plot_confusion_matrix(\n                confusion_matrix,\n                classes=labels,\n                title=\"Entity Confusion matrix\",\n                output_file=confusion_matrix_filename,\n            )\n\n            if extractor in EXTRACTORS_WITH_CONFIDENCES:\n                merged_confidences = merge_confidences(aligned_predictions, extractor)\n                histogram_filename = f\"{extractor}_histogram.png\"\n                if output_directory:\n                    histogram_filename = os.path.join(\n                        output_directory, histogram_filename\n                    )\n                plot_entity_confidences(\n                    merged_targets,\n                    merged_predictions,\n                    merged_confidences,\n                    title=\"Entity Confusion matrix\",\n                    hist_filename=histogram_filename,\n                )\n\n        result[extractor] = {\n            \"report\": report,\n            \"precision\": precision,\n            \"f1_score\": f1,\n            \"accuracy\": accuracy,\n        }\n\n    return result\n\n\ndef is_token_within_entity(token: Token, entity: Dict) -> bool:\n    \"\"\"Checks if a token is within the boundaries of an entity.\"\"\"\n    return determine_intersection(token, entity) == len(token.text)\n\n\ndef does_token_cross_borders(token: Token, entity: Dict) -> bool:\n    \"\"\"Checks if a token crosses the boundaries of an entity.\"\"\"\n\n    num_intersect = determine_intersection(token, entity)\n    return 0 < num_intersect < len(token.text)\n\n\ndef determine_intersection(token: Token, entity: Dict) -> int:\n    \"\"\"Calculates how many characters a given token and entity share.\"\"\"\n\n    pos_token = set(range(token.start, token.end))\n    pos_entity = set(range(entity[\"start\"], entity[\"end\"]))\n    return len(pos_token.intersection(pos_entity))\n\n\ndef do_entities_overlap(entities: List[Dict]) -> bool:\n    \"\"\"Checks if entities overlap.\n\n    I.e. cross each others start and end boundaries.\n\n    Args:\n        entities: list of entities\n\n    Returns: true if entities overlap, false otherwise.\n    \"\"\"\n    sorted_entities = sorted(entities, key=lambda e: e[\"start\"])\n    for i in range(len(sorted_entities) - 1):\n        curr_ent = sorted_entities[i]\n        next_ent = sorted_entities[i + 1]\n        if (\n            next_ent[\"start\"] < curr_ent[\"end\"]\n            and next_ent[\"entity\"] != curr_ent[\"entity\"]\n        ):\n            logger.warning(f\"Overlapping entity {curr_ent} with {next_ent}\")\n            return True\n\n    return False\n\n\ndef find_intersecting_entities(token: Token, entities: List[Dict]) -> List[Dict]:\n    \"\"\"Finds the entities that intersect with a token.\n\n    Args:\n        token: a single token\n        entities: entities found by a single extractor\n\n    Returns: list of entities\n    \"\"\"\n    candidates = []\n    for e in entities:\n        if is_token_within_entity(token, e):\n            candidates.append(e)\n        elif does_token_cross_borders(token, e):\n            candidates.append(e)\n            logger.debug(\n                \"Token boundary error for token {}({}, {}) \"\n                \"and entity {}\"\n                \"\".format(token.text, token.start, token.end, e)\n            )\n    return candidates\n\n\ndef pick_best_entity_fit(\n    token: Token, candidates: List[Dict[Text, Any]]\n) -> Optional[Dict[Text, Any]]:\n    \"\"\"\n    Determines the best fitting entity given intersecting entities.\n\n    Args:\n        token: a single token\n        candidates: entities found by a single extractor\n        attribute_key: the attribute key of interest\n\n    Returns:\n        the value of the attribute key of the best fitting entity\n    \"\"\"\n    if len(candidates) == 0:\n        return None\n    elif len(candidates) == 1:\n        return candidates[0]\n    else:\n        best_fit = np.argmax([determine_intersection(token, c) for c in candidates])\n        return candidates[int(best_fit)]\n\n\ndef determine_token_labels(\n    token: Token,\n    entities: List[Dict],\n    extractors: Optional[Set[Text]] = None,\n    attribute_key: Text = ENTITY_ATTRIBUTE_TYPE,\n) -> Text:\n    \"\"\"\n    Determines the token label for the provided attribute key given entities that do\n    not overlap.\n\n    Args:\n        token: a single token\n        entities: entities found by a single extractor\n        extractors: list of extractors\n        attribute_key: the attribute key for which the entity type should be returned\n    Returns:\n        entity type\n    \"\"\"\n    entity = determine_entity_for_token(token, entities, extractors)\n\n    if entity is None:\n        return NO_ENTITY_TAG\n\n    label = entity.get(attribute_key)\n\n    if not label:\n        return NO_ENTITY_TAG\n\n    return label\n\n\ndef determine_entity_for_token(\n    token: Token,\n    entities: List[Dict[Text, Any]],\n    extractors: Optional[Set[Text]] = None,\n) -> Optional[Dict[Text, Any]]:\n    \"\"\"\n    Determines the best fitting entity for the given token, given entities that do\n    not overlap.\n\n    Args:\n        token: a single token\n        entities: entities found by a single extractor\n        extractors: list of extractors\n\n    Returns:\n        entity type\n    \"\"\"\n    if entities is None or len(entities) == 0:\n        return None\n    if not do_extractors_support_overlap(extractors) and do_entities_overlap(entities):\n        raise ValueError(\"The possible entities should not overlap.\")\n\n    candidates = find_intersecting_entities(token, entities)\n    return pick_best_entity_fit(token, candidates)\n\n\ndef do_extractors_support_overlap(extractors: Optional[Set[Text]]) -> bool:\n    \"\"\"Checks if extractors support overlapping entities\"\"\"\n    if extractors is None:\n        return False\n\n    from rasa.nlu.extractors.crf_entity_extractor import CRFEntityExtractor\n\n    return CRFEntityExtractor.name not in extractors\n\n\ndef align_entity_predictions(\n    result: EntityEvaluationResult, extractors: Set[Text]\n) -> Dict:\n    \"\"\"Aligns entity predictions to the message tokens.\n\n    Determines for every token the true label based on the\n    prediction targets and the label assigned by each\n    single extractor.\n\n    Args:\n        result: entity evaluation result\n        extractors: the entity extractors that should be considered\n\n    Returns: dictionary containing the true token labels and token labels\n             from the extractors\n    \"\"\"\n    true_token_labels = []\n    entities_by_extractors: Dict[Text, List] = {\n        extractor: [] for extractor in extractors\n    }\n    for p in result.entity_predictions:\n        entities_by_extractors[p[EXTRACTOR]].append(p)\n    extractor_labels: Dict[Text, List] = {extractor: [] for extractor in extractors}\n    extractor_confidences: Dict[Text, List] = {\n        extractor: [] for extractor in extractors\n    }\n    for t in result.tokens:\n        true_token_labels.append(_concat_entity_labels(t, result.entity_targets))\n        for extractor, entities in entities_by_extractors.items():\n            extracted_labels = _concat_entity_labels(t, entities, {extractor})\n            extracted_confidences = _get_entity_confidences(t, entities, {extractor})\n            extractor_labels[extractor].append(extracted_labels)\n            extractor_confidences[extractor].append(extracted_confidences)\n\n    return {\n        \"target_labels\": true_token_labels,\n        \"extractor_labels\": extractor_labels,\n        \"confidences\": extractor_confidences,\n    }\n\n\ndef _concat_entity_labels(\n    token: Token, entities: List[Dict], extractors: Optional[Set[Text]] = None\n) -> Text:\n    \"\"\"Concatenate labels for entity type, role, and group for evaluation.\n\n    In order to calculate metrics also for entity type, role, and group we need to\n    concatenate their labels. For example, 'location.destination'. This allows\n    us to report metrics for every combination of entity type, role, and group.\n\n    Args:\n        token: the token we are looking at\n        entities: the available entities\n        extractors: the extractor of interest\n\n    Returns:\n        the entity label of the provided token\n    \"\"\"\n    entity_label = determine_token_labels(\n        token, entities, extractors, ENTITY_ATTRIBUTE_TYPE\n    )\n    group_label = determine_token_labels(\n        token, entities, extractors, ENTITY_ATTRIBUTE_GROUP\n    )\n    role_label = determine_token_labels(\n        token, entities, extractors, ENTITY_ATTRIBUTE_ROLE\n    )\n\n    if entity_label == role_label == group_label == NO_ENTITY_TAG:\n        return NO_ENTITY_TAG\n\n    labels = [entity_label, group_label, role_label]\n    labels = [label for label in labels if label != NO_ENTITY_TAG]\n\n    return \".\".join(labels)\n\n\ndef _get_entity_confidences(\n    token: Token, entities: List[Dict], extractors: Optional[Set[Text]] = None\n) -> float:\n    \"\"\"Get the confidence value of the best fitting entity.\n\n    If multiple confidence values are present, e.g. for type, role, group, we\n    pick the lowest confidence value.\n\n    Args:\n        token: the token we are looking at\n        entities: the available entities\n        extractors: the extractor of interest\n\n    Returns:\n        the confidence value\n    \"\"\"\n    entity = determine_entity_for_token(token, entities, extractors)\n\n    if entity is None:\n        return 0.0\n\n    if entity.get(\"extractor\") not in EXTRACTORS_WITH_CONFIDENCES:\n        return 0.0\n\n    conf_type = entity.get(ENTITY_ATTRIBUTE_CONFIDENCE_TYPE) or 1.0\n    conf_role = entity.get(ENTITY_ATTRIBUTE_CONFIDENCE_ROLE) or 1.0\n    conf_group = entity.get(ENTITY_ATTRIBUTE_CONFIDENCE_GROUP) or 1.0\n\n    return min(conf_type, conf_role, conf_group)\n\n\ndef align_all_entity_predictions(\n    entity_results: List[EntityEvaluationResult], extractors: Set[Text]\n) -> List[Dict]:\n    \"\"\"Aligns entity predictions to the message tokens for the whole dataset\n    using align_entity_predictions.\n\n    Args:\n        entity_results: list of entity prediction results\n        extractors: the entity extractors that should be considered\n\n    Returns: list of dictionaries containing the true token labels and token\n    labels from the extractors\n    \"\"\"\n    aligned_predictions = []\n    for result in entity_results:\n        aligned_predictions.append(align_entity_predictions(result, extractors))\n\n    return aligned_predictions\n\n\ndef get_eval_data(\n    interpreter: Interpreter, test_data: TrainingData\n) -> Tuple[\n    List[IntentEvaluationResult],\n    List[ResponseSelectionEvaluationResult],\n    List[EntityEvaluationResult],\n]:\n    \"\"\"Runs the model for the test set and extracts targets and predictions.\n\n    Returns intent results (intent targets and predictions, the original\n    messages and the confidences of the predictions), response results (\n    response targets and predictions) as well as entity results\n    (entity_targets, entity_predictions, and tokens).\n\n    Args:\n        interpreter: the interpreter\n        test_data: test data\n\n    Returns: intent, response, and entity evaluation results\n    \"\"\"\n    logger.info(\"Running model for predictions:\")\n\n    intent_results, entity_results, response_selection_results = [], [], []\n\n    response_labels = [\n        e.get(INTENT_RESPONSE_KEY)\n        for e in test_data.intent_examples\n        if e.get(INTENT_RESPONSE_KEY) is not None\n    ]\n    intent_labels = [e.get(INTENT) for e in test_data.intent_examples]\n    should_eval_intents = (\n        is_intent_classifier_present(interpreter) and len(set(intent_labels)) >= 2\n    )\n    should_eval_response_selection = (\n        is_response_selector_present(interpreter) and len(set(response_labels)) >= 2\n    )\n    available_response_selector_types = get_available_response_selector_types(\n        interpreter\n    )\n\n    should_eval_entities = is_entity_extractor_present(interpreter)\n\n    for example in tqdm(test_data.nlu_examples):\n        result = interpreter.parse(example.get(TEXT), only_output_properties=False)\n\n        if should_eval_intents:\n            if rasa.nlu.classifiers.fallback_classifier.is_fallback_classifier_prediction(\n                result\n            ):\n                # Revert fallback prediction to not shadow the wrongly predicted intent\n                # during the test phase.\n                result = rasa.nlu.classifiers.fallback_classifier.undo_fallback_prediction(\n                    result\n                )\n            intent_prediction = result.get(INTENT, {}) or {}\n\n            intent_results.append(\n                IntentEvaluationResult(\n                    example.get(INTENT, \"\"),\n                    intent_prediction.get(INTENT_NAME_KEY),\n                    result.get(TEXT, {}),\n                    intent_prediction.get(\"confidence\"),\n                )\n            )\n\n        if should_eval_response_selection:\n\n            # including all examples here. Empty response examples are filtered at the\n            # time of metric calculation\n            intent_target = example.get(INTENT, \"\")\n            selector_properties = result.get(RESPONSE_SELECTOR_PROPERTY_NAME, {})\n\n            if intent_target in available_response_selector_types:\n                response_prediction_key = intent_target\n            else:\n                response_prediction_key = RESPONSE_SELECTOR_DEFAULT_INTENT\n\n            response_prediction = selector_properties.get(\n                response_prediction_key, {}\n            ).get(RESPONSE_SELECTOR_PREDICTION_KEY, {})\n\n            intent_response_key_target = example.get(INTENT_RESPONSE_KEY, \"\")\n\n            response_selection_results.append(\n                ResponseSelectionEvaluationResult(\n                    intent_response_key_target,\n                    response_prediction.get(INTENT_RESPONSE_KEY),\n                    result.get(TEXT, {}),\n                    response_prediction.get(PREDICTED_CONFIDENCE_KEY),\n                )\n            )\n\n        if should_eval_entities:\n            entity_results.append(\n                EntityEvaluationResult(\n                    example.get(ENTITIES, []),\n                    result.get(ENTITIES, []),\n                    result.get(TOKENS_NAMES[TEXT], []),\n                    result.get(TEXT, \"\"),\n                )\n            )\n\n    return intent_results, response_selection_results, entity_results\n\n\ndef get_entity_extractors(interpreter: Interpreter) -> Set[Text]:\n    \"\"\"Finds the names of entity extractors used by the interpreter.\n\n    Processors are removed since they do not detect the boundaries themselves.\n\n    Args:\n        interpreter: the interpreter\n\n    Returns: entity extractor names\n    \"\"\"\n    from rasa.nlu.extractors.extractor import EntityExtractor\n    from rasa.nlu.classifiers.diet_classifier import DIETClassifier\n\n    extractors = set()\n    for c in interpreter.pipeline:\n        if isinstance(c, EntityExtractor):\n            if isinstance(c, DIETClassifier):\n                if c.component_config[ENTITY_RECOGNITION]:\n                    extractors.add(c.name)\n            else:\n                extractors.add(c.name)\n\n    return extractors - ENTITY_PROCESSORS\n\n\ndef is_entity_extractor_present(interpreter: Interpreter) -> bool:\n    \"\"\"Checks whether entity extractor is present.\"\"\"\n\n    extractors = get_entity_extractors(interpreter)\n    return extractors != []\n\n\ndef is_intent_classifier_present(interpreter: Interpreter) -> bool:\n    \"\"\"Checks whether intent classifier is present.\"\"\"\n\n    from rasa.nlu.classifiers.classifier import IntentClassifier\n\n    intent_classifiers = [\n        c.name for c in interpreter.pipeline if isinstance(c, IntentClassifier)\n    ]\n    return intent_classifiers != []\n\n\ndef is_response_selector_present(interpreter: Interpreter) -> bool:\n    \"\"\"Checks whether response selector is present.\"\"\"\n\n    from rasa.nlu.selectors.response_selector import ResponseSelector\n\n    response_selectors = [\n        c.name for c in interpreter.pipeline if isinstance(c, ResponseSelector)\n    ]\n    return response_selectors != []\n\n\ndef get_available_response_selector_types(interpreter: Interpreter) -> List[Text]:\n    \"\"\"Gets all available response selector types.\"\"\"\n\n    from rasa.nlu.selectors.response_selector import ResponseSelector\n\n    response_selector_types = [\n        c.retrieval_intent\n        for c in interpreter.pipeline\n        if isinstance(c, ResponseSelector)\n    ]\n\n    return response_selector_types\n\n\ndef remove_pretrained_extractors(pipeline: List[Component]) -> List[Component]:\n    \"\"\"Remove pre-trained extractors from the pipeline.\n\n    Remove pre-trained extractors so that entities from pre-trained extractors\n    are not predicted upon parsing.\n\n    Args:\n        pipeline: the pipeline\n\n    Returns:\n        Updated pipeline\n    \"\"\"\n    pipeline = [c for c in pipeline if c.name not in PRETRAINED_EXTRACTORS]\n    return pipeline\n\n\ndef run_evaluation(\n    data_path: Text,\n    model_path: Text,\n    output_directory: Optional[Text] = None,\n    successes: bool = False,\n    errors: bool = False,\n    component_builder: Optional[ComponentBuilder] = None,\n    disable_plotting: bool = False,\n) -> Dict:  # pragma: no cover\n    \"\"\"Evaluate intent classification, response selection and entity extraction.\n\n    Args:\n        data_path: path to the test data\n        model_path: path to the model\n        output_directory: path to folder where all output will be stored\n        successes: if true successful predictions are written to a file\n        errors: if true incorrect predictions are written to a file\n        component_builder: component builder\n        disable_plotting: if true confusion matrix and histogram will not be rendered\n\n    Returns: dictionary containing evaluation results\n    \"\"\"\n    import rasa.shared.nlu.training_data.loading\n\n    # get the metadata config from the package data\n    interpreter = Interpreter.load(model_path, component_builder)\n\n    interpreter.pipeline = remove_pretrained_extractors(interpreter.pipeline)\n    test_data = rasa.shared.nlu.training_data.loading.load_data(\n        data_path, interpreter.model_metadata.language\n    )\n\n    result: Dict[Text, Optional[Dict]] = {\n        \"intent_evaluation\": None,\n        \"entity_evaluation\": None,\n        \"response_selection_evaluation\": None,\n    }\n\n    if output_directory:\n        rasa.shared.utils.io.create_directory(output_directory)\n\n    (intent_results, response_selection_results, entity_results) = get_eval_data(\n        interpreter, test_data\n    )\n\n    if intent_results:\n        logger.info(\"Intent evaluation results:\")\n        result[\"intent_evaluation\"] = evaluate_intents(\n            intent_results, output_directory, successes, errors, disable_plotting\n        )\n\n    if response_selection_results:\n        logger.info(\"Response selection evaluation results:\")\n        result[\"response_selection_evaluation\"] = evaluate_response_selections(\n            response_selection_results,\n            output_directory,\n            successes,\n            errors,\n            disable_plotting,\n        )\n\n    if any(entity_results):\n        logger.info(\"Entity evaluation results:\")\n        extractors = get_entity_extractors(interpreter)\n        result[\"entity_evaluation\"] = evaluate_entities(\n            entity_results,\n            extractors,\n            output_directory,\n            successes,\n            errors,\n            disable_plotting,\n        )\n\n    telemetry.track_nlu_model_test(test_data)\n\n    return result\n\n\ndef generate_folds(\n    n: int, training_data: TrainingData\n) -> Iterator[Tuple[TrainingData, TrainingData]]:\n    \"\"\"Generates n cross validation folds for given training data.\"\"\"\n\n    from sklearn.model_selection import StratifiedKFold\n\n    skf = StratifiedKFold(n_splits=n, shuffle=True)\n    x = training_data.intent_examples\n\n    # Get labels as they appear in the training data because we want a\n    # stratified split on all intents(including retrieval intents if they exist)\n    y = [example.get_full_intent() for example in x]\n    for i_fold, (train_index, test_index) in enumerate(skf.split(x, y)):\n        logger.debug(f\"Fold: {i_fold}\")\n        train = [x[i] for i in train_index]\n        test = [x[i] for i in test_index]\n        yield (\n            TrainingData(\n                training_examples=train,\n                entity_synonyms=training_data.entity_synonyms,\n                regex_features=training_data.regex_features,\n                responses=training_data.responses,\n            ),\n            TrainingData(\n                training_examples=test,\n                entity_synonyms=training_data.entity_synonyms,\n                regex_features=training_data.regex_features,\n                responses=training_data.responses,\n            ),\n        )\n\n\ndef combine_result(\n    intent_metrics: IntentMetrics,\n    entity_metrics: EntityMetrics,\n    response_selection_metrics: ResponseSelectionMetrics,\n    interpreter: Interpreter,\n    data: TrainingData,\n    intent_results: Optional[List[IntentEvaluationResult]] = None,\n    entity_results: Optional[List[EntityEvaluationResult]] = None,\n    response_selection_results: Optional[\n        List[ResponseSelectionEvaluationResult]\n    ] = None,\n) -> Tuple[IntentMetrics, EntityMetrics, ResponseSelectionMetrics]:\n    \"\"\"Collects intent, response selection and entity metrics for cross validation\n    folds.\n\n    If `intent_results`, `response_selection_results` or `entity_results` is provided\n    as a list, prediction results are also collected.\n\n    Args:\n        intent_metrics: intent metrics\n        entity_metrics: entity metrics\n        response_selection_metrics: response selection metrics\n        interpreter: the interpreter\n        data: training data\n        intent_results: intent evaluation results\n        entity_results: entity evaluation results\n        response_selection_results: reponse selection evaluation results\n\n    Returns: intent, entity, and response selection metrics\n    \"\"\"\n    (\n        intent_current_metrics,\n        entity_current_metrics,\n        response_selection_current_metrics,\n        current_intent_results,\n        current_entity_results,\n        current_response_selection_results,\n    ) = compute_metrics(interpreter, data)\n\n    if intent_results is not None:\n        intent_results += current_intent_results\n\n    if entity_results is not None:\n        entity_results += current_entity_results\n\n    if response_selection_results is not None:\n        response_selection_results += current_response_selection_results\n\n    for k, v in intent_current_metrics.items():\n        intent_metrics[k] = v + intent_metrics[k]\n\n    for k, v in response_selection_current_metrics.items():\n        response_selection_metrics[k] = v + response_selection_metrics[k]\n\n    for extractor, extractor_metric in entity_current_metrics.items():\n        entity_metrics[extractor] = {\n            k: v + entity_metrics[extractor][k] for k, v in extractor_metric.items()\n        }\n\n    return intent_metrics, entity_metrics, response_selection_metrics\n\n\ndef _contains_entity_labels(entity_results: List[EntityEvaluationResult]) -> bool:\n\n    for result in entity_results:\n        if result.entity_targets or result.entity_predictions:\n            return True\n    return False\n\n\ndef cross_validate(\n    data: TrainingData,\n    n_folds: int,\n    nlu_config: Union[RasaNLUModelConfig, Text],\n    output: Optional[Text] = None,\n    successes: bool = False,\n    errors: bool = False,\n    disable_plotting: bool = False,\n) -> Tuple[CVEvaluationResult, CVEvaluationResult, CVEvaluationResult]:\n    \"\"\"Stratified cross validation on data.\n\n    Args:\n        data: Training Data\n        n_folds: integer, number of cv folds\n        nlu_config: nlu config file\n        output: path to folder where reports are stored\n        successes: if true successful predictions are written to a file\n        errors: if true incorrect predictions are written to a file\n        disable_plotting: if true no confusion matrix and historgram plates are created\n\n    Returns:\n        dictionary with key, list structure, where each entry in list\n              corresponds to the relevant result for one fold\n    \"\"\"\n    import rasa.nlu.config\n\n    if isinstance(nlu_config, str):\n        nlu_config = rasa.nlu.config.load(nlu_config)\n\n    if output:\n        rasa.shared.utils.io.create_directory(output)\n\n    trainer = Trainer(nlu_config)\n    trainer.pipeline = remove_pretrained_extractors(trainer.pipeline)\n\n    intent_train_metrics: IntentMetrics = defaultdict(list)\n    intent_test_metrics: IntentMetrics = defaultdict(list)\n    entity_train_metrics: EntityMetrics = defaultdict(lambda: defaultdict(list))\n    entity_test_metrics: EntityMetrics = defaultdict(lambda: defaultdict(list))\n    response_selection_train_metrics: ResponseSelectionMetrics = defaultdict(list)\n    response_selection_test_metrics: ResponseSelectionMetrics = defaultdict(list)\n\n    intent_test_results: List[IntentEvaluationResult] = []\n    entity_test_results: List[EntityEvaluationResult] = []\n    response_selection_test_results: List[ResponseSelectionEvaluationResult] = []\n    intent_classifier_present = False\n    response_selector_present = False\n    entity_evaluation_possible = False\n    extractors: Set[Text] = set()\n\n    for train, test in generate_folds(n_folds, data):\n        interpreter = trainer.train(train)\n\n        # calculate train accuracy\n        combine_result(\n            intent_train_metrics,\n            entity_train_metrics,\n            response_selection_train_metrics,\n            interpreter,\n            train,\n        )\n        # calculate test accuracy\n        combine_result(\n            intent_test_metrics,\n            entity_test_metrics,\n            response_selection_test_metrics,\n            interpreter,\n            test,\n            intent_test_results,\n            entity_test_results,\n            response_selection_test_results,\n        )\n\n        if not extractors:\n            extractors = get_entity_extractors(interpreter)\n            entity_evaluation_possible = (\n                entity_evaluation_possible\n                or _contains_entity_labels(entity_test_results)\n            )\n\n        if is_intent_classifier_present(interpreter):\n            intent_classifier_present = True\n\n        if is_response_selector_present(interpreter):\n            response_selector_present = True\n\n    if intent_classifier_present and intent_test_results:\n        logger.info(\"Accumulated test folds intent evaluation results:\")\n        evaluate_intents(\n            intent_test_results, output, successes, errors, disable_plotting\n        )\n\n    if extractors and entity_evaluation_possible:\n        logger.info(\"Accumulated test folds entity evaluation results:\")\n        evaluate_entities(\n            entity_test_results, extractors, output, successes, errors, disable_plotting\n        )\n\n    if response_selector_present and response_selection_test_results:\n        logger.info(\"Accumulated test folds response selection evaluation results:\")\n        evaluate_response_selections(\n            response_selection_test_results, output, successes, errors, disable_plotting\n        )\n\n    if not entity_evaluation_possible:\n        entity_test_metrics = defaultdict(lambda: defaultdict(list))\n        entity_train_metrics = defaultdict(lambda: defaultdict(list))\n\n    return (\n        CVEvaluationResult(dict(intent_train_metrics), dict(intent_test_metrics)),\n        CVEvaluationResult(dict(entity_train_metrics), dict(entity_test_metrics)),\n        CVEvaluationResult(\n            dict(response_selection_train_metrics),\n            dict(response_selection_test_metrics),\n        ),\n    )\n\n\ndef _targets_predictions_from(\n    results: Union[\n        List[IntentEvaluationResult], List[ResponseSelectionEvaluationResult]\n    ],\n    target_key: Text,\n    prediction_key: Text,\n) -> Iterator[Iterable[Optional[Text]]]:\n    return zip(*[(getattr(r, target_key), getattr(r, prediction_key)) for r in results])\n\n\ndef compute_metrics(\n    interpreter: Interpreter, training_data: TrainingData\n) -> Tuple[\n    IntentMetrics,\n    EntityMetrics,\n    ResponseSelectionMetrics,\n    List[IntentEvaluationResult],\n    List[EntityEvaluationResult],\n    List[ResponseSelectionEvaluationResult],\n]:\n    \"\"\"Computes metrics for intent classification, response selection and entity\n    extraction.\n\n    Args:\n        interpreter: the interpreter\n        training_data: training data\n\n    Returns: intent, response selection and entity metrics, and prediction results.\n    \"\"\"\n    intent_results, response_selection_results, entity_results = get_eval_data(\n        interpreter, training_data\n    )\n\n    intent_results = remove_empty_intent_examples(intent_results)\n\n    response_selection_results = remove_empty_response_examples(\n        response_selection_results\n    )\n\n    intent_metrics = {}\n    if intent_results:\n        intent_metrics = _compute_metrics(\n            intent_results, \"intent_target\", \"intent_prediction\"\n        )\n\n    entity_metrics = {}\n    if entity_results:\n        entity_metrics = _compute_entity_metrics(entity_results, interpreter)\n\n    response_selection_metrics = {}\n    if response_selection_results:\n        response_selection_metrics = _compute_metrics(\n            response_selection_results,\n            \"intent_response_key_target\",\n            \"intent_response_key_prediction\",\n        )\n\n    return (\n        intent_metrics,\n        entity_metrics,\n        response_selection_metrics,\n        intent_results,\n        entity_results,\n        response_selection_results,\n    )\n\n\ndef compare_nlu(\n    configs: List[Text],\n    data: TrainingData,\n    exclusion_percentages: List[int],\n    f_score_results: Dict[Text, Any],\n    model_names: List[Text],\n    output: Text,\n    runs: int,\n) -> List[int]:\n    \"\"\"\n    Trains and compares multiple NLU models.\n    For each run and exclusion percentage a model per config file is trained.\n    Thereby, the model is trained only on the current percentage of training data.\n    Afterwards, the model is tested on the complete test data of that run.\n    All results are stored in the provided output directory.\n\n    Args:\n        configs: config files needed for training\n        data: training data\n        exclusion_percentages: percentages of training data to exclude during comparison\n        f_score_results: dictionary of model name to f-score results per run\n        model_names: names of the models to train\n        output: the output directory\n        runs: number of comparison runs\n\n    Returns: training examples per run\n    \"\"\"\n\n    from rasa.train import train_nlu\n\n    training_examples_per_run = []\n\n    for run in range(runs):\n\n        logger.info(\"Beginning comparison run {}/{}\".format(run + 1, runs))\n\n        run_path = os.path.join(output, \"run_{}\".format(run + 1))\n        io_utils.create_path(run_path)\n\n        test_path = os.path.join(run_path, TEST_DATA_FILE)\n        io_utils.create_path(test_path)\n\n        train, test = data.train_test_split()\n        rasa.shared.utils.io.write_text_file(test.nlu_as_markdown(), test_path)\n\n        for percentage in exclusion_percentages:\n            percent_string = f\"{percentage}%_exclusion\"\n\n            _, train_included = train.train_test_split(percentage / 100)\n            # only count for the first run and ignore the others\n            if run == 0:\n                training_examples_per_run.append(len(train_included.nlu_examples))\n\n            model_output_path = os.path.join(run_path, percent_string)\n            train_split_path = os.path.join(model_output_path, \"train\")\n            train_nlu_split_path = os.path.join(train_split_path, TRAIN_DATA_FILE)\n            train_nlg_split_path = os.path.join(train_split_path, NLG_DATA_FILE)\n            io_utils.create_path(train_nlu_split_path)\n            rasa.shared.utils.io.write_text_file(\n                train_included.nlu_as_markdown(), train_nlu_split_path\n            )\n            rasa.shared.utils.io.write_text_file(\n                train_included.nlg_as_markdown(), train_nlg_split_path\n            )\n\n            for nlu_config, model_name in zip(configs, model_names):\n                logger.info(\n                    \"Evaluating configuration '{}' with {} training data.\".format(\n                        model_name, percent_string\n                    )\n                )\n\n                try:\n                    model_path = train_nlu(\n                        nlu_config,\n                        train_split_path,\n                        model_output_path,\n                        fixed_model_name=model_name,\n                    )\n                except Exception as e:  # skipcq: PYL-W0703\n                    # general exception catching needed to continue evaluating other\n                    # model configurations\n                    logger.warning(f\"Training model '{model_name}' failed. Error: {e}\")\n                    f_score_results[model_name][run].append(0.0)\n                    continue\n\n                model_path = os.path.join(get_model(model_path), \"nlu\")\n\n                output_path = os.path.join(model_output_path, f\"{model_name}_report\")\n                result = run_evaluation(\n                    test_path, model_path, output_directory=output_path, errors=True\n                )\n\n                f1 = result[\"intent_evaluation\"][\"f1_score\"]\n                f_score_results[model_name][run].append(f1)\n\n    return training_examples_per_run\n\n\ndef _compute_metrics(\n    results: Union[\n        List[IntentEvaluationResult], List[ResponseSelectionEvaluationResult]\n    ],\n    target_key: Text,\n    prediction_key: Text,\n) -> Union[IntentMetrics, ResponseSelectionMetrics]:\n    \"\"\"Computes evaluation metrics for a given corpus and returns the results.\n\n    Args:\n        results: evaluation results\n        target_key: target key name\n        prediction_key: prediction key name\n\n    Returns: metrics\n    \"\"\"\n    from rasa.test import get_evaluation_metrics\n\n    # compute fold metrics\n    targets, predictions = _targets_predictions_from(\n        results, target_key, prediction_key\n    )\n    _, precision, f1, accuracy = get_evaluation_metrics(targets, predictions)\n\n    return {\"Accuracy\": [accuracy], \"F1-score\": [f1], \"Precision\": [precision]}\n\n\ndef _compute_entity_metrics(\n    entity_results: List[EntityEvaluationResult], interpreter: Interpreter\n) -> EntityMetrics:\n    \"\"\"Computes entity evaluation metrics and returns the results.\n\n    Args:\n        entity_results: entity evaluation results\n        interpreter: the interpreter\n\n    Returns: entity metrics\n    \"\"\"\n    from rasa.test import get_evaluation_metrics\n\n    entity_metric_results: EntityMetrics = defaultdict(lambda: defaultdict(list))\n    extractors = get_entity_extractors(interpreter)\n\n    if not extractors:\n        return entity_metric_results\n\n    aligned_predictions = align_all_entity_predictions(entity_results, extractors)\n\n    merged_targets = merge_labels(aligned_predictions)\n    merged_targets = substitute_labels(merged_targets, NO_ENTITY_TAG, NO_ENTITY)\n\n    for extractor in extractors:\n        merged_predictions = merge_labels(aligned_predictions, extractor)\n        merged_predictions = substitute_labels(\n            merged_predictions, NO_ENTITY_TAG, NO_ENTITY\n        )\n        _, precision, f1, accuracy = get_evaluation_metrics(\n            merged_targets, merged_predictions, exclude_label=NO_ENTITY\n        )\n        entity_metric_results[extractor][\"Accuracy\"].append(accuracy)\n        entity_metric_results[extractor][\"F1-score\"].append(f1)\n        entity_metric_results[extractor][\"Precision\"].append(precision)\n\n    return entity_metric_results\n\n\ndef log_results(results: IntentMetrics, dataset_name: Text) -> None:\n    \"\"\"Logs results of cross validation.\n\n    Args:\n        results: dictionary of results returned from cross validation\n        dataset_name: string of which dataset the results are from, e.g. test/train\n    \"\"\"\n    for k, v in results.items():\n        logger.info(\n            \"{} {}: {:.3f} ({:.3f})\".format(dataset_name, k, np.mean(v), np.std(v))\n        )\n\n\ndef log_entity_results(results: EntityMetrics, dataset_name: Text) -> None:\n    \"\"\"Logs entity results of cross validation.\n\n    Args:\n        results: dictionary of dictionaries of results returned from cross validation\n        dataset_name: string of which dataset the results are from, e.g. test/train\n    \"\"\"\n    for extractor, result in results.items():\n        logger.info(f\"Entity extractor: {extractor}\")\n        log_results(result, dataset_name)\n\n\n### rasa/core/policies/memoization.py ###\n\nimport zlib\n\nimport base64\nimport json\nimport logging\n\nfrom tqdm import tqdm\nfrom typing import Optional, Any, Dict, List, Text\n\nimport rasa.utils.io\nimport rasa.shared.utils.io\nfrom rasa.shared.constants import DOCS_URL_POLICIES\nfrom rasa.shared.core.domain import State, Domain\nfrom rasa.shared.core.events import ActionExecuted\nfrom rasa.core.featurizers.tracker_featurizers import (\n    TrackerFeaturizer,\n    MaxHistoryTrackerFeaturizer,\n)\nfrom rasa.shared.nlu.interpreter import NaturalLanguageInterpreter\nfrom rasa.core.policies.policy import Policy, PolicyPrediction\nfrom rasa.shared.core.trackers import DialogueStateTracker\nfrom rasa.shared.core.generator import TrackerWithCachedStates\nfrom rasa.shared.utils.io import is_logging_disabled\nfrom rasa.core.constants import MEMOIZATION_POLICY_PRIORITY\n\nlogger = logging.getLogger(__name__)\n\n# temporary constants to support back compatibility\nMAX_HISTORY_NOT_SET = -1\nOLD_DEFAULT_MAX_HISTORY = 5\n\n\nclass MemoizationPolicy(Policy):\n    \"\"\"The policy that remembers exact examples of\n    `max_history` turns from training stories.\n\n    Since `slots` that are set some time in the past are\n    preserved in all future feature vectors until they are set\n    to None, this policy implicitly remembers and most importantly\n    recalls examples in the context of the current dialogue\n    longer than `max_history`.\n\n    This policy is not supposed to be the only policy in an ensemble,\n    it is optimized for precision and not recall.\n    It should get a 100% precision because it emits probabilities of 1.1\n    along it's predictions, which makes every mistake fatal as\n    no other policy can overrule it.\n\n    If it is needed to recall turns from training dialogues where\n    some slots might not be set during prediction time, and there are\n    training stories for this, use AugmentedMemoizationPolicy.\n    \"\"\"\n\n    ENABLE_FEATURE_STRING_COMPRESSION = True\n\n    USE_NLU_CONFIDENCE_AS_SCORE = False\n\n    @staticmethod\n    def _standard_featurizer(\n        max_history: Optional[int] = None,\n    ) -> MaxHistoryTrackerFeaturizer:\n        # Memoization policy always uses MaxHistoryTrackerFeaturizer\n        # without state_featurizer\n        return MaxHistoryTrackerFeaturizer(\n            state_featurizer=None, max_history=max_history\n        )\n\n    def __init__(\n        self,\n        featurizer: Optional[TrackerFeaturizer] = None,\n        priority: int = MEMOIZATION_POLICY_PRIORITY,\n        max_history: Optional[int] = MAX_HISTORY_NOT_SET,\n        lookup: Optional[Dict] = None,\n    ) -> None:\n        \"\"\"Initialize the policy.\n\n        Args:\n            featurizer: tracker featurizer\n            priority: the priority of the policy\n            max_history: maximum history to take into account when featurizing trackers\n            lookup: a dictionary that stores featurized tracker states and\n                predicted actions for them\n        \"\"\"\n\n        if max_history == MAX_HISTORY_NOT_SET:\n            max_history = OLD_DEFAULT_MAX_HISTORY  # old default value\n            rasa.shared.utils.io.raise_warning(\n                f\"Please configure the max history in your configuration file, \"\n                f\"currently 'max_history' is set to old default value of \"\n                f\"'{max_history}'. If you want to have infinite max history \"\n                f\"set it to 'None' explicitly. We will change the default value of \"\n                f\"'max_history' in the future to 'None'.\",\n                DeprecationWarning,\n                docs=DOCS_URL_POLICIES,\n            )\n\n        if not featurizer:\n            featurizer = self._standard_featurizer(max_history)\n\n        super().__init__(featurizer, priority)\n\n        self.max_history = self.featurizer.max_history\n        self.lookup = lookup if lookup is not None else {}\n\n    def _create_lookup_from_states(\n        self,\n        trackers_as_states: List[List[State]],\n        trackers_as_actions: List[List[Text]],\n    ) -> Dict[Text, Text]:\n        \"\"\"Creates lookup dictionary from the tracker represented as states.\n\n        Args:\n            trackers_as_states: representation of the trackers as a list of states\n            trackers_as_actions: representation of the trackers as a list of actions\n\n        Returns:\n            lookup dictionary\n        \"\"\"\n\n        lookup = {}\n\n        if not trackers_as_states:\n            return lookup\n\n        assert len(trackers_as_actions[0]) == 1, (\n            f\"The second dimension of trackers_as_action should be 1, \"\n            f\"instead of {len(trackers_as_actions[0])}\"\n        )\n\n        ambiguous_feature_keys = set()\n\n        pbar = tqdm(\n            zip(trackers_as_states, trackers_as_actions),\n            desc=\"Processed actions\",\n            disable=is_logging_disabled(),\n        )\n        for states, actions in pbar:\n            action = actions[0]\n\n            feature_key = self._create_feature_key(states)\n            if not feature_key:\n                continue\n\n            if feature_key not in ambiguous_feature_keys:\n                if feature_key in lookup.keys():\n                    if lookup[feature_key] != action:\n                        # delete contradicting example created by\n                        # partial history augmentation from memory\n                        ambiguous_feature_keys.add(feature_key)\n                        del lookup[feature_key]\n                else:\n                    lookup[feature_key] = action\n            pbar.set_postfix({\"# examples\": \"{:d}\".format(len(lookup))})\n\n        return lookup\n\n    def _create_feature_key(self, states: List[State]) -> Text:\n        # we sort keys to make sure that the same states\n        # represented as dictionaries have the same json strings\n        # quotes are removed for aesthetic reasons\n        feature_str = json.dumps(states, sort_keys=True).replace('\"', \"\")\n        if self.ENABLE_FEATURE_STRING_COMPRESSION:\n            compressed = zlib.compress(\n                bytes(feature_str, rasa.shared.utils.io.DEFAULT_ENCODING)\n            )\n            return base64.b64encode(compressed).decode(\n                rasa.shared.utils.io.DEFAULT_ENCODING\n            )\n        else:\n            return feature_str\n\n    def train(\n        self,\n        training_trackers: List[TrackerWithCachedStates],\n        domain: Domain,\n        interpreter: NaturalLanguageInterpreter,\n        **kwargs: Any,\n    ) -> None:\n        # only considers original trackers (no augmented ones)\n        training_trackers = [\n            t\n            for t in training_trackers\n            if not hasattr(t, \"is_augmented\") or not t.is_augmented\n        ]\n        (\n            trackers_as_states,\n            trackers_as_actions,\n        ) = self.featurizer.training_states_and_actions(training_trackers, domain)\n        self.lookup = self._create_lookup_from_states(\n            trackers_as_states, trackers_as_actions\n        )\n        logger.debug(f\"Memorized {len(self.lookup)} unique examples.\")\n\n    def _recall_states(self, states: List[State]) -> Optional[Text]:\n        return self.lookup.get(self._create_feature_key(states))\n\n    def recall(\n        self, states: List[State], tracker: DialogueStateTracker, domain: Domain\n    ) -> Optional[Text]:\n        return self._recall_states(states)\n\n    def _prediction_result(\n        self, action_name: Text, tracker: DialogueStateTracker, domain: Domain\n    ) -> List[float]:\n        result = self._default_predictions(domain)\n        if action_name:\n            if self.USE_NLU_CONFIDENCE_AS_SCORE:\n                # the memoization will use the confidence of NLU on the latest\n                # user message to set the confidence of the action\n                score = tracker.latest_message.intent.get(\"confidence\", 1.0)\n            else:\n                score = 1.0\n\n            result[domain.index_for_action(action_name)] = score\n\n        return result\n\n    def predict_action_probabilities(\n        self,\n        tracker: DialogueStateTracker,\n        domain: Domain,\n        interpreter: NaturalLanguageInterpreter,\n        **kwargs: Any,\n    ) -> PolicyPrediction:\n        result = self._default_predictions(domain)\n\n        tracker_as_states = self.featurizer.prediction_states([tracker], domain)\n        states = tracker_as_states[0]\n        logger.debug(f\"Current tracker state:{self.format_tracker_states(states)}\")\n        predicted_action_name = self.recall(states, tracker, domain)\n        if predicted_action_name is not None:\n            logger.debug(f\"There is a memorised next action '{predicted_action_name}'\")\n            result = self._prediction_result(predicted_action_name, tracker, domain)\n        else:\n            logger.debug(\"There is no memorised next action\")\n\n        return self._prediction(result)\n\n    def _metadata(self) -> Dict[Text, Any]:\n        return {\n            \"priority\": self.priority,\n            \"max_history\": self.max_history,\n            \"lookup\": self.lookup,\n        }\n\n    @classmethod\n    def _metadata_filename(cls) -> Text:\n        return \"memorized_turns.json\"\n\n\nclass AugmentedMemoizationPolicy(MemoizationPolicy):\n    \"\"\"The policy that remembers examples from training stories\n    for `max_history` turns.\n\n    If it is needed to recall turns from training dialogues\n    where some slots might not be set during prediction time,\n    add relevant stories without such slots to training data.\n    E.g. reminder stories.\n\n    Since `slots` that are set some time in the past are\n    preserved in all future feature vectors until they are set\n    to None, this policy has a capability to recall the turns\n    up to `max_history` from training stories during prediction\n    even if additional slots were filled in the past\n    for current dialogue.\n    \"\"\"\n\n    @staticmethod\n    def _back_to_the_future(\n        tracker, again: bool = False\n    ) -> Optional[DialogueStateTracker]:\n        \"\"\"Send Marty to the past to get\n        the new featurization for the future\"\"\"\n\n        idx_of_first_action = None\n        idx_of_second_action = None\n\n        # we need to find second executed action\n        for e_i, event in enumerate(tracker.applied_events()):\n            # find second ActionExecuted\n            if isinstance(event, ActionExecuted):\n                if idx_of_first_action is None:\n                    idx_of_first_action = e_i\n                else:\n                    idx_of_second_action = e_i\n                    break\n\n        # use first action, if we went first time and second action, if we went again\n        idx_to_use = idx_of_second_action if again else idx_of_first_action\n        if idx_to_use is None:\n            return\n\n        # make second ActionExecuted the first one\n        events = tracker.applied_events()[idx_to_use:]\n        if not events:\n            return\n\n        mcfly_tracker = tracker.init_copy()\n        for e in events:\n            mcfly_tracker.update(e)\n\n        return mcfly_tracker\n\n    def _recall_using_delorean(self, old_states, tracker, domain) -> Optional[Text]:\n        \"\"\"Recursively go to the past to correctly forget slots,\n        and then back to the future to recall.\"\"\"\n\n        logger.debug(\"Launch DeLorean...\")\n\n        mcfly_tracker = self._back_to_the_future(tracker)\n        while mcfly_tracker is not None:\n            tracker_as_states = self.featurizer.prediction_states(\n                [mcfly_tracker], domain\n            )\n            states = tracker_as_states[0]\n\n            if old_states != states:\n                # check if we like new futures\n                memorised = self._recall_states(states)\n                if memorised is not None:\n                    logger.debug(f\"Current tracker state {states}\")\n                    return memorised\n                old_states = states\n\n            # go back again\n            mcfly_tracker = self._back_to_the_future(mcfly_tracker, again=True)\n\n        # No match found\n        logger.debug(f\"Current tracker state {old_states}\")\n        return None\n\n    def recall(\n        self, states: List[State], tracker: DialogueStateTracker, domain: Domain\n    ) -> Optional[Text]:\n\n        predicted_action_name = self._recall_states(states)\n        if predicted_action_name is None:\n            # let's try a different method to recall that tracker\n            return self._recall_using_delorean(states, tracker, domain)\n        else:\n            return predicted_action_name\n\n\n### rasa/shared/utils/io.py ###\n\nfrom collections import OrderedDict\nimport errno\nimport glob\nfrom hashlib import md5\nfrom io import StringIO\nimport json\nimport os\nfrom pathlib import Path\nimport re\nfrom typing import Any, Dict, List, Optional, Text, Type, Union\nimport warnings\n\nfrom ruamel import yaml as yaml\nfrom ruamel.yaml import RoundTripRepresenter, YAMLError\nfrom ruamel.yaml.constructor import DuplicateKeyError\n\nfrom rasa.shared.constants import (\n    DEFAULT_LOG_LEVEL,\n    ENV_LOG_LEVEL,\n    NEXT_MAJOR_VERSION_FOR_DEPRECATIONS,\n)\nfrom rasa.shared.exceptions import (\n    FileIOException,\n    FileNotFoundException,\n    YamlSyntaxException,\n)\n\nDEFAULT_ENCODING = \"utf-8\"\nYAML_VERSION = (1, 2)\n\n\nclass bcolors:\n    HEADER = \"\\033[95m\"\n    OKBLUE = \"\\033[94m\"\n    OKGREEN = \"\\033[92m\"\n    WARNING = \"\\033[93m\"\n    FAIL = \"\\033[91m\"\n    ENDC = \"\\033[0m\"\n    BOLD = \"\\033[1m\"\n    UNDERLINE = \"\\033[4m\"\n\n\ndef wrap_with_color(*args: Any, color: Text) -> Text:\n    return color + \" \".join(str(s) for s in args) + bcolors.ENDC\n\n\ndef raise_warning(\n    message: Text,\n    category: Optional[Type[Warning]] = None,\n    docs: Optional[Text] = None,\n    **kwargs: Any,\n) -> None:\n    \"\"\"Emit a `warnings.warn` with sensible defaults and a colored warning msg.\"\"\"\n\n    original_formatter = warnings.formatwarning\n\n    def should_show_source_line() -> bool:\n        if \"stacklevel\" not in kwargs:\n            if category == UserWarning or category is None:\n                return False\n            if category == FutureWarning:\n                return False\n        return True\n\n    def formatwarning(\n        message: Text,\n        category: Optional[Type[Warning]],\n        filename: Text,\n        lineno: Optional[int],\n        line: Optional[Text] = None,\n    ):\n        \"\"\"Function to format a warning the standard way.\"\"\"\n\n        if not should_show_source_line():\n            if docs:\n                line = f\"More info at {docs}\"\n            else:\n                line = \"\"\n\n        formatted_message = original_formatter(\n            message, category, filename, lineno, line\n        )\n        return wrap_with_color(formatted_message, color=bcolors.WARNING)\n\n    if \"stacklevel\" not in kwargs:\n        # try to set useful defaults for the most common warning categories\n        if category == DeprecationWarning:\n            kwargs[\"stacklevel\"] = 3\n        elif category in (UserWarning, FutureWarning):\n            kwargs[\"stacklevel\"] = 2\n\n    warnings.formatwarning = formatwarning\n    warnings.warn(message, category=category, **kwargs)\n    warnings.formatwarning = original_formatter\n\n\ndef write_text_file(\n    content: Text,\n    file_path: Union[Text, Path],\n    encoding: Text = DEFAULT_ENCODING,\n    append: bool = False,\n) -> None:\n    \"\"\"Writes text to a file.\n\n    Args:\n        content: The content to write.\n        file_path: The path to which the content should be written.\n        encoding: The encoding which should be used.\n        append: Whether to append to the file or to truncate the file.\n\n    \"\"\"\n    mode = \"a\" if append else \"w\"\n    with open(file_path, mode, encoding=encoding) as file:\n        file.write(content)\n\n\ndef read_file(filename: Union[Text, Path], encoding: Text = DEFAULT_ENCODING) -> Any:\n    \"\"\"Read text from a file.\"\"\"\n\n    try:\n        with open(filename, encoding=encoding) as f:\n            return f.read()\n    except FileNotFoundError:\n        raise FileNotFoundException(\n            f\"Failed to read file, \" f\"'{os.path.abspath(filename)}' does not exist.\"\n        )\n    except UnicodeDecodeError:\n        raise FileIOException(\n            f\"Failed to read file '{os.path.abspath(filename)}', \"\n            f\"could not read the file using {encoding} to decode \"\n            f\"it. Please make sure the file is stored with this \"\n            f\"encoding.\"\n        )\n\n\ndef read_json_file(filename: Union[Text, Path]) -> Any:\n    \"\"\"Read json from a file.\"\"\"\n    content = read_file(filename)\n    try:\n        return json.loads(content)\n    except ValueError as e:\n        raise FileIOException(\n            f\"Failed to read json from '{os.path.abspath(filename)}'. Error: {e}\"\n        )\n\n\ndef list_directory(path: Text) -> List[Text]:\n    \"\"\"Returns all files and folders excluding hidden files.\n\n    If the path points to a file, returns the file. This is a recursive\n    implementation returning files in any depth of the path.\"\"\"\n\n    if not isinstance(path, str):\n        raise ValueError(\n            f\"`resource_name` must be a string type. \" f\"Got `{type(path)}` instead\"\n        )\n\n    if os.path.isfile(path):\n        return [path]\n    elif os.path.isdir(path):\n        results = []\n        for base, dirs, files in os.walk(path, followlinks=True):\n            # sort files for same order across runs\n            files = sorted(files, key=_filename_without_prefix)\n            # add not hidden files\n            good_files = filter(lambda x: not x.startswith(\".\"), files)\n            results.extend(os.path.join(base, f) for f in good_files)\n            # add not hidden directories\n            good_directories = filter(lambda x: not x.startswith(\".\"), dirs)\n            results.extend(os.path.join(base, f) for f in good_directories)\n        return results\n    else:\n        raise ValueError(f\"Could not locate the resource '{os.path.abspath(path)}'.\")\n\n\ndef list_files(path: Text) -> List[Text]:\n    \"\"\"Returns all files excluding hidden files.\n\n    If the path points to a file, returns the file.\"\"\"\n\n    return [fn for fn in list_directory(path) if os.path.isfile(fn)]\n\n\ndef _filename_without_prefix(file: Text) -> Text:\n    \"\"\"Splits of a filenames prefix until after the first ``_``.\"\"\"\n    return \"_\".join(file.split(\"_\")[1:])\n\n\ndef list_subdirectories(path: Text) -> List[Text]:\n    \"\"\"Returns all folders excluding hidden files.\n\n    If the path points to a file, returns an empty list.\"\"\"\n\n    return [fn for fn in glob.glob(os.path.join(path, \"*\")) if os.path.isdir(fn)]\n\n\ndef deep_container_fingerprint(\n    obj: Union[List[Any], Dict[Any, Any]], encoding: Text = DEFAULT_ENCODING\n) -> Text:\n    \"\"\"Calculate a hash which is stable, independent of a containers key order.\n\n    Works for lists and dictionaries. For keys and values, we recursively call\n    `hash(...)` on them. Keep in mind that a list with keys in a different order\n    will create the same hash!\n\n    Args:\n        obj: dictionary or list to be hashed.\n        encoding: encoding used for dumping objects as strings\n\n    Returns:\n        hash of the container.\n    \"\"\"\n    if isinstance(obj, dict):\n        return get_dictionary_fingerprint(obj, encoding)\n    if isinstance(obj, list):\n        return get_list_fingerprint(obj, encoding)\n    else:\n        return get_text_hash(str(obj), encoding)\n\n\ndef get_dictionary_fingerprint(\n    dictionary: Dict[Any, Any], encoding: Text = DEFAULT_ENCODING\n) -> Text:\n    \"\"\"Calculate the fingerprint for a dictionary.\n\n    The dictionary can contain any keys and values which are either a dict,\n    a list or a elements which can be dumped as a string.\n\n    Args:\n        dictionary: dictionary to be hashed\n        encoding: encoding used for dumping objects as strings\n\n    Returns:\n        The hash of the dictionary\n    \"\"\"\n    stringified = json.dumps(\n        {\n            deep_container_fingerprint(k, encoding): deep_container_fingerprint(\n                v, encoding\n            )\n            for k, v in dictionary.items()\n        },\n        sort_keys=True,\n    )\n    return get_text_hash(stringified, encoding)\n\n\ndef get_list_fingerprint(\n    elements: List[Any], encoding: Text = DEFAULT_ENCODING\n) -> Text:\n    \"\"\"Calculate a fingerprint for an unordered list.\n\n    Args:\n        elements: unordered list\n        encoding: encoding used for dumping objects as strings\n\n    Returns:\n        the fingerprint of the list\n    \"\"\"\n    stringified = json.dumps(\n        [deep_container_fingerprint(element, encoding) for element in elements]\n    )\n    return get_text_hash(stringified, encoding)\n\n\ndef get_text_hash(text: Text, encoding: Text = DEFAULT_ENCODING) -> Text:\n    \"\"\"Calculate the md5 hash for a text.\"\"\"\n    return md5(text.encode(encoding)).hexdigest()\n\n\ndef json_to_string(obj: Any, **kwargs: Any) -> Text:\n    indent = kwargs.pop(\"indent\", 2)\n    ensure_ascii = kwargs.pop(\"ensure_ascii\", False)\n    return json.dumps(obj, indent=indent, ensure_ascii=ensure_ascii, **kwargs)\n\n\ndef fix_yaml_loader() -> None:\n    \"\"\"Ensure that any string read by yaml is represented as unicode.\"\"\"\n\n    def construct_yaml_str(self, node):\n        # Override the default string handling function\n        # to always return unicode objects\n        return self.construct_scalar(node)\n\n    yaml.Loader.add_constructor(\"tag:yaml.org,2002:str\", construct_yaml_str)\n    yaml.SafeLoader.add_constructor(\"tag:yaml.org,2002:str\", construct_yaml_str)\n\n\ndef replace_environment_variables() -> None:\n    \"\"\"Enable yaml loader to process the environment variables in the yaml.\"\"\"\n    # eg. ${USER_NAME}, ${PASSWORD}\n    env_var_pattern = re.compile(r\"^(.*)\\$\\{(.*)\\}(.*)$\")\n    yaml.add_implicit_resolver(\"!env_var\", env_var_pattern)\n\n    def env_var_constructor(loader, node):\n        \"\"\"Process environment variables found in the YAML.\"\"\"\n        value = loader.construct_scalar(node)\n        expanded_vars = os.path.expandvars(value)\n        if \"$\" in expanded_vars:\n            not_expanded = [w for w in expanded_vars.split() if \"$\" in w]\n            raise ValueError(\n                \"Error when trying to expand the environment variables\"\n                \" in '{}'. Please make sure to also set these environment\"\n                \" variables: '{}'.\".format(value, not_expanded)\n            )\n        return expanded_vars\n\n    yaml.SafeConstructor.add_constructor(\"!env_var\", env_var_constructor)\n\n\ndef read_yaml(content: Text, reader_type: Union[Text, List[Text]] = \"safe\") -> Any:\n    \"\"\"Parses yaml from a text.\n\n    Args:\n        content: A text containing yaml content.\n        reader_type: Reader type to use. By default \"safe\" will be used\n\n    Raises:\n        ruamel.yaml.parser.ParserError: If there was an error when parsing the YAML.\n    \"\"\"\n    fix_yaml_loader()\n\n    replace_environment_variables()\n\n    yaml_parser = yaml.YAML(typ=reader_type)\n    yaml_parser.version = YAML_VERSION\n    yaml_parser.preserve_quotes = True\n    yaml.allow_duplicate_keys = False\n\n    if _is_ascii(content):\n        # Required to make sure emojis are correctly parsed\n        content = (\n            content.encode(\"utf-8\")\n            .decode(\"raw_unicode_escape\")\n            .encode(\"utf-16\", \"surrogatepass\")\n            .decode(\"utf-16\")\n        )\n\n    return yaml_parser.load(content) or {}\n\n\ndef _is_ascii(text: Text) -> bool:\n    return all(ord(character) < 128 for character in text)\n\n\ndef read_yaml_file(filename: Union[Text, Path]) -> Union[List[Any], Dict[Text, Any]]:\n    \"\"\"Parses a yaml file.\n\n    Raises an exception if the content of the file can not be parsed as YAML.\n\n    Args:\n        filename: The path to the file which should be read.\n\n    Returns:\n        Parsed content of the file.\n    \"\"\"\n    try:\n        return read_yaml(read_file(filename, DEFAULT_ENCODING))\n    except (YAMLError, DuplicateKeyError) as e:\n        raise YamlSyntaxException(filename, e)\n\n\ndef write_yaml(\n    data: Any,\n    target: Union[Text, Path, StringIO],\n    should_preserve_key_order: bool = False,\n) -> None:\n    \"\"\"Writes a yaml to the file or to the stream\n\n    Args:\n        data: The data to write.\n        target: The path to the file which should be written or a stream object\n        should_preserve_key_order: Whether to force preserve key order in `data`.\n    \"\"\"\n    _enable_ordered_dict_yaml_dumping()\n\n    if should_preserve_key_order:\n        data = convert_to_ordered_dict(data)\n\n    dumper = yaml.YAML()\n    # no wrap lines\n    dumper.width = YAML_LINE_MAX_WIDTH\n\n    # use `null` to represent `None`\n    dumper.representer.add_representer(\n        type(None),\n        lambda self, _: self.represent_scalar(\"tag:yaml.org,2002:null\", \"null\"),\n    )\n\n    if isinstance(target, StringIO):\n        dumper.dump(data, target)\n        return\n\n    with Path(target).open(\"w\", encoding=DEFAULT_ENCODING) as outfile:\n        dumper.dump(data, outfile)\n\n\nYAML_LINE_MAX_WIDTH = 4096\n\n\ndef convert_to_ordered_dict(obj: Any) -> Any:\n    \"\"\"Convert object to an `OrderedDict`.\n\n    Args:\n        obj: Object to convert.\n\n    Returns:\n        An `OrderedDict` with all nested dictionaries converted if `obj` is a\n        dictionary, otherwise the object itself.\n    \"\"\"\n    if isinstance(obj, OrderedDict):\n        return obj\n    # use recursion on lists\n    if isinstance(obj, list):\n        return [convert_to_ordered_dict(element) for element in obj]\n\n    if isinstance(obj, dict):\n        out = OrderedDict()\n        # use recursion on dictionaries\n        for k, v in obj.items():\n            out[k] = convert_to_ordered_dict(v)\n\n        return out\n\n    # return all other objects\n    return obj\n\n\ndef _enable_ordered_dict_yaml_dumping() -> None:\n    \"\"\"Ensure that `OrderedDict`s are dumped so that the order of keys is respected.\"\"\"\n    yaml.add_representer(\n        OrderedDict,\n        RoundTripRepresenter.represent_dict,\n        representer=RoundTripRepresenter,\n    )\n\n\ndef is_logging_disabled() -> bool:\n    \"\"\"Returns `True` if log level is set to WARNING or ERROR, `False` otherwise.\"\"\"\n    log_level = os.environ.get(ENV_LOG_LEVEL, DEFAULT_LOG_LEVEL)\n\n    return log_level in (\"ERROR\", \"WARNING\")\n\n\ndef create_directory_for_file(file_path: Union[Text, Path]) -> None:\n    \"\"\"Creates any missing parent directories of this file path.\"\"\"\n\n    create_directory(os.path.dirname(file_path))\n\n\ndef dump_obj_as_json_to_file(filename: Union[Text, Path], obj: Any) -> None:\n    \"\"\"Dump an object as a json string to a file.\"\"\"\n\n    write_text_file(json.dumps(obj, indent=2), filename)\n\n\ndef dump_obj_as_yaml_to_string(\n    obj: Any, should_preserve_key_order: bool = False\n) -> Text:\n    \"\"\"Writes data (python dict) to a yaml string.\n\n    Args:\n        obj: The object to dump. Has to be serializable.\n        should_preserve_key_order: Whether to force preserve key order in `data`.\n\n    Returns:\n        The object converted to a YAML string.\n    \"\"\"\n    buffer = StringIO()\n\n    write_yaml(obj, buffer, should_preserve_key_order=should_preserve_key_order)\n\n    return buffer.getvalue()\n\n\ndef create_directory(directory_path: Text) -> None:\n    \"\"\"Creates a directory and its super paths.\n\n    Succeeds even if the path already exists.\"\"\"\n\n    try:\n        os.makedirs(directory_path)\n    except OSError as e:\n        # be happy if someone already created the path\n        if e.errno != errno.EEXIST:\n            raise\n\n\ndef raise_deprecation_warning(\n    message: Text,\n    warn_until_version: Text = NEXT_MAJOR_VERSION_FOR_DEPRECATIONS,\n    docs: Optional[Text] = None,\n    **kwargs: Any,\n) -> None:\n    \"\"\"\n    Thin wrapper around `raise_warning()` to raise a deprecation warning. It requires\n    a version until which we'll warn, and after which the support for the feature will\n    be removed.\n    \"\"\"\n    if warn_until_version not in message:\n        message = f\"{message} (will be removed in {warn_until_version})\"\n\n    # need the correct stacklevel now\n    kwargs.setdefault(\"stacklevel\", 3)\n    # we're raising a `FutureWarning` instead of a `DeprecationWarning` because\n    # we want these warnings to be visible in the terminal of our users\n    # https://docs.python.org/3/library/warnings.html#warning-categories\n    raise_warning(message, FutureWarning, docs, **kwargs)\n\n\ndef read_config_file(filename: Union[Path, Text]) -> Dict[Text, Any]:\n    \"\"\"Parses a yaml configuration file. Content needs to be a dictionary\n\n    Args:\n        filename: The path to the file which should be read.\n    \"\"\"\n    content = read_yaml_file(filename)\n\n    if content is None:\n        return {}\n    elif isinstance(content, dict):\n        return content\n    else:\n        raise YamlSyntaxException(\n            filename,\n            ValueError(\n                f\"Tried to load configuration file '{filename}'. \"\n                f\"Expected a key value mapping but found a {type(content).__name__}\"\n            ),\n        )\n\n\ndef is_subdirectory(path: Text, potential_parent_directory: Text) -> bool:\n    if path is None or potential_parent_directory is None:\n        return False\n\n    path = os.path.abspath(path)\n    potential_parent_directory = os.path.abspath(potential_parent_directory)\n\n    return potential_parent_directory in path\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "import os\nfrom pathlib import Path\nfrom typing import Any, Text, Dict\n\nimport pytest\n\nimport rasa.shared.utils.io\nimport rasa.utils.io\nfrom rasa.core.test import (\n    _create_data_generator,\n    _collect_story_predictions,\n    test as evaluate_stories,\n    FAILED_STORIES_FILE,\n    CONFUSION_MATRIX_STORIES_FILE,\n    REPORT_STORIES_FILE,\n    SUCCESSFUL_STORIES_FILE,\n    _clean_entity_results,\n)\nfrom rasa.core.policies.memoization import MemoizationPolicy\n\n# we need this import to ignore the warning...\n# noinspection PyUnresolvedReferences\nfrom rasa.nlu.test import run_evaluation\nfrom rasa.core.agent import Agent\nfrom tests.core.conftest import (\n    DEFAULT_STORIES_FILE,\n    E2E_STORY_FILE_UNKNOWN_ENTITY,\n    END_TO_END_STORY_FILE,\n    E2E_STORY_FILE_TRIPS_CIRCUIT_BREAKER,\n    STORY_FILE_TRIPS_CIRCUIT_BREAKER,\n)\n\n\nasync def test_evaluation_file_creation(tmpdir: Path, default_agent: Agent):\n    failed_stories_path = str(tmpdir / FAILED_STORIES_FILE)\n    success_stories_path = str(tmpdir / SUCCESSFUL_STORIES_FILE)\n    report_path = str(tmpdir / REPORT_STORIES_FILE)\n    confusion_matrix_path = str(tmpdir / CONFUSION_MATRIX_STORIES_FILE)\n\n    await evaluate_stories(\n        stories=DEFAULT_STORIES_FILE,\n        agent=default_agent,\n        out_directory=str(tmpdir),\n        max_stories=None,\n        e2e=False,\n        errors=True,\n        successes=True,\n    )\n\n    assert os.path.isfile(failed_stories_path)\n    assert os.path.isfile(success_stories_path)\n    assert os.path.isfile(report_path)\n    assert os.path.isfile(confusion_matrix_path)\n\n\n@pytest.mark.parametrize(\n    \"test_file\", [END_TO_END_STORY_FILE, \"data/test_evaluations/end_to_end_story.yml\"]\n)\nasync def test_end_to_end_evaluation_script(default_agent: Agent, test_file: Text):\n    generator = await _create_data_generator(test_file, default_agent, use_e2e=True)\n    completed_trackers = generator.generate_story_trackers()\n\n    story_evaluation, num_stories = await _collect_story_predictions(\n        completed_trackers, default_agent, use_e2e=True\n    )\n\n    serialised_store = [\n        \"utter_greet\",\n        \"action_listen\",\n        \"utter_greet\",\n        \"action_listen\",\n        \"utter_default\",\n        \"action_listen\",\n        \"utter_goodbye\",\n        \"action_listen\",\n        \"utter_greet\",\n        \"action_listen\",\n        \"utter_default\",\n        \"action_listen\",\n        \"greet\",\n        \"greet\",\n        \"default\",\n        \"goodbye\",\n        \"greet\",\n        \"default\",\n        '[{\"name\": \"Max\"}]{\"entity\": \"name\", \"value\": \"Max\"}',\n    ]\n\n    assert story_evaluation.evaluation_store.serialise()[0] == serialised_store\n    assert not story_evaluation.evaluation_store.has_prediction_target_mismatch()\n    assert len(story_evaluation.failed_stories) == 0\n    assert num_stories == 3\n\n\nasync def test_end_to_end_evaluation_script_unknown_entity(default_agent: Agent):\n    generator = await _create_data_generator(\n        E2E_STORY_FILE_UNKNOWN_ENTITY, default_agent, use_e2e=True\n    )\n    completed_trackers = generator.generate_story_trackers()\n\n    story_evaluation, num_stories = await _collect_story_predictions(\n        completed_trackers, default_agent, use_e2e=True\n    )\n\n    assert story_evaluation.evaluation_store.has_prediction_target_mismatch()\n    assert len(story_evaluation.failed_stories) == 1\n    assert num_stories == 1\n\n\nasync def test_end_to_evaluation_with_forms(form_bot_agent: Agent):\n    generator = await _create_data_generator(\n        \"data/test_evaluations/form-end-to-end-stories.md\", form_bot_agent, use_e2e=True\n    )\n    test_stories = generator.generate_story_trackers()\n\n    story_evaluation, num_stories = await _collect_story_predictions(\n        test_stories, form_bot_agent, use_e2e=True\n    )\n\n    assert not story_evaluation.evaluation_store.has_prediction_target_mismatch()\n\n\nasync def test_source_in_failed_stories(tmpdir: Path, default_agent: Agent):\n    stories_path = str(tmpdir / FAILED_STORIES_FILE)\n\n    await evaluate_stories(\n        stories=E2E_STORY_FILE_UNKNOWN_ENTITY,\n        agent=default_agent,\n        out_directory=str(tmpdir),\n        max_stories=None,\n        e2e=False,\n    )\n\n    failed_stories = rasa.shared.utils.io.read_file(stories_path)\n\n    assert (\n        f\"story: simple_story_with_unknown_entity ({E2E_STORY_FILE_UNKNOWN_ENTITY})\"\n        in failed_stories\n    )\n\n\nasync def test_end_to_evaluation_trips_circuit_breaker():\n    agent = Agent(\n        domain=\"data/test_domains/default.yml\",\n        policies=[MemoizationPolicy(max_history=11)],\n    )\n    training_data = await agent.load_data(STORY_FILE_TRIPS_CIRCUIT_BREAKER)\n    agent.train(training_data)\n\n    generator = await _create_data_generator(\n        E2E_STORY_FILE_TRIPS_CIRCUIT_BREAKER, agent, use_e2e=True\n    )\n    test_stories = generator.generate_story_trackers()\n\n    story_evaluation, num_stories = await _collect_story_predictions(\n        test_stories, agent, use_e2e=True\n    )\n\n    circuit_trip_predicted = [\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"utter_greet\",\n        \"circuit breaker tripped\",\n        \"circuit breaker tripped\",\n    ]\n\n    assert (\n        story_evaluation.evaluation_store.action_predictions == circuit_trip_predicted\n    )\n    assert num_stories == 1\n\n\n@pytest.mark.parametrize(\n    \"text, entity, expected_entity\",\n    [\n        (\n            \"The first one please.\",\n            {\n                \"extractor\": \"DucklingEntityExtractor\",\n                \"entity\": \"ordinal\",\n                \"confidence\": 0.87,\n                \"start\": 4,\n                \"end\": 9,\n                \"value\": 1,\n            },\n            {\n                \"text\": \"The first one please.\",\n                \"entity\": \"ordinal\",\n                \"start\": 4,\n                \"end\": 9,\n                \"value\": \"1\",\n            },\n        ),\n        (\n            \"The first one please.\",\n            {\n                \"extractor\": \"CRFEntityExtractor\",\n                \"entity\": \"ordinal\",\n                \"confidence\": 0.87,\n                \"start\": 4,\n                \"end\": 9,\n                \"value\": \"1\",\n            },\n            {\n                \"text\": \"The first one please.\",\n                \"entity\": \"ordinal\",\n                \"start\": 4,\n                \"end\": 9,\n                \"value\": \"1\",\n            },\n        ),\n        (\n            \"Italian food\",\n            {\n                \"extractor\": \"DIETClassifier\",\n                \"entity\": \"cuisine\",\n                \"confidence\": 0.99,\n                \"start\": 0,\n                \"end\": 7,\n                \"value\": \"Italian\",\n            },\n            {\n                \"text\": \"Italian food\",\n                \"entity\": \"cuisine\",\n                \"start\": 0,\n                \"end\": 7,\n                \"value\": \"Italian\",\n            },\n        ),\n    ],\n)\ndef test_event_has_proper_implementation(\n    text: Text, entity: Dict[Text, Any], expected_entity: Dict[Text, Any]\n):\n    actual_entities = _clean_entity_results(text, [entity])\n\n    assert actual_entities[0] == expected_entity\n\n\n@pytest.mark.parametrize(\n    \"test_file\",\n    [\n        (\"data/test_yaml_stories/test_full_retrieval_intent_story.yml\"),\n        (\"data/test_yaml_stories/test_base_retrieval_intent_story.yml\"),\n    ],\n)\nasync def test_retrieval_intent(response_selector_agent: Agent, test_file: Text):\n    generator = await _create_data_generator(\n        test_file, response_selector_agent, use_e2e=True,\n    )\n    test_stories = generator.generate_story_trackers()\n\n    story_evaluation, num_stories = await _collect_story_predictions(\n        test_stories, response_selector_agent, use_e2e=True\n    )\n    # check that test story can either specify base intent or full retrieval intent\n    assert not story_evaluation.evaluation_store.has_prediction_target_mismatch()\n\n\n@pytest.mark.parametrize(\n    \"test_file\",\n    [\n        (\"data/test_yaml_stories/test_full_retrieval_intent_wrong_prediction.yml\"),\n        (\"data/test_yaml_stories/test_base_retrieval_intent_wrong_prediction.yml\"),\n    ],\n)\nasync def test_retrieval_intent_wrong_prediction(\n    tmpdir: Path, response_selector_agent: Agent, test_file: Text\n):\n    stories_path = str(tmpdir / FAILED_STORIES_FILE)\n\n    await evaluate_stories(\n        stories=test_file,\n        agent=response_selector_agent,\n        out_directory=str(tmpdir),\n        max_stories=None,\n        e2e=True,\n    )\n\n    failed_stories = rasa.shared.utils.io.read_file(stories_path)\n\n    # check if the predicted entry contains full retrieval intent\n    assert \"# predicted: chitchat/ask_name\" in failed_stories\n"
  },
  {
    "prompt": "\n\n### returns/result.py ###\n\nfrom abc import ABCMeta\nfrom functools import wraps\nfrom inspect import FrameInfo\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    ClassVar,\n    List,\n    NoReturn,\n    Optional,\n    Type,\n    TypeVar,\n    Union,\n)\n\nfrom typing_extensions import final\n\nfrom returns.interfaces.specific import result\nfrom returns.primitives.container import BaseContainer, container_equality\nfrom returns.primitives.exceptions import UnwrapFailedError\nfrom returns.primitives.hkt import Kind2, SupportsKind2\n\n# Definitions:\n_ValueType = TypeVar('_ValueType', covariant=True)\n_NewValueType = TypeVar('_NewValueType')\n_ErrorType = TypeVar('_ErrorType', covariant=True)\n_NewErrorType = TypeVar('_NewErrorType')\n\n# Aliases:\n_FirstType = TypeVar('_FirstType')\n_SecondType = TypeVar('_SecondType')\n\n\nclass Result(\n    BaseContainer,\n    SupportsKind2['Result', _ValueType, _ErrorType],\n    result.ResultBased2[_ValueType, _ErrorType],\n    metaclass=ABCMeta,\n):\n    \"\"\"\n    Base class for :class:`~Failure` and :class:`~Success`.\n\n    :class:`~Result` does not have a public constructor.\n    Use :func:`~Success` and :func:`~Failure` to construct the needed values.\n\n    See also:\n        - https://bit.ly/361qQhi\n        - https://hackernoon.com/the-throw-keyword-was-a-mistake-l9e532di\n\n    \"\"\"\n\n    __slots__ = ('_trace',)\n    __match_args__ = ('_inner_value',)\n\n    _inner_value: Union[_ValueType, _ErrorType]\n    _trace: Optional[List[FrameInfo]]\n\n    # These two are required for projects like `classes`:\n    #: Success type that is used to represent the successful computation.\n    success_type: ClassVar[Type['Success']]\n    #: Failure type that is used to represent the failed computation.\n    failure_type: ClassVar[Type['Failure']]\n\n    #: Typesafe equality comparison with other `Result` objects.\n    equals = container_equality\n\n    @property\n    def trace(self) -> Optional[List[FrameInfo]]:\n        \"\"\"Returns a list with stack trace when :func:`~Failure` was called.\"\"\"\n        return self._trace\n\n    def swap(self) -> 'Result[_ErrorType, _ValueType]':\n        \"\"\"\n        Swaps value and error types.\n\n        So, values become errors and errors become values.\n        It is useful when you have to work with errors a lot.\n        And since we have a lot of ``.bind_`` related methods\n        and only a single ``.lash`` - it is easier to work with values.\n\n        .. code:: python\n\n          >>> from returns.result import Success, Failure\n          >>> assert Success(1).swap() == Failure(1)\n          >>> assert Failure(1).swap() == Success(1)\n\n        \"\"\"\n\n    def map(\n        self,\n        function: Callable[[_ValueType], _NewValueType],\n    ) -> 'Result[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a pure function.\n\n        .. code:: python\n\n          >>> from returns.result import Failure, Success\n\n          >>> def mappable(string: str) -> str:\n          ...      return string + 'b'\n\n          >>> assert Success('a').map(mappable) == Success('ab')\n          >>> assert Failure('a').map(mappable) == Failure('a')\n\n        \"\"\"\n\n    def apply(\n        self,\n        container: Kind2[\n            'Result',\n            Callable[[_ValueType], _NewValueType],\n            _ErrorType,\n        ],\n    ) -> 'Result[_NewValueType, _ErrorType]':\n        \"\"\"\n        Calls a wrapped function in a container on this container.\n\n        .. code:: python\n\n          >>> from returns.result import Failure, Success\n\n          >>> def appliable(string: str) -> str:\n          ...      return string + 'b'\n\n          >>> assert Success('a').apply(Success(appliable)) == Success('ab')\n          >>> assert Failure('a').apply(Success(appliable)) == Failure('a')\n\n          >>> assert Success('a').apply(Failure(1)) == Failure(1)\n          >>> assert Failure(1).apply(Failure(2)) == Failure(1)\n\n        \"\"\"\n\n    def bind(\n        self,\n        function: Callable[\n            [_ValueType],\n            Kind2['Result', _NewValueType, _ErrorType],\n        ],\n    ) -> 'Result[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a function that returns a container.\n\n        .. code:: python\n\n          >>> from returns.result import Result, Success, Failure\n\n          >>> def bindable(arg: str) -> Result[str, str]:\n          ...      if len(arg) > 1:\n          ...          return Success(arg + 'b')\n          ...      return Failure(arg + 'c')\n\n          >>> assert Success('aa').bind(bindable) == Success('aab')\n          >>> assert Success('a').bind(bindable) == Failure('ac')\n          >>> assert Failure('a').bind(bindable) == Failure('a')\n\n        \"\"\"\n\n    #: Alias for `bind_result` method, it is the same as `bind` here.\n    bind_result = bind\n\n    def alt(\n        self,\n        function: Callable[[_ErrorType], _NewErrorType],\n    ) -> 'Result[_ValueType, _NewErrorType]':\n        \"\"\"\n        Composes failed container with a pure function to modify failure.\n\n        .. code:: python\n\n          >>> from returns.result import Failure, Success\n\n          >>> def altable(arg: str) -> str:\n          ...      return arg + 'b'\n\n          >>> assert Success('a').alt(altable) == Success('a')\n          >>> assert Failure('a').alt(altable) == Failure('ab')\n\n        \"\"\"\n\n    def lash(\n        self,\n        function: Callable[\n            [_ErrorType], Kind2['Result', _ValueType, _NewErrorType],\n        ],\n    ) -> 'Result[_ValueType, _NewErrorType]':\n        \"\"\"\n        Composes failed container with a function that returns a container.\n\n        .. code:: python\n\n          >>> from returns.result import Result, Success, Failure\n\n          >>> def lashable(arg: str) -> Result[str, str]:\n          ...      if len(arg) > 1:\n          ...          return Success(arg + 'b')\n          ...      return Failure(arg + 'c')\n\n          >>> assert Success('a').lash(lashable) == Success('a')\n          >>> assert Failure('a').lash(lashable) == Failure('ac')\n          >>> assert Failure('aa').lash(lashable) == Success('aab')\n\n        \"\"\"\n\n    def value_or(\n        self,\n        default_value: _NewValueType,\n    ) -> Union[_ValueType, _NewValueType]:\n        \"\"\"\n        Get value or default value.\n\n        .. code:: python\n\n          >>> from returns.result import Failure, Success\n          >>> assert Success(1).value_or(2) == 1\n          >>> assert Failure(1).value_or(2) == 2\n\n        \"\"\"\n\n    def unwrap(self) -> _ValueType:\n        \"\"\"\n        Get value or raise exception.\n\n        .. code:: pycon\n          :force:\n\n          >>> from returns.result import Failure, Success\n          >>> assert Success(1).unwrap() == 1\n\n          >>> Failure(1).unwrap()\n          Traceback (most recent call last):\n            ...\n          returns.primitives.exceptions.UnwrapFailedError\n\n        \"\"\"  # noqa: RST307\n\n    def failure(self) -> _ErrorType:\n        \"\"\"\n        Get failed value or raise exception.\n\n        .. code:: pycon\n          :force:\n\n          >>> from returns.result import Failure, Success\n          >>> assert Failure(1).failure() == 1\n\n          >>> Success(1).failure()\n          Traceback (most recent call last):\n            ...\n          returns.primitives.exceptions.UnwrapFailedError\n\n        \"\"\"  # noqa: RST307\n\n    @classmethod\n    def from_value(\n        cls, inner_value: _NewValueType,\n    ) -> 'Result[_NewValueType, Any]':\n        \"\"\"\n        One more value to create success unit values.\n\n        It is useful as a united way to create a new value from any container.\n\n        .. code:: python\n\n          >>> from returns.result import Result, Success\n          >>> assert Result.from_value(1) == Success(1)\n\n        You can use this method or :func:`~Success`,\n        choose the most convenient for you.\n\n        \"\"\"\n        return Success(inner_value)\n\n    @classmethod\n    def from_failure(\n        cls, inner_value: _NewErrorType,\n    ) -> 'Result[Any, _NewErrorType]':\n        \"\"\"\n        One more value to create failure unit values.\n\n        It is useful as a united way to create a new value from any container.\n\n        .. code:: python\n\n          >>> from returns.result import Result, Failure\n          >>> assert Result.from_failure(1) == Failure(1)\n\n        You can use this method or :func:`~Failure`,\n        choose the most convenient for you.\n\n        \"\"\"\n        return Failure(inner_value)\n\n    @classmethod\n    def from_result(\n        cls, inner_value: 'Result[_NewValueType, _NewErrorType]',\n    ) -> 'Result[_NewValueType, _NewErrorType]':\n        \"\"\"\n        Creates a new ``Result`` instance from existing ``Result`` instance.\n\n        .. code:: python\n\n          >>> from returns.result import Result, Failure, Success\n          >>> assert Result.from_result(Success(1)) == Success(1)\n          >>> assert Result.from_result(Failure(1)) == Failure(1)\n\n        This is a part of\n        :class:`returns.interfaces.specific.result.ResultBasedN` interface.\n        \"\"\"\n        return inner_value\n\n\n@final  # noqa: WPS338\nclass Failure(Result[Any, _ErrorType]):  # noqa: WPS338\n    \"\"\"\n    Represents a calculation which has failed.\n\n    It should contain an error code or message.\n    \"\"\"\n\n    _inner_value: _ErrorType\n\n    def __init__(self, inner_value: _ErrorType) -> None:\n        \"\"\"Failure constructor.\"\"\"\n        super().__init__(inner_value)\n        object.__setattr__(self, '_trace', self._get_trace())  # noqa: WPS609\n\n    if not TYPE_CHECKING:  # noqa: C901, WPS604  # pragma: no branch\n        def alt(self, function):\n            \"\"\"Composes failed container with a pure function to modify failure.\"\"\"  # noqa: E501\n            return Failure(function(self._inner_value))\n\n        def map(self, function):\n            \"\"\"Does nothing for ``Failure``.\"\"\"\n            return self\n\n        def bind(self, function):\n            \"\"\"Does nothing for ``Failure``.\"\"\"\n            return self\n\n        #: Alias for `bind` method. Part of the `ResultBasedN` interface.\n        bind_result = bind\n\n        def lash(self, function):\n            \"\"\"Composes this container with a function returning container.\"\"\"\n            return function(self._inner_value)\n\n        def apply(self, container):\n            \"\"\"Does nothing for ``Failure``.\"\"\"\n            return self\n\n        def value_or(self, default_value):\n            \"\"\"Returns default value for failed container.\"\"\"\n            return default_value\n\n    def swap(self):\n        \"\"\"Failures swap to :class:`Success`.\"\"\"\n        return Success(self._inner_value)\n\n    def unwrap(self) -> NoReturn:\n        \"\"\"Raises an exception, since it does not have a value inside.\"\"\"\n        if isinstance(self._inner_value, Exception):\n            raise UnwrapFailedError(self) from self._inner_value\n        raise UnwrapFailedError(self)\n\n    def failure(self) -> _ErrorType:\n        \"\"\"Returns failed value.\"\"\"\n        return self._inner_value\n\n    def _get_trace(self) -> Optional[List[FrameInfo]]:\n        \"\"\"Method that will be monkey patched when trace is active.\"\"\"\n        return None  # noqa: WPS324\n\n\n@final\nclass Success(Result[_ValueType, Any]):\n    \"\"\"\n    Represents a calculation which has succeeded and contains the result.\n\n    Contains the computation value.\n    \"\"\"\n\n    _inner_value: _ValueType\n\n    def __init__(self, inner_value: _ValueType) -> None:\n        \"\"\"Success constructor.\"\"\"\n        super().__init__(inner_value)\n\n    if not TYPE_CHECKING:  # noqa: C901, WPS604  # pragma: no branch\n        def alt(self, function):\n            \"\"\"Does nothing for ``Success``.\"\"\"\n            return self\n\n        def map(self, function):\n            \"\"\"Composes current container with a pure function.\"\"\"\n            return Success(function(self._inner_value))\n\n        def bind(self, function):\n            \"\"\"Binds current container to a function that returns container.\"\"\"\n            return function(self._inner_value)\n\n        #: Alias for `bind` method. Part of the `ResultBasedN` interface.\n        bind_result = bind\n\n        def lash(self, function):\n            \"\"\"Does nothing for ``Success``.\"\"\"\n            return self\n\n        def apply(self, container):\n            \"\"\"Calls a wrapped function in a container on this container.\"\"\"\n            if isinstance(container, self.success_type):\n                return self.map(container.unwrap())\n            return container\n\n        def value_or(self, default_value):\n            \"\"\"Returns the value for successful container.\"\"\"\n            return self._inner_value\n\n    def swap(self):\n        \"\"\"Successes swap to :class:`Failure`.\"\"\"\n        return Failure(self._inner_value)\n\n    def unwrap(self) -> _ValueType:\n        \"\"\"Returns the unwrapped value from successful container.\"\"\"\n        return self._inner_value\n\n    def failure(self) -> NoReturn:\n        \"\"\"Raises an exception for successful container.\"\"\"\n        raise UnwrapFailedError(self)\n\n\nResult.success_type = Success\nResult.failure_type = Failure\n\n# Aliases:\n\n#: Alias for a popular case when ``Result`` has ``Exception`` as error type.\nResultE = Result[_ValueType, Exception]\n\n\n# Decorators:\n\ndef safe(\n    function: Callable[..., _ValueType],\n) -> Callable[..., ResultE[_ValueType]]:\n    \"\"\"\n    Decorator to convert exception-throwing function to ``Result`` container.\n\n    Should be used with care, since it only catches ``Exception`` subclasses.\n    It does not catch ``BaseException`` subclasses.\n\n    If you need to mark ``async`` function as ``safe``,\n    use :func:`returns.future.future_safe` instead.\n    This decorator only works with sync functions. Example:\n\n    .. code:: python\n\n      >>> from returns.result import Result, Success, safe\n\n      >>> @safe\n      ... def might_raise(arg: int) -> float:\n      ...     return 1 / arg\n\n      >>> assert might_raise(1) == Success(1.0)\n      >>> assert isinstance(might_raise(0), Result.failure_type)\n\n    Similar to :func:`returns.io.impure_safe`\n    and :func:`returns.future.future_safe` decorators.\n\n    Requires our :ref:`mypy plugin <mypy-plugins>`.\n\n    \"\"\"\n    @wraps(function)\n    def decorator(*args, **kwargs):\n        try:\n            return Success(function(*args, **kwargs))\n        except Exception as exc:\n            return Failure(exc)\n    return decorator\n\n\n### returns/io.py ###\n\nfrom abc import ABCMeta\nfrom functools import wraps\nfrom inspect import FrameInfo\nfrom typing import (\n    TYPE_CHECKING,\n    Any,\n    Callable,\n    ClassVar,\n    List,\n    Optional,\n    Type,\n    TypeVar,\n    Union,\n)\n\nfrom typing_extensions import final\n\nfrom returns.interfaces.specific import io, ioresult\nfrom returns.primitives.container import BaseContainer, container_equality\nfrom returns.primitives.hkt import (\n    Kind1,\n    Kind2,\n    SupportsKind1,\n    SupportsKind2,\n    dekind,\n)\nfrom returns.result import Failure, Result, Success\n\n_ValueType = TypeVar('_ValueType', covariant=True)\n_NewValueType = TypeVar('_NewValueType')\n\n# Result related:\n_ErrorType = TypeVar('_ErrorType', covariant=True)\n_NewErrorType = TypeVar('_NewErrorType')\n\n# Helpers:\n_FirstType = TypeVar('_FirstType')\n_SecondType = TypeVar('_SecondType')\n\n\nclass IO(\n    BaseContainer,\n    SupportsKind1['IO', _ValueType],\n    io.IOLike1[_ValueType],\n):\n    \"\"\"\n    Explicit container for impure function results.\n\n    We also sometimes call it \"marker\" since once it is marked,\n    it cannot be ever unmarked.\n    There's no way to directly get its internal value.\n\n    Note that ``IO`` represents a computation that never fails.\n\n    Examples of such computations are:\n\n    - read / write to localStorage\n    - get the current time\n    - write to the console\n    - get a random number\n\n    Use ``IOResult[...]`` for operations that might fail.\n    Like DB access or network operations.\n\n    See also:\n        - https://dev.to/gcanti/getting-started-with-fp-ts-io-36p6\n        - https://gist.github.com/chris-taylor/4745921\n\n    \"\"\"\n\n    _inner_value: _ValueType\n\n    #: Typesafe equality comparison with other `Result` objects.\n    equals = container_equality\n\n    def __init__(self, inner_value: _ValueType) -> None:\n        \"\"\"\n        Public constructor for this type. Also required for typing.\n\n        .. code:: python\n\n          >>> from returns.io import IO\n          >>> assert str(IO(1)) == '<IO: 1>'\n\n        \"\"\"\n        super().__init__(inner_value)\n\n    def map(\n        self,\n        function: Callable[[_ValueType], _NewValueType],\n    ) -> 'IO[_NewValueType]':\n        \"\"\"\n        Applies function to the inner value.\n\n        Applies 'function' to the contents of the IO instance\n        and returns a new IO object containing the result.\n        'function' should accept a single \"normal\" (non-container) argument\n        and return a non-container result.\n\n        .. code:: python\n\n          >>> def mappable(string: str) -> str:\n          ...      return string + 'b'\n\n          >>> assert IO('a').map(mappable) == IO('ab')\n\n        \"\"\"\n        return IO(function(self._inner_value))\n\n    def apply(\n        self,\n        container: Kind1['IO', Callable[[_ValueType], _NewValueType]],\n    ) -> 'IO[_NewValueType]':\n        \"\"\"\n        Calls a wrapped function in a container on this container.\n\n        .. code:: python\n\n          >>> from returns.io import IO\n          >>> assert IO('a').apply(IO(lambda inner: inner + 'b')) == IO('ab')\n\n        Or more complex example that shows how we can work\n        with regular functions and multiple ``IO`` arguments:\n\n        .. code:: python\n\n          >>> from returns.curry import curry\n\n          >>> @curry\n          ... def appliable(first: str, second: str) -> str:\n          ...      return first + second\n\n          >>> assert IO('b').apply(IO('a').apply(IO(appliable))) == IO('ab')\n\n        \"\"\"\n        return self.map(dekind(container)._inner_value)  # noqa: WPS437\n\n    def bind(\n        self,\n        function: Callable[[_ValueType], Kind1['IO', _NewValueType]],\n    ) -> 'IO[_NewValueType]':\n        \"\"\"\n        Applies 'function' to the result of a previous calculation.\n\n        'function' should accept a single \"normal\" (non-container) argument\n        and return ``IO`` type object.\n\n        .. code:: python\n\n          >>> def bindable(string: str) -> IO[str]:\n          ...      return IO(string + 'b')\n\n          >>> assert IO('a').bind(bindable) == IO('ab')\n\n        \"\"\"\n        return dekind(function(self._inner_value))\n\n    #: Alias for `bind` method. Part of the `IOLikeN` interface.\n    bind_io = bind\n\n    @classmethod\n    def from_value(cls, inner_value: _NewValueType) -> 'IO[_NewValueType]':\n        \"\"\"\n        Unit function to construct new ``IO`` values.\n\n        Is the same as regular constructor:\n\n        .. code:: python\n\n          >>> from returns.io import IO\n          >>> assert IO(1) == IO.from_value(1)\n\n        Part of the :class:`returns.interfaces.applicative.ApplicativeN`\n        interface.\n        \"\"\"\n        return IO(inner_value)\n\n    @classmethod\n    def from_io(cls, inner_value: 'IO[_NewValueType]') -> 'IO[_NewValueType]':\n        \"\"\"\n        Unit function to construct new ``IO`` values from existing ``IO``.\n\n        .. code:: python\n\n          >>> from returns.io import IO\n          >>> assert IO(1) == IO.from_io(IO(1))\n\n        Part of the :class:`returns.interfaces.specific.IO.IOLikeN` interface.\n\n        \"\"\"\n        return inner_value\n\n    @classmethod\n    def from_ioresult(\n        cls,\n        inner_value: 'IOResult[_NewValueType, _NewErrorType]',\n    ) -> 'IO[Result[_NewValueType, _NewErrorType]]':\n        \"\"\"\n        Converts ``IOResult[a, b]`` back to ``IO[Result[a, b]]``.\n\n        Can be really helpful for composition.\n\n        .. code:: python\n\n            >>> from returns.io import IO, IOSuccess\n            >>> from returns.result import Success\n            >>> assert IO.from_ioresult(IOSuccess(1)) == IO(Success(1))\n\n        Is the reverse of :meth:`returns.io.IOResult.from_typecast`.\n        \"\"\"\n        return IO(inner_value._inner_value)  # noqa: WPS437\n\n\n# Helper functions:\n\ndef impure(\n    function: Callable[..., _NewValueType],\n) -> Callable[..., IO[_NewValueType]]:\n    \"\"\"\n    Decorator to mark function that it returns :class:`~IO` container.\n\n    If you need to mark ``async`` function as impure,\n    use :func:`returns.future.future` instead.\n    This decorator only works with sync functions. Example:\n\n    .. code:: python\n\n      >>> from returns.io import IO, impure\n\n      >>> @impure\n      ... def function(arg: int) -> int:\n      ...     return arg + 1  # this action is pure, just an example\n      ...\n\n      >>> assert function(1) == IO(2)\n\n    Requires our :ref:`mypy plugin <mypy-plugins>`.\n\n    \"\"\"\n    @wraps(function)\n    def decorator(*args, **kwargs):\n        return IO(function(*args, **kwargs))\n    return decorator\n\n\n# IO and Result:\n\nclass IOResult(\n    BaseContainer,\n    SupportsKind2['IOResult', _ValueType, _ErrorType],\n    ioresult.IOResultBased2[_ValueType, _ErrorType],\n    metaclass=ABCMeta,\n):\n    \"\"\"\n    Explicit container for impure function results that might fail.\n\n    .. rubric:: Definition\n\n    This type is similar to :class:`returns.result.Result`.\n    This basically a more useful version of ``IO[Result[a, b]]``.\n    Use this type for ``IO`` computations that might fail.\n    Examples of ``IO`` computations that might fail are:\n\n    - access database\n    - access network\n    - access filesystem\n\n    Use :class:`~IO` for operations that do ``IO`` but do not fail.\n\n    Note, that even methods like :meth:`~IOResult.unwrap``\n    and :meth:`~IOResult.value_or` return values wrapped in ``IO``.\n\n    ``IOResult`` is a complex compound value that consists of:\n\n    - raw value\n    - ``Result``\n    - ``IO``\n\n    This is why it has so many helper and factory methods:\n\n    - You can construct ``IOResult`` from raw values\n      with :func:`~IOSuccess` and :func:`~IOFailure` public type constructors\n    - You can construct ``IOResult`` from ``IO`` values\n      with :meth:`~IOResult.from_failed_io`\n      and :meth:`IOResult.from_io`\n    - You can construct ``IOResult`` from ``Result`` values\n      with :meth:`~IOResult.from_result`\n\n    We also have a lot of utility methods for better function composition like:\n\n    - :meth:`~IOResult.bind_result` to work\n      with functions which return ``Result``\n    - :meth:`~IOResult.from_typecast` to work with ``IO[Result[...]]`` values\n\n    See also:\n        https://github.com/gcanti/fp-ts/blob/master/docs/modules/IOEither.ts.md\n\n    .. rubric:: Implementation\n\n    This class contains all the methods that can be delegated to ``Result``.\n    But, some methods are not implemented which means\n    that we have to use special :class:`~_IOSuccess` and :class:`~_IOFailure`\n    implementation details to correctly handle these callbacks.\n\n    Do not rely on them! Use public functions and types instead.\n\n    \"\"\"\n\n    _inner_value: Result[_ValueType, _ErrorType]\n    __match_args__ = ('_inner_value',)\n\n    # These two are required for projects like `classes`:\n    #: Success type that is used to represent the successful computation.\n    success_type: ClassVar[Type['IOSuccess']]\n    #: Failure type that is used to represent the failed computation.\n    failure_type: ClassVar[Type['IOFailure']]\n\n    #: Typesafe equality comparison with other `IOResult` objects.\n    equals = container_equality\n\n    def __init__(self, inner_value: Result[_ValueType, _ErrorType]) -> None:\n        \"\"\"\n        Private type constructor.\n\n        Use :func:`~IOSuccess` and :func:`~IOFailure` instead.\n        Or :meth:`~IOResult.from_result` factory.\n        \"\"\"\n        super().__init__(inner_value)\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Custom ``str`` representation for better readability.\n\n        .. code:: python\n\n          >>> from returns.io import IOSuccess, IOFailure\n          >>> assert str(IOSuccess(1)) == '<IOResult: <Success: 1>>'\n          >>> assert repr(IOSuccess(1)) == '<IOResult: <Success: 1>>'\n          >>> str(IOFailure(ValueError('wrong!')))\n          '<IOResult: <Failure: wrong!>>'\n\n        \"\"\"\n        return '<IOResult: {0}>'.format(str(self._inner_value))\n\n    @property\n    def trace(self) -> Optional[List[FrameInfo]]:\n        \"\"\"Returns a stack trace when :func:`~IOFailure` was called.\"\"\"\n        return self._inner_value.trace\n\n    def swap(self) -> 'IOResult[_ErrorType, _ValueType]':\n        \"\"\"\n        Swaps value and error types.\n\n        So, values become errors and errors become values.\n        It is useful when you have to work with errors a lot.\n        And since we have a lot of ``.bind_`` related methods\n        and only a single ``.lash`` - it is easier to work with values.\n\n        .. code:: python\n\n          >>> from returns.io import IOSuccess, IOFailure\n          >>> assert IOSuccess(1).swap() == IOFailure(1)\n          >>> assert IOFailure(1).swap() == IOSuccess(1)\n\n        \"\"\"\n        return self.from_result(self._inner_value.swap())\n\n    def map(\n        self, function: Callable[[_ValueType], _NewValueType],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a pure function.\n\n        .. code:: python\n\n          >>> from returns.io import IOSuccess\n          >>> assert IOSuccess(1).map(lambda num: num + 1) == IOSuccess(2)\n\n        \"\"\"\n        return self.from_result(self._inner_value.map(function))\n\n    def apply(\n        self,\n        container: Kind2[\n            'IOResult',\n            Callable[[_ValueType], _NewValueType],\n            _ErrorType,\n        ],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Calls a wrapped function in a container on this container.\n\n        .. code:: python\n\n          >>> from returns.io import IOSuccess, IOFailure\n\n          >>> def appliable(first: str) -> str:\n          ...      return first + 'b'\n\n          >>> assert IOSuccess('a').apply(\n          ...     IOSuccess(appliable),\n          ... ) == IOSuccess('ab')\n          >>> assert IOFailure('a').apply(\n          ...     IOSuccess(appliable),\n          ... ) == IOFailure('a')\n\n          >>> assert IOSuccess('a').apply(IOFailure(1)) == IOFailure(1)\n          >>> assert IOFailure('a').apply(IOFailure('b')) == IOFailure('a')\n\n        \"\"\"\n        if isinstance(self, self.failure_type):\n            return self\n        if isinstance(container, self.success_type):\n            return self.from_result(\n                self._inner_value.map(\n                    container.unwrap()._inner_value,  # noqa: WPS437\n                ),\n            )\n        return container  # type: ignore\n\n    def bind(\n        self,\n        function: Callable[\n            [_ValueType],\n            Kind2['IOResult', _NewValueType, _ErrorType],\n        ],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a function that returns a container.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOFailure, IOSuccess\n          >>> def bindable(string: str) -> IOResult[str, str]:\n          ...      if len(string) > 1:\n          ...          return IOSuccess(string + 'b')\n          ...      return IOFailure(string + 'c')\n\n          >>> assert IOSuccess('aa').bind(bindable) == IOSuccess('aab')\n          >>> assert IOSuccess('a').bind(bindable) == IOFailure('ac')\n          >>> assert IOFailure('a').bind(bindable) == IOFailure('a')\n\n        \"\"\"\n\n    #: Alias for `bind_ioresult` method. Part of the `IOResultBasedN` interface.\n    bind_ioresult = bind\n\n    def bind_result(\n        self,\n        function: Callable[\n            [_ValueType],\n            Result[_NewValueType, _ErrorType],\n        ],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a function that returns a container.\n\n        Similar to :meth:`~IOResult.bind`, but works with containers\n        that return :class:`returns.result.Result`\n        instead of :class:`~IOResult`.\n\n        .. code:: python\n\n          >>> from returns.io import IOFailure, IOSuccess\n          >>> from returns.result import Result, Success\n\n          >>> def bindable(string: str) -> Result[str, str]:\n          ...      if len(string) > 1:\n          ...          return Success(string + 'b')\n          ...      return Failure(string + 'c')\n\n          >>> assert IOSuccess('aa').bind_result(bindable) == IOSuccess('aab')\n          >>> assert IOSuccess('a').bind_result(bindable) == IOFailure('ac')\n          >>> assert IOFailure('a').bind_result(bindable) == IOFailure('a')\n\n        \"\"\"\n\n    def bind_io(\n        self,\n        function: Callable[[_ValueType], IO[_NewValueType]],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes successful container with a function that returns a container.\n\n        Similar to :meth:`~IOResult.bind`, but works with containers\n        that return :class:`returns.io.IO` instead of :class:`~IOResult`.\n\n        .. code:: python\n\n          >>> from returns.io import IO, IOFailure, IOSuccess\n\n          >>> def bindable(string: str) -> IO[str]:\n          ...      return IO(string + 'z')\n\n          >>> assert IOSuccess('a').bind_io(bindable) == IOSuccess('az')\n          >>> assert IOFailure('a').bind_io(bindable) == IOFailure('a')\n\n        \"\"\"\n\n    def alt(\n        self,\n        function: Callable[[_ErrorType], _NewErrorType],\n    ) -> 'IOResult[_ValueType, _NewErrorType]':\n        \"\"\"\n        Composes failed container with a pure function to modify failure.\n\n        .. code:: python\n\n          >>> from returns.io import IOFailure\n          >>> assert IOFailure(1).alt(float) == IOFailure(1.0)\n\n        \"\"\"\n        return self.from_result(self._inner_value.alt(function))\n\n    def lash(\n        self,\n        function: Callable[\n            [_ErrorType],\n            Kind2['IOResult', _ValueType, _NewErrorType],\n        ],\n    ) -> 'IOResult[_ValueType, _NewErrorType]':\n        \"\"\"\n        Composes failed container with a function that returns a container.\n\n        .. code:: python\n\n          >>> from returns.io import IOFailure, IOSuccess, IOResult\n          >>> def lashable(state: str) -> IOResult[int, str]:\n          ...     if len(state) > 1:\n          ...         return IOSuccess(len(state))\n          ...     return IOFailure('oops')\n\n          >>> assert IOFailure('a').lash(lashable) == IOFailure('oops')\n          >>> assert IOFailure('abc').lash(lashable) == IOSuccess(3)\n          >>> assert IOSuccess('a').lash(lashable) == IOSuccess('a')\n\n        \"\"\"\n\n    def value_or(\n        self,\n        default_value: _NewValueType,\n    ) -> IO[Union[_ValueType, _NewValueType]]:\n        \"\"\"\n        Get value from successful container or default value from failed one.\n\n        .. code:: python\n\n          >>> from returns.io import IO, IOFailure, IOSuccess\n          >>> assert IOSuccess(1).value_or(None) == IO(1)\n          >>> assert IOFailure(1).value_or(None) == IO(None)\n\n        \"\"\"\n        return IO(self._inner_value.value_or(default_value))\n\n    def unwrap(self) -> IO[_ValueType]:\n        \"\"\"\n        Get value from successful container or raise exception for failed one.\n\n        .. code:: pycon\n          :force:\n\n          >>> from returns.io import IO, IOFailure, IOSuccess\n          >>> assert IOSuccess(1).unwrap() == IO(1)\n\n          >>> IOFailure(1).unwrap()\n          Traceback (most recent call last):\n            ...\n          returns.primitives.exceptions.UnwrapFailedError\n\n        \"\"\"  # noqa: RST307\n        return IO(self._inner_value.unwrap())\n\n    def failure(self) -> IO[_ErrorType]:\n        \"\"\"\n        Get failed value from failed container or raise exception from success.\n\n        .. code:: pycon\n          :force:\n\n          >>> from returns.io import IO, IOFailure, IOSuccess\n          >>> assert IOFailure(1).failure() == IO(1)\n\n          >>> IOSuccess(1).failure()\n          Traceback (most recent call last):\n            ...\n          returns.primitives.exceptions.UnwrapFailedError\n\n        \"\"\"  # noqa: RST307\n        return IO(self._inner_value.failure())\n\n    def compose_result(\n        self,\n        function: Callable[\n            [Result[_ValueType, _ErrorType]],\n            Kind2['IOResult', _NewValueType, _ErrorType],\n        ],\n    ) -> 'IOResult[_NewValueType, _ErrorType]':\n        \"\"\"\n        Composes inner ``Result`` with ``IOResult`` returning function.\n\n        Can be useful when you need an access to both states of the result.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOSuccess, IOFailure\n          >>> from returns.result import Result\n\n          >>> def count(container: Result[int, int]) -> IOResult[int, int]:\n          ...     return IOResult.from_result(\n          ...         container.map(lambda x: x + 1).alt(abs),\n          ...     )\n\n          >>> assert IOSuccess(1).compose_result(count) == IOSuccess(2)\n          >>> assert IOFailure(-1).compose_result(count) == IOFailure(1)\n\n        \"\"\"\n        return dekind(function(self._inner_value))\n\n    @classmethod\n    def from_typecast(\n        cls, inner_value: IO[Result[_NewValueType, _NewErrorType]],\n    ) -> 'IOResult[_NewValueType, _NewErrorType]':\n        \"\"\"\n        Converts ``IO[Result[_ValueType, _ErrorType]]`` to ``IOResult``.\n\n        Also prevails the type of ``Result`` to ``IOResult``, so:\n        ``IO[Result[_ValueType, _ErrorType]]`` would become\n        ``IOResult[_ValueType, _ErrorType]``.\n\n        .. code:: python\n\n          >>> from returns.result import Success\n          >>> from returns.io import IO, IOResult, IOSuccess\n          >>> container = IO(Success(1))\n          >>> assert IOResult.from_typecast(container) == IOSuccess(1)\n\n        Can be reverted via :meth:`returns.io.IO.from_ioresult` method.\n        \"\"\"\n        return cls.from_result(inner_value._inner_value)  # noqa: WPS437\n\n    @classmethod\n    def from_failed_io(\n        cls, inner_value: IO[_NewErrorType],\n    ) -> 'IOResult[Any, _NewErrorType]':\n        \"\"\"\n        Creates new ``IOResult`` from \"failed\" ``IO`` container.\n\n        .. code:: python\n\n          >>> from returns.io import IO, IOResult, IOFailure\n          >>> container = IO(1)\n          >>> assert IOResult.from_failed_io(container) == IOFailure(1)\n\n        \"\"\"\n        return IOFailure(inner_value._inner_value)  # noqa: WPS437\n\n    @classmethod\n    def from_io(\n        cls, inner_value: IO[_NewValueType],\n    ) -> 'IOResult[_NewValueType, Any]':\n        \"\"\"\n        Creates new ``IOResult`` from \"successful\" ``IO`` container.\n\n        .. code:: python\n\n          >>> from returns.io import IO, IOResult, IOSuccess\n          >>> container = IO(1)\n          >>> assert IOResult.from_io(container) == IOSuccess(1)\n\n        \"\"\"\n        return IOSuccess(inner_value._inner_value)  # noqa: WPS437\n\n    @classmethod\n    def from_result(\n        cls, inner_value: Result[_NewValueType, _NewErrorType],\n    ) -> 'IOResult[_NewValueType, _NewErrorType]':\n        \"\"\"\n        Creates ``IOResult`` from ``Result`` value.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOSuccess, IOFailure\n          >>> from returns.result import Success, Failure\n\n          >>> assert IOResult.from_result(Success(1)) == IOSuccess(1)\n          >>> assert IOResult.from_result(Failure(2)) == IOFailure(2)\n\n        \"\"\"\n        if isinstance(inner_value, inner_value.success_type):\n            return IOSuccess(inner_value._inner_value)  # noqa: WPS437\n        return IOFailure(inner_value._inner_value)  # type: ignore[arg-type]  # noqa: WPS437, E501\n\n    @classmethod\n    def from_ioresult(\n        cls, inner_value: 'IOResult[_NewValueType, _NewErrorType]',\n    ) -> 'IOResult[_NewValueType, _NewErrorType]':\n        \"\"\"\n        Creates ``IOResult`` from existing ``IOResult`` value.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOSuccess, IOFailure\n\n          >>> assert IOResult.from_ioresult(IOSuccess(1)) == IOSuccess(1)\n          >>> assert IOResult.from_ioresult(IOFailure(2)) == IOFailure(2)\n\n        \"\"\"\n        return inner_value\n\n    @classmethod\n    def from_value(\n        cls, inner_value: _NewValueType,\n    ) -> 'IOResult[_NewValueType, Any]':\n        \"\"\"\n        One more value to create success unit values.\n\n        It is useful as a united way to create a new value from any container.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOSuccess\n          >>> assert IOResult.from_value(1) == IOSuccess(1)\n\n        You can use this method or :func:`~IOSuccess`,\n        choose the most convenient for you.\n\n        \"\"\"\n        return IOSuccess(inner_value)\n\n    @classmethod\n    def from_failure(\n        cls, inner_value: _NewErrorType,\n    ) -> 'IOResult[Any, _NewErrorType]':\n        \"\"\"\n        One more value to create failure unit values.\n\n        It is useful as a united way to create a new value from any container.\n\n        .. code:: python\n\n          >>> from returns.io import IOResult, IOFailure\n          >>> assert IOResult.from_failure(1) == IOFailure(1)\n\n        You can use this method or :func:`~IOFailure`,\n        choose the most convenient for you.\n\n        \"\"\"\n        return IOFailure(inner_value)\n\n\n@final\nclass IOFailure(IOResult[Any, _ErrorType]):\n    \"\"\"``IOFailure`` representation.\"\"\"\n\n    _inner_value: Result[Any, _ErrorType]\n\n    def __init__(self, inner_value: _ErrorType) -> None:\n        \"\"\"IOFailure constructor.\"\"\"  # noqa: D403\n        super().__init__(Failure(inner_value))\n\n    if not TYPE_CHECKING:  # noqa: WPS604  # pragma: no branch\n        def bind(self, function):\n            \"\"\"Does nothing for ``IOFailure``.\"\"\"\n            return self\n\n        #: Alias for `bind_ioresult` method. Part of the `IOResultBasedN` interface.  # noqa: E501\n        bind_ioresult = bind\n\n        def bind_result(self, function):\n            \"\"\"Does nothing for ``IOFailure``.\"\"\"\n            return self\n\n        def bind_io(self, function):\n            \"\"\"Does nothing for ``IOFailure``.\"\"\"\n            return self\n\n        def lash(self, function):\n            \"\"\"Composes this container with a function returning ``IOResult``.\"\"\"  # noqa: E501\n            return function(self._inner_value.failure())\n\n\n@final\nclass IOSuccess(IOResult[_ValueType, Any]):\n    \"\"\"``IOSuccess`` representation.\"\"\"\n\n    _inner_value: Result[_ValueType, Any]\n\n    def __init__(self, inner_value: _ValueType) -> None:\n        \"\"\"IOSuccess constructor.\"\"\"  # noqa: D403\n        super().__init__(Success(inner_value))\n\n    if not TYPE_CHECKING:  # noqa: WPS604  # pragma: no branch\n        def bind(self, function):\n            \"\"\"Composes this container with a function returning ``IOResult``.\"\"\"  # noqa: E501\n            return function(self._inner_value.unwrap())\n\n        #: Alias for `bind_ioresult` method. Part of the `IOResultBasedN` interface.  # noqa: E501\n        bind_ioresult = bind\n\n        def bind_result(self, function):\n            \"\"\"Binds ``Result`` returning function to current container.\"\"\"\n            return self.from_result(function(self._inner_value.unwrap()))\n\n        def bind_io(self, function):\n            \"\"\"Binds ``IO`` returning function to current container.\"\"\"\n            return self.from_io(function(self._inner_value.unwrap()))\n\n        def lash(self, function):\n            \"\"\"Does nothing for ``IOSuccess``.\"\"\"\n            return self\n\n\nIOResult.success_type = IOSuccess\nIOResult.failure_type = IOFailure\n\n\n# Aliases:\n\n#: Alias for a popular case when ``IOResult`` has ``Exception`` as error type.\nIOResultE = IOResult[_ValueType, Exception]\n\n\n# impure_safe decorator:\n\ndef impure_safe(\n    function: Callable[..., _NewValueType],\n) -> Callable[..., IOResultE[_NewValueType]]:\n    \"\"\"\n    Decorator to mark function that it returns :class:`~IOResult` container.\n\n    Should be used with care, since it only catches ``Exception`` subclasses.\n    It does not catch ``BaseException`` subclasses.\n\n    If you need to mark ``async`` function as impure,\n    use :func:`returns.future.future_safe` instead.\n    This decorator only works with sync functions. Example:\n\n    .. code:: python\n\n      >>> from returns.io import IOSuccess, impure_safe\n\n      >>> @impure_safe\n      ... def function(arg: int) -> float:\n      ...     return 1 / arg\n      ...\n\n      >>> assert function(1) == IOSuccess(1.0)\n      >>> assert function(0).failure()\n\n    Similar to :func:`returns.future.future_safe`\n    and :func:`returns.result.safe` decorators.\n\n    Requires our :ref:`mypy plugin <mypy-plugins>`.\n    \"\"\"\n    @wraps(function)\n    def decorator(*args, **kwargs):\n        try:\n            return IOSuccess(function(*args, **kwargs))\n        except Exception as exc:\n            return IOFailure(exc)\n    return decorator\n\n\n### returns/pipeline.py ###\n\nfrom typing import ClassVar\n\nfrom returns._internal.pipeline.flow import flow as flow\nfrom returns._internal.pipeline.managed import managed as managed\nfrom returns._internal.pipeline.pipe import pipe as pipe\nfrom returns.interfaces.unwrappable import Unwrappable\nfrom returns.primitives.exceptions import UnwrapFailedError\n\n\ndef is_successful(container: Unwrappable) -> bool:\n    \"\"\"\n    Determines if a container was successful or not.\n\n    .. code:: python\n\n      >>> from returns.maybe import Some, Nothing\n      >>> from returns.result import Failure, Success\n      >>> from returns.io import IOSuccess, IOFailure\n\n      >>> assert is_successful(Some(1))\n      >>> assert not is_successful(Nothing)\n\n      >>> assert is_successful(Success(1))\n      >>> assert not is_successful(Failure(1))\n\n      >>> assert is_successful(IOSuccess(1))\n      >>> assert not is_successful(IOFailure(1))\n\n    This function can work with containers\n    that are instance of :class:`returns.interfaces.unwrappable.Unwrappable`.\n\n    \"\"\"\n    try:\n        container.unwrap()\n    except UnwrapFailedError:\n        return False\n    return True\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "from typing import List, Tuple\n\nimport pytest\n\nfrom returns.io import IOFailure, IOResult, IOSuccess\nfrom returns.pipeline import managed\nfrom returns.result import Failure, Result, Success\n\n_acquire_success = IOSuccess('acquire success')\n_acquire_failure = IOFailure('acquire failure')\n\n\ndef _use_success(inner_value: str) -> IOResult[str, str]:\n    return IOSuccess('use success')\n\n\ndef _use_failure(inner_value: str) -> IOResult[str, str]:\n    return IOFailure('use failure')\n\n\nclass _ReleaseSuccess(object):\n    def __init__(self, logs: List[Tuple[str, Result[str, str]]]) -> None:\n        self._logs = logs\n\n    def __call__(\n        self,\n        inner_value: str,\n        use_result: Result[str, str],\n    ) -> IOResult[None, str]:\n        self._logs.append((inner_value, use_result))\n        return IOSuccess(None)\n\n\nclass _ReleaseFailure(object):\n    def __init__(self, logs: List[Tuple[str, Result[str, str]]]) -> None:\n        self._logs = logs\n\n    def __call__(\n        self,\n        inner_value: str,\n        use_result: Result[str, str],\n    ) -> IOResult[None, str]:\n        return IOFailure('release failure')\n\n\n@pytest.mark.parametrize(('acquire', 'use', 'release', 'final_result', 'log'), [\n    # Acquire success:\n    (\n        _acquire_success,\n        _use_success,\n        _ReleaseSuccess,\n        IOSuccess('use success'),\n        [('acquire success', Success('use success'))],\n    ),\n    (\n        _acquire_success,\n        _use_success,\n        _ReleaseFailure,\n        IOFailure('release failure'),\n        [],\n    ),\n    (\n        _acquire_success,\n        _use_failure,\n        _ReleaseSuccess,\n        IOFailure('use failure'),\n        [('acquire success', Failure('use failure'))],\n    ),\n    (\n        _acquire_success,\n        _use_failure,\n        _ReleaseFailure,\n        IOFailure('release failure'),\n        [],\n    ),\n\n    # Acquire failure:\n    (\n        _acquire_failure,\n        _use_success,\n        _ReleaseSuccess,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_failure,\n        _ReleaseSuccess,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_success,\n        _ReleaseFailure,\n        IOFailure('acquire failure'),\n        [],\n    ),\n    (\n        _acquire_failure,\n        _use_failure,\n        _ReleaseFailure,\n        IOFailure('acquire failure'),\n        [],\n    ),\n])\ndef test_all_success(acquire, use, release, final_result, log):\n    \"\"\"Ensures that managed works as intended.\"\"\"\n    pipeline_logs: List[Tuple[str, Result[str, str]]] = []\n    pipeline_result = managed(\n        use,\n        release(pipeline_logs),\n    )(acquire)\n\n    assert pipeline_result == final_result\n    assert pipeline_logs == log\n\n\ndef test_full_typing():\n    \"\"\"This test is here to be a case for typing.\"\"\"\n    logs: List[Tuple[str, Result[str, str]]] = []\n    pipeline_result = managed(\n        _use_success,\n        _ReleaseSuccess(logs),\n    )(_acquire_success)\n\n    assert pipeline_result == IOSuccess('use success')\n    assert logs == [('acquire success', Success('use success'))]\n"
  },
  {
    "prompt": "\n\n### postgres/tests/common.py ###\n\n# (C) Datadog, Inc. 2010-present\n# All rights reserved\n# Licensed under Simplified BSD License (see LICENSE)\nimport os\nfrom sys import maxsize\n\nimport pytest\n\nfrom datadog_checks.dev import get_docker_hostname\n\nHOST = get_docker_hostname()\nPORT = '5432'\nUSER = 'datadog'\nPASSWORD = 'datadog'\nDB_NAME = 'datadog_test'\nPOSTGRES_VERSION = os.environ.get('POSTGRES_VERSION', None)\nPOSTGRES_IMAGE = \"alpine\"\n\nUSING_LATEST = False\n\nif POSTGRES_VERSION is not None:\n    USING_LATEST = POSTGRES_VERSION.endswith('latest')\n    POSTGRES_IMAGE = POSTGRES_VERSION + \"-alpine\"\n\nif USING_LATEST is True:\n    POSTGRES_VERSION = str(maxsize)\n    POSTGRES_IMAGE = \"alpine\"\n\nSCHEMA_NAME = 'schemaname'\n\nCOMMON_METRICS = [\n    'postgresql.before_xid_wraparound',\n    'postgresql.commits',\n    'postgresql.rollbacks',\n    'postgresql.disk_read',\n    'postgresql.buffer_hit',\n    'postgresql.rows_returned',\n    'postgresql.rows_fetched',\n    'postgresql.rows_inserted',\n    'postgresql.rows_updated',\n    'postgresql.rows_deleted',\n    'postgresql.database_size',\n    'postgresql.deadlocks',\n    'postgresql.temp_bytes',\n    'postgresql.temp_files',\n]\n\nDBM_MIGRATED_METRICS = [\n    'postgresql.connections',\n]\n\nCOMMON_BGW_METRICS = [\n    'postgresql.bgwriter.checkpoints_timed',\n    'postgresql.bgwriter.checkpoints_requested',\n    'postgresql.bgwriter.buffers_checkpoint',\n    'postgresql.bgwriter.buffers_clean',\n    'postgresql.bgwriter.maxwritten_clean',\n    'postgresql.bgwriter.buffers_backend',\n    'postgresql.bgwriter.buffers_alloc',\n    'postgresql.bgwriter.buffers_backend_fsync',\n    'postgresql.bgwriter.write_time',\n    'postgresql.bgwriter.sync_time',\n]\n\nCOMMON_BGW_METRICS_PG_ABOVE_94 = ['postgresql.archiver.archived_count', 'postgresql.archiver.failed_count']\n\nrequires_static_version = pytest.mark.skipif(USING_LATEST, reason='Version `latest` is ever-changing, skipping')\n\n\ndef check_common_metrics(aggregator, expected_tags, count=1):\n    for name in COMMON_METRICS:\n        aggregator.assert_metric(name, count=count, tags=expected_tags)\n\n\ndef check_bgw_metrics(aggregator, expected_tags):\n    for name in COMMON_BGW_METRICS:\n        aggregator.assert_metric(name, count=1, tags=expected_tags)\n\n    if float(POSTGRES_VERSION) >= 9.4:\n        for name in COMMON_BGW_METRICS_PG_ABOVE_94:\n            aggregator.assert_metric(name, count=1, tags=expected_tags)\n\n\n### Unit tests for the above files using pytest. Make sure they are concise and complete. ###\n\n",
    "completion": "# (C) Datadog, Inc. 2021-present\n# All rights reserved\n# Licensed under Simplified BSD License (see LICENSE)\nimport pytest\n\nfrom datadog_checks.postgres.relationsmanager import ALL_SCHEMAS, IDX_METRICS, LOCK_METRICS, RelationsManager\n\nfrom .common import SCHEMA_NAME\n\npytestmark = pytest.mark.unit\n\n\n@pytest.mark.parametrize(\n    'relations_config,expected_filter',\n    [\n        (\n            [\n                {'relation_regex': 'ix.*', 'schemas': ['public', 's1', 's2']},\n                {'relation_regex': 'ibx.*', 'schemas': ['public']},\n                {'relation_regex': 'icx.*', 'schemas': ['public']},\n            ],\n            \"( relname ~ 'ix.*' AND schemaname = ANY(array['public','s1','s2']::text[]) ) \"\n            \"OR ( relname ~ 'ibx.*' AND schemaname = ANY(array['public']::text[]) ) \"\n            \"OR ( relname ~ 'icx.*' AND schemaname = ANY(array['public']::text[]) )\",\n        ),\n        (\n            [\n                {'relation_regex': '.+_archive'},\n            ],\n            \"( relname ~ '.+_archive' )\",\n        ),\n        (\n            [\n                {'relation_name': 'my_table', 'schemas': ['public', 'app'], 'relkind': ['r']},  # relkind ignored\n                {'relation_name': 'my_table2', 'relkind': ['p', 'r']},  # relkind ignored\n                {'relation_regex': 'table.*'},\n            ],\n            \"( relname = 'my_table' AND schemaname = ANY(array['public','app']::text[]) ) \"\n            \"OR ( relname = 'my_table2' ) \"\n            \"OR ( relname ~ 'table.*' )\",\n        ),\n        (\n            ['table1', 'table2'],\n            \"( relname = 'table1' ) OR ( relname = 'table2' )\",\n        ),\n    ],\n)\ndef test_relations_cases(relations_config, expected_filter):\n    query = '{relations}'\n    relations = RelationsManager(relations_config)\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == expected_filter\n\n\ndef test_relation_filter():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'breed', 'schemas': ['public']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert (\n        query_filter == \"Select foo from bar where ( relname = 'breed' AND schemaname = ANY(array['public']::text[]) )\"\n    )\n\n\ndef test_relation_filter_no_schemas():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_name': 'persons', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname = 'persons' )\"\n\n\ndef test_relation_filter_regex():\n    query = \"Select foo from bar where {relations}\"\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS]}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert query_filter == \"Select foo from bar where ( relname ~ 'b.*' )\"\n\n\ndef test_relation_filter_relkind():\n    query = LOCK_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r', 't']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert \"AND relkind = ANY(array['r','t'])\" in query_filter\n\n\ndef test_relkind_does_not_apply_to_index_metrics():\n    query = IDX_METRICS['query'].replace('{metrics_columns}', 'foo')\n    relations_config = [{'relation_regex': 'b.*', 'schemas': [ALL_SCHEMAS], 'relkind': ['r']}]\n    relations = RelationsManager(relations_config)\n\n    query_filter = relations.filter_relation_query(query, SCHEMA_NAME)\n    assert 'relkind' not in query_filter\n"
  }
]
